"""
LambdaÂ³ GPUç‰ˆä½ç›¸ç©ºé–“è§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆçˆ†é€Ÿã‚«ãƒ¼ãƒãƒ«ç‰ˆï¼‰
é«˜æ¬¡å…ƒä½ç›¸ç©ºé–“ã§ã®ç•°å¸¸æ¤œå‡ºã¨ã‚¢ãƒˆãƒ©ã‚¯ã‚¿è§£æ
CUDAã‚«ãƒ¼ãƒãƒ«ã«ã‚ˆã‚‹è¶…é«˜é€ŸåŒ–å®Ÿè£…
"""

import numpy as np
import cupy as cp
from typing import Dict, List, Tuple, Optional, Any
from numba import cuda
import math

from ..types import ArrayType, NDArray
from ..core.gpu_utils import GPUBackend

class PhaseSpaceAnalyzerGPU(GPUBackend):
    """ä½ç›¸ç©ºé–“è§£æã®GPUå®Ÿè£…ï¼ˆçˆ†é€Ÿç‰ˆï¼‰"""
    
    def __init__(self, force_cpu=False):
        super().__init__(force_cpu)
        self.embedding_cache = {}
        self._init_kernels()
        
    def _init_kernels(self):
        """CUDAã‚«ãƒ¼ãƒãƒ«ã®åˆæœŸåŒ–"""
        # RQAç‰¹å¾´é‡è¨ˆç®—ã‚«ãƒ¼ãƒãƒ«
        self._rqa_features_kernel = cuda.jit(self._compute_rqa_features_kernel_impl)
        # ã‚¢ãƒˆãƒ©ã‚¯ã‚¿ä½“ç©è¨ˆç®—ã‚«ãƒ¼ãƒãƒ«
        self._attractor_volume_kernel = cuda.jit(self._compute_attractor_volume_kernel_impl)
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¨ˆç®—ã‚«ãƒ¼ãƒãƒ«
        self._fractal_kernel = cuda.jit(self._compute_fractal_dimension_kernel_impl)
        # è¤‡é›‘æ€§æŒ‡æ¨™ã‚«ãƒ¼ãƒãƒ«
        self._complexity_kernel = cuda.jit(self._compute_complexity_measures_kernel_impl)
        # k-NNç•°å¸¸æ¤œå‡ºã‚«ãƒ¼ãƒãƒ«
        self._knn_anomaly_kernel = cuda.jit(self._knn_trajectory_anomaly_kernel_impl)
        # å¯¾è§’ç·šé•·åˆ†å¸ƒã‚«ãƒ¼ãƒãƒ«
        self._diagonal_dist_kernel = cuda.jit(self._compute_diagonal_distribution_kernel_impl)
        
    def analyze_phase_space(self,
                          structures: Dict[str, np.ndarray],
                          embedding_params: Optional[Dict] = None) -> Dict[str, Any]:
        """
        åŒ…æ‹¬çš„ãªä½ç›¸ç©ºé–“è§£æï¼ˆçˆ†é€Ÿç‰ˆï¼‰
        
        Parameters
        ----------
        structures : Dict[str, np.ndarray]
            Lambdaæ§‹é€ ä½“
        embedding_params : Dict, optional
            åŸ‹ã‚è¾¼ã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            
        Returns
        -------
        Dict[str, Any]
            ä½ç›¸ç©ºé–“è§£æçµæœ
        """
        print("\nğŸš€ Ultra-Fast Phase Space Analysis on GPU...")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        if embedding_params is None:
            embedding_params = {
                'embedding_dim': 3,
                'delay': 50,
                'n_neighbors': 20,
                'recurrence_threshold': 0.1,
                'min_diagonal_length': 2,
                'voxel_grid_size': 128
            }
        
        # ä¸»è¦ãªæ™‚ç³»åˆ—ã‚’å–å¾—
        primary_series = self._get_primary_series(structures)
        
        results = {}
        
        with self.memory_manager.batch_context(len(primary_series) * 10):
            # 1. æœ€é©åŸ‹ã‚è¾¼ã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¨å®šï¼ˆGPUä¸¦åˆ—åŒ–ï¼‰
            optimal_params = self._estimate_embedding_parameters_gpu(
                primary_series, embedding_params
            )
            results['optimal_parameters'] = optimal_params
            
            # 2. ä½ç›¸ç©ºé–“å†æ§‹æˆ
            phase_space = self._reconstruct_phase_space_gpu(
                primary_series,
                optimal_params['embedding_dim'],
                optimal_params['delay']
            )
            results['phase_space'] = self.to_cpu(phase_space)
            
            # 3. ã‚¢ãƒˆãƒ©ã‚¯ã‚¿è§£æï¼ˆçˆ†é€Ÿã‚«ãƒ¼ãƒãƒ«ç‰ˆï¼‰
            attractor_features = self._analyze_attractor_gpu_fast(
                phase_space, embedding_params['voxel_grid_size']
            )
            results['attractor_features'] = attractor_features
            
            # 4. ãƒªã‚«ãƒ¬ãƒ³ã‚¹ãƒ—ãƒ­ãƒƒãƒˆè§£æï¼ˆä¸¦åˆ—RQAï¼‰
            recurrence_features = self._recurrence_analysis_gpu_fast(
                phase_space, 
                embedding_params['recurrence_threshold'],
                embedding_params['min_diagonal_length']
            )
            results['recurrence_features'] = recurrence_features
            
            # 5. ç•°å¸¸è»Œé“æ¤œå‡ºï¼ˆä¸¦åˆ—k-NNï¼‰
            anomaly_scores = self._detect_anomalous_trajectories_gpu_fast(
                phase_space, embedding_params['n_neighbors']
            )
            results['anomaly_scores'] = self.to_cpu(anomaly_scores)
            
            # 6. ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ç‰¹æ€§ï¼ˆä¸¦åˆ—è§£æï¼‰
            dynamics_features = self._analyze_dynamics_gpu_fast(phase_space)
            results['dynamics_features'] = dynamics_features
            
            # 7. çµ±åˆã‚¹ã‚³ã‚¢
            integrated_score = self._compute_integrated_score_gpu(
                anomaly_scores, attractor_features, recurrence_features
            )
            results['integrated_anomaly_score'] = self.to_cpu(integrated_score)
        
        self._print_summary(results)
        
        return results
    
    def detect_phase_transitions(self,
                               structures: Dict[str, np.ndarray],
                               window_size: int = 1000,
                               stride: int = 100) -> Dict[str, cp.ndarray]:
        """
        ä½ç›¸ç©ºé–“ã§ã®é·ç§»æ¤œå‡ºï¼ˆä¸¦åˆ—ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼‰
        """
        print("\nâš¡ Detecting phase transitions with GPU acceleration...")
        
        primary_series = self._get_primary_series(structures)
        n_frames = len(primary_series)
        n_windows = (n_frames - window_size) // stride + 1
        
        transition_scores = cp.zeros(n_frames)
        phase_distances = []
        
        # ä¸¦åˆ—ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å‡¦ç†ã®æº–å‚™
        all_features = []
        
        for i in range(n_windows):
            start = i * stride
            end = start + window_size
            
            if end > n_frames:
                break
            
            # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å†…ã®ä½ç›¸ç©ºé–“
            window_series = primary_series[start:end]
            phase_space = self._reconstruct_phase_space_gpu(
                window_series, embedding_dim=3, delay=20
            )
            
            # ä½ç›¸ç©ºé–“ã®ç‰¹å¾´æŠ½å‡ºï¼ˆä¸¦åˆ—åŒ–ï¼‰
            features = self._extract_phase_features_gpu_fast(phase_space)
            all_features.append(features)
        
        # ä¸¦åˆ—ã§è·é›¢è¨ˆç®—
        if len(all_features) > 1:
            distances = self._compute_phase_distances_parallel(all_features)
            phase_distances = self.to_cpu(distances).tolist()
            
            # ã‚¹ã‚³ã‚¢ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆä¸¦åˆ—åŒ–ï¼‰
            self._map_transition_scores_kernel(transition_scores, distances, window_size, stride)
        
        # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã¨æ­£è¦åŒ–
        transition_scores = self._smooth_and_normalize_gpu(transition_scores)
        
        return {
            'transition_scores': transition_scores,
            'phase_distances': phase_distances,
            'window_size': window_size,
            'stride': stride
        }
    
    # === çˆ†é€Ÿå®Ÿè£…ãƒ¡ã‚½ãƒƒãƒ‰ ===
    
    def _analyze_attractor_gpu_fast(self, 
                                   phase_space: cp.ndarray,
                                   voxel_grid_size: int) -> Dict:
        """ã‚¢ãƒˆãƒ©ã‚¯ã‚¿ç‰¹æ€§ã®é«˜é€Ÿè§£æ"""
        features = {}
        n_points = len(phase_space)
        dim = phase_space.shape[1]
        
        # 1. ç›¸é–¢æ¬¡å…ƒï¼ˆä¸¦åˆ—è¨ˆç®—ï¼‰
        features['correlation_dimension'] = float(
            self._correlation_dimension_gpu_fast(phase_space)
        )
        
        # 2. LyapunovæŒ‡æ•°ï¼ˆä¸¦åˆ—è¿‘å‚æ¢ç´¢ï¼‰
        features['lyapunov_exponent'] = float(
            self._estimate_lyapunov_gpu_fast(phase_space)
        )
        
        # 3. ã‚¢ãƒˆãƒ©ã‚¯ã‚¿ä½“ç©ï¼ˆãƒœã‚¯ã‚»ãƒ«åŒ–ï¼‰
        voxel_grid = cp.zeros(voxel_grid_size**3, dtype=cp.int32)
        blocks, threads = self._optimize_kernel_launch(n_points)
        
        # ä½ç›¸ç©ºé–“ã®ç¯„å›²ã‚’è¨ˆç®—
        phase_min = cp.min(phase_space, axis=0)
        phase_max = cp.max(phase_space, axis=0)
        phase_range = phase_max - phase_min + 1e-10
        
        self._attractor_volume_kernel[blocks, threads](
            phase_space, voxel_grid, phase_min, phase_range,
            n_points, dim, voxel_grid_size
        )
        
        occupied_voxels = cp.sum(voxel_grid > 0)
        total_voxels = voxel_grid_size**3
        features['attractor_volume'] = float(occupied_voxels / total_voxels)
        
        # 4. ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¸¬åº¦ï¼ˆä¸¦åˆ—ç›¸é–¢ç©åˆ†ï¼‰
        features['fractal_measure'] = float(
            self._compute_fractal_measure_gpu_fast(phase_space)
        )
        
        # 5. æƒ…å ±æ¬¡å…ƒ
        features['information_dimension'] = float(
            self._compute_information_dimension_gpu(phase_space)
        )
        
        return features
    
    def _recurrence_analysis_gpu_fast(self,
                                     phase_space: cp.ndarray,
                                     threshold: float,
                                     min_line_length: int) -> Dict:
        """é«˜é€Ÿãƒªã‚«ãƒ¬ãƒ³ã‚¹å®šé‡åŒ–è§£æ"""
        n = len(phase_space)
        
        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®ãŸã‚ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        max_size = 5000
        if n > max_size:
            indices = cp.random.choice(n, max_size, replace=False)
            phase_space_sample = phase_space[indices]
            n = max_size
        else:
            phase_space_sample = phase_space
        
        # ãƒªã‚«ãƒ¬ãƒ³ã‚¹è¡Œåˆ—ï¼ˆä¸¦åˆ—è·é›¢è¨ˆç®—ï¼‰
        rec_matrix = self._compute_recurrence_matrix_gpu_fast(
            phase_space_sample, threshold
        )
        
        # RQAç‰¹å¾´é‡ã‚’ä¸¦åˆ—è¨ˆç®—
        features_array = cp.zeros(10, dtype=cp.float32)
        blocks, threads = self._optimize_kernel_launch(n)
        
        self._rqa_features_kernel[blocks, threads](
            rec_matrix, features_array, n, min_line_length
        )
        
        # å¯¾è§’ç·šé•·åˆ†å¸ƒã®è§£æ
        diag_dist = cp.zeros(n//2, dtype=cp.int32)
        self._diagonal_dist_kernel[blocks, threads](
            rec_matrix, diag_dist, n
        )
        
        # çµ±è¨ˆé‡ã‚’è¨ˆç®—
        total_points = n * n
        rec_points = cp.sum(rec_matrix)
        
        features = {
            'recurrence_rate': float(rec_points / total_points),
            'determinism': float(features_array[0] / (rec_points + 1e-10)),
            'laminarity': float(features_array[1] / (rec_points + 1e-10)),
            'diagonal_lines': int(features_array[3]),
            'vertical_lines': int(features_array[4]),
            'entropy': float(self._compute_entropy_from_distribution(diag_dist)),
            'trapping_time': float(features_array[2] / (features_array[4] + 1e-10)),
            'max_diagonal_length': int(cp.max(diag_dist))
        }
        
        return features
    
    def _detect_anomalous_trajectories_gpu_fast(self,
                                              phase_space: cp.ndarray,
                                              n_neighbors: int) -> cp.ndarray:
        """é«˜é€Ÿç•°å¸¸è»Œé“æ¤œå‡º"""
        n = len(phase_space)
        dim = phase_space.shape[1]
        
        # ç•°å¸¸ã‚¹ã‚³ã‚¢é…åˆ—
        anomaly_scores = cp.zeros(n, dtype=cp.float32)
        
        # k-NNç•°å¸¸æ¤œå‡ºï¼ˆä¸¦åˆ—åŒ–ï¼‰
        blocks, threads = self._optimize_kernel_launch(n)
        
        self._knn_anomaly_kernel[blocks, threads](
            phase_space, anomaly_scores, n_neighbors, n, dim
        )
        
        # æ›²ç‡ç•°å¸¸ï¼ˆä¸¦åˆ—è¨ˆç®—ï¼‰
        curvature_anomaly = cp.zeros(n, dtype=cp.float32)
        self._compute_curvature_anomaly_kernel[blocks, threads](
            phase_space, curvature_anomaly, n, dim
        )
        
        # é€Ÿåº¦ç•°å¸¸ï¼ˆä¸¦åˆ—è¨ˆç®—ï¼‰
        velocity_anomaly = cp.zeros(n, dtype=cp.float32)
        self._compute_velocity_anomaly_kernel[blocks, threads](
            phase_space, velocity_anomaly, n, dim
        )
        
        # åŠ é€Ÿåº¦ç•°å¸¸ã‚‚è¿½åŠ 
        acceleration_anomaly = cp.zeros(n, dtype=cp.float32)
        self._compute_acceleration_anomaly_kernel[blocks, threads](
            phase_space, acceleration_anomaly, n, dim
        )
        
        # é‡ã¿ä»˜ãçµ±åˆ
        anomaly_scores = (
            0.4 * anomaly_scores + 
            0.2 * curvature_anomaly + 
            0.2 * velocity_anomaly +
            0.2 * acceleration_anomaly
        )
        
        return anomaly_scores
    
    def _analyze_dynamics_gpu_fast(self, phase_space: cp.ndarray) -> Dict:
        """é«˜é€Ÿãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹è§£æ"""
        n = len(phase_space)
        dim = phase_space.shape[1]
        
        features = {}
        
        # è¤‡é›‘æ€§æŒ‡æ¨™ã‚’ä¸¦åˆ—è¨ˆç®—
        measures = cp.zeros(5, dtype=cp.float32)
        blocks, threads = self._optimize_kernel_launch(n)
        
        self._complexity_kernel[blocks, threads](
            phase_space, measures, n, dim
        )
        
        # 1. å‘¨æœŸæ€§ï¼ˆä¸¦åˆ—FFTï¼‰
        features['periodicity'] = float(
            self._detect_periodicity_gpu_fast(phase_space)
        )
        
        # 2. ã‚«ã‚ªã‚¹æ€§
        features['chaos_measure'] = float(measures[0] / n)
        
        # 3. äºˆæ¸¬å¯èƒ½æ€§
        features['predictability'] = float(1.0 / (1.0 + measures[1] / n))
        
        # 4. è¤‡é›‘æ€§
        features['complexity'] = float(measures[2] / n)
        
        # 5. ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ç‡
        features['entropy_rate'] = float(measures[3] / n)
        
        # 6. å®‰å®šæ€§
        features['stability'] = float(1.0 / (1.0 + measures[4] / n))
        
        return features
    
    # === CUDAã‚«ãƒ¼ãƒãƒ«å®Ÿè£… ===
    
    @staticmethod
    def _compute_rqa_features_kernel_impl(rec_matrix, features_out, n, min_line_length):
        """RQAç‰¹å¾´é‡è¨ˆç®—ã‚«ãƒ¼ãƒãƒ«å®Ÿè£…"""
        idx = cuda.grid(1)
        
        if idx < n:
            # å¯¾è§’ç·šæ§‹é€ ã®æ¤œå‡º
            for offset in range(1, n - idx):
                diag_len = 0
                i = idx
                j = offset
                
                while i < n and j < n:
                    if rec_matrix[i, j] > 0:
                        diag_len += 1
                    else:
                        if diag_len >= min_line_length:
                            cuda.atomic.add(features_out, 0, diag_len)  # determinism
                            cuda.atomic.add(features_out, 3, 1)  # diagonal count
                        diag_len = 0
                    i += 1
                    j += 1
            
            # å‚ç›´æ§‹é€ ã®æ¤œå‡º
            vert_len = 0
            for j in range(n):
                if rec_matrix[idx, j] > 0:
                    vert_len += 1
                else:
                    if vert_len >= min_line_length:
                        cuda.atomic.add(features_out, 1, vert_len)  # laminarity
                        cuda.atomic.add(features_out, 2, vert_len)  # trapping time
                        cuda.atomic.add(features_out, 4, 1)  # vertical count
                    vert_len = 0
    
    @staticmethod
    def _compute_attractor_volume_kernel_impl(phase_space, voxel_grid, phase_min, 
                                             phase_range, n_points, dim, grid_size):
        """ã‚¢ãƒˆãƒ©ã‚¯ã‚¿ä½“ç©è¨ˆç®—ã‚«ãƒ¼ãƒãƒ«å®Ÿè£…"""
        idx = cuda.grid(1)
        
        if idx < n_points:
            # 3æ¬¡å…ƒãƒœã‚¯ã‚»ãƒ«åº§æ¨™ã‚’è¨ˆç®—
            voxel_coords = cuda.local.array(3, dtype=cuda.int32)
            
            for d in range(min(3, dim)):
                # æ­£è¦åŒ–ã—ã¦ã‚°ãƒªãƒƒãƒ‰åº§æ¨™ã«å¤‰æ›
                normalized = (phase_space[idx, d] - phase_min[d]) / phase_range[d]
                grid_coord = int(normalized * (grid_size - 1))
                voxel_coords[d] = min(max(0, grid_coord), grid_size - 1)
            
            # 1æ¬¡å…ƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¤‰æ›
            voxel_idx = (voxel_coords[0] * grid_size * grid_size + 
                        voxel_coords[1] * grid_size + 
                        voxel_coords[2])
            
            # ãƒœã‚¯ã‚»ãƒ«ã‚’å æœ‰ã¨ã—ã¦ãƒãƒ¼ã‚¯
            voxel_grid[voxel_idx] = 1
    
    @staticmethod
    def _compute_fractal_dimension_kernel_impl(distances, correlation_integral, 
                                              radii, n_pairs, n_radii):
        """ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¨ˆç®—ã‚«ãƒ¼ãƒãƒ«å®Ÿè£…"""
        idx = cuda.grid(1)
        
        if idx < n_pairs:
            dist = distances[idx]
            
            # å„åŠå¾„ã§ã®ç›¸é–¢ç©åˆ†ã«å¯„ä¸
            for r_idx in range(n_radii):
                if dist < radii[r_idx]:
                    cuda.atomic.add(correlation_integral, r_idx, 1)
    
    @staticmethod
    def _compute_complexity_measures_kernel_impl(phase_space, measures_out, n, dim):
        """è¤‡é›‘æ€§æŒ‡æ¨™è¨ˆç®—ã‚«ãƒ¼ãƒãƒ«å®Ÿè£…"""
        idx = cuda.grid(1)
        
        if idx < n - 2:
            # å±€æ‰€çš„ãªã‚«ã‚ªã‚¹æ€§ï¼ˆè¿‘å‚ã®ç™ºæ•£ç‡ï¼‰
            local_divergence = 0.0
            for d in range(dim):
                diff1 = phase_space[idx + 1, d] - phase_space[idx, d]
                diff2 = phase_space[idx + 2, d] - phase_space[idx + 1, d]
                local_divergence += abs(diff2 - diff1)
            
            cuda.atomic.add(measures_out, 0, local_divergence)
            
            # äºˆæ¸¬èª¤å·®
            pred_error = 0.0
            for d in range(dim):
                # ç·šå½¢äºˆæ¸¬
                predicted = 2 * phase_space[idx + 1, d] - phase_space[idx, d]
                actual = phase_space[idx + 2, d]
                pred_error += (predicted - actual) ** 2
            
            cuda.atomic.add(measures_out, 1, math.sqrt(pred_error))
            
            # å±€æ‰€è¤‡é›‘æ€§ï¼ˆè¿‘å‚ã®åˆ†æ•£ï¼‰
            if idx > 0:
                local_var = 0.0
                for d in range(dim):
                    mean = (phase_space[idx - 1, d] + phase_space[idx, d] + 
                           phase_space[idx + 1, d]) / 3.0
                    local_var += ((phase_space[idx, d] - mean) ** 2)
                
                cuda.atomic.add(measures_out, 2, math.sqrt(local_var))
            
            # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼å¯„ä¸
            for d in range(dim):
                delta = abs(phase_space[idx + 1, d] - phase_space[idx, d])
                if delta > 1e-10:
                    cuda.atomic.add(measures_out, 3, -delta * math.log(delta))
            
            # å®‰å®šæ€§ï¼ˆè»Œé“ã®å±€æ‰€çš„ãªåæŸæ€§ï¼‰
            if idx < n - 3:
                stability = 0.0
                for d in range(dim):
                    second_diff = (phase_space[idx + 2, d] - 
                                 2 * phase_space[idx + 1, d] + 
                                 phase_space[idx, d])
                    stability += abs(second_diff)
                
                cuda.atomic.add(measures_out, 4, stability)
    
    @staticmethod
    def _knn_trajectory_anomaly_kernel_impl(phase_space, anomaly_scores, k, n, dim):
        """k-NNç•°å¸¸æ¤œå‡ºã‚«ãƒ¼ãƒãƒ«å®Ÿè£…"""
        idx = cuda.grid(1)
        
        if idx < n:
            # å…±æœ‰ãƒ¡ãƒ¢ãƒªã§é«˜é€ŸåŒ–
            distances = cuda.local.array(256, dtype=cuda.float32)
            
            # ãƒãƒƒãƒå‡¦ç†ã§è·é›¢è¨ˆç®—
            batch_size = min(256, n)
            for batch_start in range(0, n, batch_size):
                batch_end = min(batch_start + batch_size, n)
                
                for j in range(batch_start, batch_end):
                    if j != idx:
                        dist_sq = 0.0
                        for d in range(dim):
                            diff = phase_space[j, d] - phase_space[idx, d]
                            dist_sq += diff * diff
                        distances[j - batch_start] = math.sqrt(dist_sq)
                    else:
                        distances[j - batch_start] = 1e10
            
            # kè¿‘å‚ã‚’åŠ¹ç‡çš„ã«æ¢ç´¢ï¼ˆéƒ¨åˆ†ã‚½ãƒ¼ãƒˆï¼‰
            knn_sum = 0.0
            for kth in range(k):
                min_dist = 1e10
                min_idx = 0
                
                for j in range(min(batch_size, n)):
                    if distances[j] < min_dist:
                        min_dist = distances[j]
                        min_idx = j
                
                knn_sum += min_dist
                distances[min_idx] = 1e10
            
            anomaly_scores[idx] = knn_sum / k
    
    @staticmethod
    def _compute_diagonal_distribution_kernel_impl(rec_matrix, diag_dist, n):
        """å¯¾è§’ç·šé•·åˆ†å¸ƒè¨ˆç®—ã‚«ãƒ¼ãƒãƒ«å®Ÿè£…"""
        idx = cuda.grid(1)
        
        if idx < n:
            # å„å¯¾è§’ç·šã‚’ä¸¦åˆ—å‡¦ç†
            max_diag_len = 0
            
            for start_j in range(n):
                i, j = idx, start_j
                current_len = 0
                
                while i < n and j < n:
                    if rec_matrix[i, j] > 0:
                        current_len += 1
                        max_diag_len = max(max_diag_len, current_len)
                    else:
                        if current_len > 0:
                            cuda.atomic.add(diag_dist, min(current_len, n//2 - 1), 1)
                        current_len = 0
                    i += 1
                    j += 1
    
    @cuda.jit
    def _compute_curvature_anomaly_kernel(phase_space, curvature_anomaly, n, dim):
        """æ›²ç‡ç•°å¸¸è¨ˆç®—ã‚«ãƒ¼ãƒãƒ«"""
        idx = cuda.grid(1)
        
        if idx > 0 and idx < n - 1:
            # 3ç‚¹ã§ã®æ›²ç‡è¨ˆç®—
            v1_norm = 0.0
            v2_norm = 0.0
            dot_product = 0.0
            
            for d in range(dim):
                v1 = phase_space[idx, d] - phase_space[idx - 1, d]
                v2 = phase_space[idx + 1, d] - phase_space[idx, d]
                
                v1_norm += v1 * v1
                v2_norm += v2 * v2
                dot_product += v1 * v2
            
            v1_norm = math.sqrt(v1_norm)
            v2_norm = math.sqrt(v2_norm)
            
            if v1_norm > 1e-10 and v2_norm > 1e-10:
                cos_angle = dot_product / (v1_norm * v2_norm)
                curvature_anomaly[idx] = 1.0 - min(max(cos_angle, -1.0), 1.0)
    
    @cuda.jit
    def _compute_velocity_anomaly_kernel(phase_space, velocity_anomaly, n, dim):
        """é€Ÿåº¦ç•°å¸¸è¨ˆç®—ã‚«ãƒ¼ãƒãƒ«"""
        idx = cuda.grid(1)
        
        if idx < n - 1:
            velocity = 0.0
            for d in range(dim):
                diff = phase_space[idx + 1, d] - phase_space[idx, d]
                velocity += diff * diff
            
            velocity_anomaly[idx] = math.sqrt(velocity)
    
    @cuda.jit
    def _compute_acceleration_anomaly_kernel(phase_space, acceleration_anomaly, n, dim):
        """åŠ é€Ÿåº¦ç•°å¸¸è¨ˆç®—ã‚«ãƒ¼ãƒãƒ«"""
        idx = cuda.grid(1)
        
        if idx > 0 and idx < n - 1:
            acceleration = 0.0
            for d in range(dim):
                acc = (phase_space[idx + 1, d] - 
                      2 * phase_space[idx, d] + 
                      phase_space[idx - 1, d])
                acceleration += acc * acc
            
            acceleration_anomaly[idx] = math.sqrt(acceleration)
    
    # === è£œåŠ©ãƒ¡ã‚½ãƒƒãƒ‰ ===
    
    def _optimize_kernel_launch(self, n_elements: int) -> Tuple[int, int]:
        """ã‚«ãƒ¼ãƒãƒ«èµ·å‹•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©åŒ–"""
        device = cp.cuda.Device()
        
        # ãƒ‡ãƒã‚¤ã‚¹ç‰¹æ€§ã‚’å–å¾—
        max_threads = device.attributes['MaxThreadsPerBlock']
        sm_count = device.attributes['MultiProcessorCount']
        warp_size = 32
        
        # ãƒ¯ãƒ¼ãƒ—ã‚µã‚¤ã‚ºã®å€æ•°ã§æœ€é©åŒ–
        threads = min(256, max_threads)
        threads = (threads // warp_size) * warp_size
        
        # ãƒ–ãƒ­ãƒƒã‚¯æ•°ã‚’è¨ˆç®—
        blocks = (n_elements + threads - 1) // threads
        
        # ã‚ªã‚­ãƒ¥ãƒ‘ãƒ³ã‚·ãƒ¼æœ€é©åŒ–
        optimal_blocks = sm_count * 32  # çµŒé¨“çš„ãªå€¤
        blocks = min(blocks, optimal_blocks)
        
        return blocks, threads
    
    def _correlation_dimension_gpu_fast(self, phase_space: cp.ndarray) -> float:
        """é«˜é€Ÿç›¸é–¢æ¬¡å…ƒè¨ˆç®—"""
        n = min(2000, len(phase_space))
        
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        if len(phase_space) > n:
            indices = cp.random.choice(len(phase_space), n, replace=False)
            phase_space = phase_space[indices]
        
        # ä¸¦åˆ—è·é›¢è¨ˆç®—
        n_pairs = n * (n - 1) // 2
        distances = cp.zeros(n_pairs, dtype=cp.float32)
        
        # è·é›¢ã‚’ä¸¦åˆ—è¨ˆç®—
        blocks, threads = self._optimize_kernel_launch(n_pairs)
        self._compute_pairwise_distances_kernel[blocks, threads](
            phase_space, distances, n, phase_space.shape[1]
        )
        
        # ç›¸é–¢ç©åˆ†
        radii = cp.logspace(-2, 1, 30)
        correlation_integral = cp.zeros(len(radii), dtype=cp.int32)
        
        self._fractal_kernel[blocks, threads](
            distances, correlation_integral, radii, n_pairs, len(radii)
        )
        
        # log-logå‹¾é…
        valid = correlation_integral > 0
        if cp.sum(valid) > 5:
            log_r = cp.log(radii[valid])
            log_c = cp.log(correlation_integral[valid].astype(cp.float32) / n_pairs)
            
            # ç·šå½¢ãƒ•ã‚£ãƒƒãƒˆ
            slope = cp.polyfit(log_r, log_c, 1)[0]
            return float(cp.clip(slope, 0.5, 5.0))
        
        return 2.0
    
    def _estimate_lyapunov_gpu_fast(self, phase_space: cp.ndarray) -> float:
        """é«˜é€ŸLyapunovæŒ‡æ•°æ¨å®š"""
        n = len(phase_space)
        dim = phase_space.shape[1]
        
        # ä¸¦åˆ—è¿‘å‚æ¢ç´¢
        n_ref_points = min(200, n // 10)
        ref_indices = cp.random.choice(n - 10, n_ref_points, replace=False)
        
        lyap_values = cp.zeros(n_ref_points, dtype=cp.float32)
        
        blocks, threads = self._optimize_kernel_launch(n_ref_points)
        self._lyapunov_kernel[blocks, threads](
            phase_space, ref_indices, lyap_values, n, dim
        )
        
        # å¤–ã‚Œå€¤ã‚’é™¤å»ã—ã¦median
        lyap_values = lyap_values[lyap_values != 0]
        if len(lyap_values) > 0:
            return float(cp.median(lyap_values))
        
        return 0.0
    
    @cuda.jit
    def _lyapunov_kernel(phase_space, ref_indices, lyap_values, n, dim):
        """LyapunovæŒ‡æ•°è¨ˆç®—ã‚«ãƒ¼ãƒãƒ«"""
        idx = cuda.grid(1)
        
        if idx < len(ref_indices):
            ref_idx = ref_indices[idx]
            
            # è¿‘å‚ã‚’æ¢ç´¢
            min_dist = 1e10
            nearest_idx = -1
            
            for j in range(max(0, ref_idx - 100), min(n, ref_idx + 100)):
                if abs(j - ref_idx) > 1:
                    dist = 0.0
                    for d in range(dim):
                        diff = phase_space[j, d] - phase_space[ref_idx, d]
                        dist += diff * diff
                    
                    dist = math.sqrt(dist)
                    if dist < min_dist and dist > 1e-10:
                        min_dist = dist
                        nearest_idx = j
            
            # æ™‚é–“ç™ºå±•ã‚’è¿½è·¡
            if nearest_idx >= 0:
                max_steps = min(10, n - max(ref_idx, nearest_idx))
                lyap_sum = 0.0
                count = 0
                
                for dt in range(1, max_steps):
                    if ref_idx + dt < n and nearest_idx + dt < n:
                        evolved_dist = 0.0
                        for d in range(dim):
                            diff = (phase_space[ref_idx + dt, d] - 
                                  phase_space[nearest_idx + dt, d])
                            evolved_dist += diff * diff
                        
                        evolved_dist = math.sqrt(evolved_dist)
                        
                        if evolved_dist > 1e-10 and min_dist > 1e-10:
                            lyap_sum += math.log(evolved_dist / min_dist) / dt
                            count += 1
                
                if count > 0:
                    lyap_values[idx] = lyap_sum / count
    
    def _compute_fractal_measure_gpu_fast(self, phase_space: cp.ndarray) -> float:
        """é«˜é€Ÿãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¸¬åº¦è¨ˆç®—"""
        # ç›¸é–¢æ¬¡å…ƒã‚’ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¸¬åº¦ã¨ã—ã¦ä½¿ç”¨
        corr_dim = self._correlation_dimension_gpu_fast(phase_space)
        embedding_dim = phase_space.shape[1]
        
        # æ­£è¦åŒ–ï¼ˆ0-1ã®ç¯„å›²ã«ï¼‰
        fractal_measure = corr_dim / embedding_dim
        return float(cp.clip(fractal_measure, 0.0, 1.0))
    
    def _compute_information_dimension_gpu(self, phase_space: cp.ndarray) -> float:
        """æƒ…å ±æ¬¡å…ƒã®è¨ˆç®—"""
        n = min(1000, len(phase_space))
        
        # ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒ†ã‚£ãƒ³ã‚°æ³•
        n_boxes_list = [10, 20, 40, 80]
        entropy_values = []
        
        for n_boxes in n_boxes_list:
            # ä½ç›¸ç©ºé–“ã‚’ã‚°ãƒªãƒƒãƒ‰ã«åˆ†å‰²
            box_counts = cp.zeros(n_boxes**3, dtype=cp.int32)
            
            # å„ç‚¹ã‚’ãƒœãƒƒã‚¯ã‚¹ã«å‰²ã‚Šå½“ã¦
            phase_min = cp.min(phase_space[:n], axis=0)
            phase_max = cp.max(phase_space[:n], axis=0)
            phase_range = phase_max - phase_min + 1e-10
            
            for i in range(n):
                box_coords = ((phase_space[i] - phase_min) / phase_range * (n_boxes - 1)).astype(int)
                box_coords = cp.clip(box_coords, 0, n_boxes - 1)
                
                if len(box_coords) >= 3:
                    box_idx = (box_coords[0] * n_boxes * n_boxes + 
                             box_coords[1] * n_boxes + 
                             box_coords[2])
                    box_counts[box_idx] += 1
            
            # ã‚·ãƒ£ãƒãƒ³ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
            probs = box_counts[box_counts > 0] / n
            entropy = -cp.sum(probs * cp.log(probs))
            entropy_values.append(float(entropy))
        
        # log(box_size) vs entropyã®å‹¾é…
        if len(entropy_values) > 1:
            log_sizes = cp.log(cp.array(n_boxes_list, dtype=cp.float32))
            info_dim = cp.polyfit(log_sizes, cp.array(entropy_values), 1)[0]
            return float(cp.clip(info_dim, 0.5, 3.0))
        
        return 1.5
    
    def _compute_recurrence_matrix_gpu_fast(self,
                                           phase_space: cp.ndarray,
                                           threshold: float) -> cp.ndarray:
        """é«˜é€Ÿãƒªã‚«ãƒ¬ãƒ³ã‚¹è¡Œåˆ—è¨ˆç®—"""
        n = len(phase_space)
        rec_matrix = cp.zeros((n, n), dtype=cp.float32)
        
        # ãƒ–ãƒ­ãƒƒã‚¯å˜ä½ã§ä¸¦åˆ—å‡¦ç†
        block_size = 128
        for i in range(0, n, block_size):
            for j in range(0, n, block_size):
                i_end = min(i + block_size, n)
                j_end = min(j + block_size, n)
                
                # éƒ¨åˆ†è·é›¢è¡Œåˆ—
                block_i = phase_space[i:i_end]
                block_j = phase_space[j:j_end]
                
                # ä¸¦åˆ—è·é›¢è¨ˆç®—
                for ii in range(len(block_i)):
                    distances = cp.sqrt(cp.sum((block_j - block_i[ii])**2, axis=1))
                    rec_matrix[i + ii, j:j_end] = (distances < threshold).astype(cp.float32)
        
        return rec_matrix
    
    def _detect_periodicity_gpu_fast(self, phase_space: cp.ndarray) -> float:
        """é«˜é€Ÿå‘¨æœŸæ€§æ¤œå‡º"""
        # å„æ¬¡å…ƒã§FFT
        n = len(phase_space)
        dim = phase_space.shape[1]
        
        max_period_strength = 0.0
        
        for d in range(min(3, dim)):
            # FFT
            signal = phase_space[:, d]
            fft = cp.fft.fft(signal)
            power = cp.abs(fft[:n//2])**2
            
            # DCæˆåˆ†ã‚’é™¤å»
            power[0] = 0
            
            # æœ€å¤§ãƒ”ãƒ¼ã‚¯
            if len(power) > 1:
                max_peak = cp.max(power[1:])
                mean_power = cp.mean(power[1:])
                
                if mean_power > 0:
                    period_strength = max_peak / mean_power
                    max_period_strength = max(max_period_strength, float(period_strength))
        
        # æ­£è¦åŒ–
        return float(1.0 / (1.0 + cp.exp(-max_period_strength + 5)))
    
    def _compute_entropy_from_distribution(self, distribution: cp.ndarray) -> float:
        """åˆ†å¸ƒã‹ã‚‰ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—"""
        # æ­£è¦åŒ–
        total = cp.sum(distribution)
        if total == 0:
            return 0.0
        
        probs = distribution[distribution > 0] / total
        entropy = -cp.sum(probs * cp.log(probs))
        
        return float(entropy)
    
    def _extract_phase_features_gpu_fast(self, phase_space: cp.ndarray) -> Dict:
        """é«˜é€Ÿä½ç›¸ç©ºé–“ç‰¹å¾´æŠ½å‡º"""
        n = len(phase_space)
        dim = phase_space.shape[1]
        
        # çµ±è¨ˆé‡ã‚’ä¸¦åˆ—è¨ˆç®—
        features = {
            'center': cp.mean(phase_space, axis=0),
            'spread': cp.std(phase_space, axis=0),
            'skewness': cp.zeros(dim),
            'kurtosis': cp.zeros(dim)
        }
        
        # é«˜æ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ
        for d in range(dim):
            data = phase_space[:, d]
            mean = features['center'][d]
            std = features['spread'][d]
            
            if std > 1e-10:
                features['skewness'][d] = cp.mean(((data - mean) / std)**3)
                features['kurtosis'][d] = cp.mean(((data - mean) / std)**4) - 3
        
        # ä½“ç©ã¨è¡¨é¢ç©
        features['volume'] = self._compute_attractor_volume_gpu(phase_space)
        features['surface_area'] = self._estimate_surface_area_gpu(phase_space)
        
        return features
    
    def _compute_phase_distances_parallel(self, all_features: List[Dict]) -> cp.ndarray:
        """ä¸¦åˆ—ä½ç›¸è·é›¢è¨ˆç®—"""
        n = len(all_features)
        distances = cp.zeros(n - 1)
        
        for i in range(n - 1):
            f1 = all_features[i]
            f2 = all_features[i + 1]
            
            # å„ç‰¹å¾´ã®è·é›¢
            center_dist = cp.linalg.norm(f1['center'] - f2['center'])
            spread_dist = cp.linalg.norm(f1['spread'] - f2['spread'])
            volume_dist = abs(f1['volume'] - f2['volume'])
            
            # é‡ã¿ä»˜ãåˆè¨ˆ
            distances[i] = 0.5 * center_dist + 0.3 * spread_dist + 0.2 * volume_dist
        
        return distances
    
    @cuda.jit
    def _map_transition_scores_kernel(scores, distances, window_size, stride):
        """é·ç§»ã‚¹ã‚³ã‚¢ãƒãƒƒãƒ”ãƒ³ã‚°ã‚«ãƒ¼ãƒãƒ«"""
        idx = cuda.grid(1)
        
        if idx < len(distances):
            start = idx * stride
            end = start + window_size
            
            for j in range(start, min(end, len(scores))):
                cuda.atomic.add(scores, j, distances[idx] / window_size)
    
    @cuda.jit
    def _compute_pairwise_distances_kernel(phase_space, distances, n, dim):
        """ãƒšã‚¢ãƒ¯ã‚¤ã‚ºè·é›¢è¨ˆç®—ã‚«ãƒ¼ãƒãƒ«"""
        idx = cuda.grid(1)
        
        if idx < len(distances):
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰(i, j)ãƒšã‚¢ã‚’å¾©å…ƒ
            i = int((1 + math.sqrt(1 + 8 * idx)) / 2)
            j = idx - i * (i - 1) // 2
            
            if i < n and j < i:
                dist = 0.0
                for d in range(dim):
                    diff = phase_space[i, d] - phase_space[j, d]
                    dist += diff * diff
                
                distances[idx] = math.sqrt(dist)
    
    def _estimate_surface_area_gpu(self, phase_space: cp.ndarray) -> float:
        """è¡¨é¢ç©ã®æ¨å®šï¼ˆå‡¸åŒ…è¿‘ä¼¼ï¼‰"""
        # ç°¡æ˜“ç‰ˆï¼šæœ€å¤–ç‚¹ã‹ã‚‰ã®è·é›¢
        center = cp.mean(phase_space, axis=0)
        distances = cp.sqrt(cp.sum((phase_space - center)**2, axis=1))
        
        # è¡¨é¢ã®ç‚¹ã‚’æ¨å®š
        threshold = cp.percentile(distances, 90)
        surface_points = cp.sum(distances > threshold)
        
        return float(surface_points / len(phase_space))
    
    def _compute_attractor_volume_gpu(self, phase_space: cp.ndarray) -> float:
        """ã‚¢ãƒˆãƒ©ã‚¯ã‚¿ä½“ç©ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        # ä¸»æˆåˆ†ã§æ¬¡å…ƒå‰Šæ¸›ã—ã¦ã‹ã‚‰ä½“ç©è¨ˆç®—
        if len(phase_space) < 10:
            return 0.0
        
        # ä¸­å¿ƒåŒ–
        centered = phase_space - cp.mean(phase_space, axis=0)
        
        # å…±åˆ†æ•£è¡Œåˆ—
        cov = cp.cov(centered.T)
        
        # å›ºæœ‰å€¤ï¼ˆä½“ç©ã®è¿‘ä¼¼ï¼‰
        eigenvalues = cp.linalg.eigvalsh(cov)
        eigenvalues = eigenvalues[eigenvalues > 1e-10]
        
        if len(eigenvalues) > 0:
            # æ¥•å††ä½“ã®ä½“ç©
            volume = cp.prod(cp.sqrt(eigenvalues))
            return float(volume)
        
        return 0.0
    
    def _get_primary_series(self, structures: Dict) -> cp.ndarray:
        """ä¸»è¦ãªæ™‚ç³»åˆ—ã‚’é¸æŠ"""
        if 'rho_T' in structures:
            return self.to_gpu(structures['rho_T'])
        elif 'lambda_F_mag' in structures:
            return self.to_gpu(structures['lambda_F_mag'])
        else:
            # æœ€åˆã®åˆ©ç”¨å¯èƒ½ãªç³»åˆ—
            for key, value in structures.items():
                if isinstance(value, np.ndarray) and len(value.shape) == 1:
                    return self.to_gpu(value)
        
        raise ValueError("No suitable time series found in structures")
    
    def _estimate_embedding_parameters_gpu(self,
                                         series: cp.ndarray,
                                         params: Dict) -> Dict:
        """æœ€é©ãªåŸ‹ã‚è¾¼ã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¨å®šï¼ˆé«˜é€Ÿç‰ˆï¼‰"""
        # ç›¸äº’æƒ…å ±é‡ã«ã‚ˆã‚‹é…å»¶æ™‚é–“ã®æ¨å®š
        optimal_delay = self._estimate_delay_mutual_info_gpu_fast(series)
        
        # False Nearest Neighborsæ³•ã«ã‚ˆã‚‹æ¬¡å…ƒæ¨å®š
        optimal_dim = self._estimate_dimension_fnn_gpu_fast(
            series, optimal_delay, max_dim=10
        )
        
        return {
            'embedding_dim': int(optimal_dim),
            'delay': int(optimal_delay),
            'estimated_from': 'mutual_info_and_fnn'
        }
    
    def _estimate_delay_mutual_info_gpu_fast(self, series: cp.ndarray) -> int:
        """é«˜é€Ÿç›¸äº’æƒ…å ±é‡ã«ã‚ˆã‚‹é…å»¶æ¨å®š"""
        max_delay = min(100, len(series) // 10)
        mi_values = cp.zeros(max_delay)
        
        # ä¸¦åˆ—ã§ç›¸äº’æƒ…å ±é‡è¨ˆç®—
        for delay in range(1, max_delay):
            x = series[:-delay]
            y = series[delay:]
            
            # 2æ¬¡å…ƒãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼ˆé«˜é€Ÿç‰ˆï¼‰
            n_bins = 20
            hist_2d, _, _ = cp.histogram2d(x, y, bins=n_bins)
            
            # æ­£è¦åŒ–
            hist_2d = hist_2d / cp.sum(hist_2d)
            
            # å‘¨è¾ºåˆ†å¸ƒ
            px = cp.sum(hist_2d, axis=1)
            py = cp.sum(hist_2d, axis=0)
            
            # ç›¸äº’æƒ…å ±é‡ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
            valid = hist_2d > 0
            mi = cp.sum(hist_2d[valid] * cp.log(
                hist_2d[valid] / (px[:, None] * py[None, :])[valid]
            ))
            
            mi_values[delay] = mi
        
        # æœ€åˆã®æ¥µå°å€¤ã‚’æ¤œå‡º
        for i in range(2, len(mi_values) - 1):
            if mi_values[i] < mi_values[i-1] and mi_values[i] < mi_values[i+1]:
                return int(i)
        
        # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æ¸›è¡°ç‚¹
        decay_point = cp.where(mi_values < mi_values[1] * 0.5)[0]
        if len(decay_point) > 0:
            return int(decay_point[0])
        
        return 10  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    def _estimate_dimension_fnn_gpu_fast(self,
                                       series: cp.ndarray,
                                       delay: int,
                                       max_dim: int) -> int:
        """é«˜é€ŸFalse Nearest Neighborsæ³•"""
        fnn_fractions = []
        
        for dim in range(1, max_dim):
            try:
                # åŸ‹ã‚è¾¼ã¿
                phase_space = self._reconstruct_phase_space_gpu(series, dim, delay)
                n = min(2000, len(phase_space))
                
                if n < 100:
                    break
                
                # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                if len(phase_space) > n:
                    indices = cp.random.choice(len(phase_space), n, replace=False)
                    phase_space_sample = phase_space[indices]
                else:
                    phase_space_sample = phase_space
                
                # FNNè¨ˆç®—ï¼ˆä¸¦åˆ—åŒ–ï¼‰
                fnn_count = cp.zeros(1, dtype=cp.int32)
                
                blocks, threads = self._optimize_kernel_launch(n)
                self._fnn_kernel[blocks, threads](
                    phase_space_sample, series, fnn_count, 
                    n, dim, delay, len(series)
                )
                
                fnn_fraction = float(fnn_count[0]) / n
                fnn_fractions.append(fnn_fraction)
                
                # åæŸåˆ¤å®š
                if fnn_fraction < 0.01:
                    return dim
                
                # æ€¥æ¿€ãªæ¸›å°‘
                if len(fnn_fractions) > 1:
                    if fnn_fractions[-2] - fnn_fraction > 0.5:
                        return dim
            
            except Exception as e:
                print(f"FNN dimension {dim} failed: {e}")
                break
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        if fnn_fractions:
            # æœ€å°ã®FNNç‡ã®æ¬¡å…ƒ
            return int(cp.argmin(cp.array(fnn_fractions)) + 1)
        
        return 3
    
    @cuda.jit
    def _fnn_kernel(phase_space, series, fnn_count, n, dim, delay, series_len):
        """FNNã‚«ãƒ¼ãƒãƒ«"""
        idx = cuda.grid(1)
        
        if idx < n:
            # æœ€è¿‘å‚ã‚’æ¢ç´¢
            min_dist = 1e10
            nn_idx = -1
            
            for j in range(n):
                if j != idx:
                    dist = 0.0
                    for d in range(dim):
                        diff = phase_space[j, d] - phase_space[idx, d]
                        dist += diff * diff
                    
                    if dist < min_dist:
                        min_dist = math.sqrt(dist)
                        nn_idx = j
            
            # False nearest neighboråˆ¤å®š
            if nn_idx >= 0 and min_dist > 1e-10:
                # æ¬¡å…ƒã‚’å¢—ã‚„ã—ãŸæ™‚ã®è·é›¢
                next_dim_idx = idx + dim * delay
                next_dim_nn_idx = nn_idx + dim * delay
                
                if next_dim_idx < series_len and next_dim_nn_idx < series_len:
                    next_dim_dist = abs(series[next_dim_idx] - series[next_dim_nn_idx])
                    
                    # Kennel et al.ã®åŸºæº–
                    if next_dim_dist / min_dist > 10.0:
                        cuda.atomic.add(fnn_count, 0, 1)
    
    def _reconstruct_phase_space_gpu(self,
                                   series: cp.ndarray,
                                   embedding_dim: int,
                                   delay: int) -> cp.ndarray:
        """æ™‚ç³»åˆ—ã‹ã‚‰ä½ç›¸ç©ºé–“ã‚’å†æ§‹æˆï¼ˆé«˜é€Ÿç‰ˆï¼‰"""
        n = len(series)
        embed_length = n - (embedding_dim - 1) * delay
        
        if embed_length <= 0:
            raise ValueError(f"Series too short for embedding: {n} < {(embedding_dim - 1) * delay}")
        
        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿
        indices = cp.arange(embed_length)[:, None] + cp.arange(embedding_dim)[None, :] * delay
        phase_space = series[indices]
        
        return phase_space
    
    def _compute_integrated_score_gpu(self,
                                    anomaly_scores: cp.ndarray,
                                    attractor_features: Dict,
                                    recurrence_features: Dict) -> cp.ndarray:
        """çµ±åˆç•°å¸¸ã‚¹ã‚³ã‚¢ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        # ã‚¢ãƒˆãƒ©ã‚¯ã‚¿ç•°å¸¸åº¦
        attractor_anomaly = 0.0
        
        # LyapunovæŒ‡æ•°ï¼ˆæ­£å€¤ã¯ã‚«ã‚ªã‚¹çš„ï¼‰
        if abs(attractor_features['lyapunov_exponent']) > 0.1:
            attractor_anomaly += 0.3
        
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ€§ï¼ˆéæ•´æ•°æ¬¡å…ƒï¼‰
        frac_deviation = abs(attractor_features['fractal_measure'] - 0.5)
        attractor_anomaly += frac_deviation * 0.2
        
        # ç›¸é–¢æ¬¡å…ƒã®ç•°å¸¸
        corr_dim = attractor_features['correlation_dimension']
        if corr_dim < 1.0 or corr_dim > 3.0:
            attractor_anomaly += 0.2
        
        # æƒ…å ±æ¬¡å…ƒã¨ã®ä¹–é›¢
        info_dim = attractor_features.get('information_dimension', 2.0)
        dim_diff = abs(corr_dim - info_dim)
        attractor_anomaly += dim_diff * 0.1
        
        # ãƒªã‚«ãƒ¬ãƒ³ã‚¹ç•°å¸¸åº¦
        recurrence_anomaly = 0.0
        
        # æ±ºå®šè«–æ€§ã®ä½ä¸‹
        determinism = recurrence_features['determinism']
        if determinism < 0.7:
            recurrence_anomaly += (1 - determinism) * 0.3
        
        # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã®ç•°å¸¸
        entropy = recurrence_features['entropy']
        if entropy > 2.0:
            recurrence_anomaly += min(entropy / 5.0, 0.3)
        
        # å±¤æµæ€§ã®ç•°å¸¸
        laminarity = recurrence_features['laminarity']
        if laminarity < 0.5:
            recurrence_anomaly += (1 - laminarity) * 0.2
        
        # ãƒˆãƒ©ãƒƒãƒ”ãƒ³ã‚°æ™‚é–“
        trapping = recurrence_features.get('trapping_time', 1.0)
        if trapping > 10.0:
            recurrence_anomaly += 0.2
        
        # æ­£è¦åŒ–
        attractor_anomaly = cp.clip(attractor_anomaly, 0.0, 1.0)
        recurrence_anomaly = cp.clip(recurrence_anomaly, 0.0, 1.0)
        
        # çµ±åˆï¼ˆæ™‚ç³»åˆ—å…¨ä½“ã«é©ç”¨ï¼‰
        global_anomaly = 0.5 * attractor_anomaly + 0.5 * recurrence_anomaly
        
        # å±€æ‰€ç•°å¸¸ã¨çµ±åˆ
        integrated = 0.7 * anomaly_scores + 0.3 * global_anomaly
        
        # æ­£è¦åŒ–
        integrated = (integrated - cp.mean(integrated)) / (cp.std(integrated) + 1e-10)
        
        return integrated
    
    def _smooth_and_normalize_gpu(self, scores: cp.ndarray) -> cp.ndarray:
        """ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã¨æ­£è¦åŒ–ï¼ˆé«˜é€Ÿç‰ˆï¼‰"""
        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆä¸¦åˆ—åŒ–ï¼‰
        from cupyx.scipy.ndimage import gaussian_filter1d
        
        # é©å¿œçš„ãªã‚·ã‚°ãƒ
        sigma = max(5, len(scores) // 100)
        smoothed = gaussian_filter1d(scores, sigma=sigma)
        
        # ãƒ­ãƒã‚¹ãƒˆæ­£è¦åŒ–
        median = cp.median(smoothed)
        mad = cp.median(cp.abs(smoothed - median))
        
        if mad > 1e-10:
            normalized = (smoothed - median) / (1.4826 * mad)  # MAD to std
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if cp.std(smoothed) > 1e-10:
                normalized = (smoothed - cp.mean(smoothed)) / cp.std(smoothed)
            else:
                normalized = smoothed
        
        return normalized
    
    def _print_summary(self, results: Dict):
        """è§£æçµæœã®ã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print("\nğŸ“Š Phase Space Analysis Summary (Ultra-Fast Edition):")
        print(f"   âš¡ GPU Acceleration: ENABLED")
        print(f"   Embedding dimension: {results['optimal_parameters']['embedding_dim']}")
        print(f"   Optimal delay: {results['optimal_parameters']['delay']}")
        
        if 'attractor_features' in results:
            att = results['attractor_features']
            print(f"\n   ğŸŒ€ Attractor Features:")
            print(f"   - Correlation dimension: {att['correlation_dimension']:.3f}")
            print(f"   - Lyapunov exponent: {att['lyapunov_exponent']:.3f}")
            print(f"   - Fractal measure: {att['fractal_measure']:.3f}")
            print(f"   - Attractor volume: {att['attractor_volume']:.3f}")
            print(f"   - Information dimension: {att.get('information_dimension', 0):.3f}")
        
        if 'recurrence_features' in results:
            rec = results['recurrence_features']
            print(f"\n   ğŸ“ˆ Recurrence Features:")
            print(f"   - Recurrence rate: {rec['recurrence_rate']:.3f}")
            print(f"   - Determinism: {rec['determinism']:.3f}")
            print(f"   - Laminarity: {rec['laminarity']:.3f}")
            print(f"   - Entropy: {rec['entropy']:.3f}")
            print(f"   - Max diagonal length: {rec.get('max_diagonal_length', 0)}")
            
        if 'dynamics_features' in results:
            dyn = results['dynamics_features']
            print(f"\n   ğŸ”„ Dynamics Features:")
            print(f"   - Periodicity: {dyn['periodicity']:.3f}")
            print(f"   - Chaos measure: {dyn['chaos_measure']:.3f}")
            print(f"   - Predictability: {dyn.get('predictability', 0):.3f}")
            print(f"   - Complexity: {dyn['complexity']:.3f}")
            print(f"   - Stability: {dyn['stability']:.3f}")
