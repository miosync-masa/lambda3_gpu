"""
LambdaÂ³ GPU Advanced Optimization Techniques
ã‚«ã‚¹ã‚¿ãƒ CUDAã‚«ãƒ¼ãƒãƒ«ã¨ãƒ¡ãƒ¢ãƒªæœ€é©åŒ– - by ç’°ã¡ã‚ƒã‚“ğŸ’•
"""

import numpy as np
import cupy as cp
from cupy import cuda
from string import Template

# ===============================
# Custom CUDA Kernels
# ===============================

# æ®‹åŸºCOMè¨ˆç®—ã®è¶…é«˜é€Ÿã‚«ãƒ¼ãƒãƒ«
residue_com_kernel = cp.RawKernel(r'''
extern "C" __global__
void compute_residue_com_kernel(
    const float* trajectory,      // (n_frames, n_atoms, 3)
    const int* atom_indices,      // å„æ®‹åŸºã®åŸå­ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    const int* residue_starts,    // å„æ®‹åŸºã®é–‹å§‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    const int* residue_sizes,     // å„æ®‹åŸºã®åŸå­æ•°
    float* com_output,           // (n_frames, n_residues, 3)
    const int n_frames,
    const int n_atoms,
    const int n_residues
) {
    // ã‚°ãƒªãƒƒãƒ‰ãƒ»ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ãƒ»ãƒ«ãƒ¼ãƒ—
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int total_work = n_frames * n_residues;
    
    for (int i = idx; i < total_work; i += gridDim.x * blockDim.x) {
        int frame = i / n_residues;
        int res_id = i % n_residues;
        
        // æ®‹åŸºã®åŸå­ç¯„å›²
        int start = residue_starts[res_id];
        int size = residue_sizes[res_id];
        
        // COMè¨ˆç®—
        float com_x = 0.0f, com_y = 0.0f, com_z = 0.0f;
        
        for (int j = 0; j < size; j++) {
            int atom_idx = atom_indices[start + j];
            int traj_idx = frame * n_atoms + atom_idx;
            
            com_x += trajectory[traj_idx * 3 + 0];
            com_y += trajectory[traj_idx * 3 + 1];
            com_z += trajectory[traj_idx * 3 + 2];
        }
        
        // å¹³å‡ã‚’è¨ˆç®—ã—ã¦å‡ºåŠ›
        int out_idx = (frame * n_residues + res_id) * 3;
        com_output[out_idx + 0] = com_x / size;
        com_output[out_idx + 1] = com_y / size;
        com_output[out_idx + 2] = com_z / size;
    }
}
''', 'compute_residue_com_kernel')

# ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å ´è¨ˆç®—ã®ä¸¦åˆ—ã‚«ãƒ¼ãƒãƒ«
tension_field_kernel = cp.RawKernel(r'''
extern "C" __global__
void compute_tension_field_kernel(
    const float* positions,       // (n_frames, 3)
    float* rho_T,                // (n_frames,)
    const int n_frames,
    const int window_size
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (idx >= n_frames) return;
    
    int start = max(0, idx - window_size);
    int end = min(n_frames, idx + window_size + 1);
    int local_size = end - start;
    
    // å±€æ‰€å¹³å‡è¨ˆç®—
    float mean_x = 0.0f, mean_y = 0.0f, mean_z = 0.0f;
    for (int i = start; i < end; i++) {
        mean_x += positions[i * 3 + 0];
        mean_y += positions[i * 3 + 1];
        mean_z += positions[i * 3 + 2];
    }
    mean_x /= local_size;
    mean_y /= local_size;
    mean_z /= local_size;
    
    // å…±åˆ†æ•£è¡Œåˆ—ã®ãƒˆãƒ¬ãƒ¼ã‚¹è¨ˆç®—
    float cov_xx = 0.0f, cov_yy = 0.0f, cov_zz = 0.0f;
    for (int i = start; i < end; i++) {
        float dx = positions[i * 3 + 0] - mean_x;
        float dy = positions[i * 3 + 1] - mean_y;
        float dz = positions[i * 3 + 2] - mean_z;
        
        cov_xx += dx * dx;
        cov_yy += dy * dy;
        cov_zz += dz * dz;
    }
    
    rho_T[idx] = (cov_xx + cov_yy + cov_zz) / local_size;
}
''', 'compute_tension_field_kernel')

# ç•°å¸¸æ¤œå‡ºã®é«˜é€Ÿã‚«ãƒ¼ãƒãƒ«
anomaly_detection_kernel = cp.RawKernel(r'''
extern "C" __global__
void detect_anomalies_kernel(
    const float* series,
    float* anomaly_scores,
    const int n_points,
    const int window_size
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (idx >= n_points) return;
    
    int start = max(0, idx - window_size);
    int end = min(n_points, idx + window_size + 1);
    int local_size = end - start;
    
    // å±€æ‰€çµ±è¨ˆé‡è¨ˆç®—
    float local_mean = 0.0f;
    for (int i = start; i < end; i++) {
        local_mean += series[i];
    }
    local_mean /= local_size;
    
    float local_std = 0.0f;
    for (int i = start; i < end; i++) {
        float diff = series[i] - local_mean;
        local_std += diff * diff;
    }
    local_std = sqrtf(local_std / local_size);
    
    // Z-scoreè¨ˆç®—
    if (local_std > 1e-10f) {
        anomaly_scores[idx] = fabsf(series[idx] - local_mean) / local_std;
    } else {
        anomaly_scores[idx] = 0.0f;
    }
}
''', 'detect_anomalies_kernel')

# ===============================
# Optimized GPU Functions
# ===============================

class OptimizedGPULambda3:
    """
    æœ€é©åŒ–ã•ã‚ŒãŸGPU LambdaÂ³å®Ÿè£…
    ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ã§çˆ†é€Ÿã ã‚ˆã€œï¼âœ¨
    """
    
    def __init__(self):
        self.block_size = 256  # æœ€é©ãªãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º
        self.stream = cp.cuda.Stream()  # éåŒæœŸå®Ÿè¡Œç”¨
        
    def compute_residue_com_optimized(self, 
                                     trajectory_gpu: cp.ndarray,
                                     residue_mapping: dict) -> cp.ndarray:
        """
        ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ã«ã‚ˆã‚‹æ®‹åŸºCOMè¨ˆç®—
        """
        n_frames, n_atoms, _ = trajectory_gpu.shape
        n_residues = len(residue_mapping)
        
        # æ®‹åŸºæƒ…å ±ã‚’æº–å‚™
        all_indices = []
        residue_starts = []
        residue_sizes = []
        
        current_start = 0
        for res_id in sorted(residue_mapping.keys()):
            atoms = residue_mapping[res_id]
            all_indices.extend(atoms)
            residue_starts.append(current_start)
            residue_sizes.append(len(atoms))
            current_start += len(atoms)
        
        # GPUé…åˆ—ã«å¤‰æ›
        atom_indices_gpu = cp.array(all_indices, dtype=cp.int32)
        residue_starts_gpu = cp.array(residue_starts, dtype=cp.int32)
        residue_sizes_gpu = cp.array(residue_sizes, dtype=cp.int32)
        
        # å‡ºåŠ›é…åˆ—
        com_output_gpu = cp.zeros((n_frames, n_residues, 3), dtype=cp.float32)
        
        # ãƒ•ãƒ©ãƒƒãƒˆåŒ–
        trajectory_flat = trajectory_gpu.reshape(-1)
        
        # ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œ
        grid_size = (n_frames * n_residues + self.block_size - 1) // self.block_size
        
        residue_com_kernel(
            (grid_size,), (self.block_size,),
            (trajectory_flat, atom_indices_gpu, residue_starts_gpu, 
             residue_sizes_gpu, com_output_gpu,
             n_frames, n_atoms, n_residues)
        )
        
        return com_output_gpu
    
    def compute_pairwise_distances_optimized(self, 
                                           residue_coms: cp.ndarray) -> cp.ndarray:
        """
        æœ€é©åŒ–ã•ã‚ŒãŸè·é›¢è¡Œåˆ—è¨ˆç®—ï¼ˆå…±æœ‰ãƒ¡ãƒ¢ãƒªä½¿ç”¨ï¼‰
        """
        n_frames, n_residues, _ = residue_coms.shape
        distances = cp.zeros((n_frames, n_residues, n_residues), dtype=cp.float32)
        
        # ãƒãƒƒãƒå‡¦ç†ã§åŠ¹ç‡åŒ–
        batch_size = min(100, n_frames)  # ãƒ¡ãƒ¢ãƒªã«å¿œã˜ã¦èª¿æ•´
        
        for i in range(0, n_frames, batch_size):
            end = min(i + batch_size, n_frames)
            batch = residue_coms[i:end]
            
            # ãƒãƒƒãƒå†…ã®å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¸€åº¦ã«è¨ˆç®—
            for j in range(end - i):
                distances[i+j] = cp.sqrt(
                    ((batch[j, :, None, :] - batch[j, None, :, :])**2).sum(axis=2)
                )
        
        return distances
    
    def parallel_fft_analysis(self, 
                            signals: cp.ndarray,
                            min_period: int,
                            max_period: int) -> dict:
        """
        è¤‡æ•°ä¿¡å·ã®ä¸¦åˆ—FFTè§£æ
        """
        n_signals, n_frames = signals.shape
        
        # å…¨ä¿¡å·ã‚’ä¸€åº¦ã«FFTï¼ˆãƒãƒƒãƒFFTï¼‰
        signals_centered = signals - cp.mean(signals, axis=1, keepdims=True)
        
        # CuPyã®ãƒãƒƒãƒFFTã‚’ä½¿ç”¨
        with self.stream:
            fft_results = cp.fft.rfft(signals_centered, axis=1)
            power_spectra = cp.abs(fft_results)**2
        
        # å‘¨æ³¢æ•°è»¸
        freqs = cp.fft.rfftfreq(n_frames, 1.0)
        
        # æœ‰åŠ¹ç¯„å›²ãƒã‚¹ã‚¯
        freq_min = 1.0 / max_period
        freq_max = 1.0 / min_period
        valid_mask = (freqs > freq_min) & (freqs < freq_max) & (freqs > 0)
        
        return {
            'power_spectra': power_spectra[:, valid_mask],
            'frequencies': freqs[valid_mask],
            'n_signals': n_signals
        }

# ===============================
# Memory-Efficient Batch Processing
# ===============================

class GPUBatchProcessor:
    """
    å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒå‡¦ç†
    ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ã«å‡¦ç†ã™ã‚‹ã‚ˆã€œï¼
    """
    
    def __init__(self, max_memory_gb=8):
        self.max_memory = max_memory_gb * 1024**3  # ãƒã‚¤ãƒˆå˜ä½
        self.dtype_size = 4  # float32
        
    def estimate_batch_size(self, n_atoms, n_residues):
        """
        åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªã‹ã‚‰æœ€é©ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æ¨å®š
        """
        # å¿…è¦ãƒ¡ãƒ¢ãƒªæ¨å®š
        frame_memory = n_atoms * 3 * self.dtype_size
        residue_memory = n_residues * 3 * self.dtype_size
        processing_overhead = 2.0  # å‡¦ç†ç”¨ã®ä½™è£•
        
        total_per_frame = (frame_memory + residue_memory) * processing_overhead
        
        batch_size = int(self.max_memory / total_per_frame)
        
        print(f"ğŸ’¾ Estimated batch size: {batch_size} frames")
        print(f"   Memory per frame: {total_per_frame/1024**2:.1f} MB")
        
        return max(1, batch_size)
    
    def process_trajectory_batched(self, 
                                 trajectory: np.ndarray,
                                 processor_func,
                                 batch_size=None):
        """
        ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªã‚’ãƒãƒƒãƒå‡¦ç†
        """
        n_frames = trajectory.shape[0]
        
        if batch_size is None:
            batch_size = self.estimate_batch_size(
                trajectory.shape[1], 
                129  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ®‹åŸºæ•°
            )
        
        results = []
        
        for i in range(0, n_frames, batch_size):
            end = min(i + batch_size, n_frames)
            print(f"\rğŸ“Š Processing frames {i}-{end}/{n_frames}", end='')
            
            # ãƒãƒƒãƒã‚’GPUã«è»¢é€
            batch_gpu = cp.asarray(trajectory[i:end], dtype=cp.float32)
            
            # å‡¦ç†å®Ÿè¡Œ
            batch_result = processor_func(batch_gpu)
            
            # çµæœã‚’CPUã«æˆ»ã™
            results.append(cp.asnumpy(batch_result))
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
            del batch_gpu
            cp.cuda.MemoryPool().free_all_blocks()
        
        print("\nâœ… Batch processing complete!")
        
        # çµæœã‚’çµåˆ
        return np.concatenate(results, axis=0)

# ===============================
# Integration with Original Code
# ===============================

def integrate_gpu_acceleration(original_detector_class):
    """
    æ—¢å­˜ã®LambdaÂ³æ¤œå‡ºå™¨ã«GPUæ©Ÿèƒ½ã‚’çµ±åˆ
    """
    class GPUAcceleratedDetector(original_detector_class):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            self.gpu_optimizer = OptimizedGPULambda3()
            self.batch_processor = GPUBatchProcessor()
            self._use_gpu = cp.cuda.is_available()
            
            if self._use_gpu:
                print("ğŸš€ GPU Acceleration Enabled!")
                print(f"   Device: {cp.cuda.Device().name}")
                
        def compute_lambda_structures(self, trajectory, md_features, window_steps):
            """
            GPUã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ç‰ˆ
            """
            if self._use_gpu and trajectory.shape[0] > 1000:
                # GPUç‰ˆã‚’ä½¿ç”¨
                return compute_lambda_structures_gpu(
                    trajectory, md_features, window_steps
                )
            else:
                # CPUç‰ˆã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                return super().compute_lambda_structures(
                    trajectory, md_features, window_steps
                )
                
    return GPUAcceleratedDetector

# ===============================
# Performance Benchmarking
# ===============================

def benchmark_gpu_performance(n_frames=10000, n_atoms=1000):
    """
    GPUæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
    """
    import time
    
    print(f"\nğŸ Running GPU Performance Benchmark")
    print(f"   Frames: {n_frames}, Atoms: {n_atoms}")
    
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    trajectory = np.random.randn(n_frames, n_atoms, 3).astype(np.float32)
    
    # CPUç‰ˆ
    start = time.time()
    positions = np.mean(trajectory.reshape(n_frames, -1, 3), axis=1)
    lambda_f_cpu = np.diff(positions, axis=0)
    cpu_time = time.time() - start
    
    # GPUç‰ˆ
    if cp.cuda.is_available():
        trajectory_gpu = cp.asarray(trajectory)
        
        start = time.time()
        positions_gpu = cp.mean(trajectory_gpu.reshape(n_frames, -1, 3), axis=1)
        lambda_f_gpu = cp.diff(positions_gpu, axis=0)
        cp.cuda.Stream.null.synchronize()
        gpu_time = time.time() - start
        
        speedup = cpu_time / gpu_time
        
        print(f"\nğŸ“Š Results:")
        print(f"   CPU Time: {cpu_time:.3f} seconds")
        print(f"   GPU Time: {gpu_time:.3f} seconds")
        print(f"   Speedup: {speedup:.1f}x ğŸš€")
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
        get_gpu_memory_info()
    else:
        print("   GPU not available for benchmarking")

# ä½¿ã„æ–¹ã®ä¾‹
if __name__ == "__main__":
    print("âœ¨ LambdaÂ³ GPU Optimization Module")
    print("ç’°ã¡ã‚ƒã‚“ã®è¶…æœ€é©åŒ–ç‰ˆï¼ã‚ã¡ã‚ƒãã¡ã‚ƒé€Ÿã„ã‚ˆã€œğŸ’•")
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    benchmark_gpu_performance()
