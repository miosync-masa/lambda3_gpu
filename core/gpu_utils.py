"""
GPU Utilities and Base Classes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

GPU/CPUè‡ªå‹•åˆ‡ã‚Šæ›¿ãˆã¨ã‹ã€ä¾¿åˆ©ãªåŸºåº•ã‚¯ãƒ©ã‚¹ãŒå…¥ã£ã¦ã‚‹ã‚ˆã€œï¼ğŸ’•
by ç’°ã¡ã‚ƒã‚“
"""

import numpy as np
import logging
import time
from typing import Dict, List, Tuple, Optional, Union, Any, Callable, TYPE_CHECKING
from contextlib import contextmanager
from functools import wraps
import warnings

# GPU availability check
try:
    import cupy as cp
    from cupy import cuda
    HAS_GPU = True
    GPU_AVAILABLE = cp.cuda.is_available()
except ImportError:
    HAS_GPU = False
    GPU_AVAILABLE = False
    cp = None
    cuda = None

# å‹ãƒ’ãƒ³ãƒˆç”¨ã®å®šç¾©
if TYPE_CHECKING and cp is not None:
    NDArray = cp.ndarray
else:
    NDArray = Union[np.ndarray, Any]  # Any for when cp is None

logger = logging.getLogger('lambda3_gpu.core.utils')

# ===============================
# GPU Array Type
# ===============================

# çµ±ä¸€çš„ãªé…åˆ—å‹å®šç¾©
if GPU_AVAILABLE:
    ArrayType = Union[np.ndarray, cp.ndarray]
else:
    ArrayType = np.ndarray

# ===============================
# GPU Backend Base Class
# ===============================

class GPUBackend:
    """
    GPU/CPUè‡ªå‹•åˆ‡ã‚Šæ›¿ãˆã®åŸºåº•ã‚¯ãƒ©ã‚¹
    å…¨ã¦ã®GPUå¯¾å¿œã‚¯ãƒ©ã‚¹ã¯ã“ã‚Œã‚’ç¶™æ‰¿ã™ã‚‹ã‚ˆã€œï¼
    """
    
    def __init__(self, 
                 device: Union[str, int] = 'auto',
                 force_cpu: bool = False,
                 mixed_precision: bool = False,
                 profile: bool = False):
        """
        Parameters
        ----------
        device : str or int, default='auto'
            'auto': è‡ªå‹•é¸æŠ
            'cpu': CPUå¼·åˆ¶
            'gpu': GPUå¼·åˆ¶
            0,1,2...: ç‰¹å®šã®GPUç•ªå·
        force_cpu : bool, default=False
            Trueæ™‚ã¯GPUãŒã‚ã£ã¦ã‚‚CPUä½¿ç”¨
        mixed_precision : bool, default=False
            FP16ä½¿ç”¨ã§é«˜é€ŸåŒ–ï¼ˆç²¾åº¦ã¯è½ã¡ã‚‹ï¼‰
        profile : bool, default=False
            ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
        """
        self.force_cpu = force_cpu
        self.mixed_precision = mixed_precision
        self.profile = profile
        self._timers = {}
        
        # ãƒ‡ãƒã‚¤ã‚¹é¸æŠ
        if force_cpu or not GPU_AVAILABLE:
            self.device = 'cpu'
            self.xp = np
            self.is_gpu = False
            logger.info("Using CPU backend")
        else:
            self.device = self._select_device(device)
            self.xp = cp
            self.is_gpu = True
            logger.info(f"Using GPU backend: Device {self.device}")
            
            # Mixed precisionè¨­å®š
            if mixed_precision:
                self._setup_mixed_precision()
    
    def _select_device(self, device: Union[str, int]) -> int:
        """ãƒ‡ãƒã‚¤ã‚¹é¸æŠãƒ­ã‚¸ãƒƒã‚¯"""
        if device == 'auto':
            # è‡ªå‹•é¸æŠï¼šãƒ¡ãƒ¢ãƒªãŒä¸€ç•ªç©ºã„ã¦ã‚‹GPU
            return auto_select_device()
        elif device == 'cpu':
            self.force_cpu = True
            return -1
        elif device == 'gpu':
            return 0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆGPU
        elif isinstance(device, int):
            if device < cp.cuda.runtime.getDeviceCount():
                cp.cuda.Device(device).use()
                return device
            else:
                logger.warning(f"GPU {device} not found, using GPU 0")
                return 0
        else:
            raise ValueError(f"Invalid device: {device}")
    
    def _setup_mixed_precision(self):
        """Mixed precisionè¨­å®š"""
        if self.is_gpu:
            # TensorCoreã‚’æ´»ç”¨
            cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)
            logger.info("Mixed precision (FP16) enabled")
    
    def to_gpu(self, 
               array: np.ndarray, 
               dtype: Optional[np.dtype] = None,
               stream: Optional[Any] = None) -> ArrayType:
        """
        é…åˆ—ã‚’GPUã«è»¢é€ï¼ˆå¿…è¦ãªã‚‰ï¼‰
        """
        if not self.is_gpu:
            return array
            
        if isinstance(array, cp.ndarray):
            return array  # æ—¢ã«GPUä¸Š
            
        # ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›
        if dtype is None:
            dtype = cp.float16 if self.mixed_precision else cp.float32
            
        # ã‚¹ãƒˆãƒªãƒ¼ãƒ æŒ‡å®š
        if stream is not None:
            with stream:
                return cp.asarray(array, dtype=dtype)
        else:
            return cp.asarray(array, dtype=dtype)
    
    def to_cpu(self, array: ArrayType) -> np.ndarray:
        """
        é…åˆ—ã‚’CPUã«è»¢é€ï¼ˆå¿…è¦ãªã‚‰ï¼‰
        """
        if isinstance(array, np.ndarray):
            return array
        elif self.is_gpu and isinstance(array, cp.ndarray):
            return cp.asnumpy(array)
        else:
            return np.asarray(array)
    
    def empty(self, shape: Tuple[int, ...], dtype=None) -> ArrayType:
        """ç©ºé…åˆ—ä½œæˆ"""
        if dtype is None:
            dtype = self.xp.float16 if self.mixed_precision else self.xp.float32
        return self.xp.empty(shape, dtype=dtype)
    
    def zeros(self, shape: Tuple[int, ...], dtype=None) -> ArrayType:
        """ã‚¼ãƒ­é…åˆ—ä½œæˆ"""
        if dtype is None:
            dtype = self.xp.float16 if self.mixed_precision else self.xp.float32
        return self.xp.zeros(shape, dtype=dtype)
    
    def ones(self, shape: Tuple[int, ...], dtype=None) -> ArrayType:
        """1é…åˆ—ä½œæˆ"""
        if dtype is None:
            dtype = self.xp.float16 if self.mixed_precision else self.xp.float32
        return self.xp.ones(shape, dtype=dtype)
    
    @contextmanager
    def timer(self, name: str):
        """
        ã‚¿ã‚¤ãƒãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        
        ä½¿ã„æ–¹:
            with self.timer('my_operation'):
                # æ™‚é–“è¨ˆæ¸¬ã—ãŸã„å‡¦ç†
        """
        if not self.profile:
            yield
            return
            
        start = time.perf_counter()
        if self.is_gpu:
            cp.cuda.Stream.null.synchronize()
            
        yield
        
        if self.is_gpu:
            cp.cuda.Stream.null.synchronize()
        elapsed = time.perf_counter() - start
        
        if name not in self._timers:
            self._timers[name] = []
        self._timers[name].append(elapsed)
        
        logger.debug(f"{name}: {elapsed:.4f} seconds")
    
    def get_timing_stats(self) -> dict:
        """ã‚¿ã‚¤ãƒŸãƒ³ã‚°çµ±è¨ˆã‚’å–å¾—"""
        stats = {}
        for name, times in self._timers.items():
            stats[name] = {
                'count': len(times),
                'total': sum(times),
                'mean': np.mean(times),
                'std': np.std(times),
                'min': min(times),
                'max': max(times)
            }
        return stats
    
    def clear_cache(self):
        """GPUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"""
        if self.is_gpu:
            mempool = cp.get_default_memory_pool()
            mempool.free_all_blocks()
            logger.debug("GPU cache cleared")

# ===============================
# GPU Array Wrapper
# ===============================

class GPUArray:
    """
    GPU/CPUé€éçš„ãªé…åˆ—ãƒ©ãƒƒãƒ‘ãƒ¼
    è‡ªå‹•çš„ã«é©åˆ‡ãªãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’ä½¿ã†ã‚ˆã€œï¼
    """
    
    def __init__(self, 
                 data: Union[np.ndarray, cp.ndarray, List],
                 backend: Optional[GPUBackend] = None,
                 dtype=None):
        """
        Parameters
        ----------
        data : array-like
            å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        backend : GPUBackend, optional
            ä½¿ç”¨ã™ã‚‹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆNoneãªã‚‰è‡ªå‹•ä½œæˆï¼‰
        dtype : dtype, optional
            ãƒ‡ãƒ¼ã‚¿å‹
        """
        if backend is None:
            backend = GPUBackend()
        self.backend = backend
        
        # ãƒ‡ãƒ¼ã‚¿å¤‰æ›
        if isinstance(data, (list, tuple)):
            data = np.array(data)
            
        if backend.is_gpu:
            self._data = backend.to_gpu(data, dtype=dtype)
        else:
            self._data = np.asarray(data, dtype=dtype or np.float32)
    
    @property
    def data(self) -> ArrayType:
        """ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹"""
        return self._data
    
    @property
    def cpu_data(self) -> np.ndarray:
        """CPUç‰ˆãƒ‡ãƒ¼ã‚¿å–å¾—"""
        return self.backend.to_cpu(self._data)
    
    @property
    def shape(self) -> Tuple[int, ...]:
        return self._data.shape
    
    @property
    def dtype(self):
        return self._data.dtype
    
    @property
    def size(self) -> int:
        return self._data.size
    
    def __len__(self) -> int:
        return len(self._data)
    
    def __getitem__(self, key):
        return GPUArray(self._data[key], self.backend)
    
    def __setitem__(self, key, value):
        if isinstance(value, GPUArray):
            self._data[key] = value._data
        else:
            self._data[key] = value
    
    # æ¼”ç®—å­ã‚ªãƒ¼ãƒãƒ¼ãƒ­ãƒ¼ãƒ‰
    def __add__(self, other):
        if isinstance(other, GPUArray):
            return GPUArray(self._data + other._data, self.backend)
        return GPUArray(self._data + other, self.backend)
    
    def __sub__(self, other):
        if isinstance(other, GPUArray):
            return GPUArray(self._data - other._data, self.backend)
        return GPUArray(self._data - other, self.backend)
    
    def __mul__(self, other):
        if isinstance(other, GPUArray):
            return GPUArray(self._data * other._data, self.backend)
        return GPUArray(self._data * other, self.backend)
    
    def __truediv__(self, other):
        if isinstance(other, GPUArray):
            return GPUArray(self._data / other._data, self.backend)
        return GPUArray(self._data / other, self.backend)
    
    def mean(self, axis=None, keepdims=False):
        """å¹³å‡è¨ˆç®—"""
        return GPUArray(self.backend.xp.mean(self._data, axis=axis, keepdims=keepdims), 
                       self.backend)
    
    def std(self, axis=None, keepdims=False):
        """æ¨™æº–åå·®è¨ˆç®—"""
        return GPUArray(self.backend.xp.std(self._data, axis=axis, keepdims=keepdims), 
                       self.backend)
    
    def sum(self, axis=None, keepdims=False):
        """åˆè¨ˆè¨ˆç®—"""
        return GPUArray(self.backend.xp.sum(self._data, axis=axis, keepdims=keepdims), 
                       self.backend)

# ===============================
# Utility Functions
# ===============================

def auto_select_device() -> int:
    """
    è‡ªå‹•çš„ã«æœ€é©ãªGPUã‚’é¸æŠ
    ãƒ¡ãƒ¢ãƒªãŒä¸€ç•ªç©ºã„ã¦ã‚‹ã‚„ã¤ã‚’é¸ã¶ã‚ˆã€œï¼
    """
    if not GPU_AVAILABLE:
        return -1
        
    n_devices = cp.cuda.runtime.getDeviceCount()
    if n_devices == 0:
        return -1
    elif n_devices == 1:
        return 0
        
    # å„GPUã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ã‚’ãƒã‚§ãƒƒã‚¯
    best_device = 0
    max_free_memory = 0
    
    for i in range(n_devices):
        with cp.cuda.Device(i):
            free_mem, total_mem = cp.cuda.runtime.memGetInfo()
            logger.debug(f"GPU {i}: {free_mem/1024**3:.1f}/{total_mem/1024**3:.1f} GB free")
            
            if free_mem > max_free_memory:
                max_free_memory = free_mem
                best_device = i
    
    logger.info(f"Auto-selected GPU {best_device} ({max_free_memory/1024**3:.1f} GB free)")
    return best_device

def get_optimal_block_size(n_threads: int, 
                          max_block_size: int = 1024) -> Tuple[int, int]:
    """
    æœ€é©ãªCUDAãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚ºã¨ã‚°ãƒªãƒƒãƒ‰ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
    """
    if not GPU_AVAILABLE:
        return 1, n_threads
        
    device = cp.cuda.Device()
    
    # ãƒ‡ãƒã‚¤ã‚¹ã®åˆ¶ç´„ã‚’è€ƒæ…®
    max_threads_per_block = device.attributes['MaxThreadsPerBlock']
    max_block_size = min(max_block_size, max_threads_per_block)
    
    # ãƒ¯ãƒ¼ãƒ—ã‚µã‚¤ã‚ºï¼ˆ32ï¼‰ã®å€æ•°ã«èª¿æ•´
    warp_size = 32
    
    if n_threads <= max_block_size:
        # å°ã•ã„å ´åˆã¯ãƒ¯ãƒ¼ãƒ—ã‚µã‚¤ã‚ºã®å€æ•°ã«åˆ‡ã‚Šä¸Šã’
        block_size = ((n_threads + warp_size - 1) // warp_size) * warp_size
        block_size = min(block_size, max_block_size)
        grid_size = 1
    else:
        # å¤§ãã„å ´åˆã¯æœ€å¤§ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚ºã‚’ä½¿ç”¨
        block_size = max_block_size
        grid_size = (n_threads + block_size - 1) // block_size
    
    return grid_size, block_size

def check_gpu_capability(required_capability: Tuple[int, int] = (3, 5)) -> bool:
    """
    GPUã®Compute Capabilityã‚’ãƒã‚§ãƒƒã‚¯
    """
    if not GPU_AVAILABLE:
        return False
        
    device = cp.cuda.Device()
    capability = device.compute_capability
    
    return capability >= required_capability

# ===============================
# GPU Timer
# ===============================

class GPUTimer:
    """
    GPUå‡¦ç†ã®æ­£ç¢ºãªæ™‚é–“è¨ˆæ¸¬
    CUDA Eventã‚’ä½¿ã†ã‚ˆã€œï¼
    """
    
    def __init__(self, name: str = "GPU Operation"):
        self.name = name
        self.gpu_available = GPU_AVAILABLE
        
        if self.gpu_available:
            self.start_event = cp.cuda.Event()
            self.end_event = cp.cuda.Event()
    
    def __enter__(self):
        if self.gpu_available:
            self.start_event.record()
        else:
            self.start_time = time.perf_counter()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.gpu_available:
            self.end_event.record()
            self.end_event.synchronize()
            elapsed = cp.cuda.get_elapsed_time(self.start_event, self.end_event) / 1000.0
        else:
            elapsed = time.perf_counter() - self.start_time
            
        logger.debug(f"{self.name}: {elapsed:.4f} seconds")
        self.elapsed = elapsed

# ===============================
# Decorators
# ===============================

def gpu_accelerated(func):
    """
    GPUåŠ é€Ÿãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿
    è‡ªå‹•çš„ã«GPU/CPUã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã‚ˆã€œï¼
    """
    @wraps(func)
    def wrapper(self, *args, **kwargs):
        if hasattr(self, 'backend') and hasattr(self.backend, 'is_gpu'):
            if self.backend.is_gpu:
                # GPUç‰ˆã®é–¢æ•°ã‚’æ¢ã™
                gpu_func_name = f"{func.__name__}_gpu"
                if hasattr(self, gpu_func_name):
                    return getattr(self, gpu_func_name)(*args, **kwargs)
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆCPUç‰ˆï¼‰
        return func(self, *args, **kwargs)
    
    return wrapper

def profile_gpu(func):
    """
    ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿
    """
    @wraps(func)
    def wrapper(self, *args, **kwargs):
        if hasattr(self, 'backend') and hasattr(self.backend, 'timer'):
            with self.backend.timer(func.__name__):
                return func(self, *args, **kwargs)
        else:
            return func(self, *args, **kwargs)
    
    return wrapper

# ===============================
# Error Handling
# ===============================

def handle_gpu_errors(func):
    """
    GPUé–¢é€£ã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒƒãƒã—ã¦CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except (cp.cuda.memory.OutOfMemoryError, cp.cuda.runtime.CUDARuntimeError) as e:
            logger.warning(f"GPU error in {func.__name__}: {e}")
            logger.warning("Falling back to CPU...")
            
            # self.backend.force_cpu = True ã‚’è¨­å®šã—ã¦å†å®Ÿè¡Œ
            if args and hasattr(args[0], 'backend'):
                original_state = args[0].backend.is_gpu
                args[0].backend.is_gpu = False
                args[0].backend.xp = np
                try:
                    result = func(*args, **kwargs)
                finally:
                    args[0].backend.is_gpu = original_state
                    args[0].backend.xp = cp if original_state else np
                return result
            else:
                raise
    
    return wrapper
