"""
GPU Memory Management System
~~~~~~~~~~~~~~~~~~~~~~~~~~~

GPUãƒ¡ãƒ¢ãƒªã‚’åŠ¹ç‡çš„ã«ç®¡ç†ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã ã‚ˆã€œï¼ğŸ’•
å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚‚ãƒãƒƒãƒå‡¦ç†ã§å‡¦ç†ã§ãã¡ã‚ƒã†ï¼

by ç’°ã¡ã‚ƒã‚“
"""

import numpy as np
import logging
import gc
import warnings
from typing import Dict, List, Tuple, Optional, Union, Any, Callable
from dataclasses import dataclass
from contextlib import contextmanager
import psutil
import os

# GPU imports
try:
    import cupy as cp
    HAS_GPU = True
except ImportError:
    HAS_GPU = False
    cp = None

logger = logging.getLogger('lambda3_gpu.core.memory')

# ===============================
# Memory Info Classes
# ===============================

@dataclass
class MemoryInfo:
    """ãƒ¡ãƒ¢ãƒªæƒ…å ±ã‚’ä¿æŒã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    total: int  # ç·ãƒ¡ãƒ¢ãƒªï¼ˆãƒã‚¤ãƒˆï¼‰
    used: int   # ä½¿ç”¨ä¸­ãƒ¡ãƒ¢ãƒª
    free: int   # ç©ºããƒ¡ãƒ¢ãƒª
    
    @property
    def used_gb(self) -> float:
        return self.used / 1024**3
    
    @property
    def free_gb(self) -> float:
        return self.free / 1024**3
    
    @property
    def total_gb(self) -> float:
        return self.total / 1024**3
    
    @property
    def usage_percent(self) -> float:
        return (self.used / self.total) * 100 if self.total > 0 else 0

# ===============================
# Memory Manager
# ===============================

class GPUMemoryManager:
    """
    GPUãƒ¡ãƒ¢ãƒªç®¡ç†ã‚¯ãƒ©ã‚¹
    ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®è¿½è·¡ã¨æœ€é©åŒ–ã‚’è¡Œã†ã‚ˆã€œï¼
    """
    
    def __init__(self, 
                 max_memory_gb: float = None,
                 reserve_percent: float = 10.0,
                 enable_pooling: bool = True):
        """
        Parameters
        ----------
        max_memory_gb : float, optional
            æœ€å¤§ä½¿ç”¨ãƒ¡ãƒ¢ãƒªï¼ˆGBï¼‰ã€‚Noneãªã‚‰åˆ©ç”¨å¯èƒ½ãªå…¨ãƒ¡ãƒ¢ãƒª
        reserve_percent : float, default=10.0
            äºˆç´„ã—ã¦ãŠããƒ¡ãƒ¢ãƒªã®å‰²åˆï¼ˆ%ï¼‰
        enable_pooling : bool, default=True
            ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
        """
        self.max_memory_gb = max_memory_gb
        self.reserve_percent = reserve_percent
        self.enable_pooling = enable_pooling
        self._allocations: Dict[str, int] = {}
        
        if HAS_GPU and cp.cuda.is_available():
            self._setup_gpu_memory()
        else:
            self._setup_cpu_memory()
    
    def _setup_gpu_memory(self):
        """GPU ãƒ¡ãƒ¢ãƒªè¨­å®š"""
        self.device_type = 'gpu'
        
        # ç¾åœ¨ã®GPUæƒ…å ±å–å¾—
        free_mem, total_mem = cp.cuda.runtime.memGetInfo()
        self.total_memory = total_mem
        
        # æœ€å¤§ãƒ¡ãƒ¢ãƒªè¨­å®š
        if self.max_memory_gb is None:
            # äºˆç´„åˆ†ã‚’å¼•ã„ãŸåˆ†ã‚’ä½¿ç”¨
            usable_memory = total_mem * (1 - self.reserve_percent / 100)
            self.max_memory = int(usable_memory)
        else:
            self.max_memory = int(min(
                self.max_memory_gb * 1024**3,
                total_mem * (1 - self.reserve_percent / 100)
            ))
        
        # ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«è¨­å®š
        if self.enable_pooling:
            mempool = cp.get_default_memory_pool()
            # ãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™
            mempool.set_limit(size=self.max_memory)
        
        logger.info(f"GPU Memory initialized:")
        logger.info(f"  Total: {self.total_memory/1024**3:.1f} GB")
        logger.info(f"  Max usable: {self.max_memory/1024**3:.1f} GB")
        logger.info(f"  Reserve: {self.reserve_percent}%")
    
    def _setup_cpu_memory(self):
        """CPU ãƒ¡ãƒ¢ãƒªè¨­å®šï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        self.device_type = 'cpu'
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªæƒ…å ±
        mem = psutil.virtual_memory()
        self.total_memory = mem.total
        
        if self.max_memory_gb is None:
            # åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªã®80%ã‚’ä½¿ç”¨
            self.max_memory = int(mem.available * 0.8)
        else:
            self.max_memory = int(min(
                self.max_memory_gb * 1024**3,
                mem.available * 0.8
            ))
        
        logger.info(f"CPU Memory initialized:")
        logger.info(f"  Total: {self.total_memory/1024**3:.1f} GB")
        logger.info(f"  Max usable: {self.max_memory/1024**3:.1f} GB")
    
    def get_memory_info(self) -> MemoryInfo:
        """ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªæƒ…å ±ã‚’å–å¾—"""
        if self.device_type == 'gpu' and HAS_GPU:
            free_mem, total_mem = cp.cuda.runtime.memGetInfo()
            used_mem = total_mem - free_mem
            return MemoryInfo(total=total_mem, used=used_mem, free=free_mem)
        else:
            mem = psutil.virtual_memory()
            return MemoryInfo(total=mem.total, used=mem.used, free=mem.available)
    
    def allocate(self, 
                 size_bytes: int, 
                 name: str = None,
                 dtype=np.float32) -> bool:
        """
        ãƒ¡ãƒ¢ãƒªå‰²ã‚Šå½“ã¦å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
        
        Parameters
        ----------
        size_bytes : int
            å¿…è¦ãªãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰
        name : str, optional
            å‰²ã‚Šå½“ã¦åï¼ˆè¿½è·¡ç”¨ï¼‰
        dtype : dtype
            ãƒ‡ãƒ¼ã‚¿å‹
            
        Returns
        -------
        bool
            å‰²ã‚Šå½“ã¦å¯èƒ½ãªã‚‰True
        """
        mem_info = self.get_memory_info()
        
        # æ—¢å­˜ã®å‰²ã‚Šå½“ã¦ã‚’è€ƒæ…®
        total_allocated = sum(self._allocations.values())
        available = min(mem_info.free, self.max_memory - total_allocated)
        
        if size_bytes > available:
            logger.warning(
                f"Memory allocation failed: "
                f"requested {size_bytes/1024**3:.2f} GB, "
                f"available {available/1024**3:.2f} GB"
            )
            return False
        
        if name:
            self._allocations[name] = size_bytes
            logger.debug(f"Allocated {size_bytes/1024**3:.2f} GB for '{name}'")
        
        return True
    
    def free(self, name: str):
        """ãƒ¡ãƒ¢ãƒªå‰²ã‚Šå½“ã¦ã‚’è§£æ”¾"""
        if name in self._allocations:
            size = self._allocations.pop(name)
            logger.debug(f"Freed {size/1024**3:.2f} GB from '{name}'")
    
    def estimate_batch_size(self,
                           data_shape: Tuple[int, ...],
                           dtype=np.float32,
                           operations_multiplier: float = 3.0) -> int:
        """
        åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªã‹ã‚‰æœ€é©ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æ¨å®š
        
        Parameters
        ----------
        data_shape : tuple
            ãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶ï¼ˆãƒãƒƒãƒæ¬¡å…ƒã‚’å«ã‚€ï¼‰
        dtype : dtype
            ãƒ‡ãƒ¼ã‚¿å‹
        operations_multiplier : float
            å‡¦ç†ã«å¿…è¦ãªè¿½åŠ ãƒ¡ãƒ¢ãƒªã®å€ç‡
            
        Returns
        -------
        int
            æ¨å¥¨ãƒãƒƒãƒã‚µã‚¤ã‚º
        """
        # 1è¦ç´ ã‚ãŸã‚Šã®ãƒ¡ãƒ¢ãƒª
        element_size = np.dtype(dtype).itemsize
        elements_per_batch = np.prod(data_shape[1:])  # ãƒãƒƒãƒæ¬¡å…ƒä»¥å¤–
        bytes_per_batch = elements_per_batch * element_size
        
        # å‡¦ç†ç”¨ã®ä½™è£•ã‚’è€ƒæ…®
        required_per_batch = bytes_per_batch * operations_multiplier
        
        # åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª
        mem_info = self.get_memory_info()
        available = min(
            mem_info.free * 0.8,  # 80%ã¾ã§ä½¿ç”¨
            self.max_memory - sum(self._allocations.values())
        )
        
        # ãƒãƒƒãƒã‚µã‚¤ã‚ºè¨ˆç®—
        batch_size = int(available / required_per_batch)
        batch_size = max(1, batch_size)  # æœ€ä½1
        
        logger.info(
            f"Estimated batch size: {batch_size} "
            f"(available: {available/1024**3:.1f} GB, "
            f"per batch: {required_per_batch/1024**3:.3f} GB)"
        )
        
        return batch_size
    
    @contextmanager
    def temporary_allocation(self, size_bytes: int, name: str = "temp"):
        """
        ä¸€æ™‚çš„ãªãƒ¡ãƒ¢ãƒªå‰²ã‚Šå½“ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        
        ä½¿ã„æ–¹:
            with memory_manager.temporary_allocation(1024**3, "temp_buffer"):
                # ãƒ¡ãƒ¢ãƒªã‚’ä½¿ã†å‡¦ç†
        """
        allocated = self.allocate(size_bytes, name)
        if not allocated:
            raise MemoryError(f"Failed to allocate {size_bytes/1024**3:.2f} GB")
        
        try:
            yield
        finally:
            self.free(name)
    
    def clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        if self.device_type == 'gpu' and HAS_GPU:
            mempool = cp.get_default_memory_pool()
            pinned_mempool = cp.get_default_pinned_memory_pool()
            mempool.free_all_blocks()
            pinned_mempool.free_all_blocks()
            logger.info("GPU cache cleared")
        
        # Python GC
        gc.collect()
    
    def get_allocation_summary(self) -> str:
        """å‰²ã‚Šå½“ã¦çŠ¶æ³ã®ã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
        mem_info = self.get_memory_info()
        
        summary = [
            f"\n{'='*50}",
            f"Memory Status ({self.device_type.upper()})",
            f"{'='*50}",
            f"Total Memory: {mem_info.total_gb:.1f} GB",
            f"Used Memory: {mem_info.used_gb:.1f} GB ({mem_info.usage_percent:.1f}%)",
            f"Free Memory: {mem_info.free_gb:.1f} GB",
            f"Max Allowed: {self.max_memory/1024**3:.1f} GB",
            f"\nAllocations:"
        ]
        
        if self._allocations:
            for name, size in sorted(self._allocations.items(), 
                                    key=lambda x: x[1], reverse=True):
                summary.append(f"  {name}: {size/1024**3:.2f} GB")
        else:
            summary.append("  (none)")
        
        summary.append(f"{'='*50}\n")
        
        return '\n'.join(summary)

# ===============================
# Memory Pool
# ===============================

class GPUMemoryPool:
    """
    å†åˆ©ç”¨å¯èƒ½ãªãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«
    é »ç¹ãªå‰²ã‚Šå½“ã¦/è§£æ”¾ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å‰Šæ¸›ã™ã‚‹ã‚ˆã€œï¼
    """
    
    def __init__(self, 
                 block_size: int = 1024**3,  # 1GB
                 max_blocks: int = 10):
        """
        Parameters
        ----------
        block_size : int
            ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰
        max_blocks : int
            æœ€å¤§ãƒ–ãƒ­ãƒƒã‚¯æ•°
        """
        self.block_size = block_size
        self.max_blocks = max_blocks
        self._pool: List[Any] = []
        self._in_use: Dict[int, Any] = {}
        
        self.is_gpu = HAS_GPU and cp.cuda.is_available()
        self.xp = cp if self.is_gpu else np
    
    def get_block(self, size: int = None) -> Tuple[int, Any]:
        """
        ãƒ–ãƒ­ãƒƒã‚¯ã‚’å–å¾—
        
        Returns
        -------
        block_id : int
            ãƒ–ãƒ­ãƒƒã‚¯ID
        block : array
            ãƒ¡ãƒ¢ãƒªãƒ–ãƒ­ãƒƒã‚¯
        """
        if size is None:
            size = self.block_size
        
        # ãƒ—ãƒ¼ãƒ«ã‹ã‚‰æ¢ã™
        for i, block in enumerate(self._pool):
            if block.size * block.itemsize >= size:
                block = self._pool.pop(i)
                block_id = id(block)
                self._in_use[block_id] = block
                logger.debug(f"Reused block {block_id} from pool")
                return block_id, block
        
        # æ–°è¦ä½œæˆ
        if len(self._pool) + len(self._in_use) < self.max_blocks:
            block = self.xp.empty(size // 4, dtype=self.xp.float32)
            block_id = id(block)
            self._in_use[block_id] = block
            logger.debug(f"Created new block {block_id}")
            return block_id, block
        
        raise MemoryError("Memory pool exhausted")
    
    def release_block(self, block_id: int):
        """ãƒ–ãƒ­ãƒƒã‚¯ã‚’è§£æ”¾ï¼ˆãƒ—ãƒ¼ãƒ«ã«æˆ»ã™ï¼‰"""
        if block_id in self._in_use:
            block = self._in_use.pop(block_id)
            if len(self._pool) < self.max_blocks:
                self._pool.append(block)
                logger.debug(f"Released block {block_id} to pool")
            else:
                logger.debug(f"Released block {block_id} (pool full)")
    
    def clear(self):
        """ãƒ—ãƒ¼ãƒ«ã‚’ã‚¯ãƒªã‚¢"""
        self._pool.clear()
        self._in_use.clear()
        logger.info("Memory pool cleared")

# ===============================
# Batch Processor
# ===============================

class BatchProcessor:
    """
    å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
    ãƒ¡ãƒ¢ãƒªã«åã¾ã‚‰ãªã„ãƒ‡ãƒ¼ã‚¿ã‚‚å‡¦ç†ã§ãã‚‹ã‚ˆã€œï¼
    """
    
    def __init__(self, 
                 memory_manager: GPUMemoryManager,
                 overlap_frames: int = 0):
        """
        Parameters
        ----------
        memory_manager : GPUMemoryManager
            ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        overlap_frames : int
            ãƒãƒƒãƒé–“ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ï¼ˆå¢ƒç•Œå‡¦ç†ç”¨ï¼‰
        """
        self.memory_manager = memory_manager
        self.overlap_frames = overlap_frames
        self.is_gpu = memory_manager.device_type == 'gpu'
    
    def process_batched(self,
                       data: np.ndarray,
                       process_func: Callable,
                       axis: int = 0,
                       batch_size: Optional[int] = None,
                       dtype=np.float32,
                       return_type: str = 'concat',
                       progress_callback: Optional[Callable] = None,
                       **kwargs) -> Union[np.ndarray, List[np.ndarray]]:
        """
        ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒå‡¦ç†
        
        Parameters
        ----------
        data : np.ndarray
            å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        process_func : callable
            å„ãƒãƒƒãƒã«é©ç”¨ã™ã‚‹é–¢æ•°
        axis : int
            ãƒãƒƒãƒåˆ†å‰²ã™ã‚‹è»¸
        batch_size : int, optional
            ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆNoneãªã‚‰è‡ªå‹•è¨ˆç®—ï¼‰
        dtype : dtype
            å‡¦ç†æ™‚ã®ãƒ‡ãƒ¼ã‚¿å‹
        return_type : str
            'concat': çµæœã‚’çµåˆã—ã¦è¿”ã™
            'list': ãƒãƒƒãƒã”ã¨ã®ãƒªã‚¹ãƒˆã§è¿”ã™
        progress_callback : callable, optional
            é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯(current, total)
        **kwargs
            process_funcã«æ¸¡ã™è¿½åŠ å¼•æ•°
            
        Returns
        -------
        result : array or list
            å‡¦ç†çµæœ
        """
        # ãƒãƒƒãƒã‚µã‚¤ã‚ºæ±ºå®š
        if batch_size is None:
            # ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ã‹ã‚‰ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æ¨å®š
            batch_shape = list(data.shape)
            batch_shape[axis] = 1
            
            batch_size = self.memory_manager.estimate_batch_size(
                batch_shape, dtype=dtype
            )
        
        # ãƒãƒƒãƒå‡¦ç†
        n_samples = data.shape[axis]
        n_batches = (n_samples + batch_size - 1) // batch_size
        
        logger.info(
            f"Batch processing: {n_samples} samples, "
            f"{n_batches} batches of size {batch_size}"
        )
        
        results = []
        
        for i in range(n_batches):
            # ãƒãƒƒãƒç¯„å›²
            start_idx = i * batch_size
            end_idx = min((i + 1) * batch_size + self.overlap_frames, n_samples)
            
            # ã‚¹ãƒ©ã‚¤ã‚¹ä½œæˆ
            slices = [slice(None)] * data.ndim
            slices[axis] = slice(start_idx, end_idx)
            batch_data = data[tuple(slices)]
            
            # GPUè»¢é€ï¼ˆå¿…è¦ãªã‚‰ï¼‰
            if self.is_gpu and HAS_GPU:
                batch_data = cp.asarray(batch_data, dtype=dtype)
            
            # å‡¦ç†å®Ÿè¡Œ
            with self.memory_manager.temporary_allocation(
                batch_data.nbytes, f"batch_{i}"
            ):
                batch_result = process_func(batch_data, **kwargs)
                
                # CPUè»¢é€ï¼ˆå¿…è¦ãªã‚‰ï¼‰
                if self.is_gpu and HAS_GPU and isinstance(batch_result, cp.ndarray):
                    batch_result = cp.asnumpy(batch_result)
                
                # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—é™¤å»
                if self.overlap_frames > 0 and i < n_batches - 1:
                    if isinstance(batch_result, np.ndarray):
                        trim_slices = [slice(None)] * batch_result.ndim
                        trim_slices[axis] = slice(None, -self.overlap_frames)
                        batch_result = batch_result[tuple(trim_slices)]
                
                results.append(batch_result)
            
            # é€²æ—é€šçŸ¥
            if progress_callback:
                progress_callback(i + 1, n_batches)
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
            if i % 10 == 0:  # 10ãƒãƒƒãƒã”ã¨
                self.memory_manager.clear_cache()
        
        # çµæœã®çµåˆ
        if return_type == 'concat' and results:
            if isinstance(results[0], np.ndarray):
                return np.concatenate(results, axis=axis)
            else:
                logger.warning("Cannot concatenate non-array results")
                return results
        else:
            return results

# ===============================
# Utility Functions
# ===============================

def estimate_memory_usage(shape: Tuple[int, ...], 
                         dtype=np.float32,
                         operations: List[str] = None) -> Dict[str, float]:
    """
    ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æ¨å®š
    
    Parameters
    ----------
    shape : tuple
        ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶
    dtype : dtype
        ãƒ‡ãƒ¼ã‚¿å‹
    operations : list of str
        å®Ÿè¡Œã™ã‚‹æ“ä½œã®ãƒªã‚¹ãƒˆ
        
    Returns
    -------
    dict
        ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¨å®šå€¤ï¼ˆGBï¼‰
    """
    # åŸºæœ¬ãƒ¡ãƒ¢ãƒª
    element_size = np.dtype(dtype).itemsize
    n_elements = np.prod(shape)
    base_memory = n_elements * element_size
    
    estimates = {
        'input': base_memory / 1024**3,
        'operations': 0,
        'output': base_memory / 1024**3,
        'total': 0
    }
    
    # æ“ä½œã”ã¨ã®è¿½åŠ ãƒ¡ãƒ¢ãƒª
    if operations:
        operation_multipliers = {
            'fft': 2.0,
            'conv': 3.0,
            'matmul': 2.5,
            'gradient': 1.5,
            'sort': 1.5,
            'cumsum': 1.0
        }
        
        for op in operations:
            multiplier = operation_multipliers.get(op, 1.0)
            estimates['operations'] += base_memory * multiplier / 1024**3
    
    estimates['total'] = sum(estimates.values()) - estimates['total']
    
    return estimates

def clear_gpu_cache():
    """GPUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å®Œå…¨ã«ã‚¯ãƒªã‚¢"""
    if HAS_GPU and cp.cuda.is_available():
        # CuPyãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«
        mempool = cp.get_default_memory_pool()
        pinned_mempool = cp.get_default_pinned_memory_pool()
        
        mempool.free_all_blocks()
        pinned_mempool.free_all_blocks()
        
        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        gc.collect()
        
        # CUDAåŒæœŸ
        cp.cuda.Stream.null.synchronize()
        
        logger.info("GPU cache cleared completely")

def get_memory_summary() -> str:
    """
    ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªçŠ¶æ³ã®ã‚µãƒãƒªãƒ¼ã‚’å–å¾—
    """
    lines = ["\n" + "="*60, "Memory Summary", "="*60]
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª
    mem = psutil.virtual_memory()
    lines.extend([
        f"\nSystem Memory:",
        f"  Total: {mem.total/1024**3:.1f} GB",
        f"  Used: {mem.used/1024**3:.1f} GB ({mem.percent:.1f}%)",
        f"  Available: {mem.available/1024**3:.1f} GB"
    ])
    
    # GPUãƒ¡ãƒ¢ãƒª
    if HAS_GPU and cp.cuda.is_available():
        free_mem, total_mem = cp.cuda.runtime.memGetInfo()
        used_mem = total_mem - free_mem
        lines.extend([
            f"\nGPU Memory:",
            f"  Total: {total_mem/1024**3:.1f} GB",
            f"  Used: {used_mem/1024**3:.1f} GB ({used_mem/total_mem*100:.1f}%)",
            f"  Free: {free_mem/1024**3:.1f} GB"
        ])
        
        # ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«çŠ¶æ³
        mempool = cp.get_default_memory_pool()
        lines.extend([
            f"\nCuPy Memory Pool:",
            f"  Used blocks: {mempool.used_bytes()/1024**3:.2f} GB",
            f"  Total blocks: {mempool.total_bytes()/1024**3:.2f} GB"
        ])
    
    lines.append("="*60 + "\n")
    
    return '\n'.join(lines)

# ã‚¨ãƒ©ãƒ¼å‡¦ç†
class MemoryError(Exception):
    """ãƒ¡ãƒ¢ãƒªé–¢é€£ã‚¨ãƒ©ãƒ¼"""
    pass
