#!/usr/bin/env python3
"""
Cluster Network Analysis for Materials (GPU Version) - v4.0 Design Unified
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é–“ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æã®GPUå®Ÿè£… - ææ–™ç‰ˆï¼
é‡‘å±ã®è»¢ä½ä¼æ’­ãƒ»æ­ªã¿å ´ãƒ»äº€è£‚é€²å±•ã‚’è§£æğŸ’

Version: 4.0-material
by ç’°ã¡ã‚ƒã‚“ - Material Edition
"""

import numpy as np
import logging
from typing import Dict, List, Optional, Tuple, Union, Any, Set
from dataclasses import dataclass, field
from collections import defaultdict

# GPU imports
try:
    import cupy as cp
    from cupyx.scipy.spatial.distance import cdist as cp_cdist
    HAS_GPU = True
except ImportError:
    HAS_GPU = False
    cp = None

# Local imports
from ..types import ArrayType, NDArray
from ..core import GPUBackend, GPUMemoryManager, handle_gpu_errors
from .cluster_id_mapping import ClusterIDMapper

logger = logging.getLogger('lambda3_gpu.material.network')

# ===============================
# Data Classes (Materialç‰ˆ)
# ===============================

@dataclass
class MaterialNetworkLink:
    """ææ–™ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒªãƒ³ã‚¯"""
    from_cluster: int
    to_cluster: int
    strength: float
    lag: int = 0
    distance: Optional[float] = None
    strain_correlation: Optional[float] = None  # æ­ªã¿ç›¸é–¢
    link_type: str = 'elastic'  # 'elastic', 'plastic', 'fracture', 'dislocation'
    confidence: float = 1.0
    damage_signature: Optional[str] = None  # 'crack_initiation', 'void_growth', etc.
    element_bridge: Optional[Tuple[str, str]] = None  # å…ƒç´ é–“ãƒ–ãƒªãƒƒã‚¸ï¼ˆFe-Cç­‰ï¼‰

@dataclass
class ClusterNetworkResult:
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æçµæœ"""
    strain_network: List[MaterialNetworkLink]  # æ­ªã¿ä¼æ’­ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    dislocation_network: List[MaterialNetworkLink]  # è»¢ä½ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    damage_network: List[MaterialNetworkLink]  # æå‚·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    spatial_constraints: Dict[Tuple[int, int], float]
    adaptive_windows: Dict[int, int]
    network_stats: Dict[str, Any]
    critical_clusters: List[int]  # è‡¨ç•Œã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ï¼ˆç ´å£Šèµ·ç‚¹å€™è£œï¼‰
    
    @property
    def n_strain_links(self) -> int:
        return len(self.strain_network)
    
    @property
    def n_dislocation_links(self) -> int:
        return len(self.dislocation_network)
    
    @property
    def n_damage_links(self) -> int:
        return len(self.damage_network)

# ===============================
# CUDA Kernels (Materialç‰ˆ)
# ===============================

STRAIN_CORRELATION_KERNEL = r'''
extern "C" __global__
void compute_strain_correlation_kernel(
    const float* __restrict__ strain_tensors,  // (n_clusters, 3, 3)
    float* __restrict__ correlations,         // (n_pairs,)
    const int* __restrict__ pair_indices,     // (n_pairs, 2)
    const int n_pairs,
    const int n_clusters
) {
    const int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (idx >= n_pairs) return;
    
    const int cluster_i = pair_indices[idx * 2 + 0];
    const int cluster_j = pair_indices[idx * 2 + 1];
    
    // æ­ªã¿ãƒ†ãƒ³ã‚½ãƒ«ã®ç›¸é–¢è¨ˆç®—
    float correlation = 0.0f;
    
    for (int i = 0; i < 3; i++) {
        for (int j = 0; j < 3; j++) {
            const int idx_i = cluster_i * 9 + i * 3 + j;
            const int idx_j = cluster_j * 9 + i * 3 + j;
            
            correlation += strain_tensors[idx_i] * strain_tensors[idx_j];
        }
    }
    
    // Frobeniuså†…ç©ã‚’æ­£è¦åŒ–
    correlations[idx] = correlation / 9.0f;
}
'''

DISLOCATION_DETECTION_KERNEL = r'''
extern "C" __global__
void detect_dislocation_kernel(
    const float* __restrict__ coordination,   // (n_clusters,)
    const float* __restrict__ strain,        // (n_clusters, 3, 3)
    bool* __restrict__ is_dislocation,       // (n_clusters,)
    float* __restrict__ dislocation_strength, // (n_clusters,)
    const int n_clusters,
    const float coord_threshold,
    const float strain_threshold
) {
    const int cluster_id = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (cluster_id >= n_clusters) return;
    
    // é…ä½æ•°æ¬ é™¥ãƒã‚§ãƒƒã‚¯
    float coord_defect = fabs(coordination[cluster_id] - 12.0f);  // FCCç†æƒ³å€¤
    
    // æ­ªã¿ã®ãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆä½“ç©æ­ªã¿ï¼‰
    float strain_trace = 0.0f;
    for (int i = 0; i < 3; i++) {
        strain_trace += strain[cluster_id * 9 + i * 3 + i];
    }
    
    // è»¢ä½åˆ¤å®š
    if (coord_defect > coord_threshold && fabs(strain_trace) > strain_threshold) {
        is_dislocation[cluster_id] = true;
        dislocation_strength[cluster_id] = coord_defect * fabs(strain_trace);
    } else {
        is_dislocation[cluster_id] = false;
        dislocation_strength[cluster_id] = 0.0f;
    }
}
'''

# ===============================
# ClusterNetworkGPU Class
# ===============================

class ClusterNetworkGPU(GPUBackend):
    """
    ææ–™ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æã®GPUå®Ÿè£…
    æ­ªã¿ä¼æ’­ãƒ»è»¢ä½ç§»å‹•ãƒ»äº€è£‚é€²å±•ã‚’è¿½è·¡
    """
    
    def __init__(self,
                 max_interaction_distance: float = 10.0,  # ææ–™ã¯çŸ­ã„
                 strain_threshold: float = 0.01,  # æ­ªã¿é–¾å€¤
                 coord_defect_threshold: float = 1.0,  # é…ä½æ•°æ¬ é™¥é–¾å€¤
                 min_damage_strength: float = 0.3,
                 max_damage_links: int = 200,
                 memory_manager: Optional[GPUMemoryManager] = None,
                 **kwargs):
        super().__init__(**kwargs)
        self.max_interaction_distance = max_interaction_distance
        self.strain_threshold = strain_threshold
        self.coord_defect_threshold = coord_defect_threshold
        self.min_damage_strength = min_damage_strength
        self.max_damage_links = max_damage_links
        self.memory_manager = memory_manager or GPUMemoryManager()

        # ğŸ†• è¿½åŠ 
        self.id_mapper = None
        
        # ã‚«ãƒ¼ãƒãƒ«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
        if self.is_gpu and HAS_GPU:
            self._compile_kernels()
    
    def _compile_kernels(self):
        """ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«"""
        try:
            self.strain_corr_kernel = cp.RawKernel(
                STRAIN_CORRELATION_KERNEL, 'compute_strain_correlation_kernel'
            )
            self.dislocation_kernel = cp.RawKernel(
                DISLOCATION_DETECTION_KERNEL, 'detect_dislocation_kernel'
            )
            logger.debug("Material network kernels compiled successfully")
        except Exception as e:
            logger.warning(f"Failed to compile custom kernels: {e}")
            self.strain_corr_kernel = None
            self.dislocation_kernel = None
    
    @handle_gpu_errors
    def analyze_network(self,
                       cluster_anomaly_scores: Dict[int, np.ndarray],
                       cluster_coupling: np.ndarray,
                       cluster_centers: Optional[np.ndarray] = None,
                       coordination_numbers: Optional[np.ndarray] = None,
                       local_strain: Optional[np.ndarray] = None,
                       element_composition: Optional[Dict] = None,
                       lag_window: int = 100) -> ClusterNetworkResult:
        """
        ææ–™ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è§£æ
        
        Parameters
        ----------
        cluster_anomaly_scores : å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ç•°å¸¸ã‚¹ã‚³ã‚¢æ™‚ç³»åˆ—
        cluster_coupling : ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é–“ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°
        cluster_centers : ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é‡å¿ƒåº§æ¨™
        coordination_numbers : é…ä½æ•°
        local_strain : å±€æ‰€æ­ªã¿ãƒ†ãƒ³ã‚½ãƒ«
        element_composition : å…ƒç´ çµ„æˆ
        lag_window : ãƒ©ã‚°çª“ã‚µã‚¤ã‚º
        """
        with self.timer('analyze_material_network'):
            logger.info("âš™ï¸ Analyzing material cluster network")
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ç¢ºèª
            if not cluster_anomaly_scores:
                logger.warning("No anomaly scores provided")
                return self._create_empty_result()
            
            first_score = next(iter(cluster_anomaly_scores.values()))
            n_frames = len(first_score)
            
            if n_frames <= 0:
                logger.warning("No frames to analyze")
                return self._create_empty_result()
            
            cluster_ids = sorted(cluster_anomaly_scores.keys())
            
            # ğŸ†• IDãƒãƒƒãƒ‘ãƒ¼åˆæœŸåŒ–
            dummy_atoms = {cid: [] for cid in cluster_ids}
            self.id_mapper = ClusterIDMapper(dummy_atoms)
            
            # ========================================
            # ææ–™ç‰¹æœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¤å®š
            # ========================================
            
            material_pattern = self._detect_material_pattern(
                cluster_anomaly_scores,
                coordination_numbers,
                local_strain,
                n_frames
            )
            
            logger.info(f"   Material pattern: {material_pattern}")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥è§£æ
            if material_pattern == 'elastic_deformation':
                return self._analyze_elastic_pattern(
                    cluster_anomaly_scores, cluster_coupling, 
                    cluster_centers, local_strain
                )
            elif material_pattern == 'plastic_deformation':
                return self._analyze_plastic_pattern(
                    cluster_anomaly_scores, cluster_coupling,
                    cluster_centers, coordination_numbers, local_strain
                )
            elif material_pattern == 'fracture_initiation':
                return self._analyze_fracture_pattern(
                    cluster_anomaly_scores, cluster_coupling,
                    cluster_centers, coordination_numbers, 
                    local_strain, element_composition
                )
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè§£æ
                return self._analyze_general_pattern(
                    cluster_anomaly_scores, cluster_coupling,
                    cluster_centers, lag_window
                )
    
    def _detect_material_pattern(self,
                                anomaly_scores: Dict[int, np.ndarray],
                                coordination_numbers: Optional[np.ndarray],
                                local_strain: Optional[np.ndarray],
                                n_frames: int) -> str:
        """ææ–™å¤‰å½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º"""
        
        # æ­ªã¿ãƒ¬ãƒ™ãƒ«ãƒã‚§ãƒƒã‚¯
        if local_strain is not None and local_strain.size > 0:
            max_strain = np.max(np.abs(local_strain))
            
            if max_strain < 0.01:  # 1%æœªæº€
                return 'elastic_deformation'
            elif max_strain < 0.05:  # 5%æœªæº€
                # é…ä½æ•°æ¬ é™¥ãƒã‚§ãƒƒã‚¯
                if coordination_numbers is not None:
                    coord_defects = np.abs(coordination_numbers - 12.0)  # FCCç†æƒ³
                    if np.max(coord_defects) > 2:
                        return 'plastic_deformation'
            elif max_strain > 0.1:  # 10%ä»¥ä¸Š
                return 'fracture_initiation'
        
        # ç•°å¸¸ã‚¹ã‚³ã‚¢ãƒ‘ã‚¿ãƒ¼ãƒ³
        max_anomaly = max(np.max(scores) for scores in anomaly_scores.values())
        if max_anomaly > 3.0:
            return 'fracture_initiation'
        
        return 'general_deformation'
    
    # _analyze_elastic_pattern ãƒ¡ã‚½ãƒƒãƒ‰ã®ä¿®æ­£ï¼ˆé‡è¦ï¼ï¼‰
    def _analyze_elastic_pattern(self,
                                anomaly_scores: Dict[int, np.ndarray],
                                cluster_coupling: np.ndarray,
                                cluster_centers: np.ndarray,
                                local_strain: np.ndarray) -> ClusterNetworkResult:
        """å¼¾æ€§å¤‰å½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è§£æ"""
        
        cluster_ids = sorted(anomaly_scores.keys())
        
        # æ­ªã¿ç›¸é–¢ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        strain_links = []
        
        if local_strain is not None and local_strain.shape[0] > 0:
            # æœ€æ–°ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ­ªã¿
            current_strain = local_strain[-1] if local_strain.ndim == 4 else local_strain
            
            for i, cluster_i in enumerate(cluster_ids):
                for j, cluster_j in enumerate(cluster_ids[i+1:], i+1):
                    # ğŸ†• IDã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¤‰æ›
                    idx_i = self.id_mapper.to_idx(cluster_i)
                    idx_j = self.id_mapper.to_idx(cluster_j)
                    
                    if idx_i >= len(current_strain) or idx_j >= len(current_strain):
                        continue
                    
                    # ğŸ†• ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§é…åˆ—ã‚¢ã‚¯ã‚»ã‚¹
                    strain_i = current_strain[idx_i]
                    strain_j = current_strain[idx_j]
                    
                    correlation = np.sum(strain_i * strain_j) / 9.0
                    
                    if abs(correlation) > 0.1:
                        link = MaterialNetworkLink(
                            from_cluster=cluster_i,  # å®Ÿéš›ã®IDã‚’ä¿å­˜
                            to_cluster=cluster_j,    # å®Ÿéš›ã®IDã‚’ä¿å­˜
                            strength=abs(correlation),
                            strain_correlation=correlation,
                            link_type='elastic',
                            damage_signature='elastic_coupling'
                        )
                        strain_links.append(link)
        
        # ç©ºé–“åˆ¶ç´„
        spatial_constraints = self._compute_spatial_constraints(
            cluster_ids, cluster_centers
        ) if cluster_centers is not None else {}
        
        # çµ±è¨ˆ
        network_stats = {
            'pattern': 'elastic_deformation',
            'n_strain_links': len(strain_links),
            'max_strain': float(np.max(np.abs(local_strain))) if local_strain is not None else 0
        }
        
        return ClusterNetworkResult(
            strain_network=strain_links,
            dislocation_network=[],
            damage_network=[],
            spatial_constraints=spatial_constraints,
            adaptive_windows={},
            network_stats=network_stats,
            critical_clusters=[]
        )

    # _analyze_plastic_pattern ãƒ¡ã‚½ãƒƒãƒ‰ã®ä¿®æ­£
    def _analyze_plastic_pattern(self,
                                anomaly_scores: Dict[int, np.ndarray],
                                cluster_coupling: np.ndarray,
                                cluster_centers: np.ndarray,
                                coordination_numbers: np.ndarray,
                                local_strain: np.ndarray) -> ClusterNetworkResult:
        """å¡‘æ€§å¤‰å½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è§£æï¼ˆè»¢ä½æ¤œå‡ºï¼‰"""
        
        cluster_ids = sorted(anomaly_scores.keys())
        
        # è»¢ä½æ¤œå‡º
        dislocation_clusters = []
        dislocation_links = []
        
        if coordination_numbers is not None and local_strain is not None:
            # æœ€æ–°ãƒ•ãƒ¬ãƒ¼ãƒ 
            current_coord = coordination_numbers[-1] if coordination_numbers.ndim == 2 else coordination_numbers
            current_strain = local_strain[-1] if local_strain.ndim == 4 else local_strain
            
            # è»¢ä½åˆ¤å®š
            for cluster_id in cluster_ids:
                # ğŸ†• IDã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¤‰æ›
                idx = self.id_mapper.to_idx(cluster_id)
                
                if idx >= len(current_coord):
                    continue
                
                # ğŸ†• ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§é…åˆ—ã‚¢ã‚¯ã‚»ã‚¹
                coord_defect = abs(current_coord[idx] - 12.0)
                strain_trace = np.trace(current_strain[idx])
                
                if coord_defect > self.coord_defect_threshold and abs(strain_trace) > self.strain_threshold:
                    dislocation_clusters.append(cluster_id) 
                
            # è»¢ä½ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰
            for i, cluster_i in enumerate(dislocation_clusters):
                for j, cluster_j in enumerate(dislocation_clusters[i+1:], i+1):
                    # è»¢ä½é–“ç›¸äº’ä½œç”¨
                    distance = self._compute_distance(
                        cluster_centers, cluster_i, cluster_j
                    ) if cluster_centers is not None else 10.0
                    
                    if distance < self.max_interaction_distance:
                        strength = 1.0 / (1.0 + distance)
                        
                        link = MaterialNetworkLink(
                            from_cluster=cluster_i,
                            to_cluster=cluster_j,
                            strength=strength,
                            distance=distance,
                            link_type='plastic',
                            damage_signature='dislocation_interaction'
                        )
                        dislocation_links.append(link)
        
        # æ­ªã¿ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚‚è¨ˆç®—
        strain_links = self._compute_strain_network(
            cluster_ids, local_strain
        ) if local_strain is not None else []
        
        # çµ±è¨ˆ
        network_stats = {
            'pattern': 'plastic_deformation',
            'n_dislocations': len(dislocation_clusters),
            'n_dislocation_links': len(dislocation_links)
        }
        
        return ClusterNetworkResult(
            strain_network=strain_links,
            dislocation_network=dislocation_links,
            damage_network=[],
            spatial_constraints={},
            adaptive_windows={},
            network_stats=network_stats,
            critical_clusters=dislocation_clusters
        )
    
    def _analyze_fracture_pattern(self,
                                 anomaly_scores: Dict[int, np.ndarray],
                                 cluster_coupling: np.ndarray,
                                 cluster_centers: np.ndarray,
                                 coordination_numbers: np.ndarray,
                                 local_strain: np.ndarray,
                                 element_composition: Optional[Dict]) -> ClusterNetworkResult:
        """ç ´å£Šé–‹å§‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è§£æ"""
        
        cluster_ids = sorted(anomaly_scores.keys())
        
        # è‡¨ç•Œã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ¤œå‡º
        critical_clusters = []
        damage_links = []
        
        # é«˜ç•°å¸¸ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼
        for cluster_id, scores in anomaly_scores.items():
            if np.max(scores) > 3.0:
                critical_clusters.append(cluster_id)
        
        logger.info(f"   Found {len(critical_clusters)} critical clusters")
        
        # æå‚·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰
        for i, cluster_i in enumerate(critical_clusters):
            for j, cluster_j in enumerate(critical_clusters[i+1:], i+1):
                # æå‚·ä¼æ’­å¼·åº¦
                score_i = np.max(anomaly_scores[cluster_i])
                score_j = np.max(anomaly_scores[cluster_j])
                strength = np.sqrt(score_i * score_j) / 3.0
                
                # å…ƒç´ ãƒ–ãƒªãƒƒã‚¸ãƒã‚§ãƒƒã‚¯
                element_bridge = None
                if element_composition:
                    comp_i = element_composition.get(cluster_i, {})
                    comp_j = element_composition.get(cluster_j, {})
                    
                    # ä¸»è¦å…ƒç´ 
                    main_i = max(comp_i, key=comp_i.get) if comp_i else 'Fe'
                    main_j = max(comp_j, key=comp_j.get) if comp_j else 'Fe'
                    
                    if main_i != main_j:
                        element_bridge = (main_i, main_j)
                        # ç•°ç¨®å…ƒç´ ç•Œé¢ã¯å¼±ã„
                        strength *= 1.5
                
                link = MaterialNetworkLink(
                    from_cluster=cluster_i,
                    to_cluster=cluster_j,
                    strength=strength,
                    link_type='fracture',
                    damage_signature='crack_propagation',
                    element_bridge=element_bridge
                )
                damage_links.append(link)
        
        # çµ±è¨ˆ
        network_stats = {
            'pattern': 'fracture_initiation',
            'n_critical_clusters': len(critical_clusters),
            'n_damage_links': len(damage_links)
        }
        
        return ClusterNetworkResult(
            strain_network=[],
            dislocation_network=[],
            damage_network=damage_links,
            spatial_constraints={},
            adaptive_windows={},
            network_stats=network_stats,
            critical_clusters=critical_clusters
        )
    
    def _analyze_general_pattern(self,
                                anomaly_scores: Dict[int, np.ndarray],
                                cluster_coupling: np.ndarray,
                                cluster_centers: np.ndarray,
                                lag_window: int) -> ClusterNetworkResult:
        """ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã®è§£æ"""
        # ç°¡æ˜“ç‰ˆå®Ÿè£…
        return self._create_empty_result()
    
    # ========================================
    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰
    # ========================================
    def _compute_strain_network(self,
                               cluster_ids: List[int],
                               local_strain: np.ndarray) -> List[MaterialNetworkLink]:
        """æ­ªã¿ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨ˆç®—"""
        strain_links = []
        
        if local_strain is None or local_strain.size == 0:
            return strain_links
        
        # æœ€æ–°ãƒ•ãƒ¬ãƒ¼ãƒ 
        current_strain = local_strain[-1] if local_strain.ndim == 4 else local_strain
        
        for i, cluster_i in enumerate(cluster_ids):
            for j, cluster_j in enumerate(cluster_ids[i+1:], i+1):
                # ğŸ†• IDã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¤‰æ›
                idx_i = self.id_mapper.to_idx(cluster_i)
                idx_j = self.id_mapper.to_idx(cluster_j)
                
                if idx_i >= len(current_strain) or idx_j >= len(current_strain):
                    continue
                
                # ğŸ†• ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§é…åˆ—ã‚¢ã‚¯ã‚»ã‚¹
                strain_i = current_strain[idx_i].flatten()
                strain_j = current_strain[idx_j].flatten()
                
                try:
                    correlation = np.corrcoef(strain_i, strain_j)[0, 1]
                    
                    if abs(correlation) > 0.3:
                        link = MaterialNetworkLink(
                            from_cluster=cluster_i,  # å®Ÿéš›ã®IDã‚’ä¿å­˜
                            to_cluster=cluster_j,    # å®Ÿéš›ã®IDã‚’ä¿å­˜
                            strength=abs(correlation),
                            strain_correlation=correlation,
                            link_type='elastic'
                        )
                        strain_links.append(link)
                except:
                    continue
        
        return strain_links
    
    def _compute_distance(self,
                         centers: np.ndarray,
                         cluster_i: int,
                         cluster_j: int) -> float:
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é–“è·é›¢è¨ˆç®—"""
        # ğŸ†• IDã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¤‰æ›
        idx_i = self.id_mapper.to_idx(cluster_i)
        idx_j = self.id_mapper.to_idx(cluster_j)
        
        if centers.ndim == 3:  # (frames, clusters, 3)
            center_i = centers[-1, idx_i]
            center_j = centers[-1, idx_j]
        else:  # (clusters, 3)
            center_i = centers[idx_i]
            center_j = centers[idx_j]
        
        return float(np.linalg.norm(center_i - center_j))
    
    def _compute_spatial_constraints(self,
                                    cluster_ids: List[int],
                                    cluster_centers: np.ndarray) -> Dict:
        """ç©ºé–“åˆ¶ç´„è¨ˆç®—"""
        spatial_constraints = {}
        
        for i, cluster_i in enumerate(cluster_ids):
            for j, cluster_j in enumerate(cluster_ids[i+1:], i+1):
                distance = self._compute_distance(
                    cluster_centers, cluster_i, cluster_j
                )
                
                if distance < self.max_interaction_distance:
                    spatial_constraints[(cluster_i, cluster_j)] = distance
        
        return spatial_constraints
    
    def _create_empty_result(self) -> ClusterNetworkResult:
        """ç©ºã®çµæœã‚’ç”Ÿæˆ"""
        return ClusterNetworkResult(
            strain_network=[],
            dislocation_network=[],
            damage_network=[],
            spatial_constraints={},
            adaptive_windows={},
            network_stats={'error': 'No data to analyze'},
            critical_clusters=[]
        )

# ===============================
# Standalone Functions
# ===============================

def analyze_cluster_network_gpu(cluster_anomaly_scores: Dict[int, np.ndarray],
                               cluster_coupling: np.ndarray,
                               cluster_centers: Optional[np.ndarray] = None,
                               coordination_numbers: Optional[np.ndarray] = None,
                               local_strain: Optional[np.ndarray] = None,
                               **kwargs) -> ClusterNetworkResult:
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æã®ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³é–¢æ•°"""
    analyzer = ClusterNetworkGPU(**kwargs)
    return analyzer.analyze_network(
        cluster_anomaly_scores, cluster_coupling, cluster_centers,
        coordination_numbers, local_strain
    )
