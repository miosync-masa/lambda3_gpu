#!/usr/bin/env python3
"""
Cluster-Level LambdaÂ³ Structure Computation for Materials (GPU Version)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

ææ–™è§£æç”¨ï¼šã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ¬ãƒ™ãƒ«ã®LambdaÂ³æ§‹é€ ã‚’GPUã§è¨ˆç®—ï¼
é‡‘å±çµæ™¶ãƒ»ãƒãƒªãƒãƒ¼ãƒ»ã‚»ãƒ©ãƒŸãƒƒã‚¯ã‚¹ã«å¯¾å¿œï¼ğŸ’

æ®‹åŸºç‰ˆ(residue_structures_gpu.py)ã‚’ãƒ™ãƒ¼ã‚¹ã«ææ–™è§£æã«ç‰¹åŒ–

by ç’°ã¡ã‚ƒã‚“ - Material Edition v1.0
"""

import numpy as np
import logging
from typing import Dict, List, Optional, Tuple, Union
from dataclasses import dataclass
import warnings

# GPU imports
try:
    import cupy as cp
    HAS_GPU = True
except ImportError:
    HAS_GPU = False
    cp = None

# Local imports
from ..types import ArrayType, NDArray
from ..core import GPUBackend, GPUMemoryManager, handle_gpu_errors
from .cluster_id_mapping import ClusterIDMapper

# cluster_com_kernelã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã¯Noneï¼‰
try:
    from ..core import cluster_com_kernel
except ImportError:
    cluster_com_kernel = None

logger = logging.getLogger('lambda3_gpu.material.structures')

# ===============================
# Helper Functions
# ===============================

def get_optimal_block_size(n_elements: int, max_block_size: int = 1024) -> int:
    """æœ€é©ãªãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚ºã‚’è¨ˆç®—"""
    if n_elements <= 32:
        return 32
    elif n_elements <= 64:
        return 64
    elif n_elements <= 128:
        return 128
    elif n_elements <= 256:
        return 256
    elif n_elements <= 512:
        return 512
    else:
        return min(1024, max_block_size)

# ===============================
# Data Classes (Materialç‰ˆ)
# ===============================

@dataclass
class ClusterStructureResult:
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ¬ãƒ™ãƒ«æ§‹é€ è¨ˆç®—ã®çµæœï¼ˆææ–™ç‰¹åŒ–ç‰ˆï¼‰"""
    cluster_lambda_f: np.ndarray         # (n_frames, n_clusters, 3) - ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°æ¸ˆã¿
    cluster_lambda_f_mag: np.ndarray     # (n_frames, n_clusters) - ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°æ¸ˆã¿
    cluster_rho_t: np.ndarray           # (n_frames, n_clusters)
    cluster_coupling: np.ndarray        # (n_frames, n_clusters, n_clusters)
    cluster_centers: np.ndarray         # (n_frames, n_clusters, 3)
    
    # Materialç‰¹æœ‰ã®è¿½åŠ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    coordination_numbers: np.ndarray    # (n_frames, n_clusters) é…ä½æ•°
    local_strain: np.ndarray           # (n_frames, n_clusters, 3, 3) æ­ªã¿ãƒ†ãƒ³ã‚½ãƒ«
    element_composition: Dict[int, Dict[str, int]]  # å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®å…ƒç´ çµ„æˆ
    bond_angles: Optional[np.ndarray] = None  # ãƒœãƒ³ãƒ‰è§’åº¦åˆ†å¸ƒ
    
    @property
    def n_frames(self) -> int:
        """å…¨é…åˆ—ã§çµ±ä¸€ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ æ•°"""
        return self.cluster_centers.shape[0]
    
    @property
    def n_clusters(self) -> int:
        return self.cluster_centers.shape[1]
    
    def validate_shapes(self) -> bool:
        """å½¢çŠ¶ã®æ•´åˆæ€§ã‚’ç¢ºèª"""
        n_frames = self.n_frames
        n_clusters = self.n_clusters
        
        expected_shapes = {
            'cluster_lambda_f': (n_frames, n_clusters, 3),
            'cluster_lambda_f_mag': (n_frames, n_clusters),
            'cluster_rho_t': (n_frames, n_clusters),
            'cluster_coupling': (n_frames, n_clusters, n_clusters),
            'cluster_centers': (n_frames, n_clusters, 3),
            'coordination_numbers': (n_frames, n_clusters),
            'local_strain': (n_frames, n_clusters, 3, 3)
        }
        
        for name, expected_shape in expected_shapes.items():
            actual_shape = getattr(self, name).shape
            if actual_shape != expected_shape:
                logger.warning(f"Shape mismatch in {name}: "
                             f"expected {expected_shape}, got {actual_shape}")
                return False
        
        return True
    
    def get_summary_stats(self) -> Dict[str, float]:
        """çµ±è¨ˆã‚µãƒãƒªãƒ¼ã‚’è¾æ›¸ã§è¿”ã™ï¼ˆææ–™ç‰¹åŒ–ç‰ˆï¼‰"""
        return {
            'mean_lambda_f': float(np.nanmean(self.cluster_lambda_f_mag)),
            'max_lambda_f': float(np.nanmax(self.cluster_lambda_f_mag)),
            'mean_rho_t': float(np.nanmean(self.cluster_rho_t)),
            'mean_coupling': float(np.nanmean(self.cluster_coupling)),
            'mean_coordination': float(np.nanmean(self.coordination_numbers)),
            'max_strain': float(np.nanmax(np.linalg.norm(self.local_strain, axis=(2,3)))),
            'n_frames': self.n_frames,
            'n_clusters': self.n_clusters
        }

# ===============================
# CUDA Kernels (Materialç‰ˆ)
# ===============================

CLUSTER_TENSION_KERNEL = r'''
extern "C" __global__
void compute_cluster_tension_kernel(
    const float* __restrict__ cluster_centers,  // (n_frames, n_clusters, 3)
    float* __restrict__ rho_t,                 // (n_frames, n_clusters)
    const int n_frames,
    const int n_clusters,
    const int window_size
) {
    const int cluster_id = blockIdx.x * blockDim.x + threadIdx.x;
    const int frame_id = blockIdx.y * blockDim.y + threadIdx.y;
    
    if (cluster_id >= n_clusters || frame_id >= n_frames) return;
    
    const int window_half = window_size / 2;
    const int start_frame = max(0, frame_id - window_half);
    const int end_frame = min(n_frames, frame_id + window_half + 1);
    const int local_window = end_frame - start_frame;
    
    // å±€æ‰€å¹³å‡
    float mean_x = 0.0f, mean_y = 0.0f, mean_z = 0.0f;
    
    for (int f = start_frame; f < end_frame; f++) {
        const int idx = (f * n_clusters + cluster_id) * 3;
        mean_x += cluster_centers[idx + 0];
        mean_y += cluster_centers[idx + 1];
        mean_z += cluster_centers[idx + 2];
    }
    
    mean_x /= local_window;
    mean_y /= local_window;
    mean_z /= local_window;
    
    // å±€æ‰€åˆ†æ•£ï¼ˆãƒˆãƒ¬ãƒ¼ã‚¹ï¼‰
    float var_sum = 0.0f;
    
    for (int f = start_frame; f < end_frame; f++) {
        const int idx = (f * n_clusters + cluster_id) * 3;
        const float dx = cluster_centers[idx + 0] - mean_x;
        const float dy = cluster_centers[idx + 1] - mean_y;
        const float dz = cluster_centers[idx + 2] - mean_z;
        
        var_sum += dx * dx + dy * dy + dz * dz;
    }
    
    rho_t[frame_id * n_clusters + cluster_id] = var_sum / local_window;
}
'''

COORDINATION_NUMBER_KERNEL = r'''
extern "C" __global__
void compute_coordination_kernel(
    const float* __restrict__ positions,      // (n_atoms, 3)
    const int* __restrict__ cluster_mapping,  // (n_atoms,) -> cluster_id
    float* __restrict__ coordination,         // (n_clusters,)
    const float cutoff_sq,                    // ã‚«ãƒƒãƒˆã‚ªãƒ•è·é›¢ã®2ä¹—
    const int n_atoms,
    const int n_clusters
) {
    const int cluster_id = blockIdx.x;
    const int tid = threadIdx.x;
    
    if (cluster_id >= n_clusters) return;
    
    __shared__ float local_coord[256];
    local_coord[tid] = 0.0f;
    
    // ã“ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«å±ã™ã‚‹åŸå­ã‚’æ¢ã™
    for (int i = tid; i < n_atoms; i += blockDim.x) {
        if (cluster_mapping[i] == cluster_id) {
            float xi = positions[i * 3 + 0];
            float yi = positions[i * 3 + 1];
            float zi = positions[i * 3 + 2];
            
            int neighbors = 0;
            
            // ä»–ã®åŸå­ã¨ã®è·é›¢ã‚’è¨ˆç®—
            for (int j = 0; j < n_atoms; j++) {
                if (i != j) {
                    float xj = positions[j * 3 + 0];
                    float yj = positions[j * 3 + 1];
                    float zj = positions[j * 3 + 2];
                    
                    float dist_sq = (xi-xj)*(xi-xj) + 
                                   (yi-yj)*(yi-yj) + 
                                   (zi-zj)*(zi-zj);
                    
                    if (dist_sq < cutoff_sq) {
                        neighbors++;
                    }
                }
            }
            
            local_coord[tid] += neighbors;
        }
    }
    
    __syncthreads();
    
    // ãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³
    for (int s = blockDim.x / 2; s > 0; s >>= 1) {
        if (tid < s) {
            local_coord[tid] += local_coord[tid + s];
        }
        __syncthreads();
    }
    
    if (tid == 0) {
        coordination[cluster_id] = local_coord[0];
    }
}
'''

# ===============================
# ClusterStructuresGPU Class
# ===============================

class ClusterStructuresGPU(GPUBackend):
    """
    ææ–™ç”¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ¬ãƒ™ãƒ«LambdaÂ³æ§‹é€ è¨ˆç®—ã®GPUå®Ÿè£…
    å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¤ãƒ™ãƒ³ãƒˆå¯¾å¿œç‰ˆï¼
    """
    
    def __init__(self,
                 memory_manager: Optional[GPUMemoryManager] = None,
                 **kwargs):
        super().__init__(**kwargs)
        self.memory_manager = memory_manager or GPUMemoryManager()

        # ğŸ†• è¿½åŠ 
        self.id_mapper = None
        
        # ã‚«ãƒ¼ãƒãƒ«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
        if self.is_gpu and HAS_GPU:
            self._compile_kernels()
    
    def _compile_kernels(self):
        """ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«"""
        try:
            self.tension_kernel = cp.RawKernel(
                CLUSTER_TENSION_KERNEL, 'compute_cluster_tension_kernel'
            )
            self.coord_kernel = cp.RawKernel(
                COORDINATION_NUMBER_KERNEL, 'compute_coordination_kernel'
            )
            logger.debug("Material structure kernels compiled successfully")
        except Exception as e:
            logger.warning(f"Failed to compile custom kernels: {e}")
            self.tension_kernel = None
            self.coord_kernel = None
    
    @handle_gpu_errors
    def compute_cluster_structures(self,
                                  trajectory: np.ndarray,
                                  start_frame: int,
                                  end_frame: int,
                                  cluster_atoms: Dict[int, List[int]],
                                  atom_types: np.ndarray,
                                  window_size: int = 50,
                                  cutoff: float = 3.0) -> ClusterStructureResult:
        """
        ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ¬ãƒ™ãƒ«ã®LambdaÂ³æ§‹é€ ã‚’è¨ˆç®—ï¼ˆå˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ å¯¾å¿œç‰ˆï¼‰
        
        é‡è¦ï¼šend_frameã¯åŒ…å«çš„ï¼ˆinclusiveï¼‰ã¨ã—ã¦æ‰±ã†ï¼
        
        Parameters
        ----------
        trajectory : ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒª
        start_frame, end_frame : ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²ï¼ˆåŒ…å«çš„ï¼‰
        cluster_atoms : ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ID â†’ åŸå­ãƒªã‚¹ãƒˆã®ãƒãƒƒãƒ”ãƒ³ã‚°
        atom_types : å„åŸå­ã®å…ƒç´ ã‚¿ã‚¤ãƒ— (æ–‡å­—åˆ—é…åˆ—)
        window_size : ÏTè¨ˆç®—ç”¨çª“ã‚µã‚¤ã‚º
        cutoff : é…ä½æ•°è¨ˆç®—ç”¨ã‚«ãƒƒãƒˆã‚ªãƒ•è·é›¢ (Ã…)
        """
        with self.timer('compute_cluster_structures'):
            # åŒ…å«çš„ç¯„å›²ã¨ã—ã¦å‡¦ç†ï¼
            actual_end = end_frame + 1  # ã‚¹ãƒ©ã‚¤ã‚¹ã®ãŸã‚ã«+1
            n_frames = actual_end - start_frame
            
            logger.info(f"âš™ï¸ Computing cluster-level LambdaÂ³ for materials")
            logger.info(f"   Frames: {start_frame}-{end_frame} ({n_frames} frames)")
            logger.info(f"   Clusters: {len(cluster_atoms)}")
            logger.info(f"   Cutoff: {cutoff} Ã…")
            
            n_clusters = len(cluster_atoms)
            
            # ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ï¼šç©ºã®ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²
            if n_frames <= 0:
                logger.warning(f"Empty frame range: {start_frame}-{end_frame}")
                return self._create_empty_result(n_clusters)
            
            # å…¥åŠ›æ¤œè¨¼
            if not self._validate_inputs(trajectory, cluster_atoms, atom_types):
                logger.error("Input validation failed")
                return self._create_empty_result(n_clusters)
            
            # 1. ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é‡å¿ƒè¨ˆç®—ï¼ˆåŒ…å«çš„ã‚¹ãƒ©ã‚¤ã‚¹ï¼‰
            with self.timer('cluster_centers'):
                cluster_centers = self._compute_cluster_centers(
                    trajectory[start_frame:actual_end], 
                    cluster_atoms
                )
            
            # 2. ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ¬ãƒ™ãƒ«Î›Fï¼ˆå½¢çŠ¶çµ±ä¸€ç‰ˆï¼‰
            with self.timer('cluster_lambda_f'):
                cluster_lambda_f, cluster_lambda_f_mag = self._compute_cluster_lambda_f(
                    cluster_centers
                )
            
            # 3. ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ¬ãƒ™ãƒ«ÏT
            with self.timer('cluster_rho_t'):
                cluster_rho_t = self._compute_cluster_rho_t(
                    cluster_centers, window_size
                )
            
            # 4. ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é–“ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°
            with self.timer('cluster_coupling'):
                cluster_coupling = self._compute_cluster_coupling(
                    cluster_centers
                )
            
            # 5. é…ä½æ•°è¨ˆç®—ï¼ˆMaterialç‰¹æœ‰ï¼ï¼‰
            with self.timer('coordination_numbers'):
                coordination_numbers = self._compute_coordination_numbers(
                    trajectory[start_frame:actual_end],
                    cluster_atoms,
                    cutoff
                )
            
            # 6. å±€æ‰€æ­ªã¿ãƒ†ãƒ³ã‚½ãƒ«ï¼ˆMaterialç‰¹æœ‰ï¼ï¼‰
            with self.timer('local_strain'):
                local_strain = self._compute_local_strain(
                    trajectory[start_frame:actual_end],
                    cluster_atoms
                )
            
            # 7. å…ƒç´ çµ„æˆï¼ˆMaterialç‰¹æœ‰ï¼ï¼‰
            element_composition = self._compute_element_composition(
                cluster_atoms, atom_types
            )
            
            # çµæœã‚’CPUã«è»¢é€
            result = ClusterStructureResult(
                cluster_lambda_f=self.to_cpu(cluster_lambda_f),
                cluster_lambda_f_mag=self.to_cpu(cluster_lambda_f_mag),
                cluster_rho_t=self.to_cpu(cluster_rho_t),
                cluster_coupling=self.to_cpu(cluster_coupling),
                cluster_centers=self.to_cpu(cluster_centers),
                coordination_numbers=self.to_cpu(coordination_numbers),
                local_strain=self.to_cpu(local_strain),
                element_composition=element_composition
            )
            
            # å½¢çŠ¶æ¤œè¨¼
            if not result.validate_shapes():
                logger.warning("Shape validation failed! But continuing...")
            
            self._print_statistics_safe(result)
            
            return result
    
    def _validate_inputs(self, trajectory, cluster_atoms, atom_types):
        """å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼"""
        n_atoms = trajectory.shape[1]
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ã®æ¤œè¨¼
        for cluster_id, atoms in cluster_atoms.items():
            if not atoms:
                logger.warning(f"Cluster {cluster_id} has no atoms")
                return False
            if max(atoms) >= n_atoms:
                logger.error(f"Cluster {cluster_id} has invalid atom indices")
                return False
        
        # å…ƒç´ ã‚¿ã‚¤ãƒ—ã®æ¤œè¨¼
        if len(atom_types) != n_atoms:
            logger.error(f"atom_types size ({len(atom_types)}) != n_atoms ({n_atoms})")
            return False
        
        return True
    
    def _create_empty_result(self, n_clusters: int) -> ClusterStructureResult:
        """ç©ºã®çµæœã‚’ç”Ÿæˆï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ç”¨ï¼‰"""
        return ClusterStructureResult(
            cluster_lambda_f=np.zeros((0, n_clusters, 3), dtype=np.float32),
            cluster_lambda_f_mag=np.zeros((0, n_clusters), dtype=np.float32),
            cluster_rho_t=np.zeros((0, n_clusters), dtype=np.float32),
            cluster_coupling=np.zeros((0, n_clusters, n_clusters), dtype=np.float32),
            cluster_centers=np.zeros((0, n_clusters, 3), dtype=np.float32),
            coordination_numbers=np.zeros((0, n_clusters), dtype=np.float32),
            local_strain=np.zeros((0, n_clusters, 3, 3), dtype=np.float32),
            element_composition={}
        )
    
    # _compute_cluster_centers ãƒ¡ã‚½ãƒƒãƒ‰ã®ä¿®æ­£ï¼ˆé‡è¦ï¼ï¼‰
    def _compute_cluster_centers(self,
                                trajectory: np.ndarray,
                                cluster_atoms: Dict[int, List[int]]) -> cp.ndarray:
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é‡å¿ƒè¨ˆç®—ï¼ˆç´°åˆ†åŒ–IDå¯¾å¿œç‰ˆï¼‰"""
        n_frames, n_atoms, _ = trajectory.shape
        n_clusters = len(cluster_atoms)
        
        # ğŸ†• IDãƒãƒƒãƒ‘ãƒ¼åˆæœŸåŒ–
        if self.id_mapper is None:
            self.id_mapper = ClusterIDMapper(cluster_atoms)
        
        if self.is_gpu and HAS_GPU and cluster_com_kernel is not None:
            # GPUç‰ˆï¼šã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ä½¿ç”¨
            trajectory_gpu = self.to_gpu(trajectory, dtype=cp.float32)
            cluster_centers = cluster_com_kernel(trajectory_gpu, cluster_atoms)
        else:
            # CPUç‰ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆä¿®æ­£ç‰ˆï¼‰
            cluster_centers = np.zeros((n_frames, n_clusters, 3), dtype=np.float32)
            
            # ğŸ†• ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼IDã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨
            for cluster_id, idx in self.id_mapper.iterate_with_idx():
                atoms = cluster_atoms[cluster_id]
                if len(atoms) > 0 and max(atoms) < n_atoms:
                    cluster_centers[:, idx] = np.mean(trajectory[:, atoms], axis=1)
            
            cluster_centers = self.to_gpu(cluster_centers)
        
        return cluster_centers
    
    def _compute_cluster_lambda_f(self, cluster_centers: cp.ndarray) -> Tuple[cp.ndarray, cp.ndarray]:
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ¬ãƒ™ãƒ«Î›Fè¨ˆç®—ï¼ˆå½¢çŠ¶çµ±ä¸€ç‰ˆï¼‰"""
        n_frames, n_clusters, _ = cluster_centers.shape
        
        # å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç‰¹åˆ¥å‡¦ç†
        if n_frames <= 1:
            # å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ï¼šå¤‰åŒ–ãªã—ï¼ˆã‚¼ãƒ­ï¼‰
            cluster_lambda_f = self.xp.zeros((n_frames, n_clusters, 3), dtype=self.xp.float32)
            cluster_lambda_f_mag = self.xp.zeros((n_frames, n_clusters), dtype=self.xp.float32)
            logger.debug(f"Single frame detected, returning zero lambda_f")
            return cluster_lambda_f, cluster_lambda_f_mag
        
        # é€šå¸¸å‡¦ç†ï¼šãƒ•ãƒ¬ãƒ¼ãƒ é–“å·®åˆ†
        cluster_lambda_f = self.xp.diff(cluster_centers, axis=0)
        cluster_lambda_f_mag = self.xp.linalg.norm(cluster_lambda_f, axis=2)
        
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼šæœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è£œå®Œï¼ˆdiffã§å¤±ã‚ã‚ŒãŸåˆ†ï¼‰
        zero_frame = self.xp.zeros((1, n_clusters, 3), dtype=cluster_lambda_f.dtype)
        cluster_lambda_f = self.xp.concatenate([zero_frame, cluster_lambda_f], axis=0)
        
        zero_mag = self.xp.zeros((1, n_clusters), dtype=cluster_lambda_f_mag.dtype)
        cluster_lambda_f_mag = self.xp.concatenate([zero_mag, cluster_lambda_f_mag], axis=0)
        
        return cluster_lambda_f, cluster_lambda_f_mag
    
    def _compute_cluster_rho_t(self,
                              cluster_centers: cp.ndarray,
                              window_size: int) -> cp.ndarray:
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ¬ãƒ™ãƒ«ÏTè¨ˆç®—ï¼ˆå˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ å¯¾å¿œï¼‰"""
        n_frames, n_clusters, _ = cluster_centers.shape
        
        # å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç‰¹åˆ¥å‡¦ç†
        if n_frames == 1:
            # å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ï¼šã‚¼ãƒ­åˆ†æ•£
            logger.debug("Single frame: returning zero rho_t")
            return self.zeros((n_frames, n_clusters), dtype=self.xp.float32)
        
        # ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ä½¿ç”¨
        if self.is_gpu and self.tension_kernel is not None:
            rho_t = self.zeros((n_frames, n_clusters), dtype=cp.float32)
            
            # 2Dã‚°ãƒªãƒƒãƒ‰è¨­å®š
            block_size = (16, 16)
            grid_size = (
                (n_clusters + block_size[0] - 1) // block_size[0],
                (n_frames + block_size[1] - 1) // block_size[1]
            )
            
            self.tension_kernel(
                grid_size, block_size,
                (cluster_centers.ravel(), rho_t, n_frames, n_clusters, window_size)
            )
            
            return rho_t
        else:
            # CPU/GPUæ±ç”¨ç‰ˆ
            cluster_rho_t = self.zeros((n_frames, n_clusters))
            
            for frame in range(n_frames):
                for cluster_id in range(n_clusters):
                    local_start = max(0, frame - window_size // 2)
                    local_end = min(n_frames, frame + window_size // 2 + 1)
                    
                    local_centers = cluster_centers[local_start:local_end, cluster_id]
                    if len(local_centers) > 1:
                        cov = self.xp.cov(local_centers.T)
                        if not self.xp.any(self.xp.isnan(cov)) and not self.xp.all(cov == 0):
                            cluster_rho_t[frame, cluster_id] = self.xp.trace(cov)
            
            return cluster_rho_t
    
    def _compute_cluster_coupling(self,
                                 cluster_centers: cp.ndarray) -> cp.ndarray:
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é–“ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°è¨ˆç®—"""
        n_frames, n_clusters, _ = cluster_centers.shape
        
        coupling = self.zeros((n_frames, n_clusters, n_clusters))
        
        for frame in range(n_frames):
            # è·é›¢è¡Œåˆ—
            distances = self.xp.linalg.norm(
                cluster_centers[frame, :, None, :] - cluster_centers[frame, None, :, :],
                axis=2
            )
            # ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ï¼ˆææ–™ç”¨ã«èª¿æ•´ï¼šè·é›¢ãŒè¿‘ã„ã»ã©å¼·ã„ï¼‰
            coupling[frame] = self.xp.exp(-distances / 5.0)  # 5Ã…ã®ç‰¹æ€§é•·
            self.xp.fill_diagonal(coupling[frame], 0)  # è‡ªå·±çµåˆã‚’é™¤å¤–
        
        return coupling

    # _compute_coordination_numbers ãƒ¡ã‚½ãƒƒãƒ‰ã®ä¿®æ­£
    def _compute_coordination_numbers(self,
                                     trajectory: np.ndarray,
                                     cluster_atoms: Dict[int, List[int]],
                                     cutoff: float) -> cp.ndarray:
        """é…ä½æ•°è¨ˆç®—ï¼ˆç´°åˆ†åŒ–IDå¯¾å¿œç‰ˆï¼‰"""
        n_frames, n_atoms, _ = trajectory.shape
        n_clusters = len(cluster_atoms)
        
        # ğŸ†• IDãƒãƒƒãƒ‘ãƒ¼ç¢ºèª
        if self.id_mapper is None:
            self.id_mapper = ClusterIDMapper(cluster_atoms)
        
        coordination = self.zeros((n_frames, n_clusters), dtype=self.xp.float32)
        cutoff_sq = cutoff * cutoff
        
        if self.is_gpu and self.coord_kernel is not None:
            # ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ä½¿ç”¨ï¼ˆä¿®æ­£ç‰ˆï¼‰
            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆï¼ˆIDã§ã¯ãªãã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ï¼‰
            cluster_mapping = -self.xp.ones(n_atoms, dtype=cp.int32)
            
            # ğŸ†• å®Ÿéš›ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼IDã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ãƒãƒƒãƒ—
            for cluster_id, atoms in cluster_atoms.items():
                idx = self.id_mapper.to_idx(cluster_id)
                for atom_id in atoms:
                    cluster_mapping[atom_id] = idx  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ ¼ç´
            
            # å„ãƒ•ãƒ¬ãƒ¼ãƒ ã§é…ä½æ•°è¨ˆç®—
            for frame in range(n_frames):
                positions = self.to_gpu(trajectory[frame], dtype=cp.float32)
                coord_frame = self.zeros(n_clusters, dtype=cp.float32)
                
                # ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œ
                block_size = 256
                grid_size = n_clusters
                
                self.coord_kernel(
                    (grid_size,), (block_size,),
                    (positions.ravel(), cluster_mapping, coord_frame, 
                     cutoff_sq, n_atoms, n_clusters)
                )
                
                coordination[frame] = coord_frame
        else:
            # CPUç‰ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆä¿®æ­£ç‰ˆï¼‰
            for frame in range(n_frames):
                positions = self.to_gpu(trajectory[frame])
                
                # ğŸ†• IDã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨
                for cluster_id, idx in self.id_mapper.iterate_with_idx():
                    atoms = cluster_atoms[cluster_id]
                    total_coord = 0
                    for atom_i in atoms:
                        pos_i = positions[atom_i]
                        distances = self.xp.linalg.norm(positions - pos_i, axis=1)
                        neighbors = self.xp.sum((distances > 0) & (distances < cutoff))
                        total_coord += neighbors
                    
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§é…åˆ—ã«æ ¼ç´
                    coordination[frame, idx] = total_coord / len(atoms) if atoms else 0
        
        return coordination
    
    # _compute_local_strain ãƒ¡ã‚½ãƒƒãƒ‰ã®ä¿®æ­£
    def _compute_local_strain(self,
                             trajectory: np.ndarray,
                             cluster_atoms: Dict[int, List[int]]) -> cp.ndarray:
        """å±€æ‰€æ­ªã¿ãƒ†ãƒ³ã‚½ãƒ«è¨ˆç®—ï¼ˆç´°åˆ†åŒ–IDå¯¾å¿œç‰ˆï¼‰"""
        n_frames = trajectory.shape[0]
        n_clusters = len(cluster_atoms)
        
        # ğŸ†• IDãƒãƒƒãƒ‘ãƒ¼ç¢ºèª
        if self.id_mapper is None:
            self.id_mapper = ClusterIDMapper(cluster_atoms)
        
        strain = self.zeros((n_frames, n_clusters, 3, 3), dtype=self.xp.float32)
        
        # åˆæœŸæ§‹é€ ã‚’å‚ç…§
        ref_positions = self.to_gpu(trajectory[0])
        
        for frame in range(n_frames):
            current_positions = self.to_gpu(trajectory[frame])
            
            # ğŸ†• IDã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨
            for cluster_id, idx in self.id_mapper.iterate_with_idx():
                atoms = cluster_atoms[cluster_id]
                if len(atoms) < 4:  # æœ€ä½4åŸå­å¿…è¦
                    continue
                
                try:
                    # å¤‰å½¢å‹¾é…ãƒ†ãƒ³ã‚½ãƒ«
                    F = self._compute_deformation_gradient(
                        ref_positions[atoms],
                        current_positions[atoms]
                    )
                    
                    # Green-Lagrangeæ­ªã¿ãƒ†ãƒ³ã‚½ãƒ«
                    strain[frame, idx] = 0.5 * (F.T @ F - self.xp.eye(3))  # idxã§æ ¼ç´
                except Exception as e:
                    logger.debug(f"Strain computation failed for cluster {cluster_id}: {e}")
                    # ã‚¼ãƒ­æ­ªã¿ã®ã¾ã¾
        
        return strain
    
    def _compute_element_composition(self,
                                    cluster_atoms: Dict[int, List[int]],
                                    atom_types: np.ndarray) -> Dict:
        """å…ƒç´ çµ„æˆã®è¨ˆç®—"""
        composition = {}
        
        for cluster_id, atoms in cluster_atoms.items():
            cluster_comp = {}
            for atom_id in atoms:
                if atom_id < len(atom_types):
                    element = str(atom_types[atom_id])  # æ–‡å­—åˆ—ã¨ã—ã¦æ‰±ã†
                    cluster_comp[element] = cluster_comp.get(element, 0) + 1
            composition[cluster_id] = cluster_comp
        
        return composition
    
    def _compute_deformation_gradient(self, ref_pos, current_pos):
        """å¤‰å½¢å‹¾é…ãƒ†ãƒ³ã‚½ãƒ«ã®è¨ˆç®—"""
        # ç°¡æ˜“ç‰ˆï¼šæœ€å°äºŒä¹—æ³•
        ref_centered = ref_pos - self.xp.mean(ref_pos, axis=0)
        current_centered = current_pos - self.xp.mean(current_pos, axis=0)
        
        # F = current @ ref^(-1)
        H = current_centered.T @ ref_centered
        C = ref_centered.T @ ref_centered
        
        try:
            # æ­£å‰‡åŒ–ã—ã¦æ•°å€¤çš„å®‰å®šæ€§ã‚’å‘ä¸Š
            C_reg = C + 1e-6 * self.xp.eye(3)
            F = H @ self.xp.linalg.inv(C_reg)
        except:
            F = self.xp.eye(3)
        
        return F
    
    def _print_statistics_safe(self, result: ClusterStructureResult):
        """çµ±è¨ˆæƒ…å ±ã‚’å®‰å…¨ã«è¡¨ç¤º"""
        logger.info(f"  âœ… Structure computation complete")
        logger.info(f"  Frames: {result.n_frames}, Clusters: {result.n_clusters}")
        
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        stats = result.get_summary_stats()
        if result.n_frames > 0:
            logger.info(f"  Mean Î›F: {stats['mean_lambda_f']:.3f}")
            logger.info(f"  Mean ÏT: {stats['mean_rho_t']:.3f}")
            logger.info(f"  Mean Coupling: {stats['mean_coupling']:.3f}")
            logger.info(f"  Mean Coordination: {stats['mean_coordination']:.2f}")
            logger.info(f"  Max Strain: {stats['max_strain']:.4f}")
        else:
            logger.info(f"  No frames to analyze")

# ===============================
# Convenience Functions
# ===============================

def compute_cluster_structures_gpu(trajectory: np.ndarray,
                                  start_frame: int,
                                  end_frame: int,
                                  cluster_atoms: Dict[int, List[int]],
                                  atom_types: np.ndarray,
                                  window_size: int = 50,
                                  cutoff: float = 3.0) -> ClusterStructureResult:
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ§‹é€ è¨ˆç®—ã®ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°ï¼ˆåŒ…å«çš„ç¯„å›²ï¼‰"""
    calculator = ClusterStructuresGPU()
    return calculator.compute_cluster_structures(
        trajectory, start_frame, end_frame, cluster_atoms, 
        atom_types, window_size, cutoff
    )

def compute_cluster_lambda_f_gpu(cluster_centers: Union[np.ndarray, cp.ndarray],
                                backend: Optional[GPUBackend] = None) -> Tuple[np.ndarray, np.ndarray]:
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼Î›Fè¨ˆç®—ã®ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³é–¢æ•°ï¼ˆãƒ‘ãƒ‡ã‚£ãƒ³ã‚°æ¸ˆã¿ï¼‰"""
    calculator = ClusterStructuresGPU() if backend is None else ClusterStructuresGPU(device=backend.device)
    centers_gpu = calculator.to_gpu(cluster_centers)
    lambda_f, lambda_f_mag = calculator._compute_cluster_lambda_f(centers_gpu)
    return calculator.to_cpu(lambda_f), calculator.to_cpu(lambda_f_mag)

def compute_cluster_rho_t_gpu(cluster_centers: Union[np.ndarray, cp.ndarray],
                             window_size: int = 50,
                             backend: Optional[GPUBackend] = None) -> np.ndarray:
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ÏTè¨ˆç®—ã®ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³é–¢æ•°"""
    calculator = ClusterStructuresGPU() if backend is None else ClusterStructuresGPU(device=backend.device)
    centers_gpu = calculator.to_gpu(cluster_centers)
    rho_t = calculator._compute_cluster_rho_t(centers_gpu, window_size)
    return calculator.to_cpu(rho_t)

def compute_cluster_coupling_gpu(cluster_centers: Union[np.ndarray, cp.ndarray],
                                backend: Optional[GPUBackend] = None) -> np.ndarray:
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é–“ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°è¨ˆç®—ã®ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³é–¢æ•°"""
    calculator = ClusterStructuresGPU() if backend is None else ClusterStructuresGPU(device=backend.device)
    centers_gpu = calculator.to_gpu(cluster_centers)
    coupling = calculator._compute_cluster_coupling(centers_gpu)
    return calculator.to_cpu(coupling)

# ===============================
# Batch Processing
# ===============================

class ClusterStructureBatchProcessor:
    """å¤§è¦æ¨¡ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªã®ãƒãƒƒãƒå‡¦ç†ï¼ˆææ–™ç”¨ï¼‰"""
    
    def __init__(self,
                 calculator: ClusterStructuresGPU,
                 batch_size: Optional[int] = None):
        self.calculator = calculator
        self.batch_size = batch_size
    
    def process_trajectory(self,
                         trajectory: np.ndarray,
                         cluster_atoms: Dict[int, List[int]],
                         atom_types: np.ndarray,
                         window_size: int = 50,
                         cutoff: float = 3.0,
                         overlap: int = 100) -> ClusterStructureResult:
        """ãƒãƒƒãƒå‡¦ç†ã§ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªå…¨ä½“ã‚’å‡¦ç†"""
        n_frames = trajectory.shape[0]
        
        if self.batch_size is None:
            # è‡ªå‹•æ±ºå®š
            self.batch_size = self.calculator.memory_manager.estimate_batch_size(
                trajectory.shape, dtype=np.float32
            )
        
        logger.info(f"Processing {n_frames} frames in batches of {self.batch_size}")
        
        # TODO: å®Ÿè£…ãŒå¿…è¦
        # ãƒãƒƒãƒã”ã¨ã«å‡¦ç†ã—ã¦çµæœã‚’çµåˆ
        raise NotImplementedError("Batch processing implementation needed")

# ===============================
# Cluster Definition Utilities
# ===============================

def create_nearest_neighbor_clusters(positions: np.ndarray,
                                    cutoff: float = 3.0,
                                    min_size: int = 12,
                                    max_size: int = 14) -> Dict[int, List[int]]:
    """æœ€è¿‘æ¥åŸå­ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’å®šç¾©ï¼ˆææ–™ç”¨ï¼‰"""
    n_atoms = len(positions)
    clusters = {}
    assigned = np.zeros(n_atoms, dtype=bool)
    cluster_id = 0
    
    for atom_id in range(n_atoms):
        if assigned[atom_id]:
            continue
        
        # ã“ã®åŸå­ã‚’ä¸­å¿ƒã«ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä½œæˆ
        distances = np.linalg.norm(positions - positions[atom_id], axis=1)
        neighbors = np.where((distances < cutoff) & (~assigned))[0]
        
        if len(neighbors) >= min_size:
            # ã‚µã‚¤ã‚ºåˆ¶é™
            if len(neighbors) > max_size:
                neighbors = neighbors[np.argsort(distances[neighbors])[:max_size]]
            
            clusters[cluster_id] = neighbors.tolist()
            assigned[neighbors] = True
            cluster_id += 1
    
    # æœªå‰²ã‚Šå½“ã¦åŸå­ã‚’æœ€è¿‘æ¥ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«è¿½åŠ 
    for atom_id in np.where(~assigned)[0]:
        if clusters:
            # æœ€è¿‘æ¥ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä¸­å¿ƒã‚’æ¢ã™
            min_dist = np.inf
            best_cluster = 0
            
            for cid, atoms in clusters.items():
                center = np.mean(positions[atoms], axis=0)
                dist = np.linalg.norm(positions[atom_id] - center)
                if dist < min_dist:
                    min_dist = dist
                    best_cluster = cid
            
            clusters[best_cluster].append(atom_id)
    
    logger.info(f"Created {len(clusters)} clusters with cutoff={cutoff}Ã…")
    
    return clusters

def create_grid_based_clusters(positions: np.ndarray,
                              grid_size: float = 1.0) -> Dict[int, List[int]]:
    """ã‚°ãƒªãƒƒãƒ‰ãƒ™ãƒ¼ã‚¹ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’å®šç¾©ï¼ˆææ–™ç”¨ï¼‰"""
    # ã‚°ãƒªãƒƒãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨ˆç®—
    grid_indices = np.floor(positions / grid_size).astype(int)
    
    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚°ãƒªãƒƒãƒ‰ã‚»ãƒ«ã‚’ç‰¹å®š
    unique_cells = np.unique(grid_indices, axis=0)
    
    clusters = {}
    for i, cell in enumerate(unique_cells):
        mask = np.all(grid_indices == cell, axis=1)
        atoms = np.where(mask)[0]
        if len(atoms) > 0:
            clusters[i] = atoms.tolist()
    
    logger.info(f"Created {len(clusters)} grid-based clusters with size={grid_size}Ã…")
    
    return clusters
