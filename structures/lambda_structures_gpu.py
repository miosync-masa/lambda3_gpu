"""
LambdaÂ³ Structure Computation (GPU Version)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

LambdaÂ³æ§‹é€ ã®è¨ˆç®—ã‚’GPUã§è¶…é«˜é€ŸåŒ–ï¼
NO TIME, NO PHYSICS, ONLY STRUCTURE... but FASTER! ğŸš€

âš¡ 2025/01/15 å®Œå…¨ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆ by ç’°ã¡ã‚ƒã‚“
- GPU/CPUåˆ‡ã‚Šæ›¿ãˆã®å®‰å…¨æ€§ã‚’å®Œå…¨ä¿è¨¼
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã§é‡è¤‡ã‚³ãƒ¼ãƒ‰å‰Šæ¸›
"""
import numpy as np
import logging
from typing import Dict, Optional, Tuple, Union, Any
from dataclasses import dataclass

# GPU imports
try:
    import cupy as cp
    from cupyx.scipy.signal import savgol_filter as cp_savgol_filter
    HAS_GPU = True
except ImportError:
    HAS_GPU = False
    cp = None
    cp_savgol_filter = None

# Local imports
from ..types import ArrayType, NDArray
from ..core import GPUBackend, GPUMemoryManager
from ..core import tension_field_kernel, topological_charge_kernel

logger = logging.getLogger('lambda3_gpu.structures.lambda_structures')

# ===============================
# å®‰å…¨æ€§ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆæ–°è¦è¿½åŠ ï¼‰
# ===============================

def safe_is_gpu_array(arr: Any) -> bool:
    """
    å®‰å…¨ã«GPUé…åˆ—ã‹ãƒã‚§ãƒƒã‚¯
    
    ç’°ã¡ã‚ƒã‚“ã®ç‰¹è£½å®‰å…¨ãƒã‚§ãƒƒã‚«ãƒ¼ï¼ğŸ’ª
    """
    return HAS_GPU and cp is not None and isinstance(arr, cp.ndarray)

def safe_to_cpu(arr: Any) -> np.ndarray:
    """
    å®‰å…¨ã«CPUé…åˆ—ã«å¤‰æ›
    
    GPUé…åˆ—ã§ã‚‚NumPyé…åˆ—ã§ã‚‚ã€ãƒªã‚¹ãƒˆã§ã‚‚ä½•ã§ã‚‚æ¥ã„ï¼
    """
    if safe_is_gpu_array(arr):
        return cp.asnumpy(arr)
    return np.asarray(arr)

def safe_to_gpu(arr: Any, dtype: Optional[np.dtype] = None) -> NDArray:
    """
    å®‰å…¨ã«GPUé…åˆ—ã«å¤‰æ›ï¼ˆGPUåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿ï¼‰
    
    GPUä½¿ãˆãªã„æ™‚ã¯è‡ªå‹•çš„ã«NumPyé…åˆ—ã¨ã—ã¦è¿”ã™ã‚ˆï¼
    """
    if HAS_GPU and cp is not None:
        if safe_is_gpu_array(arr):
            return arr.astype(dtype) if dtype else arr
        return cp.asarray(arr, dtype=dtype)
    else:
        return np.asarray(arr, dtype=dtype) if dtype else np.asarray(arr)

def get_array_module(arr: Any) -> Any:
    """
    é…åˆ—ã«é©ã—ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆnp or cpï¼‰ã‚’è¿”ã™
    
    ã“ã‚Œã§ xp ã®æ··ä¹±ã‚’é˜²ã’ã‚‹ï¼
    """
    if safe_is_gpu_array(arr):
        return cp
    return np

# ===============================
# Configuration
# ===============================

@dataclass
class LambdaStructureConfig:
    """Lambdaæ§‹é€ è¨ˆç®—ã®è¨­å®š"""
    use_mixed_precision: bool = False
    batch_size: Optional[int] = None
    cache_intermediates: bool = True
    profile: bool = False
    safe_mode: bool = True  # æ–°è¦è¿½åŠ ï¼šå®‰å…¨ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆONï¼‰

# ===============================
# Lambda Structures GPU Class
# ===============================

class LambdaStructuresGPU(GPUBackend):
    """
    LambdaÂ³æ§‹é€ è¨ˆç®—ã®GPUå®Ÿè£…ã‚¯ãƒ©ã‚¹
    ã‚ã¡ã‚ƒãã¡ã‚ƒé€Ÿã„ã—ã€ä»Šåº¦ã¯å®‰å…¨ã ã‚ˆã€œï¼âœ¨
    """
    
    def __init__(self, 
                 config: Optional[LambdaStructureConfig] = None,
                 memory_manager: Optional[GPUMemoryManager] = None,
                 **kwargs):
        """
        Parameters
        ----------
        config : LambdaStructureConfig
            è¨ˆç®—è¨­å®š
        memory_manager : GPUMemoryManager
            ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        super().__init__(
            mixed_precision=config.use_mixed_precision if config else False,
            profile=config.profile if config else False,
            **kwargs
        )
        
        self.config = config or LambdaStructureConfig()
        self.memory_manager = memory_manager or GPUMemoryManager()
        self._cache = {} if self.config.cache_intermediates else None
        
        # âš¡ é‡è¦: åˆæœŸåŒ–å¾Œã«çŠ¶æ…‹ã‚’å®Œå…¨æ¤œè¨¼
        self._validate_and_fix_gpu_state()
        
    def _validate_and_fix_gpu_state(self):
        """
        GPU/CPUçŠ¶æ…‹ã®æ•´åˆæ€§ã‚’å®Œå…¨æ¤œè¨¼ã—ã¦ä¿®æ­£
        
        ç’°ã¡ã‚ƒã‚“ã®å®Œç’§ãªçŠ¶æ…‹ãƒã‚§ãƒƒã‚«ãƒ¼ï¼ğŸ”
        """
        # GPUåˆ©ç”¨å¯èƒ½æ€§ã®å†ç¢ºèª
        if self.is_gpu:
            if not HAS_GPU or cp is None:
                logger.warning("âš ï¸ GPU mode requested but CuPy not available! Falling back to CPU mode.")
                self.is_gpu = False
                self.xp = np
            else:
                self.xp = cp
                logger.info("âœ… GPU mode confirmed: Using CuPy")
        else:
            self.xp = np
            logger.info("âœ… CPU mode confirmed: Using NumPy")
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        logger.debug(f"State validation complete: is_gpu={self.is_gpu}, xp={self.xp.__name__}, HAS_GPU={HAS_GPU}")
    
    def to_gpu(self, array: Any, dtype: Optional[np.dtype] = None) -> NDArray:
        """
        å®‰å…¨ãªGPUè»¢é€ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼‰
        """
        if self.config.safe_mode:
            return safe_to_gpu(array, dtype)
        return super().to_gpu(array, dtype)
    
    def to_cpu(self, array: Any) -> np.ndarray:
        """
        å®‰å…¨ãªCPUè»¢é€ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼‰
        """
        if self.config.safe_mode:
            return safe_to_cpu(array)
        return super().to_cpu(array)
    
    def compute_lambda_structures(self,
                                trajectory: np.ndarray,
                                md_features: Dict[str, np.ndarray],
                                window_steps: int) -> Dict[str, np.ndarray]:
        """
        LambdaÂ³æ§‹é€ ã‚’GPUã§è¨ˆç®—ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ç‰ˆï¼‰
        """
        try:
            with self.timer('compute_lambda_structures'):
                logger.info(f"ğŸš€ Computing LambdaÂ³ structures (window={window_steps}, mode={'GPU' if self.is_gpu else 'CPU'})")
                
                # å…¥åŠ›æ¤œè¨¼
                if trajectory is None or len(trajectory) == 0:
                    raise ValueError("Empty trajectory provided")
                
                # GPUè»¢é€ï¼ˆå®‰å…¨ç‰ˆï¼‰
                positions_gpu = self.to_gpu(md_features['com_positions'])
                n_frames = positions_gpu.shape[0]
                
                # 1. Î›F - æ§‹é€ ãƒ•ãƒ­ãƒ¼
                with self.timer('lambda_F'):
                    lambda_F, lambda_F_mag = self._compute_lambda_F(positions_gpu)
                
                # 2. Î›FF - äºŒæ¬¡æ§‹é€ 
                with self.timer('lambda_FF'):
                    lambda_FF, lambda_FF_mag = self._compute_lambda_FF(lambda_F)
                
                # 3. ÏT - ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å ´
                with self.timer('rho_T'):
                    rho_T = self._compute_rho_T(positions_gpu, window_steps)
                
                # 4. Q_Î› - ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ãƒãƒ£ãƒ¼ã‚¸
                with self.timer('Q_lambda'):
                    Q_lambda, Q_cumulative = self._compute_Q_lambda(lambda_F, lambda_F_mag)
                
                # 5. Ïƒâ‚› - æ§‹é€ åŒæœŸç‡
                with self.timer('sigma_s'):
                    sigma_s = self._compute_sigma_s(md_features, window_steps)
                
                # 6. æ§‹é€ çš„ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹
                with self.timer('coherence'):
                    coherence = self._compute_coherence(lambda_F, window_steps)
                
                # çµæœã‚’CPUã«è»¢é€ï¼ˆå®‰å…¨ç‰ˆï¼‰
                results = {
                    'lambda_F': self.to_cpu(lambda_F),
                    'lambda_F_mag': self.to_cpu(lambda_F_mag),
                    'lambda_FF': self.to_cpu(lambda_FF),
                    'lambda_FF_mag': self.to_cpu(lambda_FF_mag),
                    'rho_T': self.to_cpu(rho_T),
                    'Q_lambda': self.to_cpu(Q_lambda),
                    'Q_cumulative': self.to_cpu(Q_cumulative),
                    'sigma_s': self.to_cpu(sigma_s),
                    'structural_coherence': self.to_cpu(coherence)
                }
                
                # çµ±è¨ˆæƒ…å ±å‡ºåŠ›
                self._print_statistics(results)
                
                return results
                
        except Exception as e:
            logger.error(f"âŒ Error in compute_lambda_structures: {e}")
            if self.is_gpu and "out of memory" in str(e).lower():
                logger.info("ğŸ’¡ Hint: Try reducing batch_size or switch to CPU mode")
            raise
    
    def _compute_lambda_F(self, positions: NDArray) -> Tuple[NDArray, NDArray]:
        """Î›Fè¨ˆç®—ï¼ˆå®‰å…¨ç‰ˆï¼‰"""
        xp = get_array_module(positions)
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®å·®åˆ†
        lambda_F = xp.diff(positions, axis=0)
        
        # å¤§ãã•
        lambda_F_mag = xp.linalg.norm(lambda_F, axis=1)
        
        return lambda_F, lambda_F_mag
    
    def _compute_lambda_FF(self, lambda_F: NDArray) -> Tuple[NDArray, NDArray]:
        """Î›FFè¨ˆç®—ï¼ˆå®‰å…¨ç‰ˆï¼‰"""
        xp = get_array_module(lambda_F)
        
        # äºŒæ¬¡å·®åˆ†
        lambda_FF = xp.diff(lambda_F, axis=0)
        
        # å¤§ãã•
        lambda_FF_mag = xp.linalg.norm(lambda_FF, axis=1)
        
        return lambda_FF, lambda_FF_mag
    
    def _compute_rho_T(self, positions: NDArray, window_steps: int) -> NDArray:
        """
        ÏTè¨ˆç®—ï¼ˆå®Œå…¨å®‰å…¨ç‰ˆï¼‰
        
        GPU/CPUã®åˆ‡ã‚Šæ›¿ãˆã‚’å®Œå…¨ã«å®‰å…¨ã«ï¼
        """
        if self.is_gpu and HAS_GPU and cp is not None:
            try:
                # GPUç‰ˆï¼šã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ä½¿ç”¨
                if not safe_is_gpu_array(positions):
                    positions = cp.asarray(positions)
                
                rho_T = tension_field_kernel(positions, window_steps)
                
                # è¿”ã‚Šå€¤ã®å‹ç¢ºèª
                if not safe_is_gpu_array(rho_T):
                    logger.warning("tension_field_kernel returned CPU array, converting to GPU")
                    rho_T = cp.asarray(rho_T)
                
                return rho_T
                
            except Exception as e:
                logger.warning(f"GPU kernel failed: {e}, falling back to CPU")
                positions = safe_to_cpu(positions)
                return self._compute_rho_T_cpu(positions, window_steps)
        else:
            # CPUç‰ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            positions = safe_to_cpu(positions)
            return self._compute_rho_T_cpu(positions, window_steps)
    
    def _compute_rho_T_cpu(self, positions: np.ndarray, window_steps: int) -> np.ndarray:
        """ÏTè¨ˆç®—ï¼ˆCPUç‰ˆãƒ»å®Œå…¨å®‰å…¨ï¼‰"""
        # å…¥åŠ›ã‚’ç¢ºå®Ÿã«NumPyé…åˆ—ã«
        positions = safe_to_cpu(positions)
        
        n_frames = positions.shape[0]
        rho_T = np.zeros(n_frames)
        
        for step in range(n_frames):
            start = max(0, step - window_steps)
            end = min(n_frames, step + window_steps + 1)
            local_positions = positions[start:end]
            
            if len(local_positions) > 1:
                centered = local_positions - np.mean(local_positions, axis=0)
                cov = np.cov(centered.T)
                rho_T[step] = np.trace(cov)
        
        return rho_T
    
    def _compute_Q_lambda(self, 
                         lambda_F: NDArray, 
                         lambda_F_mag: NDArray) -> Tuple[NDArray, NDArray]:
        """
        Q_Î›è¨ˆç®—ï¼ˆå®Œå…¨å®‰å…¨ç‰ˆï¼‰
        
        ã©ã‚“ãªå…¥åŠ›ãŒæ¥ã¦ã‚‚å¤§ä¸ˆå¤«ï¼ğŸ’ª
        """
        if self.is_gpu and HAS_GPU and cp is not None:
            try:
                # GPUç‰ˆï¼šå…¥åŠ›ã‚’å®‰å…¨ã«å¤‰æ›
                if not safe_is_gpu_array(lambda_F):
                    lambda_F = cp.asarray(lambda_F)
                if not safe_is_gpu_array(lambda_F_mag):
                    lambda_F_mag = cp.asarray(lambda_F_mag)
                
                # ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ä½¿ç”¨
                Q_lambda = topological_charge_kernel(lambda_F, lambda_F_mag)
                
                # è¿”ã‚Šå€¤ãƒã‚§ãƒƒã‚¯
                if not safe_is_gpu_array(Q_lambda):
                    logger.warning("topological_charge_kernel returned CPU array")
                    Q_lambda = cp.asarray(Q_lambda)
                
                # GPUä¸Šã§ç´¯ç©è¨ˆç®—
                Q_cumulative = cp.cumsum(Q_lambda)
                
                return Q_lambda, Q_cumulative
                
            except Exception as e:
                logger.warning(f"GPU kernel failed: {e}, falling back to CPU")
                lambda_F = safe_to_cpu(lambda_F)
                lambda_F_mag = safe_to_cpu(lambda_F_mag)
                return self._compute_Q_lambda_cpu_safe(lambda_F, lambda_F_mag)
        else:
            # CPUç‰ˆï¼šå…¥åŠ›ã‚’å®‰å…¨ã«å¤‰æ›
            lambda_F = safe_to_cpu(lambda_F)
            lambda_F_mag = safe_to_cpu(lambda_F_mag)
            return self._compute_Q_lambda_cpu_safe(lambda_F, lambda_F_mag)
    
    def _compute_Q_lambda_cpu_safe(self, 
                                   lambda_F: np.ndarray,
                                   lambda_F_mag: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Q_Î›è¨ˆç®—ï¼ˆCPUç‰ˆãƒ»å®Œå…¨å®‰å…¨ï¼‰"""
        # å…¥åŠ›ã‚’ç¢ºå®Ÿã«NumPyé…åˆ—ã«
        lambda_F = safe_to_cpu(lambda_F)
        lambda_F_mag = safe_to_cpu(lambda_F_mag)
        
        n_steps = len(lambda_F_mag)
        Q_lambda = np.zeros(n_steps + 1)
        
        for step in range(1, n_steps):
            if lambda_F_mag[step] > 1e-10 and lambda_F_mag[step-1] > 1e-10:
                v1 = lambda_F[step-1] / lambda_F_mag[step-1]
                v2 = lambda_F[step] / lambda_F_mag[step]
                
                cos_angle = np.clip(np.dot(v1, v2), -1, 1)
                angle = np.arccos(cos_angle)
                
                # 2Då›è»¢æ–¹å‘
                cross_z = v1[0]*v2[1] - v1[1]*v2[0]
                signed_angle = angle if cross_z >= 0 else -angle
                
                Q_lambda[step] = signed_angle / (2 * np.pi)
        
        Q_lambda_result = Q_lambda[:-1]
        Q_cumulative = np.cumsum(Q_lambda_result)
        
        return Q_lambda_result, Q_cumulative
    
    def _compute_sigma_s(self, 
                        md_features: Dict[str, np.ndarray],
                        window_steps: int) -> NDArray:
        """Ïƒâ‚›è¨ˆç®—ï¼ˆå®‰å…¨ç‰ˆï¼‰"""
        n_frames = len(md_features.get('rmsd', []))
        
        if 'rmsd' not in md_features or 'radius_of_gyration' not in md_features:
            xp = cp if (self.is_gpu and HAS_GPU) else np
            return xp.zeros(n_frames)
        
        # å®‰å…¨ãªGPUè»¢é€
        rmsd_gpu = self.to_gpu(md_features['rmsd'])
        rg_gpu = self.to_gpu(md_features['radius_of_gyration'])
        
        xp = get_array_module(rmsd_gpu)
        sigma_s = xp.zeros(n_frames)
        
        # ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ç›¸é–¢è¨ˆç®—
        for step in range(n_frames):
            start = max(0, step - window_steps)
            end = min(n_frames, step + window_steps + 1)
            
            if end - start > 1:
                local_rmsd = rmsd_gpu[start:end]
                local_rg = rg_gpu[start:end]
                
                std_rmsd = xp.std(local_rmsd)
                std_rg = xp.std(local_rg)
                
                if std_rmsd > 1e-10 and std_rg > 1e-10:
                    try:
                        # GPUä¸Šã§ç›¸é–¢è¨ˆç®—
                        corr_matrix = xp.corrcoef(
                            xp.stack([local_rmsd, local_rg])
                        )
                        sigma_s[step] = xp.abs(corr_matrix[0, 1])
                    except Exception as e:
                        logger.debug(f"Correlation calculation failed at step {step}: {e}")
                        sigma_s[step] = 0.0
        
        return sigma_s
    
    def _compute_coherence(self, 
                          lambda_F: NDArray,
                          window: int) -> NDArray:
        """æ§‹é€ çš„ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹è¨ˆç®—ï¼ˆå®‰å…¨ç‰ˆï¼‰"""
        xp = get_array_module(lambda_F)
        n_frames = len(lambda_F)
        coherence = xp.zeros(n_frames + 1)
        
        for i in range(window, n_frames - window):
            local_F = lambda_F[i-window:i+window]
            
            # å¹³å‡æ–¹å‘
            mean_dir = xp.mean(local_F, axis=0)
            mean_norm = xp.linalg.norm(mean_dir)
            
            if mean_norm > 1e-10:
                mean_dir /= mean_norm
                
                # å„ãƒ™ã‚¯ãƒˆãƒ«ã¨ã®å†…ç©
                norms = xp.linalg.norm(local_F, axis=1)
                valid_mask = norms > 1e-10
                
                if xp.any(valid_mask):
                    normalized_F = local_F[valid_mask] / norms[valid_mask, xp.newaxis]
                    coherences = xp.dot(normalized_F, mean_dir)
                    coherence[i] = xp.mean(coherences)
        
        return coherence[:-1]
    
    def _print_statistics(self, results: Dict[str, np.ndarray]):
        """çµ±è¨ˆæƒ…å ±ã‚’å‡ºåŠ›ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰"""
        try:
            logger.info("ğŸ“Š Lambda Structure Statistics:")
            
            if 'lambda_F_mag' in results and len(results['lambda_F_mag']) > 0:
                logger.info(f"   Î›F magnitude range: {np.min(results['lambda_F_mag']):.3e} - "
                           f"{np.max(results['lambda_F_mag']):.3e}")
            
            if 'rho_T' in results and len(results['rho_T']) > 0:
                logger.info(f"   ÏT (tension) range: {np.min(results['rho_T']):.3f} - "
                           f"{np.max(results['rho_T']):.3f}")
            
            if 'Q_cumulative' in results and len(results['Q_cumulative']) > 0:
                logger.info(f"   Q_Î› cumulative drift: {results['Q_cumulative'][-1]:.3f}")
            
            if 'sigma_s' in results and len(results['sigma_s']) > 0:
                logger.info(f"   Average Ïƒâ‚› (sync): {np.mean(results['sigma_s']):.3f}")
                
        except Exception as e:
            logger.warning(f"Failed to print statistics: {e}")
    
    def compute_adaptive_window_size(self,
                                   md_features: Dict[str, np.ndarray],
                                   lambda_structures: Dict[str, np.ndarray],
                                   n_frames: int,
                                   config: any) -> Dict[str, Union[int, float, dict]]:
        """
        é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºè¨ˆç®—ï¼ˆå®Œå…¨å®‰å…¨ç‰ˆï¼‰
        """
        try:
            with self.timer('adaptive_window_size'):
                base_window = int(n_frames * config.window_scale)
                
                # RMSDå¤‰å‹•æ€§
                rmsd_volatility = 0.0
                if 'rmsd' in md_features:
                    rmsd_gpu = self.to_gpu(md_features['rmsd'])
                    xp = get_array_module(rmsd_gpu)
                    mean_val = xp.mean(rmsd_gpu)
                    if abs(mean_val) > 1e-10:
                        rmsd_volatility = float(xp.std(rmsd_gpu) / mean_val)
                
                # Lambda Få¤‰å‹•æ€§
                lambda_f_volatility = 0.0
                if 'lambda_F_mag' in lambda_structures:
                    lf_mag_gpu = self.to_gpu(lambda_structures['lambda_F_mag'])
                    xp = get_array_module(lf_mag_gpu)
                    mean_val = xp.mean(lf_mag_gpu)
                    if abs(mean_val) > 1e-10:
                        lambda_f_volatility = float(xp.std(lf_mag_gpu) / mean_val)
                
                # ÏTå®‰å®šæ€§
                rho_t_stability = 1.0
                if 'rho_T' in lambda_structures:
                    rho_t_gpu = self.to_gpu(lambda_structures['rho_T'])
                    xp = get_array_module(rho_t_gpu)
                    
                    # å±€æ‰€åˆ†æ•£è¨ˆç®—
                    test_window = min(50, n_frames // 20)
                    local_vars = []
                    
                    for i in range(0, len(rho_t_gpu) - test_window, test_window // 2):
                        local_var = float(xp.var(rho_t_gpu[i:i+test_window]))
                        local_vars.append(local_var)
                    
                    if local_vars:
                        mean_var = np.mean(local_vars)
                        if abs(mean_var) > 1e-10:
                            rho_t_stability = np.std(local_vars) / mean_var
                
                # ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼è¨ˆç®—
                scale_factor = 1.0
                
                if rmsd_volatility > 0.5:
                    scale_factor *= 0.7
                elif rmsd_volatility < 0.1:
                    scale_factor *= 1.5
                
                if lambda_f_volatility > 1.0:
                    scale_factor *= 0.8
                elif lambda_f_volatility < 0.2:
                    scale_factor *= 1.3
                
                if rho_t_stability > 1.5:
                    scale_factor *= 0.85
                
                # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºæ±ºå®š
                adaptive_window = int(base_window * scale_factor)
                adaptive_window = np.clip(adaptive_window, config.min_window, config.max_window)
                
                windows = {
                    'primary': adaptive_window,
                    'fast': max(config.min_window, adaptive_window // 2),
                    'slow': min(config.max_window, adaptive_window * 2),
                    'boundary': max(10, adaptive_window // 3),
                    'scale_factor': scale_factor,
                    'volatility_metrics': {
                        'rmsd': rmsd_volatility,
                        'lambda_f': lambda_f_volatility,
                        'rho_t': rho_t_stability
                    }
                }
                
                logger.info(f"\nğŸ¯ Adaptive window sizes:")
                logger.info(f"   Primary: {windows['primary']} frames")
                logger.info(f"   Scale factor: {scale_factor:.2f}")
                
                return windows
                
        except Exception as e:
            logger.error(f"Failed to compute adaptive window size: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ã‚’è¿”ã™
            return {
                'primary': config.min_window if hasattr(config, 'min_window') else 50,
                'fast': 25,
                'slow': 100,
                'boundary': 10,
                'scale_factor': 1.0,
                'volatility_metrics': {}
            }

# ===============================
# Helper Functions (å®‰å…¨ç‰ˆ)
# ===============================

def compute_structural_coherence_gpu(lambda_F: NDArray,
                                   window: int,
                                   backend: Optional[GPUBackend] = None) -> np.ndarray:
    """æ§‹é€ çš„ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹è¨ˆç®—ï¼ˆã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®‰å…¨ç‰ˆï¼‰"""
    if backend is None:
        backend = GPUBackend()
    
    lambda_F_gpu = backend.to_gpu(lambda_F) if backend.is_gpu else lambda_F
    xp = get_array_module(lambda_F_gpu)
    n_frames = len(lambda_F_gpu)
    coherence = xp.zeros(n_frames)
    
    for i in range(window, n_frames - window):
        local_F = lambda_F_gpu[i-window:i+window]
        mean_dir = xp.mean(local_F, axis=0)
        mean_norm = xp.linalg.norm(mean_dir)
        
        if mean_norm > 1e-10:
            mean_dir /= mean_norm
            norms = xp.linalg.norm(local_F, axis=1)
            valid_mask = norms > 1e-10
            
            if xp.any(valid_mask):
                normalized_F = local_F[valid_mask] / norms[valid_mask, xp.newaxis]
                coherences = xp.dot(normalized_F, mean_dir)
                coherence[i] = xp.mean(coherences)
    
    return safe_to_cpu(coherence)

def compute_local_fractal_dimension_gpu(series: NDArray,
                                      window: int,
                                      backend: Optional[GPUBackend] = None) -> np.ndarray:
    """å±€æ‰€ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¨ˆç®—ï¼ˆå®‰å…¨ç‰ˆï¼‰"""
    if backend is None:
        backend = GPUBackend()
    
    series_gpu = backend.to_gpu(series) if backend.is_gpu else series
    xp = get_array_module(series_gpu)
    n = len(series_gpu)
    dims = xp.ones(n)
    
    scales = xp.array([2, 4, 8, 16])
    
    for i in range(window, n - window):
        local = series_gpu[i-window:i+window]
        counts = xp.zeros(len(scales))
        
        for j, scale in enumerate(scales):
            boxes = 0
            for k in range(0, len(local)-scale, scale):
                segment = local[k:k+scale]
                if xp.max(segment) - xp.min(segment) > 1e-10:
                    boxes += 1
            counts[j] = max(boxes, 1)
        
        if xp.max(counts) > xp.min(counts):
            log_scales = xp.log(scales)
            log_counts = xp.log(counts + 1e-10)  # ã‚¼ãƒ­é™¤ç®—é˜²æ­¢
            
            # ç·šå½¢å›å¸°
            A = xp.vstack([log_scales, xp.ones(len(log_scales))]).T
            try:
                slope, _ = xp.linalg.lstsq(A, log_counts, rcond=None)[0]
                dims[i] = max(0.5, min(2.0, -slope))
            except:
                dims[i] = 1.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    return safe_to_cpu(dims)

# ===============================
# Main Function
# ===============================
def compute_lambda_structures_gpu(trajectory: np.ndarray,
                                md_features: Dict[str, np.ndarray],
                                window_steps: int,
                                config: Optional[LambdaStructureConfig] = None,
                                memory_manager: Optional[GPUMemoryManager] = None) -> Dict[str, np.ndarray]:
    """
    LambdaÂ³æ§‹é€ è¨ˆç®—ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆå®Œå…¨å®‰å…¨ç‰ˆï¼‰
    
    æ—¢å­˜ã®APIã¨äº’æ›æ€§ã‚’ä¿ã¤ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°
    """
    try:
        calculator = LambdaStructuresGPU(config, memory_manager)
        return calculator.compute_lambda_structures(trajectory, md_features, window_steps)
    except Exception as e:
        logger.error(f"Lambda structure computation failed: {e}")
        raise

def compute_adaptive_window_size_gpu(md_features: Dict[str, np.ndarray],
                                   lambda_structures: Dict[str, np.ndarray],
                                   n_frames: int,
                                   config: any) -> Dict[str, Union[int, float, dict]]:
    """é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºè¨ˆç®—ã®ãƒ©ãƒƒãƒ‘ãƒ¼ï¼ˆå®‰å…¨ç‰ˆï¼‰"""
    try:
        calculator = LambdaStructuresGPU()
        return calculator.compute_adaptive_window_size(
            md_features, lambda_structures, n_frames, config
        )
    except Exception as e:
        logger.error(f"Adaptive window size computation failed: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return {
            'primary': 50,
            'fast': 25, 
            'slow': 100,
            'boundary': 10,
            'scale_factor': 1.0,
            'volatility_metrics': {}
        }

def compute_structural_coherence_gpu(lambda_F: np.ndarray,
                                    window: int = 50) -> np.ndarray:
    """æ§‹é€ çš„ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹è¨ˆç®—ã®ãƒ©ãƒƒãƒ‘ãƒ¼"""
    computer = LambdaStructuresGPU()
    lambda_F_gpu = computer.to_gpu(lambda_F)
    coherence = computer._compute_coherence(lambda_F_gpu, window)
    return computer.to_cpu(coherence)

def compute_local_fractal_dimension_gpu(q_cumulative: np.ndarray,
                                       window: int = 50) -> np.ndarray:
    """å±€æ‰€ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¨ˆç®—ã®ãƒ©ãƒƒãƒ‘ãƒ¼"""
    from ..detection.boundary_detection_gpu import BoundaryDetectorGPU
    detector = BoundaryDetectorGPU()
    return detector._compute_fractal_dimensions_gpu(q_cumulative, window)

def compute_coupling_strength_gpu(q_cumulative: np.ndarray,
                                 window: int = 50) -> np.ndarray:
    """çµåˆå¼·åº¦è¨ˆç®—ã®ãƒ©ãƒƒãƒ‘ãƒ¼"""
    from ..detection.boundary_detection_gpu import BoundaryDetectorGPU
    detector = BoundaryDetectorGPU()
    return detector._compute_coupling_strength_gpu(q_cumulative, window)

def compute_structural_entropy_gpu(rho_t: np.ndarray,
                                  window: int = 50) -> np.ndarray:
    """æ§‹é€ ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—ã®ãƒ©ãƒƒãƒ‘ãƒ¼"""
    from ..detection.boundary_detection_gpu import BoundaryDetectorGPU
    detector = BoundaryDetectorGPU()
    return detector._compute_structural_entropy_gpu(rho_t, window)

# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ›´æ–°
__all__ = [
    'LambdaStructuresGPU',
    'LambdaStructureConfig',
    'compute_lambda_structures_gpu',
    'compute_adaptive_window_size_gpu',
    'compute_structural_coherence_gpu',
    'compute_local_fractal_dimension_gpu',
    'compute_coupling_strength_gpu',
    'compute_structural_entropy_gpu',
]
