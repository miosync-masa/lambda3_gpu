"""
LambdaÂ³ Structure Computation (GPU Version)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

LambdaÂ³æ§‹é€ ã®è¨ˆç®—ã‚’GPUã§è¶…é«˜é€ŸåŒ–ï¼
NO TIME, NO PHYSICS, ONLY STRUCTURE... but FASTER! ğŸš€

by ç’°ã¡ã‚ƒã‚“
"""

import numpy as np
import logging
from typing import Dict, Optional, Tuple, Union
from dataclasses import dataclass

# GPU imports
try:
    import cupy as cp
    from cupyx.scipy.signal import savgol_filter as cp_savgol_filter
    HAS_GPU = True
except ImportError:
    HAS_GPU = False
    cp = None

# Local imports
from ..core import GPUBackend, GPUMemoryManager, GPUTimer
from ..core import tension_field_kernel, topological_charge_kernel
from ..types import ArrayType, NDArray

logger = logging.getLogger('lambda3_gpu.structures.lambda_structures')

# ===============================
# Configuration
# ===============================

@dataclass
class LambdaStructureConfig:
    """Lambdaæ§‹é€ è¨ˆç®—ã®è¨­å®š"""
    use_mixed_precision: bool = False
    batch_size: Optional[int] = None
    cache_intermediates: bool = True
    profile: bool = False

# ===============================
# Lambda Structures GPU Class
# ===============================

class LambdaStructuresGPU(GPUBackend):
    """
    LambdaÂ³æ§‹é€ è¨ˆç®—ã®GPUå®Ÿè£…ã‚¯ãƒ©ã‚¹
    ã‚ã¡ã‚ƒãã¡ã‚ƒé€Ÿã„ã‚ˆã€œï¼âœ¨
    """
    
    def __init__(self, 
                 config: Optional[LambdaStructureConfig] = None,
                 memory_manager: Optional[GPUMemoryManager] = None,
                 **kwargs):
        """
        Parameters
        ----------
        config : LambdaStructureConfig
            è¨ˆç®—è¨­å®š
        memory_manager : GPUMemoryManager
            ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        super().__init__(
            mixed_precision=config.use_mixed_precision if config else False,
            profile=config.profile if config else False,
            **kwargs
        )
        
        self.config = config or LambdaStructureConfig()
        self.memory_manager = memory_manager or GPUMemoryManager()
        self._cache = {} if self.config.cache_intermediates else None
        
    def compute_lambda_structures(self,
                                trajectory: np.ndarray,
                                md_features: Dict[str, np.ndarray],
                                window_steps: int) -> Dict[str, np.ndarray]:
        """
        LambdaÂ³æ§‹é€ ã‚’GPUã§è¨ˆç®—
        
        Parameters
        ----------
        trajectory : np.ndarray
            ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒª (n_frames, n_atoms, 3)
        md_features : dict
            MDç‰¹å¾´é‡è¾æ›¸
        window_steps : int
            ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
            
        Returns
        -------
        dict
            Lambdaæ§‹é€ ã®è¾æ›¸
        """
        with self.timer('compute_lambda_structures'):
            logger.info(f"ğŸš€ GPU Computing LambdaÂ³ structures (window={window_steps})")
            
            # GPUè»¢é€
            positions_gpu = self.to_gpu(md_features['com_positions'])
            n_frames = positions_gpu.shape[0]
            
            # 1. Î›F - æ§‹é€ ãƒ•ãƒ­ãƒ¼
            with self.timer('lambda_F'):
                lambda_F, lambda_F_mag = self._compute_lambda_F(positions_gpu)
            
            # 2. Î›FF - äºŒæ¬¡æ§‹é€ 
            with self.timer('lambda_FF'):
                lambda_FF, lambda_FF_mag = self._compute_lambda_FF(lambda_F)
            
            # 3. ÏT - ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å ´
            with self.timer('rho_T'):
                rho_T = self._compute_rho_T(positions_gpu, window_steps)
            
            # 4. Q_Î› - ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ãƒãƒ£ãƒ¼ã‚¸
            with self.timer('Q_lambda'):
                Q_lambda, Q_cumulative = self._compute_Q_lambda(lambda_F, lambda_F_mag)
            
            # 5. Ïƒâ‚› - æ§‹é€ åŒæœŸç‡
            with self.timer('sigma_s'):
                sigma_s = self._compute_sigma_s(md_features, window_steps)
            
            # 6. æ§‹é€ çš„ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹
            with self.timer('coherence'):
                coherence = self._compute_coherence(lambda_F, window_steps)
            
            # çµæœã‚’CPUã«è»¢é€
            results = {
                'lambda_F': self.to_cpu(lambda_F),
                'lambda_F_mag': self.to_cpu(lambda_F_mag),
                'lambda_FF': self.to_cpu(lambda_FF),
                'lambda_FF_mag': self.to_cpu(lambda_FF_mag),
                'rho_T': self.to_cpu(rho_T),
                'Q_lambda': self.to_cpu(Q_lambda),
                'Q_cumulative': self.to_cpu(Q_cumulative),
                'sigma_s': self.to_cpu(sigma_s),
                'structural_coherence': self.to_cpu(coherence)
            }
            
            # çµ±è¨ˆæƒ…å ±å‡ºåŠ›
            self._print_statistics(results)
            
            return results
    
    def _compute_lambda_F(self, positions: cp.ndarray) -> Tuple[cp.ndarray, cp.ndarray]:
        """Î›Fè¨ˆç®—ï¼ˆGPUç‰ˆï¼‰"""
        # ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®å·®åˆ†
        lambda_F = self.xp.diff(positions, axis=0)
        
        # å¤§ãã•
        lambda_F_mag = self.xp.linalg.norm(lambda_F, axis=1)
        
        return lambda_F, lambda_F_mag
    
    def _compute_lambda_FF(self, lambda_F: cp.ndarray) -> Tuple[cp.ndarray, cp.ndarray]:
        """Î›FFè¨ˆç®—ï¼ˆGPUç‰ˆï¼‰"""
        # äºŒæ¬¡å·®åˆ†
        lambda_FF = self.xp.diff(lambda_F, axis=0)
        
        # å¤§ãã•
        lambda_FF_mag = self.xp.linalg.norm(lambda_FF, axis=1)
        
        return lambda_FF, lambda_FF_mag
    
    def _compute_rho_T(self, positions: cp.ndarray, window_steps: int) -> cp.ndarray:
        """ÏTè¨ˆç®—ï¼ˆã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ä½¿ç”¨ï¼‰"""
        if self.is_gpu and HAS_GPU:
            # ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ä½¿ç”¨
            return tension_field_kernel(positions, window_steps)
        else:
            # CPUç‰ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self._compute_rho_T_cpu(positions, window_steps)
    
    def _compute_rho_T_cpu(self, positions: np.ndarray, window_steps: int) -> np.ndarray:
        """ÏTè¨ˆç®—ï¼ˆCPUç‰ˆï¼‰"""
        n_frames = positions.shape[0]
        rho_T = np.zeros(n_frames)
        
        for step in range(n_frames):
            start = max(0, step - window_steps)
            end = min(n_frames, step + window_steps + 1)
            local_positions = positions[start:end]
            
            if len(local_positions) > 1:
                centered = local_positions - np.mean(local_positions, axis=0)
                cov = np.cov(centered.T)
                rho_T[step] = np.trace(cov)
        
        return rho_T
    
    def _compute_Q_lambda(self, 
                         lambda_F: cp.ndarray, 
                         lambda_F_mag: cp.ndarray) -> Tuple[cp.ndarray, cp.ndarray]:
        """Q_Î›è¨ˆç®—ï¼ˆã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ä½¿ç”¨ï¼‰"""
        if self.is_gpu and HAS_GPU:
            # ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ä½¿ç”¨
            Q_lambda = topological_charge_kernel(lambda_F, lambda_F_mag)
        else:
            # CPUç‰ˆ
            Q_lambda = self._compute_Q_lambda_cpu(lambda_F, lambda_F_mag)
        
        # ç´¯ç©
        Q_cumulative = self.xp.cumsum(Q_lambda)
        
        return Q_lambda, Q_cumulative
    
    def _compute_Q_lambda_cpu(self, 
                             lambda_F: np.ndarray,
                             lambda_F_mag: np.ndarray) -> np.ndarray:
        """Q_Î›è¨ˆç®—ï¼ˆCPUç‰ˆï¼‰"""
        n_steps = len(lambda_F_mag)
        Q_lambda = np.zeros(n_steps + 1)
        
        for step in range(1, n_steps):
            if lambda_F_mag[step] > 1e-10 and lambda_F_mag[step-1] > 1e-10:
                v1 = lambda_F[step-1] / lambda_F_mag[step-1]
                v2 = lambda_F[step] / lambda_F_mag[step]
                
                cos_angle = np.clip(np.dot(v1, v2), -1, 1)
                angle = np.arccos(cos_angle)
                
                # 2Då›è»¢æ–¹å‘
                cross_z = v1[0]*v2[1] - v1[1]*v2[0]
                signed_angle = angle if cross_z >= 0 else -angle
                
                Q_lambda[step] = signed_angle / (2 * np.pi)
        
        return Q_lambda[:-1]
    
    def _compute_sigma_s(self, 
                        md_features: Dict[str, np.ndarray],
                        window_steps: int) -> cp.ndarray:
        """Ïƒâ‚›è¨ˆç®—ï¼ˆGPUç‰ˆï¼‰"""
        n_frames = len(md_features.get('rmsd', []))
        
        if 'rmsd' not in md_features or 'radius_of_gyration' not in md_features:
            return self.zeros(n_frames)
        
        # GPUè»¢é€
        rmsd_gpu = self.to_gpu(md_features['rmsd'])
        rg_gpu = self.to_gpu(md_features['radius_of_gyration'])
        
        sigma_s = self.zeros(n_frames)
        
        # ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ç›¸é–¢è¨ˆç®—
        for step in range(n_frames):
            start = max(0, step - window_steps)
            end = min(n_frames, step + window_steps + 1)
            
            if end - start > 1:
                local_rmsd = rmsd_gpu[start:end]
                local_rg = rg_gpu[start:end]
                
                std_rmsd = self.xp.std(local_rmsd)
                std_rg = self.xp.std(local_rg)
                
                if std_rmsd > 1e-10 and std_rg > 1e-10:
                    # GPUä¸Šã§ç›¸é–¢è¨ˆç®—
                    corr_matrix = self.xp.corrcoef(
                        self.xp.stack([local_rmsd, local_rg])
                    )
                    sigma_s[step] = self.xp.abs(corr_matrix[0, 1])
        
        return sigma_s
    
    def _compute_coherence(self, 
                          lambda_F: cp.ndarray,
                          window: int) -> cp.ndarray:
        """æ§‹é€ çš„ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹è¨ˆç®—ï¼ˆGPUç‰ˆï¼‰"""
        n_frames = len(lambda_F)
        coherence = self.zeros(n_frames + 1)
        
        for i in range(window, n_frames - window):
            local_F = lambda_F[i-window:i+window]
            
            # å¹³å‡æ–¹å‘
            mean_dir = self.xp.mean(local_F, axis=0)
            mean_norm = self.xp.linalg.norm(mean_dir)
            
            if mean_norm > 1e-10:
                mean_dir /= mean_norm
                
                # å„ãƒ™ã‚¯ãƒˆãƒ«ã¨ã®å†…ç©
                norms = self.xp.linalg.norm(local_F, axis=1)
                valid_mask = norms > 1e-10
                
                if self.xp.any(valid_mask):
                    normalized_F = local_F[valid_mask] / norms[valid_mask, self.xp.newaxis]
                    coherences = self.xp.dot(normalized_F, mean_dir)
                    coherence[i] = self.xp.mean(coherences)
        
        return coherence[:-1]
    
    def _print_statistics(self, results: Dict[str, np.ndarray]):
        """çµ±è¨ˆæƒ…å ±ã‚’å‡ºåŠ›"""
        logger.info(f"   Î›F magnitude range: {np.min(results['lambda_F_mag']):.3e} - "
                   f"{np.max(results['lambda_F_mag']):.3e}")
        logger.info(f"   ÏT (tension) range: {np.min(results['rho_T']):.3f} - "
                   f"{np.max(results['rho_T']):.3f}")
        logger.info(f"   Q_Î› cumulative drift: {results['Q_cumulative'][-1]:.3f}")
        logger.info(f"   Average Ïƒâ‚› (sync): {np.mean(results['sigma_s']):.3f}")
    
    def compute_adaptive_window_size(self,
                                   md_features: Dict[str, np.ndarray],
                                   lambda_structures: Dict[str, np.ndarray],
                                   n_frames: int,
                                   config: any) -> Dict[str, Union[int, float, dict]]:
        """
        é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºè¨ˆç®—ï¼ˆGPUç‰ˆï¼‰
        """
        with self.timer('adaptive_window_size'):
            base_window = int(n_frames * config.window_scale)
            
            # GPUè»¢é€
            if 'rmsd' in md_features:
                rmsd_gpu = self.to_gpu(md_features['rmsd'])
                rmsd_volatility = float(self.xp.std(rmsd_gpu) / (self.xp.mean(rmsd_gpu) + 1e-10))
            else:
                rmsd_volatility = 0.0
            
            if 'lambda_F_mag' in lambda_structures:
                lf_mag_gpu = self.to_gpu(lambda_structures['lambda_F_mag'])
                lambda_f_volatility = float(self.xp.std(lf_mag_gpu) / (self.xp.mean(lf_mag_gpu) + 1e-10))
            else:
                lambda_f_volatility = 0.0
            
            if 'rho_T' in lambda_structures:
                rho_t_gpu = self.to_gpu(lambda_structures['rho_T'])
                
                # å±€æ‰€åˆ†æ•£è¨ˆç®—
                test_window = min(50, n_frames // 20)
                local_vars = []
                
                for i in range(0, len(rho_t_gpu) - test_window, test_window // 2):
                    local_var = float(self.xp.var(rho_t_gpu[i:i+test_window]))
                    local_vars.append(local_var)
                
                if local_vars:
                    rho_t_stability = np.std(local_vars) / (np.mean(local_vars) + 1e-10)
                else:
                    rho_t_stability = 1.0
            else:
                rho_t_stability = 1.0
            
            # ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼è¨ˆç®—
            scale_factor = 1.0
            
            if rmsd_volatility > 0.5:
                scale_factor *= 0.7
            elif rmsd_volatility < 0.1:
                scale_factor *= 1.5
            
            if lambda_f_volatility > 1.0:
                scale_factor *= 0.8
            elif lambda_f_volatility < 0.2:
                scale_factor *= 1.3
            
            if rho_t_stability > 1.5:
                scale_factor *= 0.85
            
            # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºæ±ºå®š
            adaptive_window = int(base_window * scale_factor)
            adaptive_window = np.clip(adaptive_window, config.min_window, config.max_window)
            
            windows = {
                'primary': adaptive_window,
                'fast': max(config.min_window, adaptive_window // 2),
                'slow': min(config.max_window, adaptive_window * 2),
                'boundary': max(10, adaptive_window // 3),
                'scale_factor': scale_factor,
                'volatility_metrics': {
                    'rmsd': rmsd_volatility,
                    'lambda_f': lambda_f_volatility,
                    'rho_t': rho_t_stability
                }
            }
            
            logger.info(f"\nğŸ¯ Adaptive window sizes (GPU computed):")
            logger.info(f"   Primary: {windows['primary']} frames")
            logger.info(f"   Scale factor: {scale_factor:.2f}")
            
            return windows

# ===============================
# Helper Functions (GPUç‰ˆ)
# ===============================

def compute_structural_coherence_gpu(lambda_F: Union[np.ndarray, cp.ndarray],
                                   window: int,
                                   backend: Optional[GPUBackend] = None) -> np.ndarray:
    """æ§‹é€ çš„ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹è¨ˆç®—ï¼ˆã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ç‰ˆï¼‰"""
    if backend is None:
        backend = GPUBackend()
    
    lambda_F_gpu = backend.to_gpu(lambda_F)
    n_frames = len(lambda_F_gpu)
    coherence = backend.zeros(n_frames)
    
    for i in range(window, n_frames - window):
        local_F = lambda_F_gpu[i-window:i+window]
        mean_dir = backend.xp.mean(local_F, axis=0)
        mean_norm = backend.xp.linalg.norm(mean_dir)
        
        if mean_norm > 1e-10:
            mean_dir /= mean_norm
            norms = backend.xp.linalg.norm(local_F, axis=1)
            valid_mask = norms > 1e-10
            
            if backend.xp.any(valid_mask):
                normalized_F = local_F[valid_mask] / norms[valid_mask, backend.xp.newaxis]
                coherences = backend.xp.dot(normalized_F, mean_dir)
                coherence[i] = backend.xp.mean(coherences)
    
    return backend.to_cpu(coherence)

def compute_local_fractal_dimension_gpu(series: Union[np.ndarray, cp.ndarray],
                                      window: int,
                                      backend: Optional[GPUBackend] = None) -> np.ndarray:
    """å±€æ‰€ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¨ˆç®—ï¼ˆGPUç‰ˆï¼‰"""
    if backend is None:
        backend = GPUBackend()
    
    series_gpu = backend.to_gpu(series)
    n = len(series_gpu)
    dims = backend.ones(n)
    
    scales = backend.xp.array([2, 4, 8, 16])
    
    for i in range(window, n - window):
        local = series_gpu[i-window:i+window]
        counts = backend.zeros(len(scales))
        
        for j, scale in enumerate(scales):
            boxes = 0
            for k in range(0, len(local)-scale, scale):
                segment = local[k:k+scale]
                if backend.xp.max(segment) - backend.xp.min(segment) > 1e-10:
                    boxes += 1
            counts[j] = max(boxes, 1)
        
        if backend.xp.max(counts) > backend.xp.min(counts):
            log_scales = backend.xp.log(scales)
            log_counts = backend.xp.log(counts)
            
            # ç·šå½¢å›å¸°
            A = backend.xp.vstack([log_scales, backend.xp.ones(len(log_scales))]).T
            slope, _ = backend.xp.linalg.lstsq(A, log_counts, rcond=None)[0]
            dims[i] = max(0.5, min(2.0, -slope))
    
    return backend.to_cpu(dims)

def compute_coupling_strength_gpu(Q_cumulative: Union[np.ndarray, cp.ndarray],
                                window: int,
                                backend: Optional[GPUBackend] = None) -> np.ndarray:
    """çµåˆå¼·åº¦è¨ˆç®—ï¼ˆGPUç‰ˆï¼‰"""
    if backend is None:
        backend = GPUBackend()
    
    Q_gpu = backend.to_gpu(Q_cumulative)
    coupling = backend.ones_like(Q_gpu)
    
    for i in range(window, len(Q_gpu) - window):
        local_Q = Q_gpu[i-window:i+window]
        var = backend.xp.var(local_Q)
        if var > 1e-10:
            coupling[i] = 1.0 / (1.0 + var)
    
    return backend.to_cpu(coupling)

def compute_structural_entropy_gpu(rho_T: Union[np.ndarray, cp.ndarray],
                                 window: int,
                                 backend: Optional[GPUBackend] = None) -> np.ndarray:
    """æ§‹é€ ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—ï¼ˆGPUç‰ˆï¼‰"""
    if backend is None:
        backend = GPUBackend()
    
    rho_T_gpu = backend.to_gpu(rho_T)
    entropy = backend.zeros_like(rho_T_gpu)
    
    for i in range(window, len(rho_T_gpu) - window):
        local_rho = rho_T_gpu[i-window:i+window]
        
        if backend.xp.sum(local_rho) > 0:
            # æ­£è¦åŒ–
            p = local_rho / backend.xp.sum(local_rho)
            # ã‚·ãƒ£ãƒãƒ³ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
            entropy[i] = -backend.xp.sum(p * backend.xp.log(p + 1e-10))
    
    return backend.to_cpu(entropy)

# ===============================
# Main Function
# ===============================

def compute_lambda_structures_gpu(trajectory: np.ndarray,
                                md_features: Dict[str, np.ndarray],
                                window_steps: int,
                                config: Optional[LambdaStructureConfig] = None,
                                memory_manager: Optional[GPUMemoryManager] = None) -> Dict[str, np.ndarray]:
    """
    LambdaÂ³æ§‹é€ è¨ˆç®—ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆGPUç‰ˆï¼‰
    
    æ—¢å­˜ã®APIã¨äº’æ›æ€§ã‚’ä¿ã¤ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°
    """
    calculator = LambdaStructuresGPU(config, memory_manager)
    return calculator.compute_lambda_structures(trajectory, md_features, window_steps)

def compute_adaptive_window_size_gpu(md_features: Dict[str, np.ndarray],
                                   lambda_structures: Dict[str, np.ndarray],
                                   n_frames: int,
                                   config: any) -> Dict[str, Union[int, float, dict]]:
    """é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºè¨ˆç®—ã®ãƒ©ãƒƒãƒ‘ãƒ¼"""
    calculator = LambdaStructuresGPU()
    return calculator.compute_adaptive_window_size(
        md_features, lambda_structures, n_frames, config
    )
