#!/usr/bin/env python3
"""
Third Impact Analytics v3.0 - GPU Atomic Network Edition
========================================================

åŸå­ãƒ¬ãƒ™ãƒ«é‡å­ç—•è·¡ã®é«˜é€Ÿæ¤œå‡º + é«˜åº¦ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æ
residue_networkã®è³¢ã„åˆ¤å®šã‚’åŸå­ãƒ¬ãƒ™ãƒ«ã§å®Ÿç¾ï¼ï¼

- å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ï¼šç¬é–“çš„å”èª¿ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
- è¤‡æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ï¼šéåŒæœŸç›¸é–¢ãƒ»ãƒ©ã‚°ä»˜ãå› æœãƒ»é©å¿œçš„çª“
- æ®‹åŸºé–“ãƒ–ãƒªãƒƒã‚¸ï¼šåŸå­ãŒæ‹…ã†æ®‹åŸºé–“æƒ…å ±ä¼é”ã‚’ç‰¹å®š

Version: 3.0.0 - GPU Atomic Network Edition
Authors: ç’°ã¡ã‚ƒã‚“ & ã”ä¸»äººã•ã¾ ğŸ’•
"""

import numpy as np
import logging
from typing import Dict, List, Optional, Tuple, Any, Set
from dataclasses import dataclass, field
from pathlib import Path
import json
import time
from collections import Counter, defaultdict

# GPU imports
try:
    import cupy as cp
    from cupyx.scipy.spatial.distance import cdist as cp_cdist
    HAS_GPU = True
except ImportError:
    HAS_GPU = False
    cp = None

logger = logging.getLogger('lambda3_gpu.analysis.third_impact')

# ============================================
# Data Classes (v3.0 æ‹¡å¼µç‰ˆ)
# ============================================

@dataclass
class AtomicQuantumTrace:
    """åŸå­ãƒ¬ãƒ™ãƒ«é‡å­ç—•è·¡ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æƒ…å ±ä»˜ãï¼‰"""
    atom_id: int
    residue_id: int
    
    # çµ±è¨ˆçš„ç•°å¸¸åº¦
    displacement_zscore: float = 0.0
    lambda_change: float = 0.0
    
    # é‡å­ã‚·ã‚°ãƒãƒãƒ£ãƒ¼
    quantum_signature: str = "unknown"
    confidence: float = 0.0
    
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç‰¹æ€§ï¼ˆNEW!ï¼‰
    connectivity_degree: int = 0  # æ¥ç¶šæ•°
    is_hub: bool = False          # ãƒãƒ–åŸå­ã‹
    is_bridge: bool = False       # æ®‹åŸºé–“ãƒ–ãƒªãƒƒã‚¸ã‹

@dataclass
class AtomicNetworkLink:
    """åŸå­é–“ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒªãƒ³ã‚¯"""
    from_atom: int
    to_atom: int
    from_residue: int
    to_residue: int
    link_type: str  # 'sync', 'causal', 'async'
    strength: float
    lag: int = 0
    distance: Optional[float] = None

@dataclass
class ResidueBridge:
    """æ®‹åŸºé–“ãƒ–ãƒªãƒƒã‚¸æƒ…å ±"""
    from_residue: int
    to_residue: int
    bridge_atoms: List[Tuple[int, int]]  # (from_atom, to_atom)ã®ãƒªã‚¹ãƒˆ
    total_strength: float
    dominant_type: str  # 'sync' or 'causal'

@dataclass
class EventOrigin:
    """ã‚¤ãƒ™ãƒ³ãƒˆèµ·æºæƒ…å ±ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä»˜ãï¼‰"""
    genesis_atoms: List[int] = field(default_factory=list)
    first_wave_atoms: List[int] = field(default_factory=list)
    
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯èµ·æºï¼ˆNEW!ï¼‰
    network_initiators: List[int] = field(default_factory=list)  # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒãƒ–
    
    # çµ±è¨ˆæƒ…å ±
    mean_displacement: float = 0.0
    std_displacement: float = 0.0
    threshold_used: float = 0.0

@dataclass
class AtomicNetworkResult:
    """åŸå­ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æçµæœ"""
    sync_network: List[AtomicNetworkLink] = field(default_factory=list)
    causal_network: List[AtomicNetworkLink] = field(default_factory=list)
    async_network: List[AtomicNetworkLink] = field(default_factory=list)
    
    residue_bridges: List[ResidueBridge] = field(default_factory=list)
    adaptive_windows: Dict[int, int] = field(default_factory=dict)
    
    network_pattern: str = "unknown"  # 'instantaneous', 'parallel', 'cascade'
    hub_atoms: List[int] = field(default_factory=list)

@dataclass
class ThirdImpactResult:
    """Third Impactè§£æçµæœï¼ˆv3.0ï¼‰"""
    event_name: str
    residue_id: int
    event_type: str
    
    # èµ·æºæƒ…å ±
    origin: EventOrigin = field(default_factory=EventOrigin)
    
    # åŸå­ç—•è·¡
    quantum_atoms: Dict[int, AtomicQuantumTrace] = field(default_factory=dict)
    
    # åŸå­ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆNEW!ï¼‰
    atomic_network: Optional[AtomicNetworkResult] = None
    
    # çµ±è¨ˆ
    n_quantum_atoms: int = 0
    n_network_links: int = 0
    n_residue_bridges: int = 0
    strongest_signature: str = ""
    max_confidence: float = 0.0
    
    # å‰µè–¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
    drug_target_atoms: List[int] = field(default_factory=list)
    bridge_target_atoms: List[int] = field(default_factory=list)  # ãƒ–ãƒªãƒƒã‚¸åŸå­

# ============================================
# GPU Atomic Network Analyzer
# ============================================

class AtomicNetworkGPU:
    """
    åŸå­ãƒ¬ãƒ™ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æï¼ˆGPUé«˜é€ŸåŒ–ç‰ˆï¼‰
    residue_networkã®é«˜åº¦ãªæ‰‹æ³•ã‚’åŸå­ãƒ¬ãƒ™ãƒ«ã«é©ç”¨ï¼
    """
    
    def __init__(self, 
                 correlation_threshold: float = 0.6,
                 sync_threshold: float = 0.8,
                 max_lag: int = 5,
                 distance_cutoff: float = 5.0):
        """
        Parameters
        ----------
        correlation_threshold : float
            ç›¸é–¢ã®é–¾å€¤
        sync_threshold : float
            åŒæœŸåˆ¤å®šã®é–¾å€¤
        max_lag : int
            æœ€å¤§ãƒ©ã‚°ï¼ˆå› æœè§£æç”¨ï¼‰
        distance_cutoff : float
            åŸå­é–“è·é›¢ã‚«ãƒƒãƒˆã‚ªãƒ•ï¼ˆÃ…ï¼‰
        """
        self.correlation_threshold = correlation_threshold
        self.sync_threshold = sync_threshold
        self.max_lag = max_lag
        self.distance_cutoff = distance_cutoff
        
        self.xp = cp if HAS_GPU else np
        logger.info(f"ğŸ”º AtomicNetworkGPU initialized (GPU: {HAS_GPU})")
    
    def analyze_network(self,
                       trajectory: np.ndarray,
                       anomaly_atoms: List[int],
                       residue_mapping: Dict[int, List[int]],
                       start_frame: int,
                       end_frame: int) -> AtomicNetworkResult:
        """
        åŸå­ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰
        
        Parameters
        ----------
        trajectory : np.ndarray
            è»Œé“ãƒ‡ãƒ¼ã‚¿ (n_frames, n_atoms, 3)
        anomaly_atoms : List[int]
            ç•°å¸¸åŸå­ã®ãƒªã‚¹ãƒˆ
        residue_mapping : Dict[int, List[int]]
            æ®‹åŸºâ†’åŸå­ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        """
        if not anomaly_atoms:
            return AtomicNetworkResult()
        
        n_frames = end_frame - start_frame + 1
        
        # å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ã®å ´åˆ
        if n_frames <= 1:
            return self._analyze_instantaneous_network(
                trajectory[start_frame], anomaly_atoms, residue_mapping
            )
        
        # è¤‡æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ã®é«˜åº¦ãªè§£æ
        return self._analyze_temporal_network(
            trajectory[start_frame:end_frame+1],
            anomaly_atoms,
            residue_mapping
        )
    
    def _analyze_instantaneous_network(self,
                                      frame: np.ndarray,
                                      atoms: List[int],
                                      residue_mapping: Dict) -> AtomicNetworkResult:
        """å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç¬é–“çš„å”èª¿ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"""
        result = AtomicNetworkResult(network_pattern="instantaneous")
        
        # åŸå­åº§æ¨™
        coords = frame[atoms]
        n_atoms = len(atoms)
        
        # è·é›¢è¡Œåˆ—
        if HAS_GPU:
            coords_gpu = cp.asarray(coords)
            dist_matrix = cp_cdist(coords_gpu, coords_gpu)
            dist_matrix = cp.asnumpy(dist_matrix)
        else:
            from scipy.spatial.distance import cdist
            dist_matrix = cdist(coords, coords)
        
        # è¿‘æ¥åŸå­ã®ã¿ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŒ–
        for i in range(n_atoms):
            for j in range(i+1, n_atoms):
                if dist_matrix[i, j] < self.distance_cutoff:
                    link = AtomicNetworkLink(
                        from_atom=atoms[i],
                        to_atom=atoms[j],
                        from_residue=self._get_residue_id(atoms[i], residue_mapping),
                        to_residue=self._get_residue_id(atoms[j], residue_mapping),
                        link_type='sync',
                        strength=1.0 / (1.0 + dist_matrix[i, j]),
                        distance=dist_matrix[i, j]
                    )
                    result.sync_network.append(link)
        
        # ãƒãƒ–åŸå­ã®ç‰¹å®š
        degree_count = Counter()
        for link in result.sync_network:
            degree_count[link.from_atom] += 1
            degree_count[link.to_atom] += 1
        
        result.hub_atoms = [atom for atom, count in degree_count.most_common(5)]
        
        # æ®‹åŸºé–“ãƒ–ãƒªãƒƒã‚¸
        result.residue_bridges = self._detect_bridges(result.sync_network)
        
        return result
    
    def _analyze_temporal_network(self,
                                 trajectory: np.ndarray,
                                 atoms: List[int],
                                 residue_mapping: Dict) -> AtomicNetworkResult:
        """è¤‡æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ™‚é–“çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æ"""
        result = AtomicNetworkResult()
        
        # GPUè»¢é€
        if HAS_GPU:
            traj_gpu = cp.asarray(trajectory[:, atoms])
        else:
            traj_gpu = trajectory[:, atoms]
        
        n_frames, n_atoms = traj_gpu.shape[0], len(atoms)
        
        # 1. é©å¿œçš„çª“ã®è¨ˆç®—
        adaptive_windows = self._compute_adaptive_windows(traj_gpu, atoms)
        result.adaptive_windows = adaptive_windows
        
        # 2. ç›¸é–¢è¡Œåˆ—ã®è¨ˆç®—
        correlations = self._compute_correlations(traj_gpu, adaptive_windows)
        
        # 3. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰
        networks = self._build_networks(
            correlations, atoms, trajectory[0], residue_mapping
        )
        
        result.sync_network = networks['sync']
        result.causal_network = networks['causal']
        result.async_network = networks['async']
        
        # 4. ãƒ‘ã‚¿ãƒ¼ãƒ³è­˜åˆ¥
        result.network_pattern = self._identify_pattern(networks)
        
        # 5. ãƒãƒ–åŸå­ã®ç‰¹å®š
        all_links = networks['sync'] + networks['causal'] + networks['async']
        degree_count = Counter()
        for link in all_links:
            degree_count[link.from_atom] += 1
            degree_count[link.to_atom] += 1
        
        result.hub_atoms = [atom for atom, count in degree_count.most_common(10)]
        
        # 6. æ®‹åŸºé–“ãƒ–ãƒªãƒƒã‚¸æ¤œå‡º
        result.residue_bridges = self._detect_bridges(networks['causal'])
        
        return result
    
    def _compute_adaptive_windows(self, 
                                 traj_gpu: Any,
                                 atoms: List[int]) -> Dict[int, int]:
        """åŸå­ã”ã¨ã®é©å¿œçš„çª“ã‚µã‚¤ã‚ºè¨ˆç®—"""
        n_frames = traj_gpu.shape[0]
        windows = {}
        
        for i, atom in enumerate(atoms):
            # å¤‰ä½ã®å¤‰å‹•æ€§ã‚’è¨ˆç®—
            if HAS_GPU:
                displacements = cp.diff(traj_gpu[:, i], axis=0)
                volatility = float(cp.std(cp.linalg.norm(displacements, axis=1)))
            else:
                displacements = np.diff(traj_gpu[:, i], axis=0)
                volatility = float(np.std(np.linalg.norm(displacements, axis=1)))
            
            # å¤‰å‹•æ€§ã«åŸºã¥ãçª“ã‚µã‚¤ã‚º
            if volatility > 2.0:
                windows[atom] = min(5, n_frames)
            elif volatility < 0.5:
                windows[atom] = min(20, n_frames)
            else:
                windows[atom] = min(10, n_frames)
        
        return windows
    
    def _compute_correlations(self,
                            traj_gpu: Any,
                            windows: Dict[int, int]) -> Dict:
        """å…¨åŸå­ãƒšã‚¢ã®ç›¸é–¢è¨ˆç®—ï¼ˆåŒæœŸãƒ»éåŒæœŸãƒ»å› æœï¼‰"""
        n_frames, n_atoms = traj_gpu.shape[:2]
        
        correlations = {
            'sync': np.zeros((n_atoms, n_atoms)),
            'lagged': np.zeros((n_atoms, n_atoms, self.max_lag + 1)),
            'async_strength': np.zeros((n_atoms, n_atoms))
        }
        
        for i in range(n_atoms):
            for j in range(i+1, n_atoms):
                window = min(windows[list(windows.keys())[i]], 
                           windows[list(windows.keys())[j]])
                
                # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿
                if HAS_GPU:
                    ts_i = cp.linalg.norm(traj_gpu[:, i], axis=1)
                    ts_j = cp.linalg.norm(traj_gpu[:, j], axis=1)
                else:
                    ts_i = np.linalg.norm(traj_gpu[:, i], axis=1)
                    ts_j = np.linalg.norm(traj_gpu[:, j], axis=1)
                
                # åŒæœŸç›¸é–¢
                if HAS_GPU:
                    sync_corr = float(cp.corrcoef(ts_i[:window], ts_j[:window])[0, 1])
                else:
                    sync_corr = np.corrcoef(ts_i[:window], ts_j[:window])[0, 1]
                
                correlations['sync'][i, j] = sync_corr
                correlations['sync'][j, i] = sync_corr
                
                # ãƒ©ã‚°ä»˜ãç›¸é–¢
                for lag in range(1, min(self.max_lag + 1, window)):
                    if HAS_GPU:
                        lagged_corr = float(cp.corrcoef(ts_i[:-lag], ts_j[lag:])[0, 1])
                    else:
                        lagged_corr = np.corrcoef(ts_i[:-lag], ts_j[lag:])[0, 1]
                    
                    correlations['lagged'][i, j, lag] = lagged_corr
                
                # éåŒæœŸå¼·åº¦
                if abs(sync_corr) < 0.2:  # åŒæœŸã—ã¦ãªã„
                    # è·é›¢ãƒ™ãƒ¼ã‚¹ã®çµåˆå¼·åº¦
                    if HAS_GPU:
                        mean_dist = float(cp.mean(cp.linalg.norm(
                            traj_gpu[:, i] - traj_gpu[:, j], axis=1
                        )))
                    else:
                        mean_dist = np.mean(np.linalg.norm(
                            traj_gpu[:, i] - traj_gpu[:, j], axis=1
                        ))
                    
                    if mean_dist < self.distance_cutoff:
                        correlations['async_strength'][i, j] = 1.0 / (1.0 + mean_dist)
        
        return correlations
    
    def _build_networks(self,
                       correlations: Dict,
                       atoms: List[int],
                       first_frame: np.ndarray,
                       residue_mapping: Dict) -> Dict:
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰"""
        networks = {'sync': [], 'causal': [], 'async': []}
        n_atoms = len(atoms)
        
        for i in range(n_atoms):
            for j in range(i+1, n_atoms):
                atom_i, atom_j = atoms[i], atoms[j]
                res_i = self._get_residue_id(atom_i, residue_mapping)
                res_j = self._get_residue_id(atom_j, residue_mapping)
                
                # è·é›¢
                dist = np.linalg.norm(first_frame[atom_i] - first_frame[atom_j])
                
                # åŒæœŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
                sync_corr = correlations['sync'][i, j]
                if abs(sync_corr) > self.sync_threshold:
                    networks['sync'].append(AtomicNetworkLink(
                        from_atom=atom_i,
                        to_atom=atom_j,
                        from_residue=res_i,
                        to_residue=res_j,
                        link_type='sync',
                        strength=abs(sync_corr),
                        distance=dist
                    ))
                
                # å› æœãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
                max_lag_corr = 0.0
                best_lag = 0
                for lag in range(1, self.max_lag + 1):
                    lag_corr = correlations['lagged'][i, j, lag]
                    if abs(lag_corr) > abs(max_lag_corr):
                        max_lag_corr = lag_corr
                        best_lag = lag
                
                if abs(max_lag_corr) > self.correlation_threshold:
                    networks['causal'].append(AtomicNetworkLink(
                        from_atom=atom_i,
                        to_atom=atom_j,
                        from_residue=res_i,
                        to_residue=res_j,
                        link_type='causal',
                        strength=abs(max_lag_corr),
                        lag=best_lag,
                        distance=dist
                    ))
                
                # éåŒæœŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
                async_strength = correlations['async_strength'][i, j]
                if async_strength > 0.3:
                    networks['async'].append(AtomicNetworkLink(
                        from_atom=atom_i,
                        to_atom=atom_j,
                        from_residue=res_i,
                        to_residue=res_j,
                        link_type='async',
                        strength=async_strength,
                        distance=dist
                    ))
        
        return networks
    
    def _identify_pattern(self, networks: Dict) -> str:
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è­˜åˆ¥"""
        n_sync = len(networks['sync'])
        n_causal = len(networks['causal'])
        n_async = len(networks['async'])
        
        if n_sync > n_causal * 2:
            return "parallel"  # åŒæœŸçš„å”èª¿
        elif n_causal > n_sync * 2:
            return "cascade"   # ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ä¼æ’­
        else:
            return "mixed"
    
    def _detect_bridges(self, links: List[AtomicNetworkLink]) -> List[ResidueBridge]:
        """æ®‹åŸºé–“ãƒ–ãƒªãƒƒã‚¸ã®æ¤œå‡º"""
        bridges_dict = defaultdict(list)
        
        for link in links:
            if link.from_residue != link.to_residue:
                key = (link.from_residue, link.to_residue)
                bridges_dict[key].append((link.from_atom, link.to_atom, link.strength))
        
        bridges = []
        for (from_res, to_res), atom_pairs in bridges_dict.items():
            total_strength = sum(s for _, _, s in atom_pairs)
            bridges.append(ResidueBridge(
                from_residue=from_res,
                to_residue=to_res,
                bridge_atoms=[(a1, a2) for a1, a2, _ in atom_pairs],
                total_strength=total_strength,
                dominant_type='causal' if links else 'sync'
            ))
        
        return sorted(bridges, key=lambda b: b.total_strength, reverse=True)
    
    def _get_residue_id(self, atom_id: int, mapping: Dict) -> int:
        """åŸå­IDã‹ã‚‰æ®‹åŸºIDã‚’å–å¾—"""
        for res_id, atom_list in mapping.items():
            if atom_id in atom_list:
                return res_id
        return -1  # ä¸æ˜

# ============================================
# Third Impact Analyzer v3.0
# ============================================

class ThirdImpactAnalyzer:
    """
    Third Impact Analytics v3.0
    åŸå­ãƒ¬ãƒ™ãƒ«é‡å­ç—•è·¡ + GPUé«˜é€Ÿãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æ
    """
    
    def __init__(self, 
                 residue_mapping: Optional[Dict[int, List[int]]] = None,
                 sigma_threshold: float = 3.0,
                 use_network_analysis: bool = True,
                 use_gpu: bool = True):
        """
        Parameters
        ----------
        residue_mapping : Dict[int, List[int]], optional
            æ®‹åŸºID -> åŸå­IDãƒªã‚¹ãƒˆã®ãƒãƒƒãƒ”ãƒ³ã‚°
        sigma_threshold : float
            çµ±è¨ˆçš„æœ‰æ„æ€§ã®é–¾å€¤
        use_network_analysis : bool
            ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æã‚’ä½¿ç”¨ã™ã‚‹ã‹
        use_gpu : bool
            GPUåŠ é€Ÿã‚’ä½¿ç”¨ã™ã‚‹ã‹
        """
        self.residue_mapping = residue_mapping
        self.sigma_threshold = sigma_threshold
        self.use_network_analysis = use_network_analysis
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æå™¨
        if use_network_analysis and use_gpu and HAS_GPU:
            self.atomic_network = AtomicNetworkGPU()
            logger.info("ğŸš€ GPU-accelerated atomic network analysis enabled")
        elif use_network_analysis:
            self.atomic_network = AtomicNetworkGPU()  # GPUç„¡ã—ã§ã‚‚å‹•ã
            logger.info("ğŸ”º CPU atomic network analysis enabled")
        else:
            self.atomic_network = None
        
        logger.info(f"ğŸ”º Third Impact Analyzer v3.0 initialized")
    
    def analyze_critical_residues(self,
                                 lambda_result: Any,
                                 two_stage_result: Any,
                                 trajectory: np.ndarray,
                                 top_n: int = 3,
                                 **kwargs) -> Dict[str, ThirdImpactResult]:
        """
        ç•°å¸¸æ®‹åŸºã®åŸå­ãƒ¬ãƒ™ãƒ«è§£æï¼ˆv3.0ï¼‰
        """
        logger.info("\n" + "="*60)
        logger.info("ğŸ”º THIRD IMPACT v3.0 - Atomic Network Analysis")
        logger.info("="*60)
        
        start_time = time.time()
        results = {}
        
        # Top Næ®‹åŸºã®ç‰¹å®š
        top_residues = self._identify_top_residues(two_stage_result, top_n)
        logger.info(f"Analyzing top {len(top_residues)} residues")
        
        # å„ã‚¤ãƒ™ãƒ³ãƒˆã®è§£æ
        for event_name, residue_analysis in two_stage_result.residue_analyses.items():
            for residue_event in residue_analysis.residue_events:
                if residue_event.residue_id not in top_residues:
                    continue
                
                residue_id = residue_event.residue_id
                start_frame = residue_event.start_frame
                end_frame = residue_event.end_frame
                duration = end_frame - start_frame
                
                # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®åˆ¤å®š
                if duration <= 1:
                    event_type = "instantaneous"
                else:
                    event_type = "propagation"
                
                logger.info(f"\nğŸ“ {event_name} - Residue {residue_id} ({event_type})")
                
                # æ®‹åŸºã®åŸå­ã‚’å–å¾—
                residue_atoms = self._get_residue_atoms(residue_id, trajectory.shape[1])
                
                # åŸºæœ¬è§£æ
                if event_type == "instantaneous":
                    result = self._analyze_instantaneous_event(
                        residue_id, event_name, 
                        trajectory, lambda_result.lambda_structures,
                        start_frame, residue_atoms
                    )
                else:
                    result = self._analyze_propagation_event(
                        residue_id, event_name,
                        trajectory, lambda_result.lambda_structures,
                        start_frame, end_frame, residue_atoms
                    )
                
                # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æï¼ˆNEW!ï¼‰
                if self.atomic_network and result.quantum_atoms:
                    logger.info("   ğŸŒ Analyzing atomic network...")
                    network_result = self.atomic_network.analyze_network(
                        trajectory=trajectory,
                        anomaly_atoms=list(result.quantum_atoms.keys()),
                        residue_mapping=self.residue_mapping,
                        start_frame=start_frame,
                        end_frame=end_frame
                    )
                    
                    result.atomic_network = network_result
                    result.n_network_links = (
                        len(network_result.sync_network) +
                        len(network_result.causal_network) +
                        len(network_result.async_network)
                    )
                    result.n_residue_bridges = len(network_result.residue_bridges)
                    
                    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æƒ…å ±ã‚’åŸå­ç—•è·¡ã«åæ˜ 
                    self._update_quantum_traces_with_network(result)
                
                # å‰µè–¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰¹å®š
                result.drug_target_atoms = self._identify_drug_targets(result)
                
                # ãƒ–ãƒªãƒƒã‚¸åŸå­ã‚‚ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ï¼ˆNEW!ï¼‰
                if result.atomic_network and result.atomic_network.residue_bridges:
                    for bridge in result.atomic_network.residue_bridges[:3]:
                        for atom_pair in bridge.bridge_atoms[:2]:
                            result.bridge_target_atoms.extend(atom_pair)
                
                results[f"{event_name}_res{residue_id}"] = result
        
        computation_time = time.time() - start_time
        logger.info(f"\nğŸ”º Analysis complete in {computation_time:.2f}s")
        
        self._print_summary(results)
        return results
    
    def _analyze_instantaneous_event(self,
                                    residue_id: int,
                                    event_name: str,
                                    trajectory: np.ndarray,
                                    lambda_structures: Dict,
                                    frame: int,
                                    residue_atoms: List[int]) -> ThirdImpactResult:
        """å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¤ãƒ™ãƒ³ãƒˆã®è§£æ"""
        result = ThirdImpactResult(
            event_name=event_name,
            residue_id=residue_id,
            event_type="instantaneous"
        )
        
        if frame == 0:
            return result
        
        # å…¨åŸå­ã®å¤‰ä½ã‚’è¨ˆç®—
        displacements = trajectory[frame] - trajectory[frame-1]
        distances = np.linalg.norm(displacements, axis=1)
        
        # çµ±è¨ˆé‡
        mean_d = np.mean(distances)
        std_d = np.std(distances)
        threshold = mean_d + self.sigma_threshold * std_d
        
        result.origin.mean_displacement = mean_d
        result.origin.std_displacement = std_d
        result.origin.threshold_used = threshold
        
        # æ®‹åŸºå†…ã§ç•°å¸¸ãªåŸå­ã‚’ç‰¹å®š
        for atom_id in residue_atoms:
            if atom_id >= len(distances):
                continue
                
            z_score = (distances[atom_id] - mean_d) / (std_d + 1e-10)
            
            if z_score > self.sigma_threshold:
                trace = AtomicQuantumTrace(
                    atom_id=atom_id,
                    residue_id=residue_id,
                    displacement_zscore=z_score
                )
                
                # Lambdaå¤‰åŒ–
                if 'lambda_F_mag' in lambda_structures:
                    lambda_change = lambda_structures['lambda_F_mag'][frame] - \
                                  lambda_structures['lambda_F_mag'][frame-1]
                    trace.lambda_change = float(lambda_change)
                
                # ã‚·ã‚°ãƒãƒãƒ£ãƒ¼åˆ†é¡
                trace.quantum_signature = self._classify_signature(z_score, trace.lambda_change)
                trace.confidence = min(z_score / 5.0, 1.0)
                
                result.quantum_atoms[atom_id] = trace
                result.origin.genesis_atoms.append(atom_id)
        
        # çµ±è¨ˆæ›´æ–°
        result.n_quantum_atoms = len(result.quantum_atoms)
        if result.quantum_atoms:
            confidences = [t.confidence for t in result.quantum_atoms.values()]
            result.max_confidence = max(confidences)
            
            signatures = [t.quantum_signature for t in result.quantum_atoms.values()]
            if signatures:
                result.strongest_signature = Counter(signatures).most_common(1)[0][0]
        
        return result
    
    def _analyze_propagation_event(self,
                                  residue_id: int,
                                  event_name: str,
                                  trajectory: np.ndarray,
                                  lambda_structures: Dict,
                                  start_frame: int,
                                  end_frame: int,
                                  residue_atoms: List[int]) -> ThirdImpactResult:
        """è¤‡æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¤ãƒ™ãƒ³ãƒˆã®è§£æï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æä»˜ãï¼‰"""
        result = ThirdImpactResult(
            event_name=event_name,
            residue_id=residue_id,
            event_type="propagation"
        )
        
        if start_frame == 0:
            return result
        
        # èµ·æºåŸå­ã®ç‰¹å®š
        genesis_result = self._analyze_instantaneous_event(
            residue_id, event_name, trajectory, lambda_structures,
            start_frame, residue_atoms
        )
        
        result.origin.genesis_atoms = genesis_result.origin.genesis_atoms
        result.quantum_atoms = genesis_result.quantum_atoms
        
        # ç¬¬ä¸€æ³¢ã®è¿½è·¡ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        max_propagation_frames = min(2, end_frame - start_frame)
        
        for delta in range(1, max_propagation_frames + 1):
            frame = start_frame + delta
            if frame >= len(trajectory):
                break
            
            wave_result = self._analyze_instantaneous_event(
                residue_id, f"{event_name}_wave{delta}",
                trajectory, lambda_structures, frame, residue_atoms
            )
            
            new_atoms = [a for a in wave_result.origin.genesis_atoms 
                        if a not in result.origin.genesis_atoms]
            result.origin.first_wave_atoms.extend(new_atoms)
            
            # æ–°è¦ç•°å¸¸åŸå­ã‚‚è¿½åŠ 
            for atom_id, trace in wave_result.quantum_atoms.items():
                if atom_id not in result.quantum_atoms:
                    result.quantum_atoms[atom_id] = trace
        
        # çµ±è¨ˆæ›´æ–°
        result.n_quantum_atoms = len(result.quantum_atoms)
        if result.quantum_atoms:
            confidences = [t.confidence for t in result.quantum_atoms.values()]
            result.max_confidence = max(confidences)
            
            signatures = [t.quantum_signature for t in result.quantum_atoms.values()]
            if signatures:
                result.strongest_signature = Counter(signatures).most_common(1)[0][0]
        
        return result
    
    def _update_quantum_traces_with_network(self, result: ThirdImpactResult):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æƒ…å ±ã§é‡å­ç—•è·¡ã‚’æ›´æ–°"""
        if not result.atomic_network:
            return
        
        # æ¥ç¶šåº¦ã‚’è¨ˆç®—
        degree_count = Counter()
        all_links = (result.atomic_network.sync_network + 
                    result.atomic_network.causal_network +
                    result.atomic_network.async_network)
        
        for link in all_links:
            degree_count[link.from_atom] += 1
            degree_count[link.to_atom] += 1
        
        # ãƒãƒ–åŸå­ã‚’ãƒãƒ¼ã‚¯
        hub_atoms = set(result.atomic_network.hub_atoms)
        
        # ãƒ–ãƒªãƒƒã‚¸åŸå­ã‚’ãƒãƒ¼ã‚¯
        bridge_atoms = set()
        for bridge in result.atomic_network.residue_bridges:
            for atom_pair in bridge.bridge_atoms:
                bridge_atoms.update(atom_pair)
        
        # é‡å­ç—•è·¡ã‚’æ›´æ–°
        for atom_id, trace in result.quantum_atoms.items():
            trace.connectivity_degree = degree_count.get(atom_id, 0)
            trace.is_hub = atom_id in hub_atoms
            trace.is_bridge = atom_id in bridge_atoms
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯èµ·æºã«è¿½åŠ 
            if trace.is_hub:
                result.origin.network_initiators.append(atom_id)
    
    def _classify_signature(self, z_score: float, lambda_change: float) -> str:
        """é‡å­ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ã®åˆ†é¡"""
        if z_score > 5.0:
            return "quantum_jump"
        elif z_score > 4.0 and abs(lambda_change) > 0.1:
            return "tunneling"
        elif z_score > 3.5:
            return "entanglement"
        elif z_score > 3.0:
            return "quantum_anomaly"
        else:
            return "thermal"
    
    def _identify_drug_targets(self, result: ThirdImpactResult) -> List[int]:
        """å‰µè–¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåŸå­ã®ç‰¹å®šï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æƒ…å ±ã‚‚è€ƒæ…®ï¼‰"""
        targets = []
        
        # ãƒãƒ–åŸå­ã‚’æœ€å„ªå…ˆ
        for atom_id, trace in result.quantum_atoms.items():
            if trace.is_hub and trace.confidence > 0.7:
                targets.append(atom_id)
        
        # ãƒ–ãƒªãƒƒã‚¸åŸå­ã‚‚é‡è¦
        for atom_id, trace in result.quantum_atoms.items():
            if trace.is_bridge and atom_id not in targets:
                targets.append(atom_id)
        
        # é«˜ä¿¡é ¼åº¦ã®èµ·æºåŸå­
        for atom_id, trace in result.quantum_atoms.items():
            if trace.confidence > 0.8 and atom_id not in targets:
                targets.append(atom_id)
        
        return targets[:7]  # æœ€å¤§7å€‹
    
    def _identify_top_residues(self, two_stage_result: Any, top_n: int) -> Set[int]:
        """ä¸Šä½ç•°å¸¸æ®‹åŸºã‚’ç‰¹å®š"""
        if not hasattr(two_stage_result, 'global_residue_importance'):
            return set()
        
        importance_scores = two_stage_result.global_residue_importance
        sorted_residues = sorted(importance_scores.items(), 
                                key=lambda x: x[1], reverse=True)
        
        return set(res_id for res_id, _ in sorted_residues[:top_n])
    
    def _get_residue_atoms(self, residue_id: int, n_atoms: int) -> List[int]:
        """æ®‹åŸºã«å±ã™ã‚‹åŸå­IDã‚’å–å¾—"""
        if self.residue_mapping and residue_id in self.residue_mapping:
            return self.residue_mapping[residue_id]
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        logger.warning(f"No mapping for residue {residue_id}, using fallback")
        atoms_per_residue = 15
        start_atom = residue_id * atoms_per_residue
        end_atom = min(start_atom + atoms_per_residue, n_atoms)
        return list(range(start_atom, end_atom))
    
    def _print_summary(self, results: Dict[str, ThirdImpactResult]):
        """è§£æã‚µãƒãƒªãƒ¼ã®å‡ºåŠ›ï¼ˆv3.0ï¼‰"""
        print("\n" + "="*60)
        print("ğŸ”º THIRD IMPACT v3.0 SUMMARY")
        print("="*60)
        
        total_genesis = sum(len(r.origin.genesis_atoms) for r in results.values())
        total_quantum = sum(r.n_quantum_atoms for r in results.values())
        total_links = sum(r.n_network_links for r in results.values())
        total_bridges = sum(r.n_residue_bridges for r in results.values())
        
        print(f"\nğŸ“Š Statistics:")
        print(f"  - Events analyzed: {len(results)}")
        print(f"  - Genesis atoms: {total_genesis}")
        print(f"  - Quantum atoms: {total_quantum}")
        print(f"  - Network links: {total_links}")
        print(f"  - Residue bridges: {total_bridges}")
        
        # å„ã‚¤ãƒ™ãƒ³ãƒˆã®è©³ç´°
        for event_key, result in results.items():
            print(f"\nğŸ“ {event_key} ({result.event_type}):")
            print(f"  - Residue: {result.residue_id}")
            print(f"  - Genesis atoms: {result.origin.genesis_atoms[:5]}")
            
            if result.atomic_network:
                print(f"  - Network pattern: {result.atomic_network.network_pattern}")
                print(f"  - Hub atoms: {result.atomic_network.hub_atoms[:3]}")
                
                if result.atomic_network.residue_bridges:
                    bridge = result.atomic_network.residue_bridges[0]
                    print(f"  - Main bridge: Res{bridge.from_residue}â†’Res{bridge.to_residue}")
                    print(f"    Bridge atoms: {bridge.bridge_atoms[:2]}")
            
            if result.drug_target_atoms:
                print(f"  - Drug targets: {result.drug_target_atoms[:5]}")
            
            if result.bridge_target_atoms:
                print(f"  - Bridge targets: {result.bridge_target_atoms[:3]}")

# ============================================
# Integration Functions
# ============================================

def run_third_impact_analysis(lambda_result: Any,
                             two_stage_result: Any,
                             trajectory: np.ndarray,
                             residue_mapping: Optional[Dict[int, List[int]]] = None,
                             output_dir: Optional[Path] = None,
                             use_network_analysis: bool = True,
                             **kwargs) -> Dict[str, ThirdImpactResult]:
    """
    Third Impactè§£æã®å®Ÿè¡Œï¼ˆv3.0ï¼‰
    
    Parameters
    ----------
    use_network_analysis : bool
        åŸå­ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æã‚’ä½¿ç”¨ã™ã‚‹ã‹
    """
    logger.info("ğŸ”º Starting Third Impact Analysis v3.0...")
    
    # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
    analyzer = ThirdImpactAnalyzer(
        residue_mapping=residue_mapping,
        sigma_threshold=kwargs.get('sigma_threshold', 3.0),
        use_network_analysis=use_network_analysis,
        use_gpu=kwargs.get('use_gpu', True)
    )
    
    # è§£æå®Ÿè¡Œ
    results = analyzer.analyze_critical_residues(
        lambda_result=lambda_result,
        two_stage_result=two_stage_result,
        trajectory=trajectory,
        top_n=kwargs.get('top_n', 3)
    )
    
    # çµæœä¿å­˜
    if output_dir:
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # JSONä¿å­˜
        save_results_json(results, output_path)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = generate_impact_report(results)
        with open(output_path / 'third_impact_v3_report.txt', 'w') as f:
            f.write(report)
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯è¦–åŒ–ç”¨ãƒ‡ãƒ¼ã‚¿
        if use_network_analysis:
            save_network_data(results, output_path)
        
        logger.info(f"Results saved to {output_path}")
    
    return results

def save_results_json(results: Dict[str, ThirdImpactResult], output_path: Path):
    """çµæœã‚’JSONå½¢å¼ã§ä¿å­˜ï¼ˆv3.0ï¼‰"""
    json_data = {}
    
    for event_key, result in results.items():
        json_data[event_key] = {
            'event_name': result.event_name,
            'residue_id': result.residue_id,
            'event_type': result.event_type,
            'n_quantum_atoms': result.n_quantum_atoms,
            'n_network_links': result.n_network_links,
            'n_residue_bridges': result.n_residue_bridges,
            'genesis_atoms': result.origin.genesis_atoms,
            'network_initiators': result.origin.network_initiators,
            'strongest_signature': result.strongest_signature,
            'max_confidence': float(result.max_confidence),
            'drug_target_atoms': result.drug_target_atoms,
            'bridge_target_atoms': result.bridge_target_atoms,
            'statistics': {
                'mean_displacement': float(result.origin.mean_displacement),
                'std_displacement': float(result.origin.std_displacement),
                'threshold': float(result.origin.threshold_used)
            }
        }
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æƒ…å ±
        if result.atomic_network:
            json_data[event_key]['network'] = {
                'pattern': result.atomic_network.network_pattern,
                'hub_atoms': result.atomic_network.hub_atoms,
                'n_sync_links': len(result.atomic_network.sync_network),
                'n_causal_links': len(result.atomic_network.causal_network),
                'n_async_links': len(result.atomic_network.async_network),
                'n_bridges': len(result.atomic_network.residue_bridges)
            }
    
    with open(output_path / 'third_impact_v3.json', 'w') as f:
        json.dump(json_data, f, indent=2)

def save_network_data(results: Dict[str, ThirdImpactResult], output_path: Path):
    """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯è¦–åŒ–ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
    for event_key, result in results.items():
        if not result.atomic_network:
            continue
        
        # NetworkXç”¨ã‚¨ãƒƒã‚¸ãƒªã‚¹ãƒˆ
        edges = []
        
        for link in result.atomic_network.sync_network:
            edges.append({
                'source': link.from_atom,
                'target': link.to_atom,
                'type': 'sync',
                'weight': link.strength
            })
        
        for link in result.atomic_network.causal_network:
            edges.append({
                'source': link.from_atom,
                'target': link.to_atom,
                'type': 'causal',
                'weight': link.strength,
                'lag': link.lag
            })
        
        # ä¿å­˜
        network_file = output_path / f'{event_key}_network.json'
        with open(network_file, 'w') as f:
            json.dump({'edges': edges, 'hubs': result.atomic_network.hub_atoms}, f, indent=2)

def generate_impact_report(results: Dict[str, ThirdImpactResult]) -> str:
    """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆv3.0ï¼‰"""
    report = """
================================================================================
ğŸ”º THIRD IMPACT ANALYSIS v3.0 - GPU Atomic Network Edition
================================================================================

"""
    
    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    total_genesis = sum(len(r.origin.genesis_atoms) for r in results.values())
    total_quantum = sum(r.n_quantum_atoms for r in results.values())
    total_links = sum(r.n_network_links for r in results.values())
    total_bridges = sum(r.n_residue_bridges for r in results.values())
    
    report += f"""EXECUTIVE SUMMARY
-----------------
Events Analyzed: {len(results)}
Genesis Atoms Identified: {total_genesis}
Quantum Atoms Detected: {total_quantum}
Network Links Discovered: {total_links}
Residue Bridges Found: {total_bridges}

DETAILED ANALYSIS
-----------------
"""
    
    for event_key, result in results.items():
        report += f"\n{event_key} ({result.event_type})\n"
        report += "=" * len(event_key) + "\n"
        report += f"Target Residue: {result.residue_id}\n"
        report += f"Genesis Atoms: {result.origin.genesis_atoms[:10]}\n"
        
        if result.origin.network_initiators:
            report += f"Network Hubs: {result.origin.network_initiators[:5]}\n"
        
        if result.atomic_network:
            report += f"\nNetwork Analysis:\n"
            report += f"  Pattern: {result.atomic_network.network_pattern}\n"
            report += f"  Sync Links: {len(result.atomic_network.sync_network)}\n"
            report += f"  Causal Links: {len(result.atomic_network.causal_network)}\n"
            report += f"  Async Links: {len(result.atomic_network.async_network)}\n"
            
            if result.atomic_network.residue_bridges:
                report += f"\nResidue Bridges:\n"
                for bridge in result.atomic_network.residue_bridges[:3]:
                    report += f"  Res{bridge.from_residue} â†’ Res{bridge.to_residue} "
                    report += f"(strength: {bridge.total_strength:.3f})\n"
                    report += f"    Atoms: {bridge.bridge_atoms[:2]}\n"
        
        report += f"\nQuantum Signature: {result.strongest_signature}\n"
        report += f"Max Confidence: {result.max_confidence:.3f}\n"
        
        if result.drug_target_atoms:
            report += f"\nDrug Target Atoms: {result.drug_target_atoms}\n"
        
        if result.bridge_target_atoms:
            report += f"Bridge Target Atoms: {result.bridge_target_atoms[:5]}\n"
        
        report += f"\nStatistics:\n"
        report += f"  Î¼_displacement: {result.origin.mean_displacement:.3f} Ã…\n"
        report += f"  Ïƒ_displacement: {result.origin.std_displacement:.3f} Ã…\n"
        report += f"  Detection threshold: {result.origin.threshold_used:.3f} Ã…\n"
    
    report += """
================================================================================
Generated by Third Impact Analytics v3.0 - GPU Atomic Network Edition
Powered by residue_network GPU technology adapted to atomic level
================================================================================
"""
    
    return report
