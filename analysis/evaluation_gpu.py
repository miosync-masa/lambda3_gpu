"""
LambdaÂ³ GPUç‰ˆæ€§èƒ½è©•ä¾¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
æ¤œå‡ºæ€§èƒ½ã®å¤šæ®µéšè©•ä¾¡ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
"""

import numpy as np
import time
from typing import Dict, List, Tuple, Optional, Any, TYPE_CHECKING
from dataclasses import dataclass

# CuPyã®æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã“ã“ãŒé‡è¦ï¼ï¼‰
if TYPE_CHECKING:
    import cupy as cp
    NDArray = cp.ndarray
else:
    try:
        import cupy as cp
        NDArray = cp.ndarray
    except ImportError:
        cp = None
        NDArray = np.ndarray 

# ä»–ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from sklearn.metrics import roc_auc_score, precision_recall_curve, auc
import matplotlib.pyplot as plt
from ..core.gpu_utils import GPUBackend
from .md_lambda3_detector_gpu import MDLambda3Result
from .two_stage_analyzer_gpu import TwoStageLambda3Result


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    # ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡º
    detection_rate: float
    n_detected: int
    n_total: int
    average_confidence: float
    
    # ã‚¿ã‚¤ãƒŸãƒ³ã‚°ç²¾åº¦
    mean_timing_error: float
    median_timing_error: float
    timing_accuracy: float
    
    # å¾“æ¥å‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    roc_auc: float
    pr_auc: float
    false_positive_rate: float
    
    # ç·åˆã‚¹ã‚³ã‚¢
    overall_score: float
    grade: str
    
    # GPUæ€§èƒ½
    gpu_speedup: float = 1.0
    memory_efficiency: float = 1.0
    computation_time: float = 0.0


@dataclass
class EventDetectionResult:
    """ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡ºçµæœ"""
    name: str
    detected: bool
    confidence: float
    criteria: Dict[str, Any]
    timing_error: Optional[float] = None


class PerformanceEvaluatorGPU(GPUBackend):
    """GPUç‰ˆæ€§èƒ½è©•ä¾¡å™¨"""
    
    def __init__(self, force_cpu=False):
        super().__init__(force_cpu)
        self.benchmark_results = {}
    
    def evaluate_detection_performance(self,
                                     result: MDLambda3Result,
                                     ground_truth_events: List[Tuple[int, int, str]],
                                     cpu_baseline_time: Optional[float] = None) -> PerformanceMetrics:
        """
        LambdaÂ³æ¤œå‡ºæ€§èƒ½ã®å¤šæ®µéšè©•ä¾¡
        
        Parameters
        ----------
        result : MDLambda3Result
            æ¤œå‡ºçµæœ
        ground_truth_events : List[Tuple[int, int, str]]
            æ­£è§£ã‚¤ãƒ™ãƒ³ãƒˆ [(start, end, name), ...]
        cpu_baseline_time : float, optional
            CPUç‰ˆã®å®Ÿè¡Œæ™‚é–“ï¼ˆã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—è¨ˆç®—ç”¨ï¼‰
            
        Returns
        -------
        PerformanceMetrics
            è©•ä¾¡çµæœ
        """
        print("\n" + "="*60)
        print("=== Multi-level Detection Performance Evaluation (GPU) ===")
        print("="*60)
        
        start_time = time.time()
        n_frames = result.n_frames
        
        # GPUä¸Šã§è©•ä¾¡ã‚’å®Ÿè¡Œ
        with self.memory_manager.batch_context(n_frames * 8):
            # 1. ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡ºè©•ä¾¡
            event_results = self._evaluate_event_detection_gpu(
                result, ground_truth_events
            )
            
            # 2. ã‚¿ã‚¤ãƒŸãƒ³ã‚°ç²¾åº¦è©•ä¾¡
            timing_metrics = self._evaluate_timing_accuracy_gpu(
                result, ground_truth_events
            )
            
            # 3. å¾“æ¥å‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            traditional_metrics = self._evaluate_traditional_metrics_gpu(
                result, ground_truth_events
            )
            
            # 4. GPUæ€§èƒ½è©•ä¾¡
            gpu_metrics = self._evaluate_gpu_performance(
                result, cpu_baseline_time
            )
        
        # ç·åˆè©•ä¾¡
        overall_metrics = self._compute_overall_metrics(
            event_results, timing_metrics, traditional_metrics, gpu_metrics
        )
        
        evaluation_time = time.time() - start_time
        overall_metrics.computation_time = evaluation_time
        
        self._print_evaluation_summary(overall_metrics)
        
        return overall_metrics
    
    def _evaluate_event_detection_gpu(self,
                                    result: MDLambda3Result,
                                    ground_truth_events: List[Tuple[int, int, str]]) -> List[EventDetectionResult]:
        """ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡ºã®è©•ä¾¡ï¼ˆGPUé«˜é€ŸåŒ–ï¼‰"""
        print("\nğŸ“Š Level 1: Event Detection")
        print("-" * 40)
        
        event_detection_results = []
        
        # ã‚¹ã‚³ã‚¢ã‚’GPUã«è»¢é€
        score_key = 'final_combined' if 'final_combined' in result.anomaly_scores else 'combined'
        scores_gpu = self.to_gpu(result.anomaly_scores[score_key])
        
        # å¢ƒç•Œä½ç½®ã‚’GPUã«
        if 'boundary_locations' in result.structural_boundaries:
            boundaries_gpu = self.to_gpu(result.structural_boundaries['boundary_locations'])
        else:
            boundaries_gpu = cp.array([])
        
        for start, end, name in ground_truth_events:
            detection_criteria = {}
            
            # ã‚¤ãƒ™ãƒ³ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®ã‚¹ã‚³ã‚¢
            event_scores = scores_gpu[start:end]
            
            if len(event_scores) > 0:
                # 1. ãƒ”ãƒ¼ã‚¯æ¤œå‡º
                max_score = float(cp.max(event_scores))
                detection_criteria['peak_score'] = max_score
                detection_criteria['has_peak'] = max_score > 2.0
                
                # 2. å¢ƒç•Œæ¤œå‡º
                boundary_tolerance = 5000
                
                # GPUä¸Šã§å¢ƒç•Œã¨ã®è·é›¢è¨ˆç®—
                if len(boundaries_gpu) > 0:
                    start_distances = cp.abs(boundaries_gpu - start)
                    end_distances = cp.abs(boundaries_gpu - end)
                    
                    detection_criteria['start_boundary'] = bool(cp.any(start_distances <= boundary_tolerance))
                    detection_criteria['end_boundary'] = bool(cp.any(end_distances <= boundary_tolerance))
                    
                    # ã‚¤ãƒ™ãƒ³ãƒˆå†…ã®å¢ƒç•Œ
                    internal_mask = (boundaries_gpu >= start) & (boundaries_gpu <= end)
                    detection_criteria['internal_boundary'] = bool(cp.any(internal_mask))
                else:
                    detection_criteria['start_boundary'] = False
                    detection_criteria['end_boundary'] = False
                    detection_criteria['internal_boundary'] = False
                
                detection_criteria['any_boundary'] = any([
                    detection_criteria['start_boundary'],
                    detection_criteria['end_boundary'],
                    detection_criteria['internal_boundary']
                ])
                
                # 3. æŒç¶šçš„ç•°å¸¸
                anomaly_frames = int(cp.sum(event_scores > 1.5))
                detection_criteria['sustained_ratio'] = anomaly_frames / len(event_scores)
                detection_criteria['has_sustained'] = detection_criteria['sustained_ratio'] > 0.1
                
                # ç·åˆåˆ¤å®š
                detected = detection_criteria['has_peak'] or detection_criteria['any_boundary']
                confidence = max_score / 2.0 if max_score > 2.0 else detection_criteria['sustained_ratio']
            else:
                detected = False
                confidence = 0.0
            
            event_result = EventDetectionResult(
                name=name,
                detected=detected,
                confidence=confidence,
                criteria=detection_criteria
            )
            event_detection_results.append(event_result)
            
            # çµæœè¡¨ç¤º
            print(f"\n{name} ({start}-{end}):")
            print(f"  âœ“ Detected: {'YES' if detected else 'NO'}")
            if len(event_scores) > 0:
                print(f"  - Peak score: {max_score:.2f} {'âœ“' if detection_criteria['has_peak'] else 'âœ—'}")
                print(f"  - Boundaries: Start={'âœ“' if detection_criteria['start_boundary'] else 'âœ—'}, "
                      f"End={'âœ“' if detection_criteria['end_boundary'] else 'âœ—'}")
                print(f"  - Sustained anomaly: {detection_criteria['sustained_ratio']:.1%}")
        
        return event_detection_results
    
    def _evaluate_timing_accuracy_gpu(self,
                                    result: MDLambda3Result,
                                    ground_truth_events: List[Tuple[int, int, str]]) -> Dict[str, Any]:
        """ã‚¿ã‚¤ãƒŸãƒ³ã‚°ç²¾åº¦ã®è©•ä¾¡ï¼ˆGPUé«˜é€ŸåŒ–ï¼‰"""
        print("\n\nğŸ“Š Level 2: Boundary Timing Accuracy")
        print("-" * 40)
        
        timing_results = []
        
        if 'boundary_locations' in result.structural_boundaries:
            boundaries = self.to_gpu(result.structural_boundaries['boundary_locations'])
        else:
            boundaries = cp.array([])
        
        for start, end, name in ground_truth_events:
            if len(boundaries) > 0:
                # GPUä¸Šã§æœ€è¿‘å‚å¢ƒç•Œã‚’æ¤œç´¢
                start_distances = cp.abs(boundaries - start)
                end_distances = cp.abs(boundaries - end)
                
                start_error = int(cp.min(start_distances))
                end_error = int(cp.min(end_distances))
                
                start_boundary_idx = int(cp.argmin(start_distances))
                end_boundary_idx = int(cp.argmin(end_distances))
                
                start_boundary = int(boundaries[start_boundary_idx])
                end_boundary = int(boundaries[end_boundary_idx])
            else:
                start_error = result.n_frames
                end_error = result.n_frames
                start_boundary = None
                end_boundary = None
            
            timing_results.append({
                'name': name,
                'start_error': start_error,
                'end_error': end_error,
                'mean_error': (start_error + end_error) / 2,
                'start_accurate': start_error < 5000,
                'end_accurate': end_error < 5000,
                'start_boundary': start_boundary,
                'end_boundary': end_boundary
            })
            
            print(f"\n{name}:")
            print(f"  Start: error={start_error} frames {'âœ“' if start_error < 5000 else 'âœ—'}")
            if start_boundary is not None:
                print(f"    â†’ Detected at frame {start_boundary} (true: {start})")
            print(f"  End: error={end_error} frames {'âœ“' if end_error < 5000 else 'âœ—'}")
            if end_boundary is not None:
                print(f"    â†’ Detected at frame {end_boundary} (true: {end})")
        
        # çµ±è¨ˆè¨ˆç®—
        all_errors = ([t['start_error'] for t in timing_results] + 
                     [t['end_error'] for t in timing_results])
        
        return {
            'timing_results': timing_results,
            'mean_error': np.mean(all_errors),
            'median_error': np.median(all_errors),
            'accuracy_5000': sum(1 for e in all_errors if e < 5000) / len(all_errors)
        }
    
    def _evaluate_traditional_metrics_gpu(self,
                                        result: MDLambda3Result,
                                        ground_truth_events: List[Tuple[int, int, str]]) -> Dict[str, float]:
        """å¾“æ¥å‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è©•ä¾¡ï¼ˆGPUé«˜é€ŸåŒ–ï¼‰"""
        print("\n\nğŸ“Š Level 3: Traditional Frame-wise Metrics")
        print("-" * 40)
        
        n_frames = result.n_frames
        
        # Ground truthãƒ©ãƒ™ãƒ«ä½œæˆï¼ˆGPUä¸Šï¼‰
        ground_truth_gpu = cp.zeros(n_frames)
        for start, end, name in ground_truth_events:
            ground_truth_gpu[start:end] = 1
        
        ground_truth = self.to_cpu(ground_truth_gpu)
        
        # å„ã‚¹ã‚³ã‚¢ã‚¿ã‚¤ãƒ—ã‚’è©•ä¾¡
        traditional_results = {}
        
        for score_name in ['global', 'local', 'combined', 'final_combined']:
            if score_name in result.anomaly_scores:
                scores = result.anomaly_scores[score_name]
                
                # ROC-AUC
                try:
                    auc_score = roc_auc_score(ground_truth, scores)
                except:
                    auc_score = 0.5
                
                # Precision-Recall
                try:
                    precision, recall, _ = precision_recall_curve(ground_truth, scores)
                    pr_auc = auc(recall, precision)
                except:
                    pr_auc = 0.0
                
                # False Positive Rate
                scores_gpu = self.to_gpu(scores)
                ground_truth_neg = ground_truth_gpu == 0
                if cp.sum(ground_truth_neg) > 0:
                    fpr = float(cp.mean(scores_gpu[ground_truth_neg] > 2.0))
                else:
                    fpr = 0.0
                
                traditional_results[score_name] = {
                    'roc_auc': auc_score,
                    'pr_auc': pr_auc,
                    'fpr': fpr
                }
                
                print(f"\n{score_name.capitalize()} scores:")
                print(f"  ROC-AUC: {auc_score:.4f}")
                print(f"  PR-AUC: {pr_auc:.4f}")
                print(f"  FPR: {fpr:.4f}")
        
        # æœ€è‰¯ã®ã‚¹ã‚³ã‚¢ã‚’é¸æŠ
        best_score_name = max(traditional_results.keys(), 
                            key=lambda x: traditional_results[x]['roc_auc'])
        
        return {
            'best_roc_auc': traditional_results[best_score_name]['roc_auc'],
            'best_pr_auc': traditional_results[best_score_name]['pr_auc'],
            'best_fpr': traditional_results[best_score_name]['fpr'],
            'all_results': traditional_results
        }
    
    def _evaluate_gpu_performance(self,
                                 result: MDLambda3Result,
                                 cpu_baseline_time: Optional[float]) -> Dict[str, float]:
        """GPUæ€§èƒ½ã®è©•ä¾¡"""
        gpu_metrics = {
            'gpu_time': result.computation_time,
            'frames_per_second': result.n_frames / result.computation_time,
            'speedup': 1.0,
            'memory_used_gb': 0.0
        }
        
        # ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—è¨ˆç®—
        if cpu_baseline_time and cpu_baseline_time > 0:
            gpu_metrics['speedup'] = cpu_baseline_time / result.computation_time
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
        if result.gpu_info and 'memory_used' in result.gpu_info:
            gpu_metrics['memory_used_gb'] = result.gpu_info['memory_used']
        
        return gpu_metrics
    
    def _compute_overall_metrics(self,
                               event_results: List[EventDetectionResult],
                               timing_metrics: Dict,
                               traditional_metrics: Dict,
                               gpu_metrics: Dict) -> PerformanceMetrics:
        """ç·åˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—"""
        # ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡ºçµ±è¨ˆ
        n_detected = sum(1 for e in event_results if e.detected)
        detection_rate = n_detected / len(event_results) if event_results else 0
        avg_confidence = np.mean([e.confidence for e in event_results]) if event_results else 0
        
        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        overall_score = (
            0.4 * detection_rate +
            0.3 * timing_metrics['accuracy_5000'] +
            0.2 * traditional_metrics['best_roc_auc'] +
            0.1 * (1 - traditional_metrics['best_fpr'])
        )
        
        # ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¤å®š
        if overall_score > 0.8:
            grade = "Excellent"
        elif overall_score > 0.6:
            grade = "Good"
        elif overall_score > 0.4:
            grade = "Fair"
        else:
            grade = "Needs Improvement"
        
        # GPUåŠ¹ç‡
        memory_efficiency = 1.0
        if gpu_metrics['memory_used_gb'] > 0:
            # ä»®å®š: 16GB GPUã§ã®åŠ¹ç‡
            memory_efficiency = min(1.0, 16.0 / gpu_metrics['memory_used_gb'])
        
        return PerformanceMetrics(
            # ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡º
            detection_rate=detection_rate,
            n_detected=n_detected,
            n_total=len(event_results),
            average_confidence=avg_confidence,
            
            # ã‚¿ã‚¤ãƒŸãƒ³ã‚°
            mean_timing_error=timing_metrics['mean_error'],
            median_timing_error=timing_metrics['median_error'],
            timing_accuracy=timing_metrics['accuracy_5000'],
            
            # å¾“æ¥å‹
            roc_auc=traditional_metrics['best_roc_auc'],
            pr_auc=traditional_metrics['best_pr_auc'],
            false_positive_rate=traditional_metrics['best_fpr'],
            
            # ç·åˆ
            overall_score=overall_score,
            grade=grade,
            
            # GPU
            gpu_speedup=gpu_metrics['speedup'],
            memory_efficiency=memory_efficiency
        )
    
    def _print_evaluation_summary(self, metrics: PerformanceMetrics):
        """è©•ä¾¡ã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º"""
        print("\n" + "="*60)
        print("=== Overall Performance Summary ===")
        print("="*60)
        
        print(f"\nğŸ† Performance Metrics:")
        print(f"   Event Detection Rate: {metrics.detection_rate:.1%}")
        print(f"   Timing Accuracy: {metrics.timing_accuracy:.1%}")
        print(f"   Best Traditional AUC: {metrics.roc_auc:.3f}")
        print(f"   False Positive Rate: {metrics.false_positive_rate:.1%}")
        
        print(f"\nğŸ’» GPU Performance:")
        print(f"   Speedup: {metrics.gpu_speedup:.1f}x")
        print(f"   Memory Efficiency: {metrics.memory_efficiency:.1%}")
        print(f"   Computation Time: {metrics.computation_time:.2f}s")
        
        print(f"\n   â†’ Overall Score: {metrics.overall_score:.3f}")
        print(f"   â†’ Performance Grade: {metrics.grade}")
    
    def benchmark_gpu_vs_cpu(self,
                           trajectory: np.ndarray,
                           config: Any,
                           n_runs: int = 3) -> Dict[str, Any]:
        """GPU vs CPU ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        print("\nğŸ Running GPU vs CPU Benchmark...")
        
        # GPUç‰ˆ
        from .md_lambda3_detector_gpu import MDLambda3DetectorGPU
        
        gpu_times = []
        for i in range(n_runs):
            detector_gpu = MDLambda3DetectorGPU(config, device='gpu')
            start = time.time()
            _ = detector_gpu.analyze(trajectory)
            gpu_times.append(time.time() - start)
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
            self.memory_manager.clear_cache()
            cp.get_default_memory_pool().free_all_blocks()
        
        # CPUç‰ˆï¼ˆå¯èƒ½ã§ã‚ã‚Œã°ï¼‰
        cpu_times = []
        try:
            detector_cpu = MDLambda3DetectorGPU(config, device='cpu')
            for i in range(min(1, n_runs)):  # CPUç‰ˆã¯1å›ã®ã¿
                start = time.time()
                _ = detector_cpu.analyze(trajectory)
                cpu_times.append(time.time() - start)
        except:
            print("  CPU version not available or too slow")
            cpu_times = [gpu_times[0] * 10]  # æ¨å®šå€¤
        
        # çµæœ
        benchmark_results = {
            'gpu_mean_time': np.mean(gpu_times),
            'gpu_std_time': np.std(gpu_times),
            'cpu_mean_time': np.mean(cpu_times) if cpu_times else None,
            'speedup': np.mean(cpu_times) / np.mean(gpu_times) if cpu_times else None,
            'n_frames': trajectory.shape[0],
            'n_atoms': trajectory.shape[1]
        }
        
        print(f"\nğŸ“Š Benchmark Results:")
        print(f"   GPU: {benchmark_results['gpu_mean_time']:.2f} Â± {benchmark_results['gpu_std_time']:.2f}s")
        if benchmark_results['cpu_mean_time']:
            print(f"   CPU: {benchmark_results['cpu_mean_time']:.2f}s")
            print(f"   Speedup: {benchmark_results['speedup']:.1f}x")
        
        return benchmark_results


def evaluate_two_stage_performance(two_stage_result: TwoStageLambda3Result,
                                 ground_truth_residue_events: Optional[Dict] = None) -> Dict[str, Any]:
    """
    2æ®µéšè§£æã®æ€§èƒ½è©•ä¾¡
    
    Parameters
    ----------
    two_stage_result : TwoStageLambda3Result
        2æ®µéšè§£æçµæœ
    ground_truth_residue_events : Dict, optional
        æ®‹åŸºãƒ¬ãƒ™ãƒ«ã®æ­£è§£ã‚¤ãƒ™ãƒ³ãƒˆ
        
    Returns
    -------
    Dict[str, Any]
        è©•ä¾¡çµæœ
    """
    evaluation = {
        'n_events_analyzed': len(two_stage_result.residue_analyses),
        'total_residues_involved': len(two_stage_result.global_residue_importance),
        'n_intervention_points': len(two_stage_result.suggested_intervention_points),
        'network_complexity': two_stage_result.global_network_stats['total_causal_links'],
        'async_ratio': two_stage_result.global_network_stats['async_to_causal_ratio'],
        'gpu_time': two_stage_result.total_gpu_time
    }
    
    # æ®‹åŸºãƒ¬ãƒ™ãƒ«ã®æ¤œè¨¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if ground_truth_residue_events:
        # å®Ÿè£…ã¯çœç•¥
        pass
    
    return evaluation
