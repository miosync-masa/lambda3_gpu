"""
MD LambdaÂ³ Detector GPU - ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆ
ãƒãƒƒãƒå‡¦ç†å¾Œã®è§£æã‚¹ãƒ†ãƒƒãƒ—ã‚’é©åˆ‡ã«å®Ÿè£…
"""

import numpy as np
import time
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
import warnings

# CuPyã®æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import cupy as cp
    HAS_GPU = True
except ImportError:
    cp = None
    HAS_GPU = False

from ..core.gpu_utils import GPUBackend
from ..structures.lambda_structures_gpu import LambdaStructuresGPU
from ..structures.md_features_gpu import MDFeaturesGPU
from ..detection.anomaly_detection_gpu import AnomalyDetectorGPU
from ..detection.boundary_detection_gpu import BoundaryDetectorGPU  # detectionã‹ã‚‰ï¼
from ..detection.topology_breaks_gpu import TopologyBreaksDetectorGPU
from ..detection.phase_space_gpu import PhaseSpaceAnalyzerGPU  
from ..detection.extended_detection_gpu import ExtendedDetectorGPU

@dataclass
class MDConfig:
    """MDè§£æè¨­å®š"""
    # LambdaÂ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    adaptive_window: bool = True
    extended_detection: bool = True
    use_extended_detection: bool = True
    use_phase_space: bool = False
    sensitivity: float = 2.0
    min_boundary_gap: int = 100
    
    # MDç‰¹æœ‰ã®è¨­å®š
    use_rmsd: bool = True
    use_rg: bool = True
    use_dihedrals: bool = True
    use_contacts: bool = True
    
    # GPUè¨­å®š
    gpu_batch_size: int = 10000
    mixed_precision: bool = False
    benchmark_mode: bool = False


@dataclass
class MDLambda3Result:
    """MD LambdaÂ³è§£æçµæœã®ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    # Core LambdaÂ³æ§‹é€ 
    lambda_structures: Dict[str, np.ndarray]
    structural_boundaries: Dict[str, Any]
    topological_breaks: Dict[str, np.ndarray]
    
    # MDç‰¹æœ‰ã®ç‰¹å¾´
    md_features: Dict[str, np.ndarray]
    
    # è§£æçµæœ
    anomaly_scores: Dict[str, np.ndarray]
    detected_structures: List[Dict]
    
    # ä½ç›¸ç©ºé–“è§£æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    phase_space_analysis: Optional[Dict] = None
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    n_frames: int = 0
    n_atoms: int = 0
    window_steps: int = 0
    computation_time: float = 0.0
    gpu_info: Dict = None
    critical_events: List = field(default_factory=list)


class MDLambda3DetectorGPU(GPUBackend):
    """GPUç‰ˆLambdaÂ³ MDæ¤œå‡ºå™¨ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼‰"""
    
    def __init__(self, config: MDConfig = None, device: str = 'auto'):
        """
        Parameters
        ----------
        config : MDConfig, optional
            è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        device : str, default='auto'
            'auto', 'gpu', 'cpu'ã®ã„ãšã‚Œã‹
        """
        # GPUBackendã®åˆæœŸåŒ–
        if device == 'cpu':
            super().__init__(device='cpu', force_cpu=True)
        else:
            super().__init__(device=device, force_cpu=False)
        
        self.config = config or MDConfig()
        self.verbose = True
        
        # force_cpuãƒ•ãƒ©ã‚°ã‚’æ±ºå®š
        force_cpu_flag = not self.is_gpu
        
        # GPUç‰ˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
        self.structure_computer = LambdaStructuresGPU(force_cpu_flag)
        self.feature_extractor = MDFeaturesGPU(force_cpu_flag)
        self.anomaly_detector = AnomalyDetectorGPU(force_cpu_flag)
        self.boundary_detector = BoundaryDetectorGPU(force_cpu_flag)
        self.topology_detector = TopologyBreaksDetectorGPU(force_cpu_flag)
        self.extended_detector = ExtendedDetectorGPU(force_cpu_flag)
        self.phase_space_analyzer = PhaseSpaceAnalyzerGPU(force_cpu_flag)
        
        # ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ã¨ãƒ‡ãƒã‚¤ã‚¹ã‚’å…±æœ‰
        for component in [self.structure_computer, self.feature_extractor,
                         self.anomaly_detector, self.boundary_detector,
                         self.topology_detector, self.extended_detector,
                         self.phase_space_analyzer]:
            if hasattr(component, 'memory_manager'):
                component.memory_manager = self.memory_manager
            if hasattr(component, 'device'):
                component.device = self.device
        
        self._print_initialization_info()
    
    def analyze(self, 
                trajectory: np.ndarray,
                backbone_indices: Optional[np.ndarray] = None) -> MDLambda3Result:
        """
        MDè»Œé“ã®LambdaÂ³è§£æï¼ˆå®Œå…¨GPUåŒ–ï¼‰
        
        Parameters
        ----------
        trajectory : np.ndarray
            MDè»Œé“ (n_frames, n_atoms, 3)
        backbone_indices : np.ndarray, optional
            ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³åŸå­ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            
        Returns
        -------
        MDLambda3Result
            è§£æçµæœ
        """
        start_time = time.time()
        n_frames, n_atoms, _ = trajectory.shape
        
        print(f"\n{'='*60}")
        print(f"=== LambdaÂ³ MD Analysis (GPU) ===")
        print(f"{'='*60}")
        print(f"Trajectory: {n_frames} frames, {n_atoms} atoms")
        print(f"GPU Device: {self.device}")
        
        # ãƒ¡ãƒ¢ãƒªæƒ…å ±ã®å®‰å…¨ãªå–å¾—
        try:
            mem_info = self.memory_manager.get_memory_info()
            print(f"Available GPU Memory: {mem_info.free / 1e9:.2f} GB")
        except Exception as e:
            print(f"Memory info unavailable: {e}")
        
        # ãƒãƒƒãƒå‡¦ç†ã®åˆ¤å®š
        batch_size = min(self.config.gpu_batch_size, n_frames)
        n_batches = (n_frames + batch_size - 1) // batch_size
        
        if n_batches > 1:
            print(f"Processing in {n_batches} batches of {batch_size} frames")
            result = self._analyze_batched(trajectory, backbone_indices, batch_size)
        else:
            # å˜ä¸€ãƒãƒƒãƒå‡¦ç†
            result = self._analyze_single_trajectory(trajectory, backbone_indices)
        
        computation_time = time.time() - start_time
        result.computation_time = computation_time
        
        self._print_summary(result)
        
        return result
    
    def _analyze_single_trajectory(self,
                                 trajectory: np.ndarray,
                                 backbone_indices: Optional[np.ndarray]) -> MDLambda3Result:
        """å˜ä¸€è»Œé“ã®è§£æï¼ˆãƒ¡ãƒ¢ãƒªã«åã¾ã‚‹å ´åˆï¼‰"""
        n_frames, n_atoms, _ = trajectory.shape
        
        # 1. MDç‰¹å¾´æŠ½å‡º
        print("\n1. Extracting MD features on GPU...")
        md_features = self.feature_extractor.extract_md_features(
            trajectory, backbone_indices
        )
        
        # 2. åˆæœŸã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
        initial_window = self._compute_initial_window(n_frames)
        
        # 3. Lambdaæ§‹é€ è¨ˆç®—ï¼ˆç¬¬1å›ï¼‰
        print("\n2. Computing LambdaÂ³ structures (first pass)...")
        lambda_structures = self.structure_computer.compute_lambda_structures(
            trajectory, md_features, initial_window
        )
        
        # 4. é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºæ±ºå®š
        adaptive_windows = self._determine_adaptive_windows(
            lambda_structures, initial_window
        )
        primary_window = adaptive_windows.get('primary', initial_window)
        
        # 5. æ§‹é€ å¢ƒç•Œæ¤œå‡º
        print("\n3. Detecting structural boundaries...")
        boundary_window = adaptive_windows.get('boundary', primary_window // 3)
        structural_boundaries = self.boundary_detector.detect_structural_boundaries(
            lambda_structures, boundary_window
        )
        
        # 6. ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ç ´ã‚Œæ¤œå‡º
        print("\n4. Detecting topological breaks...")
        fast_window = adaptive_windows.get('fast', primary_window // 2)
        topological_breaks = self.topology_detector.detect_topological_breaks(
            lambda_structures, fast_window
        )
        
        # 7. ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç•°å¸¸æ¤œå‡º
        print("\n5. Computing multi-scale anomaly scores...")
        anomaly_scores = self.anomaly_detector.compute_multiscale_anomalies(
            lambda_structures,
            structural_boundaries,
            topological_breaks,
            md_features,
            self.config
        )
        
        # 8. æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        print("\n6. Detecting structural patterns...")
        slow_window = adaptive_windows.get('slow', primary_window * 2)
        detected_structures = self._detect_structural_patterns(
            lambda_structures, structural_boundaries, slow_window
        )
        
        # 9. ä½ç›¸ç©ºé–“è§£æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        phase_space_analysis = None
        if self.config.use_phase_space:
            print("\n7. Performing phase space analysis...")
            try:
                phase_space_analysis = self.phase_space_analyzer.analyze_phase_space(
                    lambda_structures
                )
            except Exception as e:
                print(f"Phase space analysis failed: {e}")
        
        # è‡¨ç•Œã‚¤ãƒ™ãƒ³ãƒˆã®æ¤œå‡º
        critical_events = self._detect_critical_events(anomaly_scores)
        
        # GPUæƒ…å ±ã‚’åé›†
        gpu_info = self._get_gpu_info()
        
        # çµæœã‚’æ§‹ç¯‰
        result = MDLambda3Result(
            lambda_structures=self._to_cpu_dict(lambda_structures),
            structural_boundaries=structural_boundaries,
            topological_breaks=self._to_cpu_dict(topological_breaks),
            md_features=self._to_cpu_dict(md_features),
            anomaly_scores=self._to_cpu_dict(anomaly_scores),
            detected_structures=detected_structures,
            phase_space_analysis=phase_space_analysis,
            critical_events=critical_events,
            n_frames=n_frames,
            n_atoms=n_atoms,
            window_steps=primary_window,
            computation_time=0.0,
            gpu_info=gpu_info
        )
        
        return result
    
    def _analyze_batched(self,
                        trajectory: np.ndarray,
                        backbone_indices: Optional[np.ndarray],
                        batch_size: int) -> MDLambda3Result:
        """ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹è§£æï¼ˆå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ç”¨ï¼‰- ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆ"""
        print("\nâš¡ Running batched GPU analysis...")
        
        n_frames = trajectory.shape[0]
        n_batches = (n_frames + batch_size - 1) // batch_size
        
        # ãƒãƒƒãƒã”ã¨ã®çµæœã‚’è“„ç©
        batch_results = []
        
        # Step 1: é‡ã„å‡¦ç†ã‚’ãƒãƒƒãƒã§å®Ÿè¡Œï¼ˆMDç‰¹å¾´ã¨Lambdaæ§‹é€ ï¼‰
        print("\n[Step 1] Processing batches for feature extraction...")
        for batch_idx in range(n_batches):
            start_idx = batch_idx * batch_size
            end_idx = min((batch_idx + 1) * batch_size, n_frames)
            
            print(f"  Batch {batch_idx + 1}/{n_batches}: frames {start_idx}-{end_idx}")
            
            batch_trajectory = trajectory[start_idx:end_idx]
            
            # ãƒãƒƒãƒè§£æï¼ˆç‰¹å¾´æŠ½å‡ºã¨Lambdaæ§‹é€ è¨ˆç®—ã®ã¿ï¼‰
            batch_result = self._analyze_single_batch(
                batch_trajectory, backbone_indices, start_idx
            )
            
            batch_results.append(batch_result)
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
            self.memory_manager.clear_cache()
        
        # Step 2: çµæœã‚’ãƒãƒ¼ã‚¸ï¼ˆãƒ‡ãƒ¼ã‚¿çµåˆã®ã¿ï¼‰
        print("\n[Step 2] Merging batch results...")
        merged_result = self._merge_batch_results(batch_results, trajectory.shape)
        
        # Step 3: ãƒãƒ¼ã‚¸ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§è§£æã‚’å®Œäº†ï¼ˆè»½ã„å‡¦ç†ï¼‰
        print("\n[Step 3] Completing analysis on merged data...")
        final_result = self._complete_analysis(merged_result)
        
        return final_result
    
    def _analyze_single_batch(self,
                            batch_trajectory: np.ndarray,
                            backbone_indices: Optional[np.ndarray],
                            offset: int) -> Dict:
        """å˜ä¸€ãƒãƒƒãƒã®è§£æï¼ˆç‰¹å¾´æŠ½å‡ºã¨Lambdaæ§‹é€ è¨ˆç®—ã®ã¿ï¼‰"""
        # MDç‰¹å¾´æŠ½å‡ºï¼ˆé‡ã„å‡¦ç†ï¼‰
        md_features = self.feature_extractor.extract_md_features(
            batch_trajectory, backbone_indices
        )
        
        window = self._compute_initial_window(len(batch_trajectory))
        
        # Lambdaæ§‹é€ è¨ˆç®—ï¼ˆé‡ã„å‡¦ç†ï¼‰
        lambda_structures = self.structure_computer.compute_lambda_structures(
            batch_trajectory, md_features, window
        )
        
        return {
            'offset': offset,
            'n_frames': len(batch_trajectory),
            'lambda_structures': lambda_structures,
            'md_features': md_features,
            'window': window
        }
    
    def _merge_batch_results(self,
                           batch_results: List[Dict],
                           original_shape: Tuple) -> MDLambda3Result:
        """ãƒãƒƒãƒçµæœã®çµ±åˆï¼ˆãƒ‡ãƒ¼ã‚¿çµåˆã®ã¿ï¼‰"""
        print("  Merging data from all batches...")
        
        n_frames, n_atoms, _ = original_shape
        
        if not batch_results:
            return self._create_empty_result(n_frames, n_atoms)
        
        # çµæœã‚’ä¿å­˜ã™ã‚‹è¾æ›¸ã‚’åˆæœŸåŒ–
        merged_lambda_structures = {}
        merged_md_features = {}
        
        # æœ€åˆã®ãƒãƒƒãƒã‹ã‚‰ã‚­ãƒ¼ã¨å½¢çŠ¶ã‚’å–å¾—
        first_batch = batch_results[0]
        lambda_keys = first_batch.get('lambda_structures', {}).keys()
        feature_keys = first_batch.get('md_features', {}).keys()
        
        print(f"    Lambda structure keys: {list(lambda_keys)}")
        print(f"    MD feature keys: {list(feature_keys)}")
        
        # Lambdaæ§‹é€ ã®é…åˆ—ã‚’åˆæœŸåŒ–
        for key in lambda_keys:
            sample = first_batch['lambda_structures'][key]
            if isinstance(sample, (np.ndarray, self.xp.ndarray)):
                rest_shape = sample.shape[1:] if len(sample.shape) > 1 else ()
                full_shape = (n_frames,) + rest_shape
                dtype = sample.dtype
                merged_lambda_structures[key] = np.full(full_shape, np.nan, dtype=dtype)
        
        # MDç‰¹å¾´ã®é…åˆ—ã‚’åˆæœŸåŒ–
        for key in feature_keys:
            sample = first_batch['md_features'][key]
            if isinstance(sample, (np.ndarray, self.xp.ndarray)):
                rest_shape = sample.shape[1:] if len(sample.shape) > 1 else ()
                full_shape = (n_frames,) + rest_shape
                dtype = sample.dtype
                merged_md_features[key] = np.full(full_shape, np.nan, dtype=dtype)
        
        # å„ãƒãƒƒãƒã®çµæœã‚’æ­£ã—ã„ä½ç½®ã«é…ç½®
        for batch_idx, batch_result in enumerate(batch_results):
            offset = batch_result['offset']
            batch_n_frames = batch_result['n_frames']
            end_idx = offset + batch_n_frames
            
            # ç¯„å›²ãƒã‚§ãƒƒã‚¯
            if end_idx > n_frames:
                end_idx = n_frames
                batch_n_frames = end_idx - offset
            
            # Lambdaæ§‹é€ ã‚’ãƒãƒ¼ã‚¸
            for key, value in batch_result.get('lambda_structures', {}).items():
                if key in merged_lambda_structures:
                    if hasattr(value, 'get'):  # CuPyé…åˆ—ã®å ´åˆ
                        value = self.to_cpu(value)
                    actual_frames = min(len(value), batch_n_frames)
                    merged_lambda_structures[key][offset:offset + actual_frames] = value[:actual_frames]
            
            # MDç‰¹å¾´ã‚’ãƒãƒ¼ã‚¸
            for key, value in batch_result.get('md_features', {}).items():
                if key in merged_md_features:
                    if hasattr(value, 'get'):
                        value = self.to_cpu(value)
                    actual_frames = min(len(value), batch_n_frames)
                    merged_md_features[key][offset:offset + actual_frames] = value[:actual_frames]
        
        # NaNãƒã‚§ãƒƒã‚¯
        for key, arr in merged_lambda_structures.items():
            nan_count = np.isnan(arr).sum()
            if nan_count > 0:
                print(f"    âš ï¸ Warning: {key} has {nan_count} unprocessed frames")
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¹ãƒ†ãƒƒãƒ—ã®è¨ˆç®—
        window_steps = 100  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        if 'window' in first_batch:
            windows = [b.get('window', 100) for b in batch_results if 'window' in b]
            if windows:
                window_steps = int(np.mean(windows))
        
        # GPUæƒ…å ±ã®æ§‹ç¯‰
        gpu_info = {
            'computation_mode': 'batched',
            'n_batches': len(batch_results),
            'device_name': str(self.device),
            'batch_sizes': [b['n_frames'] for b in batch_results]
        }
        
        print(f"  âœ… Merged {n_frames} frames successfully")
        
        # ãƒãƒ¼ã‚¸çµæœã‚’è¿”ã™ï¼ˆè§£æã¯æœªå®Œäº†ï¼‰
        return MDLambda3Result(
            lambda_structures=merged_lambda_structures,
            structural_boundaries={},  # å¾Œã§è¨ˆç®—
            topological_breaks={},      # å¾Œã§è¨ˆç®—
            md_features=merged_md_features,
            anomaly_scores={},          # å¾Œã§è¨ˆç®—
            detected_structures=[],     # å¾Œã§è¨ˆç®—
            critical_events=[],         # å¾Œã§è¨ˆç®—
            n_frames=n_frames,
            n_atoms=n_atoms,
            window_steps=window_steps,
            computation_time=0.0,
            gpu_info=gpu_info
        )
    
    def _complete_analysis(self, merged_result: MDLambda3Result) -> MDLambda3Result:
        """ãƒãƒ¼ã‚¸å¾Œã®ãƒ‡ãƒ¼ã‚¿ã§è§£æã‚’å®Œäº†ï¼ˆå¢ƒç•Œæ¤œå‡ºã€ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—ãªã©ï¼‰"""
        
        lambda_structures = merged_result.lambda_structures
        md_features = merged_result.md_features
        n_frames = merged_result.n_frames
        
        # é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºæ±ºå®š
        initial_window = merged_result.window_steps
        adaptive_windows = self._determine_adaptive_windows(
            lambda_structures, initial_window
        )
        primary_window = adaptive_windows.get('primary', initial_window)
        
        # 5. æ§‹é€ å¢ƒç•Œæ¤œå‡ºï¼ˆå…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã§å®Ÿè¡Œ - è»½ã„å‡¦ç†ï¼‰
        print("  - Detecting structural boundaries...")
        boundary_window = adaptive_windows.get('boundary', primary_window // 3)
        structural_boundaries = self.boundary_detector.detect_structural_boundaries(
            lambda_structures, boundary_window
        )
        
        # 6. ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ç ´ã‚Œæ¤œå‡ºï¼ˆå…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã§å®Ÿè¡Œ - è»½ã„å‡¦ç†ï¼‰
        print("  - Detecting topological breaks...")
        fast_window = adaptive_windows.get('fast', primary_window // 2)
        topological_breaks = self.topology_detector.detect_topological_breaks(
            lambda_structures, fast_window
        )
        
        # 7. ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç•°å¸¸æ¤œå‡ºï¼ˆå…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã§å®Ÿè¡Œ - è»½ã„å‡¦ç†ï¼‰
        print("  - Computing anomaly scores...")
        anomaly_scores = self.anomaly_detector.compute_multiscale_anomalies(
            lambda_structures,
            structural_boundaries,
            topological_breaks,
            md_features,
            self.config
        )
        
        # 8. æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        print("  - Detecting structural patterns...")
        slow_window = adaptive_windows.get('slow', primary_window * 2)
        detected_structures = self._detect_structural_patterns(
            lambda_structures, structural_boundaries, slow_window
        )
        
        # 9. ä½ç›¸ç©ºé–“è§£æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        phase_space_analysis = None
        if self.config.use_phase_space:
            print("  - Performing phase space analysis...")
            try:
                phase_space_analysis = self.phase_space_analyzer.analyze_phase_space(
                    lambda_structures
                )
            except Exception as e:
                print(f"    Phase space analysis failed: {e}")
        
        # è‡¨ç•Œã‚¤ãƒ™ãƒ³ãƒˆã®æ¤œå‡º
        critical_events = self._detect_critical_events(anomaly_scores)
        
        print("  âœ… Analysis completed!")
        
        # çµæœã‚’æ›´æ–°
        merged_result.structural_boundaries = structural_boundaries
        merged_result.topological_breaks = topological_breaks
        merged_result.anomaly_scores = anomaly_scores
        merged_result.detected_structures = detected_structures
        merged_result.phase_space_analysis = phase_space_analysis
        merged_result.critical_events = critical_events
        merged_result.window_steps = primary_window
        
        return merged_result
    
    # === ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ ===
    
    def _compute_initial_window(self, n_frames: int) -> int:
        """åˆæœŸã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã®è¨ˆç®—"""
        return min(100, n_frames // 10)
    
    def _determine_adaptive_windows(self, lambda_structures: Dict, 
                                   initial_window: int) -> Dict[str, int]:
        """é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã®æ±ºå®š"""
        if not self.config.adaptive_window:
            return {'primary': initial_window}
        
        # Lambdaæ§‹é€ ã®å¤‰å‹•ã‹ã‚‰æœ€é©ãªã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’æ¨å®š
        windows = {
            'primary': initial_window,
            'fast': max(10, initial_window // 2),
            'slow': min(500, initial_window * 2),
            'boundary': max(20, initial_window // 3)
        }
        
        return windows
    
    def _detect_structural_patterns(self, lambda_structures: Dict,
                                   boundaries: Dict, window: int) -> List[Dict]:
        """æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º"""
        patterns = []
        
        if isinstance(boundaries, dict) and 'boundary_locations' in boundaries:
            boundary_locs = boundaries['boundary_locations']
            
            # å¢ƒç•Œé–“ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ§‹é€ ã¨ã—ã¦èªè­˜
            if len(boundary_locs) > 0:
                # æœ€åˆã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
                if boundary_locs[0] > 50:
                    patterns.append({
                        'type': 'initial_structure',
                        'start': 0,
                        'end': boundary_locs[0],
                        'duration': boundary_locs[0]
                    })
                
                # ä¸­é–“ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
                for i in range(len(boundary_locs) - 1):
                    duration = boundary_locs[i+1] - boundary_locs[i]
                    if duration > 30:
                        patterns.append({
                            'type': 'intermediate_structure',
                            'start': boundary_locs[i],
                            'end': boundary_locs[i+1],
                            'duration': duration
                        })
        
        return patterns
    
    def _detect_critical_events(self, anomaly_scores: Dict) -> List:
        """è‡¨ç•Œã‚¤ãƒ™ãƒ³ãƒˆã®æ¤œå‡º"""
        events = []
        
        if 'combined' in anomaly_scores:
            scores = anomaly_scores['combined']
            threshold = np.mean(scores) + 2 * np.std(scores)
            
            # é–¾å€¤ã‚’è¶…ãˆã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¤œå‡º
            critical_frames = np.where(scores > threshold)[0]
            
            # é€£ç¶šã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            if len(critical_frames) > 0:
                current_event_start = critical_frames[0]
                current_event_end = critical_frames[0]
                
                for frame in critical_frames[1:]:
                    if frame == current_event_end + 1:
                        current_event_end = frame
                    else:
                        # ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¨˜éŒ²
                        events.append((current_event_start, current_event_end))
                        current_event_start = frame
                        current_event_end = frame
                
                # æœ€å¾Œã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¨˜éŒ²
                events.append((current_event_start, current_event_end))
        
        return events
    
    def _to_cpu_dict(self, data_dict: Dict) -> Dict:
        """è¾æ›¸å†…ã®GPUé…åˆ—ã‚’CPUã«è»¢é€"""
        cpu_dict = {}
        for key, value in data_dict.items():
            if hasattr(value, 'get'):  # CuPyé…åˆ—ã®å ´åˆ
                cpu_dict[key] = self.to_cpu(value)
            elif isinstance(value, dict):
                cpu_dict[key] = self._to_cpu_dict(value)
            else:
                cpu_dict[key] = value
        return cpu_dict
    
    def _get_gpu_info(self) -> Dict:
        """GPUæƒ…å ±ã‚’å®‰å…¨ã«å–å¾—"""
        gpu_info = {
            'device_name': str(self.device),
            'computation_mode': 'single_batch'
        }
        
        try:
            mem_info = self.memory_manager.get_memory_info()
            gpu_info['memory_used'] = mem_info.used / 1e9
        except:
            gpu_info['memory_used'] = 0.0
        
        return gpu_info
    
    def _create_empty_result(self, n_frames: int, n_atoms: int) -> MDLambda3Result:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return MDLambda3Result(
            lambda_structures={},
            structural_boundaries={},
            topological_breaks={},
            md_features={},
            anomaly_scores={},
            detected_structures=[],
            critical_events=[],
            n_frames=n_frames,
            n_atoms=n_atoms,
            window_steps=100,
            computation_time=0.0,
            gpu_info={'computation_mode': 'batched', 'n_batches': 0}
        )
    
    def _print_initialization_info(self):
        """åˆæœŸåŒ–æƒ…å ±ã®è¡¨ç¤º"""
        if self.verbose:
            print(f"\nğŸš€ LambdaÂ³ GPU Detector Initialized")
            print(f"   Device: {self.device}")
            print(f"   GPU Mode: {self.is_gpu}")
            print(f"   Memory Limit: {self.memory_manager.max_memory / 1e9:.2f} GB")
            
            try:
                mem_info = self.memory_manager.get_memory_info()
                print(f"   Available: {mem_info.free / 1e9:.2f} GB")
            except:
                pass
            
            print(f"   Batch Size: {self.config.gpu_batch_size} frames")
            print(f"   Extended Detection: {'ON' if self.config.use_extended_detection else 'OFF'}")
            print(f"   Phase Space Analysis: {'ON' if self.config.use_phase_space else 'OFF'}")
    
    def _print_summary(self, result: MDLambda3Result):
        """çµæœã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º"""
        print("\n" + "="*60)
        print("=== Analysis Complete ===")
        print("="*60)
        print(f"Total frames: {result.n_frames}")
        print(f"Computation time: {result.computation_time:.2f} seconds")
        
        if result.computation_time > 0:
            print(f"Speed: {result.n_frames / result.computation_time:.1f} frames/second")
        
        if result.gpu_info:
            print(f"\nGPU Performance:")
            print(f"  Memory used: {result.gpu_info.get('memory_used', 0):.2f} GB")
            print(f"  Computation mode: {result.gpu_info.get('computation_mode', 'unknown')}")
        
        print(f"\nDetected features:")
        if isinstance(result.structural_boundaries, dict):
            n_boundaries = len(result.structural_boundaries.get('boundary_locations', []))
        else:
            n_boundaries = 0
        print(f"  Structural boundaries: {n_boundaries}")
        print(f"  Detected patterns: {len(result.detected_structures)}")
        print(f"  Critical events: {len(result.critical_events)}")
        
        if 'combined' in result.anomaly_scores:
            scores = result.anomaly_scores['combined']
            print(f"\nAnomaly statistics:")
            print(f"  Mean score: {np.mean(scores):.3f}")
            print(f"  Max score: {np.max(scores):.3f}")
            print(f"  Frames > 2Ïƒ: {np.sum(scores > 2.0)}")
    
    # === è¿½åŠ ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¡ã‚½ãƒƒãƒ‰ ===
    
    def enable_mixed_precision(self):
        """æ··åˆç²¾åº¦ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–"""
        self.config.mixed_precision = True
        print("âœ“ Mixed precision mode enabled")
    
    def benchmark_mode(self, enable: bool = True):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆ"""
        self.config.benchmark_mode = enable
        if enable:
            print("â±ï¸ Benchmark mode enabled - timing all operations")
    
    def set_batch_size(self, batch_size: int):
        """ãƒãƒƒãƒã‚µã‚¤ã‚ºã®è¨­å®š"""
        self.config.gpu_batch_size = batch_size
        print(f"âœ“ Batch size set to {batch_size} frames")
