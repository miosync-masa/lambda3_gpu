"""
Quantum Validation Module v4.0 - LambdaÂ³ Integrated Edition
===========================================================

LambdaÂ³ãŒæ¤œå‡ºã—ãŸæ§‹é€ å¤‰åŒ–ã‚¤ãƒ™ãƒ³ãƒˆã®é‡å­èµ·æºã‚’åˆ¤å®šã™ã‚‹çµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

è¨­è¨ˆæ€æƒ³ï¼š
- LambdaÂ³ã®æ§‹é€ ç•°å¸¸æ¤œå‡ºã‚’å‰æã¨ã—ãŸåˆ¤å®š
- 3ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆç¬é–“/é·ç§»/ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ï¼‰ã®æ˜ç¢ºãªåŒºåˆ¥
- Trajectoryã‹ã‚‰ã®åŸå­ãƒ¬ãƒ™ãƒ«è¨¼æ‹ ã®æ´»ç”¨
- ç¾å®Ÿçš„ã‹ã¤ç§‘å­¦çš„ãªåˆ¤å®šåŸºæº–

Version: 4.0 - Complete Refactoring
Authors: ç’°ã¡ã‚ƒã‚“ & ã”ä¸»äººã•ã¾
Date: 2024
"""

import numpy as np
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, field
from enum import Enum
import logging
from scipy import stats, signal
from scipy.spatial.distance import cdist

# Loggerè¨­å®š
logger = logging.getLogger('quantum_validation_v4')

# ============================================
# Enums and Constants
# ============================================

class StructuralEventPattern(Enum):
    """æ§‹é€ å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡"""
    INSTANTANEOUS = "instantaneous"  # å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆç¬é–“çš„ï¼‰
    TRANSITION = "transition"        # é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆé·ç§»ï¼‰
    CASCADE = "cascade"              # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰

class QuantumSignature(Enum):
    """é‡å­çš„ã‚·ã‚°ãƒãƒãƒ£ãƒ¼"""
    ENTANGLEMENT = "quantum_entanglement"        # é‡å­ã‚‚ã¤ã‚Œ
    TUNNELING = "quantum_tunneling"              # é‡å­ãƒˆãƒ³ãƒãƒªãƒ³ã‚°
    COHERENCE = "quantum_coherence"              # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹
    PHASE_TRANSITION = "quantum_phase_transition" # é‡å­ç›¸è»¢ç§»
    INFORMATION_TRANSFER = "quantum_info_transfer" # é‡å­æƒ…å ±ä¼é”
    NONE = "classical"                           # å¤å…¸çš„

# ============================================
# Data Classes
# ============================================

@dataclass
class LambdaAnomaly:
    """Lambdaæ§‹é€ ã®ç•°å¸¸æ€§è©•ä¾¡"""
    lambda_jump: float = 0.0          # Î›ã®å¤‰åŒ–é‡
    lambda_zscore: float = 0.0        # çµ±è¨ˆçš„ç•°å¸¸åº¦
    rho_t_spike: float = 0.0          # ÏTã®ã‚¹ãƒ‘ã‚¤ã‚¯
    sigma_s_value: float = 0.0        # Ïƒsï¼ˆæ§‹é€ åŒæœŸï¼‰
    coordination: float = 0.0          # å”èª¿æ€§ï¼ˆãƒ¬ãƒ—ãƒªã‚«ãŒã‚ã‚‹å ´åˆï¼‰
    statistical_rarity: float = 1.0    # på€¤
    thermal_comparison: float = 0.0    # ç†±çš„ã‚†ã‚‰ãã¨ã®æ¯”

@dataclass
class AtomicEvidence:
    """åŸå­ãƒ¬ãƒ™ãƒ«ã®è¨¼æ‹ """
    max_velocity: float = 0.0          # æœ€å¤§åŸå­é€Ÿåº¦
    max_acceleration: float = 0.0      # æœ€å¤§åŠ é€Ÿåº¦
    correlation_coefficient: float = 0.0 # åŸå­é‹å‹•ã®ç›¸é–¢
    bond_anomalies: List[Dict] = field(default_factory=list)
    dihedral_flips: List[Dict] = field(default_factory=list)
    hydrogen_behavior: Dict = field(default_factory=dict)

@dataclass
class QuantumAssessment:
    """é‡å­æ€§è©•ä¾¡çµæœ"""
    pattern: StructuralEventPattern
    signature: QuantumSignature
    confidence: float = 0.0
    is_quantum: bool = False
    
    # è©³ç´°è©•ä¾¡
    lambda_anomaly: Optional[LambdaAnomaly] = None
    atomic_evidence: Optional[AtomicEvidence] = None
    
    # åˆ¤å®šæ ¹æ‹ 
    criteria_met: List[str] = field(default_factory=list)
    explanation: str = ""
    
    # ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰å›ºæœ‰
    bell_inequality: Optional[float] = None
    async_bonds_used: List[Dict] = field(default_factory=list)

# ============================================
# Main Quantum Validator Class
# ============================================

class QuantumValidatorV4:
    """
    LambdaÂ³çµ±åˆå‹é‡å­åˆ¤å®šå™¨
    
    LambdaÂ³ãŒæ¤œå‡ºã—ãŸæ§‹é€ å¤‰åŒ–ã‚¤ãƒ™ãƒ³ãƒˆã‚’å—ã‘å–ã‚Šã€
    ãã®å¤‰åŒ–ãŒé‡å­çš„èµ·æºã‚’æŒã¤ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚
    """
    
    def __init__(self,
                 trajectory: Optional[np.ndarray] = None,
                 topology: Optional[Any] = None,
                 dt_ps: float = 100.0,
                 temperature_K: float = 300.0,
                 config: Optional[Dict] = None):
        """
        Parameters
        ----------
        trajectory : np.ndarray, optional
            åŸå­åº§æ¨™ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒª [frames, atoms, 3]
        topology : Any, optional
            ãƒˆãƒãƒ­ã‚¸ãƒ¼æƒ…å ±ï¼ˆçµåˆã€åŸå­ã‚¿ã‚¤ãƒ—ãªã©ï¼‰
        dt_ps : float
            ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆãƒ”ã‚³ç§’ï¼‰
        temperature_K : float
            ç³»ã®æ¸©åº¦ï¼ˆã‚±ãƒ«ãƒ“ãƒ³ï¼‰
        config : dict, optional
            åˆ¤å®šåŸºæº–ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºè¨­å®š
        """
        self.trajectory = trajectory
        self.topology = topology
        self.dt_ps = dt_ps
        self.temperature = temperature_K
        
        # ç‰©ç†å®šæ•°
        self.k_B = 8.617333e-5  # eV/K
        self.k_B_T = self.k_B * self.temperature  # eV
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ¤å®šåŸºæº–ï¼ˆèª¿æ•´å¯èƒ½ï¼‰
        self.criteria = config or {
            # Lambdaç•°å¸¸
            'lambda_zscore_threshold': 3.0,      # 3Ïƒä»¥ä¸Š
            'coordination_threshold': 0.7,       # 70%ä»¥ä¸Šã®å”èª¿
            'statistical_rarity': 0.01,          # p < 0.01
            
            # åŸå­é‹å‹•
            'velocity_anomaly_factor': 3.0,      # å¹³å‡ã®3å€
            'correlation_threshold': 0.8,        # ç›¸é–¢ä¿‚æ•°0.8ä»¥ä¸Š
            'dihedral_flip_angle': 120.0,       # 120åº¦ä»¥ä¸Šã®å›è»¢
            
            # ãƒˆãƒ³ãƒãƒªãƒ³ã‚°
            'tunneling_enhancement': 10.0,       # å¤å…¸æ¯”10å€
            'barrier_threshold_kT': 5.0,        # 5kTä»¥ä¸Šã®éšœå£
            
            # ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹
            'coherence_time_thermal_ratio': 5.0, # ç†±çš„æ™‚é–“ã®5å€
            'phase_correlation_threshold': 0.7,  # ä½ç›¸ç›¸é–¢0.7ä»¥ä¸Š
            
            # ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰
            'bell_chsh_threshold': 2.0,         # CHSH > 2
            'causality_strength': 0.5,          # å› æœæ€§å¼·åº¦
            'cascade_speed_factor': 2.0,        # æœŸå¾…å€¤ã®2å€é€Ÿ
        }
        
        logger.info("ğŸš€ Quantum Validator v4.0 initialized")
        logger.info(f"   Temperature: {self.temperature:.1f} K")
        logger.info(f"   Time step: {self.dt_ps:.1f} ps")
        logger.info(f"   Trajectory: {'loaded' if trajectory is not None else 'not loaded'}")
    
    # ========================================
    # Main Entry Point
    # ========================================
    
    def validate_event(self,
                       event: Dict,
                       lambda_result: Any,
                       network_result: Optional[Any] = None) -> QuantumAssessment:
        """
        æ§‹é€ å¤‰åŒ–ã‚¤ãƒ™ãƒ³ãƒˆã®é‡å­æ€§ã‚’åˆ¤å®š
        
        Parameters
        ----------
        event : dict
            LambdaÂ³ãŒæ¤œå‡ºã—ãŸã‚¤ãƒ™ãƒ³ãƒˆ
            Required keys: frame_start, frame_end, type, ...
        lambda_result : Any
            LambdaÂ³è§£æçµæœï¼ˆstructures, events, etc.ï¼‰
        network_result : Any, optional
            ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æçµæœï¼ˆasync_bonds, causal_linksï¼‰
            
        Returns
        -------
        QuantumAssessment
            é‡å­æ€§è©•ä¾¡çµæœ
        """
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡
        pattern = self._classify_pattern(event, network_result)
        
        # Lambdaç•°å¸¸æ€§è©•ä¾¡
        lambda_anomaly = self._evaluate_lambda_anomaly(event, lambda_result)
        
        # åŸå­ãƒ¬ãƒ™ãƒ«è¨¼æ‹ ï¼ˆtrajectoryãŒã‚ã‚‹å ´åˆï¼‰
        atomic_evidence = None
        if self.trajectory is not None:
            atomic_evidence = self._gather_atomic_evidence(event, self.trajectory)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥åˆ¤å®š
        if pattern == StructuralEventPattern.INSTANTANEOUS:
            assessment = self._validate_instantaneous(
                event, lambda_anomaly, atomic_evidence
            )
        elif pattern == StructuralEventPattern.CASCADE:
            assessment = self._validate_cascade(
                event, lambda_anomaly, atomic_evidence, network_result
            )
        else:  # TRANSITION
            assessment = self._validate_transition(
                event, lambda_anomaly, atomic_evidence
            )
        
        # æœ€çµ‚è©•ä¾¡
        assessment.pattern = pattern
        assessment.lambda_anomaly = lambda_anomaly
        assessment.atomic_evidence = atomic_evidence
        
        # èª¬æ˜æ–‡ç”Ÿæˆ
        assessment.explanation = self._generate_explanation(assessment)
        
        return assessment
    
    # ========================================
    # Pattern Classification
    # ========================================
    
    def _classify_pattern(self, event: Dict, network_result: Optional[Any]) -> StructuralEventPattern:
        """ã‚¤ãƒ™ãƒ³ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†é¡"""
        duration = event.get('frame_end', event.get('frame', 0)) - \
                  event.get('frame_start', event.get('frame', 0)) + 1
        
        # ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰åˆ¤å®šï¼ˆasync_bondsãŒã‚ã‚‹ï¼‰
        if network_result and hasattr(network_result, 'async_strong_bonds'):
            if len(network_result.async_strong_bonds) > 0:
                return StructuralEventPattern.CASCADE
        
        # æ™‚é–“ã«ã‚ˆã‚‹åˆ†é¡
        if duration == 1:
            return StructuralEventPattern.INSTANTANEOUS
        else:
            return StructuralEventPattern.TRANSITION
    
    # ========================================
    # Lambda Anomaly Evaluation
    # ========================================
    
    def _evaluate_lambda_anomaly(self, event: Dict, lambda_result: Any) -> LambdaAnomaly:
        """Lambdaæ§‹é€ ã®ç•°å¸¸æ€§ã‚’è©•ä¾¡"""
        anomaly = LambdaAnomaly()
        
        if not hasattr(lambda_result, 'structures'):
            return anomaly
        
        structures = lambda_result.structures
        frame = event.get('frame_start', event.get('frame', 0))
        
        # Lambdaå€¤ã®å¤‰åŒ–
        if 'lambda_f' in structures and frame < len(structures['lambda_f']):
            lambda_vals = structures['lambda_f']
            
            # å‰å¾Œã¨ã®å·®åˆ†
            if frame > 0 and frame < len(lambda_vals) - 1:
                prev_val = lambda_vals[frame - 1]
                curr_val = lambda_vals[frame]
                next_val = lambda_vals[frame + 1]
                
                anomaly.lambda_jump = abs(curr_val - prev_val)
                
                # Z-scoreè¨ˆç®—
                if len(lambda_vals) > 10:
                    mean = np.mean(lambda_vals)
                    std = np.std(lambda_vals)
                    if std > 0:
                        anomaly.lambda_zscore = abs(curr_val - mean) / std
        
        # rho_tï¼ˆãƒ†ãƒ³ã‚·ãƒ§ãƒ³ï¼‰
        if 'rho_t' in structures and frame < len(structures['rho_t']):
            anomaly.rho_t_spike = structures['rho_t'][frame]
        
        # sigma_sï¼ˆæ§‹é€ åŒæœŸï¼‰
        if 'sigma_s' in structures and frame < len(structures['sigma_s']):
            anomaly.sigma_s_value = structures['sigma_s'][frame]
        
        # å”èª¿æ€§ï¼ˆãƒ¬ãƒ—ãƒªã‚«è§£æã®å ´åˆï¼‰
        if hasattr(lambda_result, 'coordination') and frame < len(lambda_result.coordination):
            anomaly.coordination = lambda_result.coordination[frame]
        
        # çµ±è¨ˆçš„ç¨€å°‘æ€§
        if anomaly.lambda_zscore > 0:
            anomaly.statistical_rarity = 2 * (1 - stats.norm.cdf(anomaly.lambda_zscore))
        
        # ç†±çš„æ¯”è¼ƒ
        thermal_energy = self.k_B_T
        if anomaly.lambda_jump > 0:
            anomaly.thermal_comparison = anomaly.lambda_jump / thermal_energy
        
        return anomaly
    
    # ========================================
    # Atomic Evidence Gathering
    # ========================================
    
    def _gather_atomic_evidence(self, event: Dict, trajectory: np.ndarray) -> AtomicEvidence:
        """åŸå­ãƒ¬ãƒ™ãƒ«ã®è¨¼æ‹ ã‚’åé›†"""
        evidence = AtomicEvidence()
        
        frame_start = event.get('frame_start', event.get('frame', 0))
        frame_end = event.get('frame_end', frame_start)
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²ãƒã‚§ãƒƒã‚¯
        if frame_start >= len(trajectory) or frame_end >= len(trajectory):
            return evidence
        
        # åŸå­é€Ÿåº¦ãƒ»åŠ é€Ÿåº¦
        if frame_start > 0:
            # é€Ÿåº¦è¨ˆç®—
            velocities = (trajectory[frame_start] - trajectory[frame_start - 1]) / self.dt_ps
            evidence.max_velocity = np.max(np.linalg.norm(velocities, axis=1))
            
            # åŠ é€Ÿåº¦è¨ˆç®—
            if frame_start > 1:
                prev_vel = (trajectory[frame_start - 1] - trajectory[frame_start - 2]) / self.dt_ps
                accelerations = (velocities - prev_vel) / self.dt_ps
                evidence.max_acceleration = np.max(np.linalg.norm(accelerations, axis=1))
        
        # åŸå­é‹å‹•ã®ç›¸é–¢
        if frame_end > frame_start:
            displacements = []
            for f in range(frame_start, min(frame_end + 1, len(trajectory))):
                if f > 0:
                    disp = trajectory[f] - trajectory[f - 1]
                    displacements.append(disp.flatten())
            
            if len(displacements) > 1:
                corr_matrix = np.corrcoef(displacements)
                # ä¸Šä¸‰è§’ã®æœ€å¤§ç›¸é–¢
                upper_triangle = np.triu(corr_matrix, k=1)
                evidence.correlation_coefficient = np.max(np.abs(upper_triangle))
        
        # çµåˆé•·ç•°å¸¸ï¼ˆãƒˆãƒãƒ­ã‚¸ãƒ¼æƒ…å ±ãŒã‚ã‚‹å ´åˆï¼‰
        if self.topology is not None:
            evidence.bond_anomalies = self._check_bond_anomalies(
                trajectory[frame_start], self.topology
            )
        
        # äºŒé¢è§’ãƒ•ãƒªãƒƒãƒ—
        if frame_start > 0 and self.topology is not None:
            evidence.dihedral_flips = self._check_dihedral_flips(
                trajectory[frame_start - 1], trajectory[frame_start], self.topology
            )
        
        # æ°´ç´ ã®æŒ¯ã‚‹èˆã„ï¼ˆãƒˆãƒãƒ­ã‚¸ãƒ¼æƒ…å ±ãŒã‚ã‚‹å ´åˆï¼‰
        if self.topology is not None:
            evidence.hydrogen_behavior = self._analyze_hydrogen_behavior(
                event, trajectory, self.topology
            )
        
        return evidence
    
    def _check_bond_anomalies(self, coords: np.ndarray, topology: Any) -> List[Dict]:
        """çµåˆé•·ã®ç•°å¸¸ã‚’ãƒã‚§ãƒƒã‚¯"""
        anomalies = []
        
        # ãƒˆãƒãƒ­ã‚¸ãƒ¼ã‹ã‚‰çµåˆãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆå®Ÿè£…ã¯ãƒˆãƒãƒ­ã‚¸ãƒ¼å½¢å¼ã«ä¾å­˜ï¼‰
        # ã“ã“ã§ã¯ç°¡ç•¥åŒ–
        try:
            if hasattr(topology, 'bonds'):
                for bond in topology.bonds[:100]:  # æœ€åˆã®100çµåˆã®ã¿ãƒã‚§ãƒƒã‚¯
                    i, j = bond[0], bond[1]
                    if i < len(coords) and j < len(coords):
                        distance = np.linalg.norm(coords[i] - coords[j])
                        
                        # ç•°å¸¸ã«çŸ­ã„çµåˆï¼ˆ< 0.8 Ã…ï¼‰
                        if distance < 0.8:
                            anomalies.append({
                                'atoms': (i, j),
                                'distance': distance,
                                'type': 'ultra_short'
                            })
        except:
            pass
        
        return anomalies
    
    def _check_dihedral_flips(self, coords1: np.ndarray, coords2: np.ndarray, 
                              topology: Any) -> List[Dict]:
        """äºŒé¢è§’ã®æ€¥æ¿€ãªå¤‰åŒ–ã‚’ãƒã‚§ãƒƒã‚¯"""
        flips = []
        
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸå®Ÿè£…
        # å®Ÿéš›ã«ã¯ãƒˆãƒãƒ­ã‚¸ãƒ¼ã‹ã‚‰äºŒé¢è§’å®šç¾©ã‚’å–å¾—
        
        return flips
    
    def _analyze_hydrogen_behavior(self, event: Dict, trajectory: np.ndarray, 
                                  topology: Any) -> Dict:
        """æ°´ç´ åŸå­ã®é‡å­çš„æŒ¯ã‚‹èˆã„ã‚’è§£æ"""
        behavior = {
            'tunneling_candidates': 0,
            'delocalized_hydrogens': 0
        }
        
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸå®Ÿè£…
        # å®Ÿéš›ã«ã¯æ°´ç´ çµåˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è§£æ
        
        return behavior
    
    # ========================================
    # Pattern-Specific Validation
    # ========================================
    
    def _validate_instantaneous(self,
                               event: Dict,
                               lambda_anomaly: LambdaAnomaly,
                               atomic_evidence: Optional[AtomicEvidence]) -> QuantumAssessment:
        """ç¬é–“çš„å¤‰åŒ–ã®é‡å­æ€§åˆ¤å®š"""
        assessment = QuantumAssessment(
            pattern=StructuralEventPattern.INSTANTANEOUS,
            signature=QuantumSignature.NONE
        )
        
        criteria_met = []
        confidence = 0.0
        
        # Lambdaç•°å¸¸æ€§ãƒã‚§ãƒƒã‚¯
        if lambda_anomaly.lambda_zscore > self.criteria['lambda_zscore_threshold']:
            criteria_met.append(f"Lambda Z-score: {lambda_anomaly.lambda_zscore:.2f}")
            confidence += 0.3
        
        if lambda_anomaly.statistical_rarity < self.criteria['statistical_rarity']:
            criteria_met.append(f"Statistical rarity: p={lambda_anomaly.statistical_rarity:.4f}")
            confidence += 0.3
        
        if lambda_anomaly.coordination > self.criteria['coordination_threshold']:
            criteria_met.append(f"High coordination: {lambda_anomaly.coordination:.2%}")
            confidence += 0.2
            assessment.signature = QuantumSignature.ENTANGLEMENT
        
        # åŸå­ãƒ¬ãƒ™ãƒ«è¨¼æ‹ 
        if atomic_evidence:
            if atomic_evidence.correlation_coefficient > self.criteria['correlation_threshold']:
                criteria_met.append(f"Atomic correlation: {atomic_evidence.correlation_coefficient:.3f}")
                confidence += 0.2
                assessment.signature = QuantumSignature.ENTANGLEMENT
            
            if len(atomic_evidence.bond_anomalies) > 0:
                criteria_met.append(f"Bond anomalies: {len(atomic_evidence.bond_anomalies)}")
                confidence += 0.1
        
        # ç¬é–“çš„å¤‰åŒ–ã¯æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«çš„ã«é‡å­çš„
        criteria_met.append("Instantaneous timescale")
        confidence += 0.1
        
        # æœ€çµ‚åˆ¤å®š
        assessment.confidence = min(confidence, 1.0)
        assessment.is_quantum = confidence > 0.5
        assessment.criteria_met = criteria_met
        
        if assessment.is_quantum and assessment.signature == QuantumSignature.NONE:
            assessment.signature = QuantumSignature.PHASE_TRANSITION
        
        return assessment
    
    def _validate_transition(self,
                            event: Dict,
                            lambda_anomaly: LambdaAnomaly,
                            atomic_evidence: Optional[AtomicEvidence]) -> QuantumAssessment:
        """é·ç§»éç¨‹ã®é‡å­æ€§åˆ¤å®š"""
        assessment = QuantumAssessment(
            pattern=StructuralEventPattern.TRANSITION,
            signature=QuantumSignature.NONE
        )
        
        criteria_met = []
        confidence = 0.0
        
        # é·ç§»é€Ÿåº¦ã®è©•ä¾¡
        duration = event.get('frame_end', 0) - event.get('frame_start', 0) + 1
        transition_time = duration * self.dt_ps
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼éšœå£ã®æ¨å®šï¼ˆLambdaå¤‰åŒ–ã‹ã‚‰ï¼‰
        if lambda_anomaly.lambda_jump > 0:
            # éšœå£é«˜ã•ã®æ¨å®šï¼ˆç°¡ç•¥åŒ–ï¼‰
            barrier_estimate = lambda_anomaly.lambda_jump * 10  # kTå˜ä½
            
            # å¤å…¸çš„é·ç§»æ™‚é–“ï¼ˆKramersç†è«–ï¼‰
            classical_time = np.exp(barrier_estimate) * 1.0  # psï¼ˆç°¡ç•¥åŒ–ï¼‰
            
            if transition_time < classical_time / self.criteria['tunneling_enhancement']:
                criteria_met.append(f"Fast transition: {transition_time:.1f} ps << {classical_time:.1f} ps")
                confidence += 0.4
                assessment.signature = QuantumSignature.TUNNELING
        
        # ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯
        if lambda_anomaly.sigma_s_value > 0.8:  # é«˜ã„æ§‹é€ åŒæœŸ
            thermal_decoherence = 0.1  # psï¼ˆå®¤æ¸©ã§ã®å…¸å‹å€¤ï¼‰
            if transition_time > thermal_decoherence * self.criteria['coherence_time_thermal_ratio']:
                criteria_met.append(f"Sustained coherence: {transition_time:.1f} ps")
                confidence += 0.3
                assessment.signature = QuantumSignature.COHERENCE
        
        # åŸå­ãƒ¬ãƒ™ãƒ«è¨¼æ‹ 
        if atomic_evidence:
            if atomic_evidence.max_velocity > 0:
                # é€Ÿåº¦ç•°å¸¸
                typical_velocity = 1.0  # Ã…/psï¼ˆã‚¿ãƒ³ãƒ‘ã‚¯è³ªã®å…¸å‹å€¤ï¼‰
                if atomic_evidence.max_velocity > typical_velocity * self.criteria['velocity_anomaly_factor']:
                    criteria_met.append(f"Velocity anomaly: {atomic_evidence.max_velocity:.2f} Ã…/ps")
                    confidence += 0.2
            
            # æ°´ç´ ãƒˆãƒ³ãƒãƒªãƒ³ã‚°
            if atomic_evidence.hydrogen_behavior.get('tunneling_candidates', 0) > 0:
                criteria_met.append("Hydrogen tunneling candidates detected")
                confidence += 0.2
                assessment.signature = QuantumSignature.TUNNELING
        
        # æœ€çµ‚åˆ¤å®š
        assessment.confidence = min(confidence, 1.0)
        assessment.is_quantum = confidence > 0.4
        assessment.criteria_met = criteria_met
        
        return assessment
    
    def _validate_cascade(self,
                         event: Dict,
                         lambda_anomaly: LambdaAnomaly,
                         atomic_evidence: Optional[AtomicEvidence],
                         network_result: Any) -> QuantumAssessment:
        """ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ã®é‡å­æ€§åˆ¤å®š"""
        assessment = QuantumAssessment(
            pattern=StructuralEventPattern.CASCADE,
            signature=QuantumSignature.NONE
        )
        
        criteria_met = []
        confidence = 0.0
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æ
        if network_result and hasattr(network_result, 'async_strong_bonds'):
            async_bonds = network_result.async_strong_bonds
            
            if len(async_bonds) > 0:
                # æœ€å¼·ã®éåŒæœŸçµåˆ
                strongest_bond = max(async_bonds, key=lambda b: b.strength)
                
                # Bellä¸ç­‰å¼ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                if strongest_bond.strength > self.criteria['causality_strength']:
                    # CHSHãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®š
                    S_estimate = 2.0 + strongest_bond.strength * 0.8
                    
                    if S_estimate > self.criteria['bell_chsh_threshold']:
                        criteria_met.append(f"CHSH violation: S={S_estimate:.2f}")
                        confidence += 0.4
                        assessment.signature = QuantumSignature.INFORMATION_TRANSFER
                        assessment.bell_inequality = S_estimate
                
                # ä¼æ’­é€Ÿåº¦
                if hasattr(network_result, 'propagation_speed'):
                    expected_speed = 1.0  # æ®‹åŸº/psï¼ˆå…¸å‹å€¤ï¼‰
                    if network_result.propagation_speed > expected_speed * self.criteria['cascade_speed_factor']:
                        criteria_met.append(f"Fast propagation: {network_result.propagation_speed:.2f} residues/ps")
                        confidence += 0.3
                
                # async_bondsè¨˜éŒ²
                assessment.async_bonds_used = [
                    {
                        'residues': (b.from_res, b.to_res),
                        'strength': b.strength,
                        'lag': b.lag
                    }
                    for b in async_bonds[:5]  # ä¸Šä½5å€‹
                ]
        
        # Lambdaç•°å¸¸æ€§ã‚‚è€ƒæ…®
        if lambda_anomaly.rho_t_spike > 0:
            # ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®ä¼æ’­
            criteria_met.append(f"Tension cascade: ÏT={lambda_anomaly.rho_t_spike:.2f}")
            confidence += 0.2
        
        # åŸå­ãƒ¬ãƒ™ãƒ«è¨¼æ‹ 
        if atomic_evidence and atomic_evidence.correlation_coefficient > 0.7:
            criteria_met.append("Correlated atomic motion in cascade")
            confidence += 0.1
        
        # æœ€çµ‚åˆ¤å®š
        assessment.confidence = min(confidence, 1.0)
        assessment.is_quantum = confidence > 0.4
        assessment.criteria_met = criteria_met
        
        return assessment
    
    # ========================================
    # Explanation Generation
    # ========================================
    
    def _generate_explanation(self, assessment: QuantumAssessment) -> str:
        """åˆ¤å®šçµæœã®èª¬æ˜æ–‡ã‚’ç”Ÿæˆ"""
        if not assessment.is_quantum:
            return f"Classical {assessment.pattern.value} process with confidence {assessment.confidence:.1%}"
        
        explanations = {
            QuantumSignature.ENTANGLEMENT: "Quantum entanglement detected through instantaneous correlation",
            QuantumSignature.TUNNELING: "Quantum tunneling through energy barrier",
            QuantumSignature.COHERENCE: "Sustained quantum coherence beyond thermal decoherence time",
            QuantumSignature.PHASE_TRANSITION: "Quantum phase transition with discontinuous change",
            QuantumSignature.INFORMATION_TRANSFER: "Non-local quantum information transfer via entangled network"
        }
        
        base_explanation = explanations.get(
            assessment.signature,
            f"Quantum {assessment.pattern.value} detected"
        )
        
        return f"{base_explanation} (confidence: {assessment.confidence:.1%})"
    
    # ========================================
    # Batch Processing
    # ========================================
    
    def validate_events(self,
                        events: List[Dict],
                        lambda_result: Any,
                        network_results: Optional[List[Any]] = None) -> List[QuantumAssessment]:
        """è¤‡æ•°ã‚¤ãƒ™ãƒ³ãƒˆã®ä¸€æ‹¬å‡¦ç†"""
        assessments = []
        
        for i, event in enumerate(events):
            network = network_results[i] if network_results and i < len(network_results) else None
            
            try:
                assessment = self.validate_event(event, lambda_result, network)
                assessments.append(assessment)
            except Exception as e:
                logger.warning(f"Failed to process event {i}: {e}")
                # å¤±æ•—æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè©•ä¾¡
                assessments.append(QuantumAssessment(
                    pattern=StructuralEventPattern.INSTANTANEOUS,
                    signature=QuantumSignature.NONE,
                    is_quantum=False,
                    explanation=f"Processing failed: {e}"
                ))
        
        return assessments
    
    # ========================================
    # Summary and Reporting
    # ========================================
    
    def generate_summary(self, assessments: List[QuantumAssessment]) -> Dict:
        """è©•ä¾¡çµæœã®ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        total = len(assessments)
        quantum_count = sum(1 for a in assessments if a.is_quantum)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥é›†è¨ˆ
        pattern_stats = {}
        for pattern in StructuralEventPattern:
            count = sum(1 for a in assessments if a.pattern == pattern)
            quantum = sum(1 for a in assessments if a.pattern == pattern and a.is_quantum)
            pattern_stats[pattern.value] = {
                'total': count,
                'quantum': quantum,
                'ratio': quantum / count if count > 0 else 0
            }
        
        # ã‚·ã‚°ãƒãƒãƒ£ãƒ¼åˆ¥é›†è¨ˆ
        signature_stats = {}
        for sig in QuantumSignature:
            count = sum(1 for a in assessments if a.signature == sig)
            if count > 0:
                signature_stats[sig.value] = count
        
        # ä¿¡é ¼åº¦åˆ†å¸ƒ
        confidences = [a.confidence for a in assessments if a.is_quantum]
        
        summary = {
            'total_events': total,
            'quantum_events': quantum_count,
            'quantum_ratio': quantum_count / total if total > 0 else 0,
            'pattern_statistics': pattern_stats,
            'signature_distribution': signature_stats,
            'confidence_stats': {
                'mean': np.mean(confidences) if confidences else 0,
                'std': np.std(confidences) if confidences else 0,
                'min': np.min(confidences) if confidences else 0,
                'max': np.max(confidences) if confidences else 0
            }
        }
        
        return summary
    
    def print_summary(self, assessments: List[QuantumAssessment]):
        """ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        summary = self.generate_summary(assessments)
        
        print("\n" + "="*70)
        print("ğŸŒŒ QUANTUM VALIDATION SUMMARY v4.0")
        print("="*70)
        
        print(f"\nğŸ“Š Overall Statistics:")
        print(f"   Total events: {summary['total_events']}")
        print(f"   Quantum events: {summary['quantum_events']} ({summary['quantum_ratio']:.1%})")
        
        print(f"\nğŸ¯ Pattern Analysis:")
        for pattern, stats in summary['pattern_statistics'].items():
            if stats['total'] > 0:
                print(f"   {pattern}: {stats['quantum']}/{stats['total']} quantum ({stats['ratio']:.1%})")
        
        print(f"\nâš›ï¸ Quantum Signatures:")
        for sig, count in summary['signature_distribution'].items():
            if sig != 'classical':
                print(f"   {sig}: {count}")
        
        conf_stats = summary['confidence_stats']
        print(f"\nğŸ“ˆ Confidence Statistics:")
        print(f"   Mean: {conf_stats['mean']:.3f}")
        print(f"   Std: {conf_stats['std']:.3f}")
        print(f"   Range: [{conf_stats['min']:.3f}, {conf_stats['max']:.3f}]")

# ============================================
# Convenience Functions
# ============================================

def validate_lambda_events(lambda_result: Any,
                           trajectory: Optional[np.ndarray] = None,
                           network_results: Optional[List[Any]] = None,
                           **kwargs) -> List[QuantumAssessment]:
    """LambdaÂ³ã‚¤ãƒ™ãƒ³ãƒˆã®é‡å­æ€§ã‚’æ¤œè¨¼ã™ã‚‹ç°¡æ˜“ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    
    # ã‚¤ãƒ™ãƒ³ãƒˆæŠ½å‡º
    events = []
    if hasattr(lambda_result, 'critical_events'):
        for e in lambda_result.critical_events:
            if isinstance(e, (tuple, list)) and len(e) >= 2:
                events.append({
                    'frame_start': int(e[0]),
                    'frame_end': int(e[1]),
                    'type': 'critical'
                })
    
    # ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼ä½œæˆ
    validator = QuantumValidatorV4(trajectory=trajectory, **kwargs)
    
    # æ¤œè¨¼å®Ÿè¡Œ
    assessments = validator.validate_events(events, lambda_result, network_results)
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    validator.print_summary(assessments)
    
    return assessments

# ============================================
# Example Usage
# ============================================

if __name__ == "__main__":
    # Example: ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
    print("Quantum Validator v4.0 - Test Run")
    
    # ãƒ€ãƒŸãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ
    test_event = {
        'frame_start': 100,
        'frame_end': 100,
        'type': 'critical'
    }
    
    # ãƒ€ãƒŸãƒ¼Lambdaçµæœ
    class DummyLambdaResult:
        def __init__(self):
            self.structures = {
                'lambda_f': np.random.randn(1000),
                'rho_t': np.random.rand(1000),
                'sigma_s': np.random.rand(1000)
            }
    
    # ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼ä½œæˆ
    validator = QuantumValidatorV4(dt_ps=100.0, temperature_K=300.0)
    
    # æ¤œè¨¼å®Ÿè¡Œ
    assessment = validator.validate_event(
        test_event,
        DummyLambdaResult()
    )
    
    # çµæœè¡¨ç¤º
    print(f"\nPattern: {assessment.pattern.value}")
    print(f"Quantum: {assessment.is_quantum}")
    print(f"Signature: {assessment.signature.value}")
    print(f"Confidence: {assessment.confidence:.1%}")
    print(f"Explanation: {assessment.explanation}")
