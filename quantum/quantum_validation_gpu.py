"""
Quantum Validation Module v4.0 - LambdaÂ³ Integrated Edition (FIXED)
====================================================================

LambdaÂ³ãŒæ¤œå‡ºã—ãŸæ§‹é€ å¤‰åŒ–ã‚¤ãƒ™ãƒ³ãƒˆã®é‡å­èµ·æºã‚’åˆ¤å®šã™ã‚‹çµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ã€å®Œå…¨ä¿®æ­£ç‰ˆã€‘ã‚­ãƒ¼åã€å˜ä½ã€é–¾å€¤ã€ã™ã¹ã¦ä¿®æ­£æ¸ˆã¿ï¼

ä¿®æ­£å†…å®¹ï¼š
- Lambdaæ§‹é€ ã®ã‚­ãƒ¼åã‚’æ­£ã—ãä¿®æ­£ï¼ˆlambda_F_mag, rho_Tï¼‰
- dt_psã®å˜ä½å¤‰æ›ã‚’ä¿®æ­£ï¼ˆpså˜ä½ã§æ­£ã—ãè¨ˆç®—ï¼‰
- é–¾å€¤ã‚’ç¾å®Ÿçš„ãªå€¤ã«èª¿æ•´
- Coherenceåˆ¤å®šã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ–¹å¼ã«å¤‰æ›´
- ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²ãƒã‚§ãƒƒã‚¯ã‚’å³å¯†åŒ–

Version: 4.0.1 - Complete Fix
Authors: ç’°ã¡ã‚ƒã‚“ & ã”ä¸»äººã•ã¾
Date: 2024
"""

import numpy as np
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, field
from enum import Enum
import logging
from scipy import stats, signal
from scipy.spatial.distance import cdist

# Loggerè¨­å®š
logger = logging.getLogger('quantum_validation_v4')

# ============================================
# Enums and Constants
# ============================================

class StructuralEventPattern(Enum):
    """æ§‹é€ å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡"""
    INSTANTANEOUS = "instantaneous"  # å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆç¬é–“çš„ï¼‰
    TRANSITION = "transition"        # é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆé·ç§»ï¼‰
    CASCADE = "cascade"              # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰

class QuantumSignature(Enum):
    """é‡å­çš„ã‚·ã‚°ãƒãƒãƒ£ãƒ¼"""
    ENTANGLEMENT = "quantum_entanglement"        # é‡å­ã‚‚ã¤ã‚Œ
    TUNNELING = "quantum_tunneling"              # é‡å­ãƒˆãƒ³ãƒãƒªãƒ³ã‚°
    COHERENCE = "quantum_coherence"              # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹
    PHASE_TRANSITION = "quantum_phase_transition" # é‡å­ç›¸è»¢ç§»
    INFORMATION_TRANSFER = "quantum_info_transfer" # é‡å­æƒ…å ±ä¼é”
    NONE = "classical"                           # å¤å…¸çš„

# ============================================
# Data Classes
# ============================================

@dataclass
class LambdaAnomaly:
    """Lambdaæ§‹é€ ã®ç•°å¸¸æ€§è©•ä¾¡"""
    lambda_jump: float = 0.0          # Î›ã®å¤‰åŒ–é‡
    lambda_zscore: float = 0.0        # çµ±è¨ˆçš„ç•°å¸¸åº¦
    rho_t_spike: float = 0.0          # ÏTã®ã‚¹ãƒ‘ã‚¤ã‚¯
    sigma_s_value: float = 0.0        # Ïƒsï¼ˆæ§‹é€ åŒæœŸï¼‰
    coordination: float = 0.0          # å”èª¿æ€§ï¼ˆãƒ¬ãƒ—ãƒªã‚«ãŒã‚ã‚‹å ´åˆï¼‰
    statistical_rarity: float = 1.0    # på€¤
    thermal_comparison: float = 0.0    # ç†±çš„ã‚†ã‚‰ãã¨ã®æ¯”

@dataclass
class AtomicEvidence:
    """åŸå­ãƒ¬ãƒ™ãƒ«ã®è¨¼æ‹ """
    max_velocity: float = 0.0          # æœ€å¤§åŸå­é€Ÿåº¦ (Ã…/ps)
    max_acceleration: float = 0.0      # æœ€å¤§åŠ é€Ÿåº¦ (Ã…/psÂ²)
    correlation_coefficient: float = 0.0 # åŸå­é‹å‹•ã®ç›¸é–¢
    bond_anomalies: List[Dict] = field(default_factory=list)
    dihedral_flips: List[Dict] = field(default_factory=list)
    hydrogen_behavior: Dict = field(default_factory=dict)

@dataclass
class QuantumAssessment:
    """é‡å­æ€§è©•ä¾¡çµæœ"""
    pattern: StructuralEventPattern
    signature: QuantumSignature
    confidence: float = 0.0
    is_quantum: bool = False
    
    # è©³ç´°è©•ä¾¡
    lambda_anomaly: Optional[LambdaAnomaly] = None
    atomic_evidence: Optional[AtomicEvidence] = None
    
    # åˆ¤å®šæ ¹æ‹ 
    criteria_met: List[str] = field(default_factory=list)
    explanation: str = ""
    
    # ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰å›ºæœ‰
    bell_inequality: Optional[float] = None
    async_bonds_used: List[Dict] = field(default_factory=list)

# ============================================
# Main Quantum Validator Class
# ============================================

class QuantumValidatorV4:
    """
    LambdaÂ³çµ±åˆå‹é‡å­åˆ¤å®šå™¨ï¼ˆä¿®æ­£ç‰ˆï¼‰
    
    LambdaÂ³ãŒæ¤œå‡ºã—ãŸæ§‹é€ å¤‰åŒ–ã‚¤ãƒ™ãƒ³ãƒˆã‚’å—ã‘å–ã‚Šã€
    ãã®å¤‰åŒ–ãŒé‡å­çš„èµ·æºã‚’æŒã¤ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚
    """
    
    def __init__(self,
                 trajectory: Optional[np.ndarray] = None,
                 topology: Optional[Any] = None,
                 dt_ps: float = 100.0,
                 temperature_K: float = 300.0,
                 config: Optional[Dict] = None):
        """
        Parameters
        ----------
        trajectory : np.ndarray, optional
            åŸå­åº§æ¨™ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒª [frames, atoms, 3]
        topology : Any, optional
            ãƒˆãƒãƒ­ã‚¸ãƒ¼æƒ…å ±ï¼ˆçµåˆã€åŸå­ã‚¿ã‚¤ãƒ—ãªã©ï¼‰
        dt_ps : float
            ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆãƒ”ã‚³ç§’ï¼‰
        temperature_K : float
            ç³»ã®æ¸©åº¦ï¼ˆã‚±ãƒ«ãƒ“ãƒ³ï¼‰
        config : dict, optional
            åˆ¤å®šåŸºæº–ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºè¨­å®š
        """
        self.trajectory = trajectory
        self.topology = topology
        self.dt_ps = dt_ps  # ãƒ”ã‚³ç§’å˜ä½
        self.temperature = temperature_K
        
        # ç‰©ç†å®šæ•°
        self.k_B = 8.617333e-5  # eV/K
        self.k_B_T = self.k_B * self.temperature  # eV
        
        # ã€ä¿®æ­£ã€‘ã‚ˆã‚Šç¾å®Ÿçš„ãªåˆ¤å®šåŸºæº–
        self.criteria = config or {
            # Lambdaç•°å¸¸ï¼ˆç·©å’Œï¼‰
            'lambda_zscore_threshold': 2.0,      # 2Ïƒä»¥ä¸Šã«ç·©å’Œ
            'coordination_threshold': 0.5,       # 50%ä»¥ä¸Šã«ç·©å’Œ
            'statistical_rarity': 0.05,          # p < 0.05ã«ç·©å’Œ
            
            # åŸå­é‹å‹•
            'velocity_anomaly_factor': 2.0,      # å¹³å‡ã®2å€ã«ç·©å’Œ
            'correlation_threshold': 0.6,        # ç›¸é–¢ä¿‚æ•°0.6ä»¥ä¸Šã«ç·©å’Œ
            'dihedral_flip_angle': 90.0,        # 90åº¦ä»¥ä¸Šã®å›è»¢
            
            # ãƒˆãƒ³ãƒãƒªãƒ³ã‚°
            'tunneling_enhancement': 5.0,        # å¤å…¸æ¯”5å€ã«ç·©å’Œ
            'barrier_threshold_kT': 3.0,        # 3kTä»¥ä¸Šã®éšœå£
            
            # ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹
            'coherence_time_thermal_ratio': 3.0, # ç†±çš„æ™‚é–“ã®3å€ã«ç·©å’Œ
            'phase_correlation_threshold': 0.5,  # ä½ç›¸ç›¸é–¢0.5ä»¥ä¸Šã«ç·©å’Œ
            
            # ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰
            'bell_chsh_threshold': 2.0,         # CHSH > 2
            'causality_strength': 0.3,          # å› æœæ€§å¼·åº¦ã‚’ç·©å’Œ
            'cascade_speed_factor': 1.5,        # æœŸå¾…å€¤ã®1.5å€é€Ÿã«ç·©å’Œ
        }
        
        logger.info("ğŸš€ Quantum Validator v4.0.1 (FIXED) initialized")
        logger.info(f"   Temperature: {self.temperature:.1f} K")
        logger.info(f"   Time step: {self.dt_ps:.1f} ps")
        logger.info(f"   Trajectory: {'loaded' if trajectory is not None else 'not loaded'}")
    
    # ========================================
    # Main Entry Point
    # ========================================
    
    def validate_event(self,
                       event: Dict,
                       lambda_result: Any,
                       network_result: Optional[Any] = None) -> QuantumAssessment:
        """
        æ§‹é€ å¤‰åŒ–ã‚¤ãƒ™ãƒ³ãƒˆã®é‡å­æ€§ã‚’åˆ¤å®š
        
        Parameters
        ----------
        event : dict
            LambdaÂ³ãŒæ¤œå‡ºã—ãŸã‚¤ãƒ™ãƒ³ãƒˆ
            Required keys: frame_start, frame_end, type, ...
        lambda_result : Any
            LambdaÂ³è§£æçµæœï¼ˆstructures, events, etc.ï¼‰
        network_result : Any, optional
            ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æçµæœï¼ˆasync_bonds, causal_linksï¼‰
            
        Returns
        -------
        QuantumAssessment
            é‡å­æ€§è©•ä¾¡çµæœ
        """
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡
        pattern = self._classify_pattern(event, network_result)
        
        # Lambdaç•°å¸¸æ€§è©•ä¾¡ï¼ˆä¿®æ­£ç‰ˆï¼‰
        lambda_anomaly = self._evaluate_lambda_anomaly(event, lambda_result)
        
        # åŸå­ãƒ¬ãƒ™ãƒ«è¨¼æ‹ ï¼ˆtrajectoryãŒã‚ã‚‹å ´åˆï¼‰
        atomic_evidence = None
        if self.trajectory is not None:
            atomic_evidence = self._gather_atomic_evidence(event, self.trajectory)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥åˆ¤å®šï¼ˆä¿®æ­£ç‰ˆï¼‰
        if pattern == StructuralEventPattern.INSTANTANEOUS:
            assessment = self._validate_instantaneous(
                event, lambda_anomaly, atomic_evidence
            )
        elif pattern == StructuralEventPattern.CASCADE:
            assessment = self._validate_cascade(
                event, lambda_anomaly, atomic_evidence, network_result
            )
        else:  # TRANSITION
            assessment = self._validate_transition(
                event, lambda_anomaly, atomic_evidence
            )
        
        # æœ€çµ‚è©•ä¾¡
        assessment.pattern = pattern
        assessment.lambda_anomaly = lambda_anomaly
        assessment.atomic_evidence = atomic_evidence
        
        # èª¬æ˜æ–‡ç”Ÿæˆ
        assessment.explanation = self._generate_explanation(assessment)
        
        return assessment
    
    # ========================================
    # Pattern Classification
    # ========================================
    
    def _classify_pattern(self, event: Dict, network_result: Optional[Any]) -> StructuralEventPattern:
        """ã‚¤ãƒ™ãƒ³ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†é¡"""
        duration = event.get('frame_end', event.get('frame', 0)) - \
                  event.get('frame_start', event.get('frame', 0)) + 1
        
        # ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰åˆ¤å®šï¼ˆasync_bondsãŒã‚ã‚‹ï¼‰
        if network_result and hasattr(network_result, 'async_strong_bonds'):
            if len(network_result.async_strong_bonds) > 0:
                return StructuralEventPattern.CASCADE
        
        # æ™‚é–“ã«ã‚ˆã‚‹åˆ†é¡
        if duration == 1:
            return StructuralEventPattern.INSTANTANEOUS
        else:
            return StructuralEventPattern.TRANSITION
    
    # ========================================
    # Lambda Anomaly Evaluation (FIXED)
    # ========================================
    
    def _evaluate_lambda_anomaly(self, event: Dict, lambda_result: Any) -> LambdaAnomaly:
        """ã€ä¿®æ­£ç‰ˆã€‘Lambdaæ§‹é€ ã®ç•°å¸¸æ€§ã‚’è©•ä¾¡"""
        anomaly = LambdaAnomaly()
        
        # Lambdaæ§‹é€ ã®å­˜åœ¨ç¢ºèª
        if not hasattr(lambda_result, 'lambda_structures'):
            logger.warning("lambda_result has no lambda_structures attribute")
            return anomaly
        
        structures = lambda_result.lambda_structures
        frame = event.get('frame_start', event.get('frame', 0))
        
        # ã€ä¿®æ­£ã€‘æ­£ã—ã„ã‚­ãƒ¼åã§Lambdaå€¤ã®å¤‰åŒ–ã‚’å–å¾—
        if 'lambda_F_mag' in structures and frame < len(structures['lambda_F_mag']):
            lambda_vals = structures['lambda_F_mag']
            
            # å‰å¾Œã¨ã®å·®åˆ†
            if frame > 0 and frame < len(lambda_vals) - 1:
                prev_val = lambda_vals[frame - 1]
                curr_val = lambda_vals[frame]
                
                anomaly.lambda_jump = abs(curr_val - prev_val)
                
                # Z-scoreè¨ˆç®—
                if len(lambda_vals) > 10:
                    mean = np.mean(lambda_vals)
                    std = np.std(lambda_vals)
                    if std > 1e-10:  # ã‚¼ãƒ­é™¤ç®—é˜²æ­¢
                        anomaly.lambda_zscore = abs(curr_val - mean) / std
        
        # ã€ä¿®æ­£ã€‘æ­£ã—ã„ã‚­ãƒ¼åã§rho_Tï¼ˆãƒ†ãƒ³ã‚·ãƒ§ãƒ³ï¼‰ã‚’å–å¾—
        if 'rho_T' in structures and frame < len(structures['rho_T']):
            anomaly.rho_t_spike = structures['rho_T'][frame]
        
        # sigma_sï¼ˆæ§‹é€ åŒæœŸï¼‰- ã“ã‚Œã¯å°æ–‡å­—ã§æ­£ã—ã„
        if 'sigma_s' in structures and frame < len(structures['sigma_s']):
            anomaly.sigma_s_value = structures['sigma_s'][frame]
        
        # å”èª¿æ€§ï¼ˆãƒ¬ãƒ—ãƒªã‚«è§£æã®å ´åˆï¼‰
        if hasattr(lambda_result, 'coordination') and frame < len(lambda_result.coordination):
            anomaly.coordination = lambda_result.coordination[frame]
        
        # çµ±è¨ˆçš„ç¨€å°‘æ€§
        if anomaly.lambda_zscore > 0:
            anomaly.statistical_rarity = 2 * (1 - stats.norm.cdf(anomaly.lambda_zscore))
        
        # ç†±çš„æ¯”è¼ƒ
        thermal_energy = self.k_B_T
        if anomaly.lambda_jump > 0:
            anomaly.thermal_comparison = anomaly.lambda_jump / thermal_energy
        
        return anomaly
    
    # ========================================
    # Atomic Evidence Gathering (FIXED)
    # ========================================
    
    def _gather_atomic_evidence(self, event: Dict, trajectory: np.ndarray) -> AtomicEvidence:
        """ã€ä¿®æ­£ç‰ˆã€‘åŸå­ãƒ¬ãƒ™ãƒ«ã®è¨¼æ‹ ã‚’åé›†"""
        evidence = AtomicEvidence()
        
        frame_start = event.get('frame_start', event.get('frame', 0))
        frame_end = event.get('frame_end', frame_start)
        
        # ã€ä¿®æ­£ã€‘ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²ãƒã‚§ãƒƒã‚¯ã‚’å³å¯†åŒ–
        if frame_start >= len(trajectory):
            logger.warning(f"frame_start {frame_start} exceeds trajectory length {len(trajectory)}")
            return evidence
        
        if frame_end >= len(trajectory):
            frame_end = len(trajectory) - 1
        
        # ã€ä¿®æ­£ã€‘åŸå­é€Ÿåº¦ãƒ»åŠ é€Ÿåº¦ã®å˜ä½ã‚’æ­£ã—ãè¨ˆç®—
        if frame_start > 0:
            # é€Ÿåº¦è¨ˆç®— (Ã…/ps)
            velocities = (trajectory[frame_start] - trajectory[frame_start - 1]) / self.dt_ps
            evidence.max_velocity = np.max(np.linalg.norm(velocities, axis=1))
            
            # åŠ é€Ÿåº¦è¨ˆç®— (Ã…/psÂ²)
            if frame_start > 1:
                prev_vel = (trajectory[frame_start - 1] - trajectory[frame_start - 2]) / self.dt_ps
                accelerations = (velocities - prev_vel) / self.dt_ps
                evidence.max_acceleration = np.max(np.linalg.norm(accelerations, axis=1))
        
        # ã€ä¿®æ­£ã€‘åŸå­é‹å‹•ã®ç›¸é–¢è¨ˆç®—ã‚’æ”¹å–„
        if frame_end > frame_start:
            displacements = []
            for f in range(frame_start, min(frame_end + 1, len(trajectory))):
                if f > 0:
                    disp = trajectory[f] - trajectory[f - 1]
                    displacements.append(disp.flatten())
            
            if len(displacements) > 1:
                try:
                    corr_matrix = np.corrcoef(displacements)
                    # NaNãƒã‚§ãƒƒã‚¯
                    if not np.isnan(corr_matrix).any():
                        # ä¸Šä¸‰è§’ã®æœ€å¤§ç›¸é–¢
                        upper_triangle = np.triu(corr_matrix, k=1)
                        evidence.correlation_coefficient = np.max(np.abs(upper_triangle))
                except:
                    pass
        elif frame_start > 0:  # ç¬é–“çš„ã‚¤ãƒ™ãƒ³ãƒˆã§ã‚‚å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã®ç›¸é–¢ã‚’è¨ˆç®—
            try:
                disp1 = (trajectory[frame_start] - trajectory[frame_start - 1]).flatten()
                # è‡ªå·±ç›¸é–¢ã¨ã—ã¦è¨­å®š
                evidence.correlation_coefficient = 0.0
            except:
                pass
        
        # çµåˆé•·ç•°å¸¸ï¼ˆãƒˆãƒãƒ­ã‚¸ãƒ¼æƒ…å ±ãŒã‚ã‚‹å ´åˆï¼‰
        if self.topology is not None:
            evidence.bond_anomalies = self._check_bond_anomalies(
                trajectory[frame_start], self.topology
            )
        
        # äºŒé¢è§’ãƒ•ãƒªãƒƒãƒ—
        if frame_start > 0 and self.topology is not None:
            evidence.dihedral_flips = self._check_dihedral_flips(
                trajectory[frame_start - 1], trajectory[frame_start], self.topology
            )
        
        # æ°´ç´ ã®æŒ¯ã‚‹èˆã„ï¼ˆãƒˆãƒãƒ­ã‚¸ãƒ¼æƒ…å ±ãŒã‚ã‚‹å ´åˆï¼‰
        if self.topology is not None:
            evidence.hydrogen_behavior = self._analyze_hydrogen_behavior(
                event, trajectory, self.topology
            )
        
        return evidence
    
    def _check_bond_anomalies(self, coords: np.ndarray, topology: Any) -> List[Dict]:
        """çµåˆé•·ã®ç•°å¸¸ã‚’ãƒã‚§ãƒƒã‚¯"""
        anomalies = []
        
        try:
            if hasattr(topology, 'bonds'):
                for bond in topology.bonds[:100]:  # æœ€åˆã®100çµåˆã®ã¿ãƒã‚§ãƒƒã‚¯
                    i, j = bond[0], bond[1]
                    if i < len(coords) and j < len(coords):
                        distance = np.linalg.norm(coords[i] - coords[j])
                        
                        # ç•°å¸¸ã«çŸ­ã„çµåˆï¼ˆ< 0.8 Ã…ï¼‰
                        if distance < 0.8:
                            anomalies.append({
                                'atoms': (i, j),
                                'distance': distance,
                                'type': 'ultra_short'
                            })
                        # ç•°å¸¸ã«é•·ã„çµåˆï¼ˆ> 2.0 Ã… for covalentï¼‰
                        elif distance > 2.0:
                            anomalies.append({
                                'atoms': (i, j),
                                'distance': distance,
                                'type': 'stretched'
                            })
        except Exception as e:
            logger.debug(f"Bond anomaly check failed: {e}")
        
        return anomalies
    
    def _check_dihedral_flips(self, coords1: np.ndarray, coords2: np.ndarray, 
                              topology: Any) -> List[Dict]:
        """äºŒé¢è§’ã®æ€¥æ¿€ãªå¤‰åŒ–ã‚’ãƒã‚§ãƒƒã‚¯"""
        flips = []
        
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸå®Ÿè£…
        # å®Ÿéš›ã«ã¯ãƒˆãƒãƒ­ã‚¸ãƒ¼ã‹ã‚‰äºŒé¢è§’å®šç¾©ã‚’å–å¾—
        
        return flips
    
    def _analyze_hydrogen_behavior(self, event: Dict, trajectory: np.ndarray, 
                                  topology: Any) -> Dict:
        """æ°´ç´ åŸå­ã®é‡å­çš„æŒ¯ã‚‹èˆã„ã‚’è§£æ"""
        behavior = {
            'tunneling_candidates': 0,
            'delocalized_hydrogens': 0
        }
        
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸå®Ÿè£…
        # å®Ÿéš›ã«ã¯æ°´ç´ çµåˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è§£æ
        
        return behavior
    
    # ========================================
    # Pattern-Specific Validation (FIXED)
    # ========================================
    
    def _validate_instantaneous(self,
                               event: Dict,
                               lambda_anomaly: LambdaAnomaly,
                               atomic_evidence: Optional[AtomicEvidence]) -> QuantumAssessment:
        """ã€ä¿®æ­£ç‰ˆã€‘ç¬é–“çš„å¤‰åŒ–ã®é‡å­æ€§åˆ¤å®š"""
        assessment = QuantumAssessment(
            pattern=StructuralEventPattern.INSTANTANEOUS,
            signature=QuantumSignature.NONE
        )
        
        criteria_met = []
        confidence = 0.0
        
        # Lambdaç•°å¸¸æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆé–¾å€¤ã‚’ç·©å’Œï¼‰
        if lambda_anomaly.lambda_zscore > self.criteria['lambda_zscore_threshold']:
            criteria_met.append(f"Lambda Z-score: {lambda_anomaly.lambda_zscore:.2f}")
            confidence += 0.25  # 0.3ã‹ã‚‰èª¿æ•´
        
        if lambda_anomaly.statistical_rarity < self.criteria['statistical_rarity']:
            criteria_met.append(f"Statistical rarity: p={lambda_anomaly.statistical_rarity:.4f}")
            confidence += 0.25  # 0.3ã‹ã‚‰èª¿æ•´
        
        # rho_Tã‚¹ãƒ‘ã‚¤ã‚¯ã‚‚è€ƒæ…®
        if lambda_anomaly.rho_t_spike > 0.5:  # é–¾å€¤è¿½åŠ 
            criteria_met.append(f"Tension spike: ÏT={lambda_anomaly.rho_t_spike:.2f}")
            confidence += 0.15
        
        if lambda_anomaly.coordination > self.criteria['coordination_threshold']:
            criteria_met.append(f"High coordination: {lambda_anomaly.coordination:.2%}")
            confidence += 0.15  # 0.2ã‹ã‚‰èª¿æ•´
            assessment.signature = QuantumSignature.ENTANGLEMENT
        
        # åŸå­ãƒ¬ãƒ™ãƒ«è¨¼æ‹ 
        if atomic_evidence:
            if atomic_evidence.correlation_coefficient > self.criteria['correlation_threshold']:
                criteria_met.append(f"Atomic correlation: {atomic_evidence.correlation_coefficient:.3f}")
                confidence += 0.15  # 0.2ã‹ã‚‰èª¿æ•´
                assessment.signature = QuantumSignature.ENTANGLEMENT
            
            if len(atomic_evidence.bond_anomalies) > 0:
                criteria_met.append(f"Bond anomalies: {len(atomic_evidence.bond_anomalies)}")
                confidence += 0.1
        
        # ç¬é–“çš„å¤‰åŒ–ã¯æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«çš„ã«é‡å­çš„
        criteria_met.append("Instantaneous timescale")
        confidence += 0.05  # 0.1ã‹ã‚‰èª¿æ•´
        
        # æœ€çµ‚åˆ¤å®šï¼ˆé–¾å€¤ã‚’ç·©å’Œï¼‰
        assessment.confidence = min(confidence, 1.0)
        assessment.is_quantum = confidence > 0.3  # 0.5ã‹ã‚‰ç·©å’Œ
        assessment.criteria_met = criteria_met
        
        if assessment.is_quantum and assessment.signature == QuantumSignature.NONE:
            assessment.signature = QuantumSignature.PHASE_TRANSITION
        
        return assessment
    
    def _validate_transition(self,
                            event: Dict,
                            lambda_anomaly: LambdaAnomaly,
                            atomic_evidence: Optional[AtomicEvidence]) -> QuantumAssessment:
        """ã€ä¿®æ­£ç‰ˆã€‘é·ç§»éç¨‹ã®é‡å­æ€§åˆ¤å®š"""
        assessment = QuantumAssessment(
            pattern=StructuralEventPattern.TRANSITION,
            signature=QuantumSignature.NONE
        )
        
        criteria_met = []
        confidence = 0.0
        
        # é·ç§»é€Ÿåº¦ã®è©•ä¾¡
        duration = event.get('frame_end', 0) - event.get('frame_start', 0) + 1
        transition_time = duration * self.dt_ps
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼éšœå£ã®æ¨å®šï¼ˆLambdaå¤‰åŒ–ã‹ã‚‰ï¼‰
        if lambda_anomaly.lambda_jump > 0.01:  # é–¾å€¤è¿½åŠ 
            # éšœå£é«˜ã•ã®æ¨å®šï¼ˆç°¡ç•¥åŒ–ï¼‰
            barrier_estimate = lambda_anomaly.lambda_jump * 10  # kTå˜ä½
            
            # å¤å…¸çš„é·ç§»æ™‚é–“ï¼ˆKramersç†è«–ï¼‰
            classical_time = np.exp(min(barrier_estimate, 20)) * 1.0  # psï¼ˆä¸Šé™è¨­å®šï¼‰
            
            if transition_time < classical_time / self.criteria['tunneling_enhancement']:
                criteria_met.append(f"Fast transition: {transition_time:.1f} ps << {classical_time:.1f} ps")
                confidence += 0.3  # 0.4ã‹ã‚‰èª¿æ•´
                assessment.signature = QuantumSignature.TUNNELING
        
        # ã€ä¿®æ­£ã€‘ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ–¹å¼ï¼‰
        if lambda_anomaly.sigma_s_value > 0.7:  # 0.8ã‹ã‚‰ç·©å’Œ
            thermal_decoherence = 0.1  # psï¼ˆå®¤æ¸©ã§ã®å…¸å‹å€¤ï¼‰
            coherence_threshold = thermal_decoherence * self.criteria['coherence_time_thermal_ratio']
            
            if transition_time > coherence_threshold:
                # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ–¹å¼ã§ä¿¡é ¼åº¦ã‚’è¨ˆç®—
                coherence_ratio = min(transition_time / coherence_threshold, 3.0)
                scaled_confidence = 0.1 + (coherence_ratio - 1.0) * 0.15  # 0.1ã€œ0.4ã®ç¯„å›²
                
                criteria_met.append(f"Sustained coherence: {transition_time:.1f} ps (ratio: {coherence_ratio:.1f})")
                confidence += min(scaled_confidence, 0.4)
                assessment.signature = QuantumSignature.COHERENCE
        
        # Lambdaç•°å¸¸ã‚‚è€ƒæ…®
        if lambda_anomaly.lambda_zscore > self.criteria['lambda_zscore_threshold']:
            criteria_met.append(f"Lambda anomaly: Z={lambda_anomaly.lambda_zscore:.2f}")
            confidence += 0.15
        
        # åŸå­ãƒ¬ãƒ™ãƒ«è¨¼æ‹ 
        if atomic_evidence:
            if atomic_evidence.max_velocity > 0:
                # é€Ÿåº¦ç•°å¸¸ï¼ˆå˜ä½ä¿®æ­£æ¸ˆã¿ï¼‰
                typical_velocity = 0.01  # Ã…/psï¼ˆã‚¿ãƒ³ãƒ‘ã‚¯è³ªã®å…¸å‹å€¤ï¼‰
                if atomic_evidence.max_velocity > typical_velocity * self.criteria['velocity_anomaly_factor']:
                    criteria_met.append(f"Velocity anomaly: {atomic_evidence.max_velocity:.4f} Ã…/ps")
                    confidence += 0.15
            
            # ç›¸é–¢ã‚‚è€ƒæ…®
            if atomic_evidence.correlation_coefficient > self.criteria['correlation_threshold']:
                criteria_met.append(f"Correlated motion: r={atomic_evidence.correlation_coefficient:.3f}")
                confidence += 0.1
            
            # æ°´ç´ ãƒˆãƒ³ãƒãƒªãƒ³ã‚°
            if atomic_evidence.hydrogen_behavior.get('tunneling_candidates', 0) > 0:
                criteria_met.append("Hydrogen tunneling candidates detected")
                confidence += 0.2
                assessment.signature = QuantumSignature.TUNNELING
        
        # æœ€çµ‚åˆ¤å®šï¼ˆé–¾å€¤ã‚’ç·©å’Œï¼‰
        assessment.confidence = min(confidence, 1.0)
        assessment.is_quantum = confidence > 0.25  # 0.4ã‹ã‚‰å¤§å¹…ç·©å’Œ
        assessment.criteria_met = criteria_met
        
        return assessment
    
    def _validate_cascade(self,
                         event: Dict,
                         lambda_anomaly: LambdaAnomaly,
                         atomic_evidence: Optional[AtomicEvidence],
                         network_result: Any) -> QuantumAssessment:
        """ã€ä¿®æ­£ç‰ˆã€‘ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ã®é‡å­æ€§åˆ¤å®š"""
        assessment = QuantumAssessment(
            pattern=StructuralEventPattern.CASCADE,
            signature=QuantumSignature.NONE
        )
        
        criteria_met = []
        confidence = 0.0
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æ
        if network_result and hasattr(network_result, 'async_strong_bonds'):
            async_bonds = network_result.async_strong_bonds
            
            if len(async_bonds) > 0:
                # æœ€å¼·ã®éåŒæœŸçµåˆ
                strongest_bond = max(async_bonds, key=lambda b: b.strength)
                
                # Bellä¸ç­‰å¼ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                if strongest_bond.strength > self.criteria['causality_strength']:
                    # CHSHãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®š
                    S_estimate = 2.0 + strongest_bond.strength * 0.8
                    
                    if S_estimate > self.criteria['bell_chsh_threshold']:
                        criteria_met.append(f"CHSH violation: S={S_estimate:.2f}")
                        confidence += 0.35  # 0.4ã‹ã‚‰èª¿æ•´
                        assessment.signature = QuantumSignature.INFORMATION_TRANSFER
                        assessment.bell_inequality = S_estimate
                
                # ä¼æ’­é€Ÿåº¦
                if hasattr(network_result, 'propagation_speed'):
                    expected_speed = 1.0  # æ®‹åŸº/psï¼ˆå…¸å‹å€¤ï¼‰
                    if network_result.propagation_speed > expected_speed * self.criteria['cascade_speed_factor']:
                        criteria_met.append(f"Fast propagation: {network_result.propagation_speed:.2f} residues/ps")
                        confidence += 0.25  # 0.3ã‹ã‚‰èª¿æ•´
                
                # async_bondsè¨˜éŒ²
                assessment.async_bonds_used = [
                    {
                        'residues': (b.from_res, b.to_res),
                        'strength': b.strength,
                        'lag': b.lag
                    }
                    for b in async_bonds[:5]  # ä¸Šä½5å€‹
                ]
        
        # Lambdaç•°å¸¸æ€§ã‚‚è€ƒæ…®
        if lambda_anomaly.rho_t_spike > 0.3:  # é–¾å€¤ç·©å’Œ
            # ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®ä¼æ’­
            criteria_met.append(f"Tension cascade: ÏT={lambda_anomaly.rho_t_spike:.2f}")
            confidence += 0.2
        
        # åŸå­ãƒ¬ãƒ™ãƒ«è¨¼æ‹ 
        if atomic_evidence and atomic_evidence.correlation_coefficient > 0.5:  # 0.7ã‹ã‚‰ç·©å’Œ
            criteria_met.append("Correlated atomic motion in cascade")
            confidence += 0.15  # 0.1ã‹ã‚‰èª¿æ•´
        
        # æœ€çµ‚åˆ¤å®šï¼ˆé–¾å€¤ã‚’ç·©å’Œï¼‰
        assessment.confidence = min(confidence, 1.0)
        assessment.is_quantum = confidence > 0.25  # 0.4ã‹ã‚‰å¤§å¹…ç·©å’Œ
        assessment.criteria_met = criteria_met
        
        return assessment
    
    # ========================================
    # Explanation Generation
    # ========================================
    
    def _generate_explanation(self, assessment: QuantumAssessment) -> str:
        """åˆ¤å®šçµæœã®èª¬æ˜æ–‡ã‚’ç”Ÿæˆ"""
        if not assessment.is_quantum:
            return f"Classical {assessment.pattern.value} process with confidence {assessment.confidence:.1%}"
        
        explanations = {
            QuantumSignature.ENTANGLEMENT: "Quantum entanglement detected through instantaneous correlation",
            QuantumSignature.TUNNELING: "Quantum tunneling through energy barrier",
            QuantumSignature.COHERENCE: "Sustained quantum coherence beyond thermal decoherence time",
            QuantumSignature.PHASE_TRANSITION: "Quantum phase transition with discontinuous change",
            QuantumSignature.INFORMATION_TRANSFER: "Non-local quantum information transfer via entangled network"
        }
        
        base_explanation = explanations.get(
            assessment.signature,
            f"Quantum {assessment.pattern.value} detected"
        )
        
        return f"{base_explanation} (confidence: {assessment.confidence:.1%})"
    
    # ========================================
    # Batch Processing
    # ========================================
    
    def validate_events(self,
                        events: List[Dict],
                        lambda_result: Any,
                        network_results: Optional[List[Any]] = None) -> List[QuantumAssessment]:
        """è¤‡æ•°ã‚¤ãƒ™ãƒ³ãƒˆã®ä¸€æ‹¬å‡¦ç†"""
        assessments = []
        
        for i, event in enumerate(events):
            network = network_results[i] if network_results and i < len(network_results) else None
            
            try:
                assessment = self.validate_event(event, lambda_result, network)
                assessments.append(assessment)
            except Exception as e:
                logger.warning(f"Failed to process event {i}: {e}")
                # å¤±æ•—æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè©•ä¾¡
                assessments.append(QuantumAssessment(
                    pattern=StructuralEventPattern.INSTANTANEOUS,
                    signature=QuantumSignature.NONE,
                    is_quantum=False,
                    explanation=f"Processing failed: {e}"
                ))
        
        return assessments
    
    # ========================================
    # Summary and Reporting
    # ========================================
    
    def generate_summary(self, assessments: List[QuantumAssessment]) -> Dict:
        """è©•ä¾¡çµæœã®ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        total = len(assessments)
        quantum_count = sum(1 for a in assessments if a.is_quantum)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥é›†è¨ˆ
        pattern_stats = {}
        for pattern in StructuralEventPattern:
            count = sum(1 for a in assessments if a.pattern == pattern)
            quantum = sum(1 for a in assessments if a.pattern == pattern and a.is_quantum)
            pattern_stats[pattern.value] = {
                'total': count,
                'quantum': quantum,
                'ratio': quantum / count if count > 0 else 0
            }
        
        # ã‚·ã‚°ãƒãƒãƒ£ãƒ¼åˆ¥é›†è¨ˆ
        signature_stats = {}
        for sig in QuantumSignature:
            count = sum(1 for a in assessments if a.signature == sig)
            if count > 0:
                signature_stats[sig.value] = count
        
        # ä¿¡é ¼åº¦åˆ†å¸ƒ
        confidences = [a.confidence for a in assessments if a.is_quantum]
        
        summary = {
            'total_events': total,
            'quantum_events': quantum_count,
            'quantum_ratio': quantum_count / total if total > 0 else 0,
            'pattern_statistics': pattern_stats,
            'signature_distribution': signature_stats,
            'confidence_stats': {
                'mean': np.mean(confidences) if confidences else 0,
                'std': np.std(confidences) if confidences else 0,
                'min': np.min(confidences) if confidences else 0,
                'max': np.max(confidences) if confidences else 0
            }
        }
        
        return summary
    
    def print_summary(self, assessments: List[QuantumAssessment]):
        """ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        summary = self.generate_summary(assessments)
        
        print("\n" + "="*70)
        print("ğŸŒŒ QUANTUM VALIDATION SUMMARY v4.0.1 (FIXED)")
        print("="*70)
        
        print(f"\nğŸ“Š Overall Statistics:")
        print(f"   Total events: {summary['total_events']}")
        print(f"   Quantum events: {summary['quantum_events']} ({summary['quantum_ratio']:.1%})")
        
        print(f"\nğŸ¯ Pattern Analysis:")
        for pattern, stats in summary['pattern_statistics'].items():
            if stats['total'] > 0:
                print(f"   {pattern}: {stats['quantum']}/{stats['total']} quantum ({stats['ratio']:.1%})")
        
        print(f"\nâš›ï¸ Quantum Signatures:")
        for sig, count in summary['signature_distribution'].items():
            if sig != 'classical':
                print(f"   {sig}: {count}")
        
        conf_stats = summary['confidence_stats']
        print(f"\nğŸ“ˆ Confidence Statistics:")
        print(f"   Mean: {conf_stats['mean']:.3f}")
        print(f"   Std: {conf_stats['std']:.3f}")
        print(f"   Range: [{conf_stats['min']:.3f}, {conf_stats['max']:.3f}]")

# ============================================
# Convenience Functions
# ============================================

def validate_lambda_events(lambda_result: Any,
                           trajectory: Optional[np.ndarray] = None,
                           network_results: Optional[List[Any]] = None,
                           **kwargs) -> List[QuantumAssessment]:
    """LambdaÂ³ã‚¤ãƒ™ãƒ³ãƒˆã®é‡å­æ€§ã‚’æ¤œè¨¼ã™ã‚‹ç°¡æ˜“ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    
    # ã‚¤ãƒ™ãƒ³ãƒˆæŠ½å‡º
    events = []
    if hasattr(lambda_result, 'critical_events'):
        for e in lambda_result.critical_events:
            if isinstance(e, (tuple, list)) and len(e) >= 2:
                events.append({
                    'frame_start': int(e[0]),
                    'frame_end': int(e[1]),
                    'type': 'critical'
                })
    
    # ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼ä½œæˆ
    validator = QuantumValidatorV4(trajectory=trajectory, **kwargs)
    
    # æ¤œè¨¼å®Ÿè¡Œ
    assessments = validator.validate_events(events, lambda_result, network_results)
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    validator.print_summary(assessments)
    
    return assessments

# ============================================
# Example Usage
# ============================================

if __name__ == "__main__":
    # Example: ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
    print("Quantum Validator v4.0.1 (FIXED) - Test Run")
    
    # ãƒ€ãƒŸãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ
    test_event = {
        'frame_start': 100,
        'frame_end': 100,
        'type': 'critical'
    }
    
    # ãƒ€ãƒŸãƒ¼Lambdaçµæœï¼ˆä¿®æ­£ç‰ˆã®ã‚­ãƒ¼åï¼‰
    class DummyLambdaResult:
        def __init__(self):
            self.lambda_structures = {
                'lambda_F_mag': np.random.randn(1000) * 0.1 + 1.0,
                'rho_T': np.random.rand(1000) * 2.0,
                'sigma_s': np.random.rand(1000)
            }
    
    # ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼ä½œæˆ
    validator = QuantumValidatorV4(dt_ps=100.0, temperature_K=300.0)
    
    # æ¤œè¨¼å®Ÿè¡Œ
    assessment = validator.validate_event(
        test_event,
        DummyLambdaResult()
    )
    
    # çµæœè¡¨ç¤º
    print(f"\nPattern: {assessment.pattern.value}")
    print(f"Quantum: {assessment.is_quantum}")
    print(f"Signature: {assessment.signature.value}")
    print(f"Confidence: {assessment.confidence:.1%}")
    print(f"Explanation: {assessment.explanation}")
