"""
Quantum Validation Module v5.0 - Simplified Three-Axis Edition
===============================================================

LambdaÂ³æ§‹é€ å¤‰åŒ–ã‚¤ãƒ™ãƒ³ãƒˆã®é‡å­æ€§ã‚’3è»¸ã§åˆ¤å®šï¼š
1. ç©ºé–“çš„ç•°å¸¸ï¼ˆè·é›¢çš„ãªå¤§å¤‰åŒ–ï¼‰
2. åŒæœŸçš„ç•°å¸¸ï¼ˆç›¸é–¢ãƒ»å”èª¿çš„å¤‰åŒ–ï¼‰  
3. æ™‚é–“çš„ç•°å¸¸ï¼ˆé€Ÿåº¦çš„ãªç•°å¸¸ï¼‰

Version: 5.0.0 - Complete Refactoring
Authors: ç’°ã¡ã‚ƒã‚“ & ã”ä¸»äººã•ã¾
"""

import numpy as np
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from enum import Enum
import logging
from scipy import stats

logger = logging.getLogger('quantum_validation_v5')

# ============================================
# Enums (å¤–éƒ¨äº’æ›æ€§ã®ãŸã‚ç¶­æŒ)
# ============================================

class StructuralEventPattern(Enum):
    """æ§‹é€ å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡"""
    INSTANTANEOUS = "instantaneous"  # å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ 
    TRANSITION = "transition"        # é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ 
    CASCADE = "cascade"              # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰

class QuantumSignature(Enum):
    """é‡å­çš„ã‚·ã‚°ãƒãƒãƒ£ãƒ¼"""
    ENTANGLEMENT = "quantum_entanglement"
    TUNNELING = "quantum_tunneling"
    COHERENCE = "quantum_coherence"
    PHASE_TRANSITION = "quantum_phase_transition"
    INFORMATION_TRANSFER = "quantum_info_transfer"
    NONE = "classical"

# ============================================
# Data Classes (ç°¡ç•¥åŒ–ç‰ˆ)
# ============================================

@dataclass
class LambdaAnomaly:
    """Lambdaæ§‹é€ ã®ç•°å¸¸æ€§è©•ä¾¡ï¼ˆç°¡ç•¥åŒ–ï¼‰"""
    lambda_jump: float = 0.0      # Î›ã®å¤‰åŒ–é‡
    lambda_zscore: float = 0.0    # å…¨ä½“åˆ†å¸ƒã‹ã‚‰ã®Z-score
    rho_t_spike: float = 0.0      # ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å¯†åº¦
    sigma_s_value: float = 0.0    # æ§‹é€ åŒæœŸç‡
    # å‰Šé™¤: coordination, statistical_rarity, thermal_comparison

@dataclass
class AtomicEvidence:
    """åŸå­ãƒ¬ãƒ™ãƒ«ã®è¨¼æ‹ ï¼ˆç°¡ç•¥åŒ–ï¼‰"""
    max_velocity: float = 0.0              # æœ€å¤§é€Ÿåº¦ (Ã…/ps)
    max_acceleration: float = 0.0          # æœ€å¤§åŠ é€Ÿåº¦ (Ã…/psÂ²)
    correlation_coefficient: float = 0.0    # åŸå­é‹å‹•ã®ç›¸é–¢
    n_bond_anomalies: int = 0              # çµåˆç•°å¸¸ã®æ•°
    n_dihedral_flips: int = 0              # äºŒé¢è§’ãƒ•ãƒªãƒƒãƒ—ã®æ•°

@dataclass
class QuantumAssessment:
    """é‡å­æ€§è©•ä¾¡çµæœ"""
    pattern: StructuralEventPattern
    signature: QuantumSignature
    confidence: float = 0.0
    is_quantum: bool = False
    
    lambda_anomaly: Optional[LambdaAnomaly] = None
    atomic_evidence: Optional[AtomicEvidence] = None
    criteria_met: List[str] = field(default_factory=list)
    explanation: str = ""
    
    # CASCADEç”¨ï¼ˆäº’æ›æ€§ç¶­æŒï¼‰
    bell_inequality: Optional[float] = None
    async_bonds_used: List[Dict] = field(default_factory=list)

@dataclass
class AnomalyAxes:
    """3è»¸ç•°å¸¸åˆ¤å®šçµæœ"""
    spatial: float = 0.0    # ç©ºé–“çš„ç•°å¸¸åº¦ (0-1)
    sync: float = 0.0       # åŒæœŸçš„ç•°å¸¸åº¦ (0-1)
    temporal: float = 0.0   # æ™‚é–“çš„ç•°å¸¸åº¦ (0-1)

# ============================================
# Main Validator Class
# ============================================

class QuantumValidatorV4:  # ã‚¯ãƒ©ã‚¹åã¯äº’æ›æ€§ã®ãŸã‚ç¶­æŒ
    """
    LambdaÂ³çµ±åˆå‹é‡å­åˆ¤å®šå™¨ï¼ˆç°¡ç•¥åŒ–ç‰ˆï¼‰
    3è»¸åˆ¤å®š: ç©ºé–“ãƒ»åŒæœŸãƒ»æ™‚é–“
    """
    
    def __init__(self,
                 trajectory: Optional[np.ndarray] = None,
                 topology: Optional[Any] = None,
                 dt_ps: float = 100.0,
                 temperature_K: float = 300.0,
                 config: Optional[Dict] = None):
        
        self.trajectory = trajectory
        self.topology = topology
        self.dt_ps = dt_ps
        self.temperature = temperature_K
        
        # é–¾å€¤è¨­å®šï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
        self.thresholds = {
            # ç©ºé–“çš„ç•°å¸¸
            'lambda_jump_high': 0.1,
            'lambda_zscore_high': 3.0,
            'velocity_factor': 3.0,
            
            # åŒæœŸçš„ç•°å¸¸
            'sigma_s_high': 0.7,
            'correlation_high': 0.6,
            'async_bonds_min': 1,
            
            # æ™‚é–“çš„ç•°å¸¸
            'instant_frames': 1,
            'fast_transition_factor': 0.1,
            'coherence_duration': 300.0,  # ps
            
            # åˆ¤å®šé–¾å€¤
            'quantum_confidence': 0.3
        }
        
        if config:
            self.thresholds.update(config)
        
        logger.info("Quantum Validator v5.0 initialized")
    
    # ========================================
    # Main Entry Point (ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç¶­æŒ)
    # ========================================
    
    def validate_event(self,
                       event: Dict,
                       lambda_result: Any,
                       network_result: Optional[Any] = None) -> QuantumAssessment:
        """ã‚¤ãƒ™ãƒ³ãƒˆã®é‡å­æ€§ã‚’åˆ¤å®š"""
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡
        pattern = self._classify_pattern(event, network_result)
        
        # Lambdaç•°å¸¸è©•ä¾¡
        lambda_anomaly = self._evaluate_lambda_anomaly(event, lambda_result)
        
        # åŸå­ãƒ¬ãƒ™ãƒ«è¨¼æ‹ 
        atomic_evidence = None
        if self.trajectory is not None:
            atomic_evidence = self._gather_atomic_evidence(event)
        
        # 3è»¸ç•°å¸¸åº¦è¨ˆç®—
        axes = self._calculate_anomaly_axes(
            event, lambda_anomaly, atomic_evidence, network_result
        )
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ç•°å¸¸è»¸ã‹ã‚‰ã‚·ã‚°ãƒãƒãƒ£ãƒ¼åˆ¤å®š
        signature = self._determine_signature(pattern, axes)
        
        # ä¿¡é ¼åº¦è¨ˆç®—
        confidence = self._calculate_confidence(axes, pattern)
        
        # Assessmentä½œæˆ
        assessment = QuantumAssessment(
            pattern=pattern,
            signature=signature,
            confidence=confidence,
            is_quantum=(confidence >= self.thresholds['quantum_confidence']),
            lambda_anomaly=lambda_anomaly,
            atomic_evidence=atomic_evidence
        )
        
        # åˆ¤å®šæ ¹æ‹ 
        assessment.criteria_met = self._generate_criteria(axes, pattern)
        assessment.explanation = self._generate_explanation(assessment)
        
        # CASCADEç‰¹æœ‰ï¼ˆäº’æ›æ€§ï¼‰
        if pattern == StructuralEventPattern.CASCADE and network_result:
            self._add_cascade_info(assessment, network_result)
        
        return assessment
    
    # ========================================
    # Pattern Classification
    # ========================================
    
    def _classify_pattern(self, event: Dict, network_result: Optional[Any]) -> StructuralEventPattern:
        """ã‚¤ãƒ™ãƒ³ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†é¡"""
        duration = event.get('frame_end', event.get('frame', 0)) - \
                  event.get('frame_start', event.get('frame', 0)) + 1
        
        # CASCADE: async_bondsãŒã‚ã‚‹
        if network_result and hasattr(network_result, 'async_strong_bonds'):
            if len(network_result.async_strong_bonds) > 0:
                return StructuralEventPattern.CASCADE
        
        # INSTANTANEOUS: å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ 
        if duration <= self.thresholds['instant_frames']:
            return StructuralEventPattern.INSTANTANEOUS
        
        # TRANSITION: è¤‡æ•°ãƒ•ãƒ¬ãƒ¼ãƒ 
        return StructuralEventPattern.TRANSITION
    
    # ========================================
    # Lambda Anomaly Evaluation
    # ========================================
    
    def _evaluate_lambda_anomaly(self, event: Dict, lambda_result: Any) -> LambdaAnomaly:
        """Lambdaæ§‹é€ ã®ç•°å¸¸æ€§ã‚’è©•ä¾¡"""
        anomaly = LambdaAnomaly()
        
        if not hasattr(lambda_result, 'lambda_structures'):
            return anomaly
        
        structures = lambda_result.lambda_structures
        frame = event.get('frame_start', event.get('frame', 0))
        
        # Lambdaå€¤ã®å¤‰åŒ–
        if 'lambda_F_mag' in structures and frame < len(structures['lambda_F_mag']):
            lambda_vals = np.array(structures['lambda_F_mag'])
            
            # ã‚¸ãƒ£ãƒ³ãƒ—é‡
            if frame > 0:
                anomaly.lambda_jump = abs(lambda_vals[frame] - lambda_vals[frame-1])
            
            # Z-score
            if len(lambda_vals) > 10:
                mean = np.mean(lambda_vals)
                std = np.std(lambda_vals)
                if std > 1e-10:
                    anomaly.lambda_zscore = abs(lambda_vals[frame] - mean) / std
        
        # ãã®ä»–ã®æ§‹é€ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        if 'rho_T' in structures and frame < len(structures['rho_T']):
            anomaly.rho_t_spike = structures['rho_T'][frame]
        
        if 'sigma_s' in structures and frame < len(structures['sigma_s']):
            anomaly.sigma_s_value = structures['sigma_s'][frame]
        
        return anomaly
    
    # ========================================
    # Atomic Evidence Gathering
    # ========================================
    
    def _gather_atomic_evidence(self, event: Dict) -> AtomicEvidence:
        """åŸå­ãƒ¬ãƒ™ãƒ«ã®è¨¼æ‹ ã‚’åé›†"""
        evidence = AtomicEvidence()
        
        frame_start = event.get('frame_start', event.get('frame', 0))
        frame_end = event.get('frame_end', frame_start)
        
        if frame_start >= len(self.trajectory):
            return evidence
        
        frame_end = min(frame_end, len(self.trajectory) - 1)
        
        # é€Ÿåº¦ãƒ»åŠ é€Ÿåº¦
        if frame_start > 0:
            disp = self.trajectory[frame_start] - self.trajectory[frame_start-1]
            velocities = disp / self.dt_ps
            evidence.max_velocity = np.max(np.linalg.norm(velocities, axis=1))
            
            if frame_start > 1:
                prev_disp = self.trajectory[frame_start-1] - self.trajectory[frame_start-2]
                prev_vel = prev_disp / self.dt_ps
                acc = (velocities - prev_vel) / self.dt_ps
                evidence.max_acceleration = np.max(np.linalg.norm(acc, axis=1))
        
        # ç›¸é–¢è¨ˆç®—
        if frame_end > frame_start + 1:
            correlations = self._calculate_correlations(frame_start, frame_end)
            if correlations:
                evidence.correlation_coefficient = max(correlations)
        
        # çµåˆç•°å¸¸ï¼ˆç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼‰
        if self.topology is not None:
            evidence.n_bond_anomalies = self._count_bond_anomalies(
                self.trajectory[frame_start]
            )
        
        return evidence
    
    def _calculate_correlations(self, frame_start: int, frame_end: int) -> List[float]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®ç›¸é–¢ã‚’è¨ˆç®—"""
        correlations = []
        n_frames = min(frame_end - frame_start + 1, 10)
        
        displacements = []
        for i in range(n_frames):
            f = frame_start + i
            if f < len(self.trajectory) and f > 0:
                disp = self.trajectory[f] - self.trajectory[f-1]
                displacements.append(disp.flatten())
        
        if len(displacements) >= 2:
            try:
                corr_matrix = np.corrcoef(displacements)
                mask = np.triu(np.ones_like(corr_matrix), k=1).astype(bool)
                if not np.isnan(corr_matrix).any():
                    correlations = list(np.abs(corr_matrix[mask]))
            except:
                pass
        
        return correlations
    
    def _count_bond_anomalies(self, coords: np.ndarray) -> int:
        """çµåˆç•°å¸¸ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        count = 0
        if hasattr(self.topology, 'bonds'):
            for bond in self.topology.bonds[:100]:
                i, j = bond[0], bond[1]
                if i < len(coords) and j < len(coords):
                    dist = np.linalg.norm(coords[i] - coords[j])
                    if dist < 0.8 or dist > 2.0:
                        count += 1
        return count
    
    # ========================================
    # 3-Axis Anomaly Calculation
    # ========================================
    
    def _calculate_anomaly_axes(self,
                                event: Dict,
                                lambda_anomaly: LambdaAnomaly,
                                atomic_evidence: Optional[AtomicEvidence],
                                network_result: Optional[Any]) -> AnomalyAxes:
        """3è»¸ã®ç•°å¸¸åº¦ã‚’è¨ˆç®—"""
        axes = AnomalyAxes()
        
        # 1. ç©ºé–“çš„ç•°å¸¸ï¼ˆè·é›¢çš„ãªå¤§å¤‰åŒ–ï¼‰
        spatial_scores = []
        
        if lambda_anomaly.lambda_jump > self.thresholds['lambda_jump_high']:
            spatial_scores.append(min(lambda_anomaly.lambda_jump / 0.5, 1.0))
        
        if lambda_anomaly.lambda_zscore > self.thresholds['lambda_zscore_high']:
            spatial_scores.append(min(lambda_anomaly.lambda_zscore / 5.0, 1.0))
        
        if atomic_evidence:
            typical_vel = 0.02  # Ã…/ps at 300K
            if atomic_evidence.max_velocity > typical_vel * self.thresholds['velocity_factor']:
                spatial_scores.append(min(atomic_evidence.max_velocity / (typical_vel * 10), 1.0))
            
            if atomic_evidence.n_bond_anomalies > 0:
                spatial_scores.append(min(atomic_evidence.n_bond_anomalies / 10, 1.0))
        
        axes.spatial = np.mean(spatial_scores) if spatial_scores else 0.0
        
        # 2. åŒæœŸçš„ç•°å¸¸ï¼ˆç›¸é–¢ãƒ»å”èª¿ï¼‰
        sync_scores = []
        
        if lambda_anomaly.sigma_s_value > self.thresholds['sigma_s_high']:
            sync_scores.append((lambda_anomaly.sigma_s_value - 0.5) / 0.5)
        
        if atomic_evidence and atomic_evidence.correlation_coefficient > self.thresholds['correlation_high']:
            sync_scores.append(atomic_evidence.correlation_coefficient)
        
        if network_result and hasattr(network_result, 'async_strong_bonds'):
            n_bonds = len(network_result.async_strong_bonds)
            if n_bonds >= self.thresholds['async_bonds_min']:
                sync_scores.append(min(n_bonds / 10, 1.0))
        
        axes.sync = np.mean(sync_scores) if sync_scores else 0.0
        
        # 3. æ™‚é–“çš„ç•°å¸¸ï¼ˆé€Ÿåº¦çš„ãªç•°å¸¸ï¼‰
        temporal_scores = []
        
        duration = event.get('frame_end', event.get('frame', 0)) - \
                  event.get('frame_start', event.get('frame', 0)) + 1
        
        # ç¬é–“çš„å¤‰åŒ–
        if duration <= self.thresholds['instant_frames']:
            temporal_scores.append(1.0)
        
        # é€Ÿã„é·ç§»
        elif duration > 1:
            transition_time = duration * self.dt_ps
            
            # Lambda jumpã‹ã‚‰æœŸå¾…ã•ã‚Œã‚‹æ™‚é–“ã¨æ¯”è¼ƒ
            if lambda_anomaly.lambda_jump > 0.01:
                expected_time = 1000.0 * lambda_anomaly.lambda_jump  # çµŒé¨“çš„
                if transition_time < expected_time * self.thresholds['fast_transition_factor']:
                    temporal_scores.append(1.0 - transition_time / expected_time)
            
            # é•·æ™‚é–“ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹
            if lambda_anomaly.sigma_s_value > 0.7 and transition_time > self.thresholds['coherence_duration']:
                temporal_scores.append(min(transition_time / 1000.0, 1.0))
        
        axes.temporal = np.mean(temporal_scores) if temporal_scores else 0.0
        
        return axes
    
    # ========================================
    # Signature Determination
    # ========================================
    
    def _determine_signature(self, pattern: StructuralEventPattern, axes: AnomalyAxes) -> QuantumSignature:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨3è»¸ç•°å¸¸ã‹ã‚‰ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ã‚’åˆ¤å®š"""
        
        # é–¾å€¤
        threshold = 0.3
        
        spatial_high = axes.spatial > threshold
        sync_high = axes.sync > threshold
        temporal_high = axes.temporal > threshold
        
        # INSTANTANEOUSï¼ˆç¬é–“çš„ï¼‰
        if pattern == StructuralEventPattern.INSTANTANEOUS:
            if spatial_high and sync_high:
                return QuantumSignature.PHASE_TRANSITION
            elif spatial_high:
                return QuantumSignature.TUNNELING
            elif sync_high:
                return QuantumSignature.ENTANGLEMENT
        
        # TRANSITIONï¼ˆé·ç§»ï¼‰
        elif pattern == StructuralEventPattern.TRANSITION:
            if temporal_high and spatial_high:
                return QuantumSignature.TUNNELING
            elif sync_high and temporal_high:
                return QuantumSignature.COHERENCE
            elif spatial_high and sync_high:
                return QuantumSignature.PHASE_TRANSITION
        
        # CASCADEï¼ˆã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ï¼‰
        elif pattern == StructuralEventPattern.CASCADE:
            if sync_high:
                return QuantumSignature.INFORMATION_TRANSFER
            elif spatial_high and temporal_high:
                return QuantumSignature.PHASE_TRANSITION
        
        return QuantumSignature.NONE
    
    # ========================================
    # Confidence Calculation
    # ========================================
    
    def _calculate_confidence(self, axes: AnomalyAxes, pattern: StructuralEventPattern) -> float:
        """ä¿¡é ¼åº¦ã‚’è¨ˆç®—"""
        
        # åŸºæœ¬ä¿¡é ¼åº¦ï¼ˆ3è»¸ã®å¹³å‡ï¼‰
        base_confidence = (axes.spatial + axes.sync + axes.temporal) / 3.0
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹è£œæ­£
        if pattern == StructuralEventPattern.INSTANTANEOUS:
            # ç¬é–“çš„ã¯æ™‚é–“ç•°å¸¸ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãªã®ã§å°‘ã—å‰²å¼•
            confidence = base_confidence * 0.9
        elif pattern == StructuralEventPattern.CASCADE:
            # ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ã¯åŒæœŸãŒé‡è¦
            confidence = base_confidence * 0.7 + axes.sync * 0.3
        else:
            confidence = base_confidence
        
        return min(confidence, 1.0)
    
    # ========================================
    # Criteria and Explanation Generation
    # ========================================
    
    def _generate_criteria(self, axes: AnomalyAxes, pattern: StructuralEventPattern) -> List[str]:
        """åˆ¤å®šæ ¹æ‹ ã‚’ç”Ÿæˆ"""
        criteria = []
        
        if axes.spatial > 0.3:
            criteria.append(f"Spatial anomaly: {axes.spatial:.2f}")
        if axes.sync > 0.3:
            criteria.append(f"Synchronization anomaly: {axes.sync:.2f}")
        if axes.temporal > 0.3:
            criteria.append(f"Temporal anomaly: {axes.temporal:.2f}")
        
        if pattern == StructuralEventPattern.INSTANTANEOUS:
            criteria.append("Instantaneous change")
        elif pattern == StructuralEventPattern.CASCADE:
            criteria.append("Network cascade detected")
        
        return criteria
    
    def _generate_explanation(self, assessment: QuantumAssessment) -> str:
        """èª¬æ˜æ–‡ã‚’ç”Ÿæˆ"""
        if not assessment.is_quantum:
            return f"Classical {assessment.pattern.value} process (confidence: {assessment.confidence:.1%})"
        
        explanations = {
            QuantumSignature.ENTANGLEMENT: "Quantum entanglement via instantaneous correlation",
            QuantumSignature.TUNNELING: "Quantum tunneling through energy barrier",
            QuantumSignature.COHERENCE: "Sustained quantum coherence",
            QuantumSignature.PHASE_TRANSITION: "Quantum phase transition",
            QuantumSignature.INFORMATION_TRANSFER: "Non-local quantum information transfer"
        }
        
        base = explanations.get(assessment.signature, "Quantum behavior detected")
        return f"{base} (confidence: {assessment.confidence:.1%})"
    
    def _add_cascade_info(self, assessment: QuantumAssessment, network_result: Any):
        """CASCADEå›ºæœ‰æƒ…å ±ã‚’è¿½åŠ ï¼ˆäº’æ›æ€§ï¼‰"""
        if hasattr(network_result, 'async_strong_bonds'):
            bonds = network_result.async_strong_bonds[:5]
            assessment.async_bonds_used = [
                {
                    'residues': (b.from_res, b.to_res),
                    'strength': b.strength,
                    'lag': getattr(b, 'lag', 0)
                }
                for b in bonds
            ]
            
            # ç°¡æ˜“Bellä¸ç­‰å¼
            if bonds:
                max_strength = max(b.strength for b in bonds)
                assessment.bell_inequality = 2.0 + max_strength * 0.8
    
    # ========================================
    # Batch Processing (ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç¶­æŒ)
    # ========================================
    
    def validate_events(self,
                        events: List[Dict],
                        lambda_result: Any,
                        network_results: Optional[List[Any]] = None) -> List[QuantumAssessment]:
        """è¤‡æ•°ã‚¤ãƒ™ãƒ³ãƒˆã®ä¸€æ‹¬å‡¦ç†"""
        assessments = []
        
        for i, event in enumerate(events):
            network = network_results[i] if network_results and i < len(network_results) else None
            
            try:
                assessment = self.validate_event(event, lambda_result, network)
                assessments.append(assessment)
            except Exception as e:
                logger.warning(f"Failed to process event {i}: {e}")
                assessments.append(QuantumAssessment(
                    pattern=StructuralEventPattern.INSTANTANEOUS,
                    signature=QuantumSignature.NONE,
                    is_quantum=False,
                    explanation=f"Processing failed: {e}"
                ))
        
        return assessments
    
    # ========================================
    # Summary and Reporting (ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç¶­æŒ)
    # ========================================
    
    def generate_summary(self, assessments: List[QuantumAssessment]) -> Dict:
        """ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        total = len(assessments)
        quantum_count = sum(1 for a in assessments if a.is_quantum)
        
        pattern_stats = {}
        for pattern in StructuralEventPattern:
            count = sum(1 for a in assessments if a.pattern == pattern)
            quantum = sum(1 for a in assessments if a.pattern == pattern and a.is_quantum)
            pattern_stats[pattern.value] = {
                'total': count,
                'quantum': quantum,
                'ratio': quantum / count if count > 0 else 0
            }
        
        signature_stats = {}
        for sig in QuantumSignature:
            count = sum(1 for a in assessments if a.signature == sig)
            if count > 0:
                signature_stats[sig.value] = count
        
        confidences = [a.confidence for a in assessments if a.is_quantum]
        
        return {
            'total_events': total,
            'quantum_events': quantum_count,
            'quantum_ratio': quantum_count / total if total > 0 else 0,
            'pattern_statistics': pattern_stats,
            'signature_distribution': signature_stats,
            'confidence_stats': {
                'mean': np.mean(confidences) if confidences else 0,
                'std': np.std(confidences) if confidences else 0,
                'min': np.min(confidences) if confidences else 0,
                'max': np.max(confidences) if confidences else 0
            }
        }
    
    def print_summary(self, assessments: List[QuantumAssessment]):
        """ã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        summary = self.generate_summary(assessments)
        
        print("\n" + "="*70)
        print("ğŸŒŒ QUANTUM VALIDATION SUMMARY v5.0")
        print("="*70)
        print(f"\nğŸ“Š Overall Statistics:")
        print(f"   Total events: {summary['total_events']}")
        print(f"   Quantum events: {summary['quantum_events']} ({summary['quantum_ratio']:.1%})")
        
        print(f"\nğŸ¯ Pattern Analysis:")
        for pattern, stats in summary['pattern_statistics'].items():
            if stats['total'] > 0:
                print(f"   {pattern}: {stats['quantum']}/{stats['total']} quantum ({stats['ratio']:.1%})")
        
        print(f"\nâš›ï¸ Quantum Signatures:")
        for sig, count in summary['signature_distribution'].items():
            if sig != 'classical':
                print(f"   {sig}: {count}")

# ============================================
# Convenience Functions (äº’æ›æ€§ç¶­æŒ)
# ============================================

def validate_lambda_events(lambda_result: Any,
                           trajectory: Optional[np.ndarray] = None,
                           network_results: Optional[List[Any]] = None,
                           **kwargs) -> List[QuantumAssessment]:
    """LambdaÂ³ã‚¤ãƒ™ãƒ³ãƒˆã®é‡å­æ€§ã‚’æ¤œè¨¼"""
    
    events = []
    if hasattr(lambda_result, 'critical_events'):
        for e in lambda_result.critical_events:
            if isinstance(e, (tuple, list)) and len(e) >= 2:
                events.append({
                    'frame_start': int(e[0]),
                    'frame_end': int(e[1]),
                    'type': 'critical'
                })
    
    validator = QuantumValidatorV4(trajectory=trajectory, **kwargs)
    assessments = validator.validate_events(events, lambda_result, network_results)
    validator.print_summary(assessments)
    
    return assessments

# ============================================
# Example Usage
# ============================================

if __name__ == "__main__":
    # Example: ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
    print("Quantum Validator v4.0.1 (FIXED) - Test Run")
    
    # ãƒ€ãƒŸãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ
    test_event = {
        'frame_start': 100,
        'frame_end': 100,
        'type': 'critical'
    }
    
    # ãƒ€ãƒŸãƒ¼Lambdaçµæœï¼ˆä¿®æ­£ç‰ˆã®ã‚­ãƒ¼åï¼‰
    class DummyLambdaResult:
        def __init__(self):
            self.lambda_structures = {
                'lambda_F_mag': np.random.randn(1000) * 0.1 + 1.0,
                'rho_T': np.random.rand(1000) * 2.0,
                'sigma_s': np.random.rand(1000)
            }
    
    # ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼ä½œæˆ
    validator = QuantumValidatorV4(dt_ps=100.0, temperature_K=300.0)
    
    # æ¤œè¨¼å®Ÿè¡Œ
    assessment = validator.validate_event(
        test_event,
        DummyLambdaResult()
    )
    
    # çµæœè¡¨ç¤º
    print(f"\nPattern: {assessment.pattern.value}")
    print(f"Quantum: {assessment.is_quantum}")
    print(f"Signature: {assessment.signature.value}")
    print(f"Confidence: {assessment.confidence:.1%}")
    print(f"Explanation: {assessment.explanation}")
