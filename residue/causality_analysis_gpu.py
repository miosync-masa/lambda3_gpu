"""
Causality Analysis for LambdaÂ³ (GPU Version)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

æ®‹åŸºé–“ã®å› æœé–¢ä¿‚ã‚’GPUã§é«˜é€Ÿè§£æï¼
æ§‹é€ çš„å› æœæ€§ã€Transfer Entropyã€é…å»¶ç›¸é–¢ã¨ã‹å…¨éƒ¨ã§ãã‚‹ã‚ˆã€œï¼ğŸ’•

by ç’°ã¡ã‚ƒã‚“
"""

import numpy as np
import logging
from typing import Dict, List, Optional, Tuple, Union
from dataclasses import dataclass
import warnings

# GPU imports
try:
    import cupy as cp
    HAS_GPU = True
except ImportError:
    HAS_GPU = False
    cp = None

# Local imports
from ..types import ArrayType, NDArray
from ..core import GPUBackend, GPUMemoryManager, handle_gpu_errors, profile_gpu


logger = logging.getLogger('lambda3_gpu.residue.causality')

# ===============================
# Data Classes
# ===============================

@dataclass
class CausalityResult:
    """å› æœé–¢ä¿‚è§£æã®çµæœ"""
    pair: Tuple[int, int]           # (from_residue, to_residue)
    causality_strength: float       # å› æœå¼·åº¦
    optimal_lag: int               # æœ€é©ãƒ©ã‚°
    causality_profile: np.ndarray  # ãƒ©ã‚°ã”ã¨ã®å› æœå¼·åº¦
    transfer_entropy: Optional[float] = None  # Transfer Entropy
    granger_causality: Optional[float] = None  # Grangerå› æœ
    confidence: float = 1.0        # ä¿¡é ¼åº¦
    p_value: Optional[float] = None  # på€¤

# ===============================
# CUDA Kernels
# ===============================

# æ§‹é€ çš„å› æœæ€§è¨ˆç®—ã‚«ãƒ¼ãƒãƒ«ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
STRUCTURAL_CAUSALITY_KERNEL = r'''
extern "C" __global__
void compute_structural_causality_kernel(
    const float* __restrict__ anomaly_i,    // (n_frames,)
    const float* __restrict__ anomaly_j,    // (n_frames,)
    float* __restrict__ causality_profile,  // (n_lags,)
    const int n_frames,
    const int n_lags,
    const float event_threshold
) {
    const int lag = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (lag >= n_lags || lag == 0) return;
    
    // ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡ºã¨çµ±è¨ˆ
    int cause_events = 0;
    int effect_events = 0;
    int effect_given_cause = 0;
    int joint_events = 0;
    
    for (int t = 0; t < n_frames - lag; t++) {
        bool cause = anomaly_i[t] > event_threshold;
        bool effect = anomaly_j[t + lag] > event_threshold;
        
        if (cause) {
            cause_events++;
            if (effect) {
                effect_given_cause++;
                joint_events++;
            }
        }
        if (effect) {
            effect_events++;
        }
    }
    
    // æ¡ä»¶ä»˜ãç¢ºç‡ã¨ç›¸äº’æƒ…å ±é‡ã‚’è€ƒæ…®
    if (cause_events > 0 && effect_events > 0) {
        float p_effect_given_cause = (float)effect_given_cause / cause_events;
        float p_cause = (float)cause_events / (n_frames - lag);
        float p_effect = (float)effect_events / (n_frames - lag);
        float p_joint = (float)joint_events / (n_frames - lag);
        
        // æ­£è¦åŒ–ç›¸äº’æƒ…å ±é‡ã®è¿‘ä¼¼
        float mi = 0.0f;
        if (p_joint > 0 && p_cause > 0 && p_effect > 0) {
            mi = p_joint * logf(p_joint / (p_cause * p_effect));
        }
        
        // å› æœå¼·åº¦ = æ¡ä»¶ä»˜ãç¢ºç‡ Ã— (1 + æ­£è¦åŒ–MI)
        float nmi = (p_effect > 0) ? mi / (-p_effect * logf(p_effect)) : 0.0f;
        causality_profile[lag] = p_effect_given_cause * (1.0f + fmaxf(0.0f, nmi));
    } else {
        causality_profile[lag] = 0.0f;
    }
}
'''

# Transfer Entropyè¨ˆç®—ã‚«ãƒ¼ãƒãƒ«ï¼ˆæ­£ç¢ºç‰ˆï¼‰
TRANSFER_ENTROPY_KERNEL = r'''
extern "C" __global__
void compute_transfer_entropy_kernel(
    const int* __restrict__ source_discrete,  // (n_frames,) é›¢æ•£åŒ–æ¸ˆã¿
    const int* __restrict__ target_discrete,  // (n_frames,) é›¢æ•£åŒ–æ¸ˆã¿
    float* __restrict__ te_contribution,      // Transfer Entropyã¸ã®å¯„ä¸
    float* __restrict__ count,                // ã‚µãƒ³ãƒ—ãƒ«æ•°
    const int n_frames,
    const int lag,
    const int k_history,
    const int l_history,
    const int n_bins
) {
    const int tid = blockIdx.x * blockDim.x + threadIdx.x;
    const int max_history = max(k_history, l_history);
    
    if (tid >= n_frames - max_history - lag) return;
    
    const int t = tid + max_history;
    
    // å±¥æ­´ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰
    int y_past_idx = 0;
    int x_past_idx = 0;
    
    // Y_t^kã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆkå€‹ã®å±¥æ­´ã‚’1ã¤ã®æ•°å€¤ã«ï¼‰
    for (int k = 0; k < k_history; k++) {
        y_past_idx = y_past_idx * n_bins + target_discrete[t - k - 1];
    }
    
    // X_{t-lag}^lã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    for (int l = 0; l < l_history; l++) {
        x_past_idx = x_past_idx * n_bins + source_discrete[t - lag - l - 1];
    }
    
    int y_future = target_discrete[t];
    
    // ã“ã®çµ„ã¿åˆã‚ã›ã®Transfer Entropyã¸ã®å¯„ä¸ã‚’è¨ˆç®—
    // å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’äº‹å‰ã«æ§‹ç¯‰ã—ã¦ã‹ã‚‰è¨ˆç®—
    // ã“ã“ã§ã¯ç°¡æ˜“çš„ã«äºˆæ¸¬èª¤å·®ã®æ”¹å–„ã‚’ä½¿ç”¨
    
    // Y_tã®å±¥æ­´ã‹ã‚‰ã®äºˆæ¸¬
    float y_pred_from_y = 0.0f;
    for (int k = 0; k < k_history; k++) {
        y_pred_from_y += (float)target_discrete[t - k - 1] / k_history;
    }
    
    // Y_tã¨X_{t-lag}ã®å±¥æ­´ã‹ã‚‰ã®äºˆæ¸¬
    float y_pred_from_xy = 0.6f * y_pred_from_y;
    for (int l = 0; l < l_history; l++) {
        y_pred_from_xy += 0.4f * (float)source_discrete[t - lag - l - 1] / l_history;
    }
    
    // äºˆæ¸¬èª¤å·®
    float error_y_only = fabsf((float)y_future - y_pred_from_y);
    float error_xy = fabsf((float)y_future - y_pred_from_xy);
    
    // Transfer Entropyã®å¯„ä¸ï¼ˆèª¤å·®å‰Šæ¸›ã®å¯¾æ•°ï¼‰
    if (error_y_only > 1e-6f) {
        float te_local = logf((error_y_only + 1e-6f) / (error_xy + 1e-6f));
        atomicAdd(te_contribution, te_local);
        atomicAdd(count, 1.0f);
    }
}
'''

# Transfer Entropyãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ æ§‹ç¯‰ã‚«ãƒ¼ãƒãƒ«
TRANSFER_ENTROPY_HIST_KERNEL = r'''
extern "C" __global__
void build_te_histogram_kernel(
    const int* __restrict__ source_discrete,
    const int* __restrict__ target_discrete,
    int* __restrict__ hist_3d,      // p(y_{t+1}, y_t^k, x_t^l)
    int* __restrict__ hist_2d_yy,   // p(y_{t+1}, y_t^k)
    int* __restrict__ hist_1d_y,    // p(y_t^k)
    const int n_frames,
    const int lag,
    const int k_history,
    const int l_history,
    const int n_bins
) {
    const int tid = blockIdx.x * blockDim.x + threadIdx.x;
    const int max_history = max(k_history, l_history);
    
    if (tid >= n_frames - max_history - lag) return;
    
    const int t = tid + max_history;
    
    // å±¥æ­´ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨ˆç®—
    int y_past_idx = 0;
    for (int k = 0; k < k_history; k++) {
        y_past_idx = y_past_idx * n_bins + target_discrete[t - k - 1];
    }
    
    int x_past_idx = 0;
    for (int l = 0; l < l_history; l++) {
        x_past_idx = x_past_idx * n_bins + source_discrete[t - lag - l - 1];
    }
    
    int y_future = target_discrete[t];
    
    // ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ æ›´æ–°
    // 3æ¬¡å…ƒ: p(y_{t+1}, y_t^k, x_t^l)
    int idx_3d = y_future * n_bins * n_bins + y_past_idx * n_bins + x_past_idx;
    atomicAdd(&hist_3d[idx_3d], 1);
    
    // 2æ¬¡å…ƒ: p(y_{t+1}, y_t^k)
    int idx_2d = y_future * n_bins + y_past_idx;
    atomicAdd(&hist_2d_yy[idx_2d], 1);
    
    // 1æ¬¡å…ƒ: p(y_t^k)
    atomicAdd(&hist_1d_y[y_past_idx], 1);
}
'''

# é…å»¶ç›¸é–¢è¨ˆç®—ã‚«ãƒ¼ãƒãƒ«ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
LAGGED_CORRELATION_KERNEL = r'''
extern "C" __global__
void compute_lagged_correlation_kernel(
    const float* __restrict__ series_i,     // (n_frames,)
    const float* __restrict__ series_j,     // (n_frames,)
    float* __restrict__ correlations,      // (n_lags,)
    const int n_frames,
    const int n_lags
) {
    const int lag = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (lag >= n_lags) return;
    
    // æœ‰åŠ¹ãªã‚µãƒ³ãƒ—ãƒ«æ•°
    int n_valid = n_frames - lag;
    if (n_valid <= 1) {
        correlations[lag] = 0.0f;
        return;
    }
    
    // Welfordã®æ–¹æ³•ã§å®‰å®šã—ãŸå¹³å‡ã¨åˆ†æ•£è¨ˆç®—
    float mean_i = 0.0f, mean_j = 0.0f;
    float m2_i = 0.0f, m2_j = 0.0f, c_ij = 0.0f;
    
    for (int t = 0; t < n_valid; t++) {
        float xi = series_i[t];
        float xj = series_j[t + lag];
        
        float delta_i = xi - mean_i;
        mean_i += delta_i / (t + 1);
        float delta2_i = xi - mean_i;
        m2_i += delta_i * delta2_i;
        
        float delta_j = xj - mean_j;
        mean_j += delta_j / (t + 1);
        float delta2_j = xj - mean_j;
        m2_j += delta_j * delta2_j;
        
        c_ij += delta_i * (xj - mean_j);
    }
    
    // ç›¸é–¢ä¿‚æ•°
    float std_i = sqrtf(m2_i / n_valid);
    float std_j = sqrtf(m2_j / n_valid);
    
    if (std_i > 1e-6f && std_j > 1e-6f) {
        correlations[lag] = c_ij / (n_valid * std_i * std_j);
    } else {
        correlations[lag] = 0.0f;
    }
}
'''

# ===============================
# Causality Analyzer GPU Class
# ===============================

class CausalityAnalyzerGPU(GPUBackend):
    """
    å› æœé–¢ä¿‚è§£æã®GPUå®Ÿè£…
    
    æ®‹åŸºé–“ã®å› æœé–¢ä¿‚ã‚’è¤‡æ•°ã®æ‰‹æ³•ã§è§£æï¼
    æ§‹é€ çš„å› æœæ€§ã€Transfer Entropyã€Grangerå› æœã¨ã‹å…¨éƒ¨é«˜é€Ÿï¼
    """
    
    def __init__(self,
                 event_threshold: float = 1.0,
                 min_lag: int = 1,
                 max_lag: int = 200,
                 history_length: int = 5,
                 n_bins: int = 10,
                 memory_manager: Optional[GPUMemoryManager] = None,
                 **kwargs):
        """
        Parameters
        ----------
        event_threshold : float
            ã‚¤ãƒ™ãƒ³ãƒˆåˆ¤å®šé–¾å€¤
        min_lag : int
            æœ€å°ãƒ©ã‚°
        max_lag : int
            æœ€å¤§ãƒ©ã‚°
        history_length : int
            å±¥æ­´é•·ï¼ˆTransfer Entropyç”¨ï¼‰
        n_bins : int
            é›¢æ•£åŒ–ã®ãƒ“ãƒ³æ•°
        """
        super().__init__(**kwargs)
        self.event_threshold = event_threshold
        self.min_lag = min_lag
        self.max_lag = max_lag
        self.history_length = history_length
        self.n_bins = n_bins
        self.memory_manager = memory_manager or GPUMemoryManager()
        
        # ã‚«ãƒ¼ãƒãƒ«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
        if self.is_gpu and HAS_GPU:
            self._compile_kernels()
    
    def _compile_kernels(self):
        """ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«"""
        try:
            self.structural_causality_kernel = cp.RawKernel(
                STRUCTURAL_CAUSALITY_KERNEL, 'compute_structural_causality_kernel'
            )
            self.transfer_entropy_kernel = cp.RawKernel(
                TRANSFER_ENTROPY_KERNEL, 'compute_transfer_entropy_kernel'
            )
            self.transfer_entropy_hist_kernel = cp.RawKernel(
                TRANSFER_ENTROPY_HIST_KERNEL, 'build_te_histogram_kernel'
            )
            self.lagged_correlation_kernel = cp.RawKernel(
                LAGGED_CORRELATION_KERNEL, 'compute_lagged_correlation_kernel'
            )
            logger.debug("Causality analysis kernels compiled successfully")
        except Exception as e:
            logger.warning(f"Failed to compile custom kernels: {e}")
            self.structural_causality_kernel = None
            self.transfer_entropy_kernel = None
            self.transfer_entropy_hist_kernel = None
            self.lagged_correlation_kernel = None
    
    @handle_gpu_errors
    @profile_gpu
    def calculate_structural_causality(self,
                                     anomaly_i: np.ndarray,
                                     anomaly_j: np.ndarray,
                                     lag_window: Optional[int] = None) -> CausalityResult:
        """
        æ§‹é€ çš„å› æœæ€§ã‚’è¨ˆç®—
        
        Parameters
        ----------
        anomaly_i : np.ndarray
            åŸå› å´ã®ç•°å¸¸ã‚¹ã‚³ã‚¢
        anomaly_j : np.ndarray
            çµæœå´ã®ç•°å¸¸ã‚¹ã‚³ã‚¢
        lag_window : int, optional
            ãƒ©ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆNoneãªã‚‰æœ€å¤§ãƒ©ã‚°ä½¿ç”¨ï¼‰
            
        Returns
        -------
        CausalityResult
            å› æœé–¢ä¿‚è§£æçµæœ
        """
        if lag_window is None:
            lag_window = self.max_lag
        
        n_lags = min(lag_window, len(anomaly_i) // 2)
        
        # GPUè»¢é€
        anomaly_i_gpu = self.to_gpu(anomaly_i)
        anomaly_j_gpu = self.to_gpu(anomaly_j)
        
        if self.is_gpu and self.structural_causality_kernel is not None:
            # ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ä½¿ç”¨
            causality_profile = self.zeros(n_lags, dtype=cp.float32)
            
            # ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œ
            block_size = 256
            grid_size = (n_lags + block_size - 1) // block_size
            
            self.structural_causality_kernel(
                (grid_size,), (block_size,),
                (anomaly_i_gpu, anomaly_j_gpu, causality_profile,
                 len(anomaly_i), n_lags, self.event_threshold)
            )
        else:
            # æ±ç”¨GPU/CPUç‰ˆ
            causality_profile = self._calculate_structural_causality_generic(
                anomaly_i_gpu, anomaly_j_gpu, n_lags
            )
        
        # æœ€å¤§å€¤ã¨æœ€é©ãƒ©ã‚°
        max_causality = float(self.xp.max(causality_profile))
        optimal_lag = int(self.xp.argmax(causality_profile))
        
        # Transfer Entropyï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        transfer_entropy = None
        if optimal_lag > 0:
            with self.timer('transfer_entropy'):
                transfer_entropy = self.calculate_transfer_entropy(
                    anomaly_i_gpu, anomaly_j_gpu, optimal_lag
                )
        
        # çµæœä½œæˆ
        result = CausalityResult(
            pair=(0, 1),  # ãƒ€ãƒŸãƒ¼ï¼ˆå‘¼ã³å‡ºã—å´ã§è¨­å®šï¼‰
            causality_strength=max_causality,
            optimal_lag=optimal_lag,
            causality_profile=self.to_cpu(causality_profile),
            transfer_entropy=transfer_entropy
        )
        
        return result
    
    def _calculate_structural_causality_generic(self,
                                              anomaly_i: Union[np.ndarray, cp.ndarray],
                                              anomaly_j: Union[np.ndarray, cp.ndarray],
                                              n_lags: int) -> Union[np.ndarray, cp.ndarray]:
        """æ§‹é€ çš„å› æœæ€§ã®æ±ç”¨è¨ˆç®—"""
        causality_profile = self.zeros(n_lags)
        
        # ã‚¤ãƒ™ãƒ³ãƒˆåŒ–
        events_i = (anomaly_i > self.event_threshold).astype(self.xp.float32)
        events_j = (anomaly_j > self.event_threshold).astype(self.xp.float32)
        
        for lag in range(1, n_lags):
            cause = events_i[:-lag]
            effect = events_j[lag:]
            
            # æ¡ä»¶ä»˜ãç¢ºç‡ P(effect|cause)
            cause_mask = cause > 0
            if self.xp.sum(cause_mask) > 0:
                causality_profile[lag] = self.xp.mean(effect[cause_mask])
        
        return causality_profile
    
    def calculate_transfer_entropy(self,
                                  source: Union[np.ndarray, cp.ndarray],
                                  target: Union[np.ndarray, cp.ndarray],
                                  lag: int = 1,
                                  k_history: Optional[int] = None,
                                  l_history: Optional[int] = None) -> float:
        """
        Transfer Entropyè¨ˆç®—ï¼ˆæ­£ç¢ºç‰ˆï¼‰
        
        TE(Xâ†’Y) = Î£ p(y_{t+1}, y_t^k, x_t^l) log[p(y_{t+1}|y_t^k, x_t^l) / p(y_{t+1}|y_t^k)]
        
        Parameters
        ----------
        source : array
            ã‚½ãƒ¼ã‚¹ä¿¡å·ï¼ˆXï¼‰
        target : array
            ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä¿¡å·ï¼ˆYï¼‰
        lag : int
            æ™‚é–“é…ã‚Œ
        k_history : int
            ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å±¥æ­´é•·
        l_history : int
            ã‚½ãƒ¼ã‚¹ã®å±¥æ­´é•·
        """
        if k_history is None:
            k_history = min(self.history_length, 3)  # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®ãŸã‚åˆ¶é™
        if l_history is None:
            l_history = min(self.history_length, 3)
        
        # GPUå¤‰æ›
        if not isinstance(source, (cp.ndarray if HAS_GPU else np.ndarray)):
            source = self.to_gpu(source)
        if not isinstance(target, (cp.ndarray if HAS_GPU else np.ndarray)):
            target = self.to_gpu(target)
        
        n_frames = min(len(source), len(target))
        max_history = max(k_history, l_history)
        
        # ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã™ãã‚‹å ´åˆ
        if n_frames < max_history + lag + 10:
            return 0.0
        
        # ä¿¡å·ã®é›¢æ•£åŒ–
        source_discrete = self._discretize_signal(source, self.n_bins)
        target_discrete = self._discretize_signal(target, self.n_bins)
        
        # ãƒ©ã‚°é©ç”¨
        if lag > 0:
            source_discrete = source_discrete[:-lag]
            target_discrete = target_discrete[lag:]
            n_frames = len(source_discrete)
        
        if self.is_gpu and self.transfer_entropy_kernel is not None:
            # ã‚«ãƒ¼ãƒãƒ«ç‰ˆ
            te_contribution = cp.zeros(1, dtype=cp.float32)
            count = cp.zeros(1, dtype=cp.float32)
            
            block_size = 256
            n_samples = n_frames - max_history
            grid_size = (n_samples + block_size - 1) // block_size
            
            self.transfer_entropy_kernel(
                (grid_size,), (block_size,),
                (source_discrete, target_discrete, te_contribution, count,
                 n_frames, lag, k_history, l_history, self.n_bins)
            )
            
            if count[0] > 0:
                return float(te_contribution[0] / count[0])
            else:
                return 0.0
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãƒ™ãƒ¼ã‚¹ã®æ­£ç¢ºãªè¨ˆç®—
            return self._calculate_transfer_entropy_exact(
                source_discrete, target_discrete, k_history, l_history
            )
    
    def _calculate_transfer_entropy_exact(self,
                                        source_discrete: Union[np.ndarray, cp.ndarray],
                                        target_discrete: Union[np.ndarray, cp.ndarray],
                                        k_history: int,
                                        l_history: int) -> float:
        """Transfer Entropyã®æ­£ç¢ºãªè¨ˆç®—ï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãƒ™ãƒ¼ã‚¹ï¼‰"""
        n_frames = len(source_discrete)
        max_history = max(k_history, l_history)
        
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚µã‚¤ã‚º
        hist_size_3d = self.n_bins ** 3
        hist_size_2d = self.n_bins ** 2
        
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ åˆæœŸåŒ–
        hist_3d = self.zeros(hist_size_3d, dtype=self.xp.int32)
        hist_2d_yy = self.zeros(hist_size_2d, dtype=self.xp.int32)
        hist_1d_y = self.zeros(self.n_bins, dtype=self.xp.int32)
        
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ æ§‹ç¯‰
        for t in range(max_history, n_frames):
            # ç°¡æ˜“ç‰ˆï¼š1æ¬¡å…ƒã®å±¥æ­´ã®ã¿ä½¿ç”¨
            y_past = int(target_discrete[t - 1])
            x_past = int(source_discrete[t - 1])
            y_future = int(target_discrete[t])
            
            # 3æ¬¡å…ƒãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            idx_3d = y_future * self.n_bins * self.n_bins + y_past * self.n_bins + x_past
            hist_3d[idx_3d] += 1
            
            # 2æ¬¡å…ƒãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            idx_2d = y_future * self.n_bins + y_past
            hist_2d_yy[idx_2d] += 1
            
            # 1æ¬¡å…ƒãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            hist_1d_y[y_past] += 1
        
        # ç¢ºç‡åˆ†å¸ƒã«å¤‰æ›
        total = float(self.xp.sum(hist_3d))
        if total == 0:
            return 0.0
        
        p_yyx = hist_3d.astype(self.xp.float32) / total
        p_yy = hist_2d_yy.astype(self.xp.float32) / total
        p_y = hist_1d_y.astype(self.xp.float32) / total
        
        # Transfer Entropyè¨ˆç®—
        te = 0.0
        for y_future in range(self.n_bins):
            for y_past in range(self.n_bins):
                for x_past in range(self.n_bins):
                    idx_3d = y_future * self.n_bins * self.n_bins + y_past * self.n_bins + x_past
                    idx_2d = y_future * self.n_bins + y_past
                    
                    if p_yyx[idx_3d] > 0 and p_yy[idx_2d] > 0 and p_y[y_past] > 0:
                        # p(y_{t+1}|y_t, x_t)
                        p_cond_xy = p_yyx[idx_3d] / (p_y[y_past] * self.n_bins)
                        # p(y_{t+1}|y_t)
                        p_cond_y = p_yy[idx_2d] / p_y[y_past]
                        
                        if p_cond_xy > 0 and p_cond_y > 0:
                            te += p_yyx[idx_3d] * self.xp.log(p_cond_xy / p_cond_y)
        
        return float(te)
    
    def _discretize_signal(self, signal: Union[np.ndarray, cp.ndarray], n_bins: int) -> Union[np.ndarray, cp.ndarray]:
        """ä¿¡å·ã‚’é›¢æ•£åŒ–"""
        # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ“ãƒ‹ãƒ³ã‚°
        percentiles = self.xp.linspace(0, 100, n_bins + 1)
        bin_edges = self.xp.percentile(signal, percentiles)
        
        # é‡è¤‡é™¤å»
        bin_edges = self.xp.unique(bin_edges)
        
        if len(bin_edges) < 2:
            return self.zeros_like(signal, dtype=self.xp.int32)
        
        # é›¢æ•£åŒ–
        discrete = self.xp.digitize(signal, bin_edges[1:-1])
        
        return discrete.astype(self.xp.int32)
    
    @profile_gpu
    def compute_lagged_correlation(self,
                                 series_i: np.ndarray,
                                 series_j: np.ndarray,
                                 max_lag: Optional[int] = None) -> Tuple[np.ndarray, int, float]:
        """
        é…å»¶ç›¸é–¢ã‚’è¨ˆç®—
        
        Parameters
        ----------
        series_i : np.ndarray
            ç³»åˆ—1
        series_j : np.ndarray
            ç³»åˆ—2
        max_lag : int, optional
            æœ€å¤§ãƒ©ã‚°
            
        Returns
        -------
        correlations : np.ndarray
            å„ãƒ©ã‚°ã§ã®ç›¸é–¢
        optimal_lag : int
            æœ€é©ãƒ©ã‚°
        max_correlation : float
            æœ€å¤§ç›¸é–¢
        """
        if max_lag is None:
            max_lag = self.max_lag
        
        n_lags = min(max_lag, len(series_i) // 2)
        
        # GPUè»¢é€
        series_i_gpu = self.to_gpu(series_i)
        series_j_gpu = self.to_gpu(series_j)
        
        if self.is_gpu and self.lagged_correlation_kernel is not None:
            # ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ä½¿ç”¨
            correlations = self.zeros(n_lags, dtype=cp.float32)
            
            block_size = 256
            grid_size = (n_lags + block_size - 1) // block_size
            
            self.lagged_correlation_kernel(
                (grid_size,), (block_size,),
                (series_i_gpu, series_j_gpu, correlations, len(series_i), n_lags)
            )
        else:
            # æ±ç”¨ç‰ˆ
            correlations = self.zeros(n_lags)
            
            for lag in range(n_lags):
                if lag == 0:
                    corr = self.xp.corrcoef(series_i_gpu, series_j_gpu)[0, 1]
                else:
                    corr = self.xp.corrcoef(series_i_gpu[:-lag], series_j_gpu[lag:])[0, 1]
                
                correlations[lag] = corr
        
        # æœ€å¤§ç›¸é–¢ã¨ãƒ©ã‚°
        abs_corr = self.xp.abs(correlations)
        optimal_lag = int(self.xp.argmax(abs_corr))
        max_correlation = float(correlations[optimal_lag])
        
        return self.to_cpu(correlations), optimal_lag, max_correlation
    
    @handle_gpu_errors
    def detect_causal_pairs(self,
                          anomaly_scores: Dict[int, np.ndarray],
                          threshold: float = 0.2,
                          batch_size: int = 100) -> List[CausalityResult]:
        """
        è¤‡æ•°æ®‹åŸºãƒšã‚¢ã®å› æœé–¢ä¿‚ã‚’æ¤œå‡º
        
        Parameters
        ----------
        anomaly_scores : dict
            æ®‹åŸºID -> ç•°å¸¸ã‚¹ã‚³ã‚¢
        threshold : float
            å› æœå¼·åº¦é–¾å€¤
        batch_size : int
            ãƒãƒƒãƒã‚µã‚¤ã‚º
            
        Returns
        -------
        list of CausalityResult
            æ¤œå‡ºã•ã‚ŒãŸå› æœé–¢ä¿‚
        """
        residue_ids = sorted(anomaly_scores.keys())
        n_residues = len(residue_ids)
        causal_pairs = []
        
        logger.info(f"ğŸ” Detecting causal pairs among {n_residues} residues")
        
        # ãƒãƒƒãƒå‡¦ç†
        pair_count = 0
        for i in range(0, n_residues, batch_size):
            for j in range(0, n_residues, batch_size):
                # ãƒãƒƒãƒå†…ã®ãƒšã‚¢ã‚’å‡¦ç†
                batch_results = self._process_pair_batch(
                    residue_ids[i:i+batch_size],
                    residue_ids[j:j+batch_size],
                    anomaly_scores,
                    threshold
                )
                
                causal_pairs.extend(batch_results)
                pair_count += len(batch_results)
                
                if pair_count % 1000 == 0:
                    logger.debug(f"   Processed {pair_count} pairs...")
        
        # å¼·åº¦ã§ã‚½ãƒ¼ãƒˆ
        causal_pairs.sort(key=lambda x: x.causality_strength, reverse=True)
        
        logger.info(f"   Found {len(causal_pairs)} causal relationships")
        
        return causal_pairs
    
    def _process_pair_batch(self,
                          residues_i: List[int],
                          residues_j: List[int],
                          anomaly_scores: Dict[int, np.ndarray],
                          threshold: float) -> List[CausalityResult]:
        """ãƒšã‚¢ã®ãƒãƒƒãƒå‡¦ç†"""
        results = []
        
        for res_i in residues_i:
            for res_j in residues_j:
                if res_i == res_j:
                    continue
                
                # å› æœæ€§è¨ˆç®—
                result = self.calculate_structural_causality(
                    anomaly_scores[res_i],
                    anomaly_scores[res_j]
                )
                
                # é–¾å€¤ãƒã‚§ãƒƒã‚¯
                if result.causality_strength >= threshold:
                    result.pair = (res_i, res_j)
                    results.append(result)
        
        return results
    
    def compute_granger_causality(self,
                                series_i: np.ndarray,
                                series_j: np.ndarray,
                                order: int = 5) -> float:
        """
        Grangerå› æœæ€§ã‚’è¨ˆç®—ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        
        Parameters
        ----------
        series_i : np.ndarray
            åŸå› å€™è£œã®ç³»åˆ—
        series_j : np.ndarray
            çµæœå€™è£œã®ç³»åˆ—
        order : int
            è‡ªå·±å›å¸°ã®æ¬¡æ•°
            
        Returns
        -------
        float
            Grangerå› æœæ€§ã‚¹ã‚³ã‚¢
        """
        # GPUè»¢é€
        x_gpu = self.to_gpu(series_i)
        y_gpu = self.to_gpu(series_j)
        
        n = len(x_gpu)
        
        if n < order * 3:  # ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãƒã‚§ãƒƒã‚¯
            return 0.0
        
        # åˆ¶é™ãƒ¢ãƒ‡ãƒ«ï¼ˆyã®éå»ã®ã¿ï¼‰
        y_lagged = self.xp.zeros((n - order, order))
        for i in range(order):
            y_lagged[:, i] = y_gpu[order-i-1:-i-1] if i > 0 else y_gpu[order-1:-1]
        
        y_target = y_gpu[order:]
        
        # æœ€å°äºŒä¹—æ³•ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
        try:
            coef_restricted = self.xp.linalg.lstsq(y_lagged, y_target, rcond=None)[0]
            residuals_restricted = y_target - self.xp.dot(y_lagged, coef_restricted)
            rss_restricted = self.xp.sum(residuals_restricted ** 2)
        except:
            return 0.0
        
        # éåˆ¶é™ãƒ¢ãƒ‡ãƒ«ï¼ˆxã¨yã®éå»ï¼‰
        xy_lagged = self.xp.zeros((n - order, 2 * order))
        xy_lagged[:, :order] = y_lagged
        for i in range(order):
            xy_lagged[:, order+i] = x_gpu[order-i-1:-i-1] if i > 0 else x_gpu[order-1:-1]
        
        try:
            coef_unrestricted = self.xp.linalg.lstsq(xy_lagged, y_target, rcond=None)[0]
            residuals_unrestricted = y_target - self.xp.dot(xy_lagged, coef_unrestricted)
            rss_unrestricted = self.xp.sum(residuals_unrestricted ** 2)
        except:
            return 0.0
        
        # Fçµ±è¨ˆé‡
        if rss_unrestricted > 0:
            f_stat = ((rss_restricted - rss_unrestricted) / order) / \
                    (rss_unrestricted / (n - 2 * order))
            return float(max(0.0, f_stat))  # è² å€¤ã‚’é˜²ã
        
        return 0.0

# ===============================
# Standalone Functions
# ===============================

def calculate_structural_causality_gpu(anomaly_i: np.ndarray,
                                     anomaly_j: np.ndarray,
                                     lag_window: int = 200,
                                     event_threshold: float = 1.0,
                                     **kwargs) -> CausalityResult:
    """æ§‹é€ çš„å› æœæ€§è¨ˆç®—ã®ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³é–¢æ•°"""
    analyzer = CausalityAnalyzerGPU(event_threshold=event_threshold, **kwargs)
    return analyzer.calculate_structural_causality(anomaly_i, anomaly_j, lag_window)

def compute_lagged_correlation_gpu(series_i: np.ndarray,
                                 series_j: np.ndarray,
                                 max_lag: int = 200,
                                 backend: Optional[GPUBackend] = None) -> Tuple[np.ndarray, int, float]:
    """é…å»¶ç›¸é–¢è¨ˆç®—ã®ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³é–¢æ•°"""
    analyzer = CausalityAnalyzerGPU() if backend is None else CausalityAnalyzerGPU(device=backend.device)
    return analyzer.compute_lagged_correlation(series_i, series_j, max_lag)

def detect_causal_pairs_gpu(anomaly_scores: Dict[int, np.ndarray],
                          threshold: float = 0.2,
                          **kwargs) -> List[CausalityResult]:
    """å› æœãƒšã‚¢æ¤œå‡ºã®ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³é–¢æ•°"""
    analyzer = CausalityAnalyzerGPU(**kwargs)
    return analyzer.detect_causal_pairs(anomaly_scores, threshold)

def compute_transfer_entropy_gpu(source: np.ndarray,
                               target: np.ndarray,
                               lag: int,
                               history_length: int = 5,
                               n_bins: int = 10,
                               backend: Optional[GPUBackend] = None) -> float:
    """Transfer Entropyè¨ˆç®—ã®ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³é–¢æ•°"""
    analyzer = CausalityAnalyzerGPU(
        history_length=history_length,
        n_bins=n_bins
    )
    if backend:
        analyzer.device = backend.device
        analyzer.is_gpu = backend.is_gpu
        analyzer.xp = backend.xp
    
    source_gpu = analyzer.to_gpu(source)
    target_gpu = analyzer.to_gpu(target)
    
    return analyzer.calculate_transfer_entropy(source_gpu, target_gpu, lag)
