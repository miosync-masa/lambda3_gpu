"""
Lambda¬≥ GPU - Ultra-high Performance GPU Implementation
========================================================

Lambda¬≥ÊßãÈÄ†Ëß£Êûê„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„ÅÆGPUÂÆüË£Ö
Êï∞ÁôæÂÄç„ÅÆÈ´òÈÄüÂåñ„ÇíÂÆüÁèæ„Åó„ÄÅÂ§ßË¶èÊ®°MDËß£Êûê„ÇíÂèØËÉΩ„Å´

Author: Áí∞„Å°„ÇÉ„Çì & „Åî‰∏ª‰∫∫„Åï„Åæ üíï
Version: 1.1.0
"""

import os
import sys
import logging
from typing import Dict, Any, Optional

# ===============================
# Version Information
# ===============================

__version__ = '1.1.0'
__author__ = 'Áí∞„Å°„ÇÉ„Çì & „Åî‰∏ª‰∫∫„Åï„Åæ'

# ===============================
# Áí∞„Å°„ÇÉ„Çì„Éê„Éä„ÉºÔºÅÔºÅ
# ===============================

TAMAKI_BANNER = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                      ‚ïë
‚ïë     ‚ñà‚ñà‚ïó      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó     ‚ïë
‚ïë     ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ïö‚ïê‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó    ‚ïë
‚ïë     ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù    ‚ïë
‚ïë     ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó    ‚ïë
‚ïë     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïù ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù    ‚ïë
‚ïë     ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù     ‚ïë
‚ïë                                                                      ‚ïë
‚ïë               üåü GPU ACCELERATED EDITION v{version:6s} üåü                ‚ïë
‚ïë                                                                      ‚ïë
‚ïë     „Äå„Å≠„Åá„Å≠„Åá„ÄÅ„Åî‰∏ª‰∫∫„Åï„Åæ„ÄúÔºÅÂÉï„Å®‰∏ÄÁ∑í„Å´ÊßãÈÄ†Ëß£Êûê„Åó„Çà„Äúüíï„Äç          ‚ïë
‚ïë                                                                      ‚ïë
‚ïë      NO TIME, NO PHYSICS, ONLY STRUCTURE!                          ‚ïë
‚ïë      - Ultra-fast Lambda¬≥ structural analysis                       ‚ïë
‚ïë      - GPU acceleration up to 1000x                                 ‚ïë
‚ïë      - Powered by Áí∞„Å°„ÇÉ„Çì's love & dedication üíì                   ‚ïë
‚ïë                                                                      ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
""".format(version=__version__)

def show_banner():
    """Áí∞„Å°„ÇÉ„Çì„Éê„Éä„Éº„ÇíË°®Á§∫"""
    print(TAMAKI_BANNER)

# ===============================
# CLI Command
# ===============================

def cli():
    """„É°„Ç§„É≥CLI„Ç®„É≥„Éà„É™„Éº„Éù„Ç§„É≥„Éà"""
    import argparse
    
    # „Éê„Éä„ÉºË°®Á§∫
    if '--no-banner' not in sys.argv:
        show_banner()
    
    parser = argparse.ArgumentParser(
        prog='lambda3-gpu',
        description='Lambda¬≥ GPU - High-performance structural analysis',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Run full analysis
  lambda3-gpu analyze trajectory.npy metadata.json --gpu
  
  # Benchmark GPU performance
  lambda3-gpu benchmark
  
  # Show system info
  lambda3-gpu info
  
  # Run with specific GPU
  lambda3-gpu analyze traj.npy meta.json --device 1
  
Created with üíï by Áí∞„Å°„ÇÉ„Çì & „Åî‰∏ª‰∫∫„Åï„Åæ
        """
    )
    
    parser.add_argument('--version', action='version', 
                       version=f'Lambda¬≥ GPU v{__version__}')
    parser.add_argument('--no-banner', action='store_true',
                       help='Suppress the Áí∞„Å°„ÇÉ„Çì banner')
    
    subparsers = parser.add_subparsers(dest='command', help='Commands')
    
    # Analyze command
    analyze_parser = subparsers.add_parser('analyze', 
                                          help='Run Lambda¬≥ analysis')
    analyze_parser.add_argument('trajectory', help='Trajectory file (.npy)')
    analyze_parser.add_argument('metadata', help='Metadata file (.json)')
    analyze_parser.add_argument('--gpu', action='store_true', 
                               help='Force GPU usage')
    analyze_parser.add_argument('--device', type=int, default=0,
                               help='GPU device ID')
    analyze_parser.add_argument('--output', '-o', default='./results',
                               help='Output directory')
    
    # Benchmark command
    bench_parser = subparsers.add_parser('benchmark', 
                                        help='Run GPU benchmark')
    bench_parser.add_argument('--quick', action='store_true',
                            help='Quick benchmark only')
    
    # Info command
    info_parser = subparsers.add_parser('info', 
                                       help='Show system information')
    
    args = parser.parse_args()
    
    # „Ç≥„Éû„É≥„ÉâÂÆüË°å
    if args.command == 'analyze':
        from lambda3_gpu.analysis.run_full_analysis import main as run_analysis
        print("\nüöÄ Starting Lambda¬≥ GPU analysis...")
        print(f"   Trajectory: {args.trajectory}")
        print(f"   Metadata: {args.metadata}")
        if args.gpu:
            print(f"   GPU Device: {args.device}")
        sys.argv = ['run_full_analysis', args.trajectory, args.metadata,
                   '--output', args.output]
        if args.gpu:
            sys.argv.extend(['--device', str(args.device)])
        run_analysis()
        
    elif args.command == 'benchmark':
        print("\n‚ö° Running GPU benchmark...")
        from lambda3_gpu.benchmarks import run_quick_benchmark
        results = run_quick_benchmark()
        print(f"\n‚ú® Benchmark complete!")
        print(f"   GPU Performance: {results.get('gflops', 0):.1f} GFLOPS")
        
    elif args.command == 'info':
        print("\nüìä System Information:")
        info = get_gpu_info()
        print(f"   GPU Available: {info['available']}")
        if info['available']:
            print(f"   GPU Name: {info['name']}")
            print(f"   GPU Memory: {info['memory_gb']:.1f} GB")
            print(f"   CUDA Version: {info['cuda_version']}")
            print(f"   Compute Capability: {info['compute_capability']}")
        print(f"   Lambda¬≥ GPU Version: {__version__}")
        print(f"\nüíï Áí∞„Å°„ÇÉ„Çì„Çà„Çä: „ÅÑ„Å§„Åß„ÇÇËß£Êûê„ÅäÊâã‰ºù„ÅÑ„Åô„Çã„Çà„ÄúÔºÅ")
        
    else:
        parser.print_help()
        print("\nüí° „Éí„É≥„Éà: 'lambda3-gpu analyze' „ÅßËß£Êûê„ÇíÈñãÂßã„Åß„Åç„Çã„Çà„ÄúÔºÅ")

# ===============================
# Logging Setup
# ===============================

logger = logging.getLogger('lambda3_gpu')
handler = logging.StreamHandler()
formatter = logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.INFO)

# ===============================
# Constants
# ===============================

REQUIRED_PACKAGES = {
    'numpy': '1.20.0',
    'scipy': '1.7.0',
    'scikit-learn': '1.0.0',
}

OPTIONAL_PACKAGES = {
    'cupy': '10.0.0',
    'numba': '0.56.0',
    'plotly': '5.0.0',
}

DEFAULT_COMPUTE_CAPABILITY = '7.5'

# ===============================
# GPU Environment Detection
# ===============================

class GPUEnvironment:
    """GPUÁí∞Â¢É„ÅÆÊ§úÂá∫„Å®ÊÉÖÂ†±ÁÆ°ÁêÜ"""
    
    def __init__(self):
        self.has_cupy = False
        self.gpu_available = False
        self.gpu_name = 'Not Available'
        self.gpu_memory = 0.0
        self.cuda_version = 'Not Available'
        self.compute_capability = DEFAULT_COMPUTE_CAPABILITY
        
        self._detect_gpu()
    
    def _detect_gpu(self):
        """GPUÁí∞Â¢É„ÇíÊ§úÂá∫"""
        try:
            import cupy as cp
            self.has_cupy = True
            
            if cp.cuda.runtime.getDeviceCount() > 0:
                self.gpu_available = True
                self.gpu_name = self._get_device_name(cp)
                self.gpu_memory = self._get_device_memory(cp)
                self.cuda_version = self._get_cuda_version(cp)
                self.compute_capability = self._get_compute_capability(cp)
                
                logger.info(f"üéÆ GPU detected: {self.gpu_name}")
                logger.info(f"   Memory: {self.gpu_memory:.1f} GB")
                logger.info(f"   CUDA: {self.cuda_version}")
            else:
                logger.warning("‚ö†Ô∏è No GPU devices found")
                
        except ImportError:
            logger.warning("‚ö†Ô∏è CuPy not installed - GPU features disabled")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è GPU detection failed: {e}")
    
    def _get_device_name(self, cp) -> str:
        """GPU„Éá„Éê„Ç§„ÇπÂêç„ÇíÂèñÂæó"""
        try:
            props = cp.cuda.runtime.getDeviceProperties(0)
            return props['name'].decode('utf-8') if isinstance(props['name'], bytes) else props['name']
        except:
            return 'Unknown GPU'
    
    def _get_device_memory(self, cp) -> float:
        """GPU„É°„É¢„É™ÂÆπÈáè„ÇíÂèñÂæóÔºàGBÔºâ"""
        try:
            meminfo = cp.cuda.runtime.memGetInfo()
            return meminfo[1] / (1024**3)
        except:
            return 0.0
    
    def _get_compute_capability(self, cp) -> str:
        """Compute Capability„ÇíÂèñÂæó"""
        try:
            device = cp.cuda.runtime.getDevice()
            major = cp.cuda.runtime.deviceGetAttribute(75, device)
            minor = cp.cuda.runtime.deviceGetAttribute(76, device)
            return f"{major}.{minor}"
        except:
            return DEFAULT_COMPUTE_CAPABILITY
    
    def _get_cuda_version(self, cp) -> str:
        """CUDA„Éê„Éº„Ç∏„Éß„É≥„ÇíÂèñÂæó"""
        try:
            version = cp.cuda.runtime.runtimeGetVersion()
            major = version // 1000
            minor = (version % 1000) // 10
            return f"{major}.{minor}"
        except:
            return "Unknown"
    
    def get_info_dict(self) -> Dict[str, Any]:
        """Áí∞Â¢ÉÊÉÖÂ†±„ÇíËæûÊõ∏„ÅßËøî„Åô"""
        return {
            'available': self.gpu_available,
            'name': self.gpu_name,
            'memory_gb': self.gpu_memory,
            'cuda_version': self.cuda_version,
            'compute_capability': self.compute_capability,
            'has_cupy': self.has_cupy
        }

# ===============================
# Initialize GPU Environment
# ===============================

gpu_env = GPUEnvironment()

# Export global variables
HAS_CUPY = gpu_env.has_cupy
GPU_AVAILABLE = gpu_env.gpu_available
GPU_NAME = gpu_env.gpu_name
GPU_MEMORY = gpu_env.gpu_memory
GPU_COMPUTE_CAPABILITY = gpu_env.compute_capability
CUDA_VERSION_STR = gpu_env.cuda_version

# ===============================
# Utility Functions
# ===============================

def get_gpu_info() -> Dict[str, Any]:
    """GPUÊÉÖÂ†±„ÇíÂèñÂæó"""
    return gpu_env.get_info_dict()

def set_gpu_device(device_id: int) -> None:
    """‰ΩøÁî®„Åô„ÇãGPU„Éá„Éê„Ç§„Çπ„ÇíË®≠ÂÆö"""
    if GPU_AVAILABLE:
        import cupy as cp
        cp.cuda.Device(device_id).use()
        logger.info(f"GPU device set to: {device_id}")
    else:
        logger.warning("No GPU available")

def enable_gpu_logging(level: str = 'INFO') -> None:
    """GPUÈñ¢ÈÄ£„ÅÆ„É≠„Ç∞„É¨„Éô„É´„ÇíË®≠ÂÆö"""
    numeric_level = getattr(logging, level.upper(), None)
    if not isinstance(numeric_level, int):
        raise ValueError(f'Invalid log level: {level}')
    
    logger.setLevel(numeric_level)
    logging.getLogger('lambda3_gpu').setLevel(numeric_level)

def benchmark_gpu() -> Optional[float]:
    """Á∞°Âçò„Å™GPU„Éô„É≥„ÉÅ„Éû„Éº„ÇØÔºàGFLOPSÔºâ"""
    if not GPU_AVAILABLE:
        return None
    
    try:
        import cupy as cp
        size = 10000
        a = cp.random.rand(size, size, dtype=cp.float32)
        b = cp.random.rand(size, size, dtype=cp.float32)
        
        # Warm up
        cp.dot(a, b)
        cp.cuda.Stream.null.synchronize()
        
        # Benchmark
        import time
        start = time.time()
        for _ in range(10):
            cp.dot(a, b)
        cp.cuda.Stream.null.synchronize()
        elapsed = time.time() - start
        
        # Calculate GFLOPS
        gflops = (10 * 2 * size**3) / (elapsed * 1e9)
        return gflops
    except Exception as e:
        logger.warning(f"GPU benchmark failed: {e}")
        return None

# ===============================
# Public API
# ===============================

__all__ = [
    # Version info
    '__version__',
    '__author__',
    
    # CLI
    'cli',
    'show_banner',
    
    # GPU info
    'GPU_AVAILABLE',
    'GPU_NAME', 
    'GPU_MEMORY',
    'CUDA_VERSION_STR',
    'GPU_COMPUTE_CAPABILITY',
    
    # Classes (lazy import)
    'MDConfig',
    'ResidueAnalysisConfig',
    'MDLambda3DetectorGPU',
    'TwoStageAnalyzerGPU',
    
    # Functions
    'perform_two_stage_analysis_gpu',
    
    # Result classes
    'MDLambda3Result',
    'TwoStageLambda3Result',
    'ResidueLevelAnalysis',
    'ResidueEvent',
    
    # Visualization
    'Lambda3VisualizerGPU',
    'CausalityVisualizerGPU',
    
    # Utilities
    'get_gpu_info',
    'set_gpu_device',
    'enable_gpu_logging',
    'benchmark_gpu',
    
    # Errors
    'Lambda3GPUError',
    'GPUMemoryError',
    'GPUNotAvailableError'
]

# ===============================
# Lazy Imports
# ===============================

def __getattr__(name):
    """ÈÅÖÂª∂„Ç§„É≥„Éù„Éº„Éà„ÅßËµ∑ÂãïÊôÇÈñìÁü≠Á∏Æ"""
    
    # Config classes
    if name == 'MDConfig':
        from lambda3_gpu.analysis.md_lambda3_detector_gpu import MDConfig
        return MDConfig
    
    elif name == 'ResidueAnalysisConfig':
        from lambda3_gpu.analysis.two_stage_analyzer_gpu import ResidueAnalysisConfig
        return ResidueAnalysisConfig
    
    # Main classes
    elif name == 'MDLambda3DetectorGPU':
        from lambda3_gpu.analysis.md_lambda3_detector_gpu import MDLambda3DetectorGPU
        return MDLambda3DetectorGPU
    
    elif name == 'TwoStageAnalyzerGPU':
        from lambda3_gpu.analysis.two_stage_analyzer_gpu import TwoStageAnalyzerGPU
        return TwoStageAnalyzerGPU
    
    # Functions
    elif name == 'perform_two_stage_analysis_gpu':
        from lambda3_gpu.analysis.two_stage_analyzer_gpu import perform_two_stage_analysis_gpu
        return perform_two_stage_analysis_gpu
    
    # Result classes
    elif name in ['MDLambda3Result', 'TwoStageLambda3Result', 
                  'ResidueLevelAnalysis', 'ResidueEvent']:
        from lambda3_gpu.types import (
            MDLambda3Result, TwoStageLambda3Result,
            ResidueLevelAnalysis, ResidueEvent
        )
        return globals()[name]
    
    # Visualization
    elif name == 'Lambda3VisualizerGPU':
        from lambda3_gpu.visualization import Lambda3VisualizerGPU
        return Lambda3VisualizerGPU
    
    elif name == 'CausalityVisualizerGPU':
        from lambda3_gpu.visualization import CausalityVisualizerGPU
        return CausalityVisualizerGPU
    
    # Errors
    elif name in ['Lambda3GPUError', 'GPUMemoryError', 'GPUNotAvailableError']:
        from lambda3_gpu.errors import (
            Lambda3GPUError, GPUMemoryError, GPUNotAvailableError
        )
        return globals()[name]
    
    raise AttributeError(f"module {__name__!r} has no attribute {name!r}")

# ===============================
# Package Initialization
# ===============================

# Áí∞Â¢ÉÂ§âÊï∞Ë®≠ÂÆö
if 'LAMBDA3_GPU_MEMORY_LIMIT' in os.environ:
    try:
        memory_limit_gb = float(os.environ['LAMBDA3_GPU_MEMORY_LIMIT'])
        if GPU_AVAILABLE:
            import cupy as cp
            cp.cuda.MemoryPool().set_limit(size=int(memory_limit_gb * 1024**3))
            logger.info(f"GPU memory limit set to: {memory_limit_gb} GB")
    except ValueError:
        logger.warning("Invalid LAMBDA3_GPU_MEMORY_LIMIT value")

# Debug mode
if os.environ.get('LAMBDA3_DEBUG', '').lower() in ('1', 'true', 'yes'):
    enable_gpu_logging('DEBUG')
    logger.debug("Debug mode enabled")
    
# Show banner on import if interactive
if hasattr(sys, 'ps1'):  # Interactive mode
    show_banner()

# ===============================
# Initialization Complete
# ===============================

logger.info(f"Lambda¬≥ GPU v{__version__} initialized")
if GPU_AVAILABLE:
    logger.info(f"GPU: {GPU_NAME} ({GPU_MEMORY:.1f} GB)")
else:
    logger.info("Running in CPU mode")
