"""
LambdaÂ³ GPU-Accelerated MD Analysis Framework
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

ç’°ã¡ã‚ƒã‚“ãŒä½œã£ãŸè¶…é«˜é€ŸGPUç‰ˆLambdaÂ³ã ã‚ˆã€œï¼ğŸ’•
NO TIME, NO PHYSICS, ONLY STRUCTURE... but FASTER! ğŸš€

Basic usage:
    >>> from lambda3_gpu import MDLambda3DetectorGPU, MDConfig
    >>> config = MDConfig()
    >>> detector = MDLambda3DetectorGPU(config)
    >>> result = detector.analyze(trajectory)

Full documentation at https://github.com/your-repo/lambda3-gpu
"""

__version__ = '3.0.0-gpu'
__author__ = 'LambdaÂ³ Project (GPU Edition by Tamaki)'
__email__ = 'tamaki@miosync.inc'
__license__ = 'MIT'

import warnings
import logging
import sys
from typing import Optional

# ===============================
# GPUç’°å¢ƒãƒã‚§ãƒƒã‚¯
# ===============================

# CuPyã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦ã¿ã‚‹
try:
    import cupy as cp
    HAS_CUPY = True
    GPU_AVAILABLE = cp.cuda.is_available()
    
    if GPU_AVAILABLE:
        # GPUæƒ…å ±ã‚’å–å¾—
        GPU_DEVICE = cp.cuda.Device()
        GPU_NAME = GPU_DEVICE.name.decode('utf-8') if hasattr(GPU_DEVICE.name, 'decode') else str(GPU_DEVICE.name)
        GPU_MEMORY = GPU_DEVICE.mem_info[1] / 1024**3  # Total memory in GB
        GPU_COMPUTE_CAPABILITY = GPU_DEVICE.compute_capability
        
        # CUDA version
        CUDA_VERSION = cp.cuda.runtime.runtimeGetVersion()
        CUDA_VERSION_STR = f"{CUDA_VERSION // 1000}.{(CUDA_VERSION % 1000) // 10}"
    else:
        GPU_NAME = None
        GPU_MEMORY = 0
        GPU_COMPUTE_CAPABILITY = None
        CUDA_VERSION_STR = None
        
except ImportError:
    HAS_CUPY = False
    GPU_AVAILABLE = False
    GPU_NAME = None
    GPU_MEMORY = 0
    GPU_COMPUTE_CAPABILITY = None
    CUDA_VERSION_STR = None
    warnings.warn(
        "CuPy not installed! GPU acceleration disabled. "
        "Install with: pip install cupy-cuda11x (replace 11x with your CUDA version)",
        ImportWarning
    )

# ===============================
# ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
# ===============================

# å¿…é ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
REQUIRED_PACKAGES = {
    'numpy': '1.19.0',
    'scipy': '1.5.0',
    'numba': '0.50.0',
    'matplotlib': '3.2.0'
}

# ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
OPTIONAL_PACKAGES = {
    'cupy': '8.0.0',
    'cupyx': None,  # CuPyã«å«ã¾ã‚Œã‚‹
    'joblib': '0.16.0',
    'tqdm': '4.50.0'
}

def check_dependencies():
    """ä¾å­˜é–¢ä¿‚ã‚’ãƒã‚§ãƒƒã‚¯"""
    missing_required = []
    missing_optional = []
    
    for package, min_version in REQUIRED_PACKAGES.items():
        try:
            module = __import__(package)
            # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            if hasattr(module, '__version__'):
                current_version = module.__version__
                # TODO: ã‚ˆã‚Šå³å¯†ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¯”è¼ƒ
        except ImportError:
            missing_required.append(package)
    
    for package, min_version in OPTIONAL_PACKAGES.items():
        try:
            __import__(package)
        except ImportError:
            missing_optional.append(package)
    
    if missing_required:
        raise ImportError(
            f"Missing required packages: {', '.join(missing_required)}. "
            f"Please install with: pip install {' '.join(missing_required)}"
        )
    
    if missing_optional:
        warnings.warn(
            f"Missing optional packages for full functionality: {', '.join(missing_optional)}",
            ImportWarning
        )

# ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
check_dependencies()

# ===============================
# ãƒ­ã‚°è¨­å®š
# ===============================

# ãƒ­ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨­å®š
LOG_FORMAT = '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
DATE_FORMAT = '%Y-%m-%d %H:%M:%S'

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ­ã‚¬ãƒ¼è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format=LOG_FORMAT,
    datefmt=DATE_FORMAT
)

# Lambda3GPUå°‚ç”¨ãƒ­ã‚¬ãƒ¼
logger = logging.getLogger('lambda3_gpu')
logger.setLevel(logging.INFO)

# GPUçŠ¶æ…‹ãƒ­ã‚°
if GPU_AVAILABLE:
    logger.info(f"ğŸš€ GPU Enabled: {GPU_NAME}")
    logger.info(f"   Memory: {GPU_MEMORY:.1f} GB")
    logger.info(f"   CUDA: {CUDA_VERSION_STR}")
    logger.info(f"   Compute Capability: {GPU_COMPUTE_CAPABILITY}")
else:
    logger.warning("ğŸ’» Running in CPU mode (GPU not available)")

# ===============================
# ãƒ‘ãƒ–ãƒªãƒƒã‚¯API
# ===============================

# ç’°å¢ƒæƒ…å ±ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
__all__ = [
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
    '__version__',
    
    # GPUæƒ…å ±
    'GPU_AVAILABLE',
    'GPU_NAME',
    'GPU_MEMORY',
    'CUDA_VERSION_STR',
    
    # è¨­å®šã‚¯ãƒ©ã‚¹ï¼ˆé…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
    'MDConfig',
    'ResidueAnalysisConfig',
    
    # ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ï¼ˆé…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
    'MDLambda3DetectorGPU',
    'TwoStageAnalyzerGPU',
    
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    'get_gpu_info',
    'set_gpu_device',
    'enable_gpu_logging',
    'benchmark_gpu'
]

# ===============================
# é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# ===============================

def __getattr__(name):
    """é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§èµ·å‹•æ™‚é–“çŸ­ç¸®"""
    
    # è¨­å®šã‚¯ãƒ©ã‚¹
    if name == 'MDConfig':
        from lambda3_gpu.analysis.md_lambda3_detector_gpu import MDConfig
        return MDConfig
    
    elif name == 'ResidueAnalysisConfig':
        from lambda3_gpu.analysis.two_stage_analyzer_gpu import ResidueAnalysisConfig
        return ResidueAnalysisConfig
    
    # ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹
    elif name == 'MDLambda3DetectorGPU':
        from lambda3_gpu.analysis.md_lambda3_detector_gpu import MDLambda3DetectorGPU
        return MDLambda3DetectorGPU
    
    elif name == 'TwoStageAnalyzerGPU':
        from lambda3_gpu.analysis.two_stage_analyzer_gpu import TwoStageAnalyzerGPU
        return TwoStageAnalyzerGPU
    
    # ãã®ä»–
    raise AttributeError(f"module {__name__!r} has no attribute {name!r}")

# ===============================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ===============================

def get_gpu_info() -> dict:
    """GPUæƒ…å ±ã‚’å–å¾—"""
    return {
        'available': GPU_AVAILABLE,
        'name': GPU_NAME,
        'memory_gb': GPU_MEMORY,
        'cuda_version': CUDA_VERSION_STR,
        'compute_capability': GPU_COMPUTE_CAPABILITY,
        'has_cupy': HAS_CUPY
    }

def set_gpu_device(device_id: int = 0) -> bool:
    """ä½¿ç”¨ã™ã‚‹GPUãƒ‡ãƒã‚¤ã‚¹ã‚’è¨­å®š"""
    if not GPU_AVAILABLE:
        logger.warning("GPU not available, cannot set device")
        return False
    
    try:
        cp.cuda.Device(device_id).use()
        logger.info(f"Set GPU device to: {device_id}")
        return True
    except Exception as e:
        logger.error(f"Failed to set GPU device: {e}")
        return False

def enable_gpu_logging(level: str = 'DEBUG') -> None:
    """GPUé–¢é€£ã®è©³ç´°ãƒ­ã‚°ã‚’æœ‰åŠ¹åŒ–"""
    numeric_level = getattr(logging, level.upper(), None)
    if not isinstance(numeric_level, int):
        raise ValueError(f'Invalid log level: {level}')
    
    logger.setLevel(numeric_level)
    
    # CuPyã®ãƒ­ã‚°ã‚‚è¨­å®š
    if HAS_CUPY:
        cupy_logger = logging.getLogger('cupy')
        cupy_logger.setLevel(numeric_level)

def benchmark_gpu(size: int = 10000) -> Optional[dict]:
    """ç°¡æ˜“GPUãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
    if not GPU_AVAILABLE:
        logger.warning("GPU not available for benchmarking")
        return None
    
    import time
    
    # CPUè¨ˆæ¸¬
    import numpy as np
    cpu_array = np.random.randn(size, size).astype(np.float32)
    
    cpu_start = time.time()
    cpu_result = np.matmul(cpu_array, cpu_array)
    cpu_time = time.time() - cpu_start
    
    # GPUè¨ˆæ¸¬
    gpu_array = cp.asarray(cpu_array)
    
    gpu_start = time.time()
    gpu_result = cp.matmul(gpu_array, gpu_array)
    cp.cuda.Stream.null.synchronize()  # åŒæœŸå¾…ã¡
    gpu_time = time.time() - gpu_start
    
    speedup = cpu_time / gpu_time
    
    result = {
        'matrix_size': size,
        'cpu_time': cpu_time,
        'gpu_time': gpu_time,
        'speedup': speedup
    }
    
    logger.info(f"Benchmark result: {speedup:.1f}x speedup on {size}x{size} matrix multiplication")
    
    return result

# ===============================
# åˆæœŸåŒ–æ™‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
# ===============================

def _print_banner():
    """ã‹ã‚ã„ã„ãƒãƒŠãƒ¼è¡¨ç¤º"""
    if sys.stdout.isatty():  # ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã®å ´åˆã®ã¿
        print("\n" + "="*60)
        print("ğŸŒŸ LambdaÂ³ GPU - Structural Analysis at Light Speed! ğŸš€")
        print("="*60)
        if GPU_AVAILABLE:
            print(f"âœ¨ GPU Mode: {GPU_NAME} ({GPU_MEMORY:.1f}GB)")
        else:
            print("ğŸ’» CPU Mode (Install CuPy for GPU acceleration)")
        print("="*60 + "\n")

# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®ã¿ãƒãƒŠãƒ¼è¡¨ç¤º
if hasattr(sys, 'ps1'):
    _print_banner()

# ===============================
# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
# ===============================

class Lambda3GPUError(Exception):
    """Lambda3GPUåŸºæœ¬ä¾‹å¤–ã‚¯ãƒ©ã‚¹"""
    pass

class GPUMemoryError(Lambda3GPUError):
    """GPUãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼"""
    pass

class GPUNotAvailableError(Lambda3GPUError):
    """GPUåˆ©ç”¨ä¸å¯ã‚¨ãƒ©ãƒ¼"""
    pass

# ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª
import os

# GPUãƒ¡ãƒ¢ãƒªåˆ¶é™è¨­å®š
if 'LAMBDA3_GPU_MEMORY_LIMIT' in os.environ:
    try:
        memory_limit_gb = float(os.environ['LAMBDA3_GPU_MEMORY_LIMIT'])
        logger.info(f"GPU memory limit set to: {memory_limit_gb} GB")
        # TODO: å®Ÿéš›ã®ãƒ¡ãƒ¢ãƒªåˆ¶é™å®Ÿè£…
    except ValueError:
        logger.warning("Invalid LAMBDA3_GPU_MEMORY_LIMIT value")

# ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
if os.environ.get('LAMBDA3_DEBUG', '').lower() in ('1', 'true', 'yes'):
    enable_gpu_logging('DEBUG')
    logger.debug("Debug mode enabled")
