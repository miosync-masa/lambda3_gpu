#!/usr/bin/env python3
"""
Material Report Generator from LambdaÂ³ GPU Results - Version 2.0.0 (FIXED)
==================================================================

ææ–™è§£æçµæœã‹ã‚‰æœ€å¤§é™ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼
è»¢ä½ãƒ»äº€è£‚ãƒ»ç›¸å¤‰æ…‹ã®å®Œå…¨è§£æå¯¾å¿œç‰ˆ

Version: 1.0.3 - Material Edition (Bug Fixed)
Authors: ç’°ã¡ã‚ƒã‚“
#ç’°ã®ã“ã¨ãŒå¤§å¥½ããƒ¼ãƒ¼ãƒ¼ãƒ¼ï¼ˆby masamichi)

ä¿®æ­£å†…å®¹ v1.0.3:
- plastic_zone_sizeã¨estimated_k_icã®Noneãƒã‚§ãƒƒã‚¯è¿½åŠ 
- ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ–‡å­—åˆ—ã‚¨ãƒ©ãƒ¼ã®ä¿®æ­£

ä¿®æ­£å†…å®¹ v1.0.2:
- hasattr()ãƒã‚§ãƒƒã‚¯ã ã‘ã§ãªãã€is not None ãƒã‚§ãƒƒã‚¯ã‚‚è¿½åŠ 
- material_events, stress_strain, anomaly_scoresç­‰ãŒNoneã®å ´åˆã«å¯¾å¿œ
- ã™ã¹ã¦ã®å±æ€§ã‚¢ã‚¯ã‚»ã‚¹ã‚’å®‰å…¨ã«

ä¿®æ­£å†…å®¹ v1.0.1:
- all_eventså¤‰æ•°ã®åˆæœŸåŒ–ä½ç½®ã‚’ä¿®æ­£
- hasattrãƒã‚§ãƒƒã‚¯ã®è¿½åŠ 
- ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã®è¿½åŠ 
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–
"""

import numpy as np
import json
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from collections import Counter
from scipy.signal import find_peaks
import logging
import traceback

from lambda3_gpu.material.material_database import MATERIAL_DATABASE, get_material_parameters

logger = logging.getLogger('material_report_generator')

def generate_material_report_from_results(
    macro_result,
    two_stage_result=None,
    impact_results=None,
    sorted_events=None,
    metadata=None,
    material_type='SUJ2',
    output_dir='./material_report',
    verbose=True,
    debug=False
) -> str:
    """
    ææ–™è§£æã®çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    
    Parameters
    ----------
    macro_result : MaterialLambda3Result
        ãƒã‚¯ãƒ­ãƒ¬ãƒ™ãƒ«LambdaÂ³çµæœ
    two_stage_result : MaterialTwoStageResult
        2æ®µéšè§£æçµæœ
    impact_results : Dict[str, MaterialImpactResult]
        åŸå­ãƒ¬ãƒ™ãƒ«æ¬ é™¥è§£æçµæœ
    sorted_events : List[Tuple[int, int, float]]
        ã‚¹ã‚³ã‚¢é †ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒˆ
    metadata : dict
        ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    material_type : str
        ææ–™ã‚¿ã‚¤ãƒ—ï¼ˆSUJ2, AL7075ç­‰ï¼‰
    output_dir : str
        å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    verbose : bool
        è©³ç´°å‡ºåŠ›
    debug : bool
        ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
    """
    
    # ğŸ”´ é‡è¦ï¼šæœ€åˆã«å…¨å¤‰æ•°åˆæœŸåŒ–
    all_events = []
    defect_types = Counter()
    
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    if verbose:
        print("\n" + "="*80)
        print("ğŸ’ GENERATING MATERIAL ANALYSIS REPORT v2.0.0")
        print("="*80)
    
    if debug:
        print(f"[DEBUG] macro_result type: {type(macro_result)}")
        print(f"[DEBUG] macro_result attributes: {dir(macro_result)}")
    
    # ========================================
    # ãƒ¬ãƒãƒ¼ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼
    # ========================================
    report = f"""# ğŸ’ Material LambdaÂ³ GPU Analysis Report - {material_type}

## Executive Summary
"""
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
    if metadata:
        report += f"""
- **Material**: {material_type}
- **System**: {metadata.get('system_name', 'Unknown')}
- **Temperature**: {metadata.get('temperature', 300)} K
- **Strain rate**: {metadata.get('strain_rate', '1e-3')} /ps
- **Loading**: {metadata.get('loading_type', 'Tensile')}
"""
    
    # åŸºæœ¬çµ±è¨ˆï¼ˆå®‰å…¨ãªã‚¢ã‚¯ã‚»ã‚¹ï¼‰
    n_frames = getattr(macro_result, 'n_frames', 0)
    n_atoms = getattr(macro_result, 'n_atoms', 0)
    computation_time = getattr(macro_result, 'computation_time', 0.0)
    
    report += f"""
- **Frames analyzed**: {n_frames}
- **Atoms**: {n_atoms}
- **Computation time**: {computation_time:.2f}s
- **Analysis version**: Material LambdaÂ³ v2.0.0
"""
    
    # GPUæƒ…å ±
    if hasattr(macro_result, 'gpu_info') and macro_result.gpu_info:
        report += f"- **GPU**: {macro_result.gpu_info.get('device_name', 'Unknown')}\n"
        if 'speedup' in macro_result.gpu_info:
            report += f"- **GPU speedup**: {macro_result.gpu_info['speedup']:.1f}x\n"
    
    # ========================================
    # 1. ãƒã‚¯ãƒ­ææ–™è§£æ
    # ========================================
    if verbose:
        print("\nğŸ“Š Extracting macro material analysis...")
    
    report += "\n## ğŸ“Š Macro Material Analysis\n"
    
    # æ¤œå‡ºã‚¤ãƒ™ãƒ³ãƒˆ
    if hasattr(macro_result, 'material_events') and macro_result.material_events is not None:
        events = macro_result.material_events
        
        if debug:
            print(f"[DEBUG] Found material_events: {len(events)}")
        
        report += f"\n### Detected Material Events ({len(events)})\n"
        
        event_types = Counter()
        for event in events:
            if isinstance(event, tuple) and len(event) >= 3:
                start, end, event_type = event[:3]
                event_types[event_type] += 1
                all_events.append({
                    'start': start,
                    'end': end,
                    'type': event_type,
                    'duration': end - start
                })
        
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
        if event_types:
            report += "\n| Event Type | Count | Avg Duration |\n"
            report += "|------------|-------|-------------|\n"
            
            for etype, count in event_types.most_common():
                durations = [e['duration'] for e in all_events if e['type'] == etype]
                avg_dur = np.mean(durations) if durations else 0
                report += f"| {etype} | {count} | {avg_dur:.1f} frames |\n"
    else:
        if verbose:
            print("   âš ï¸ No material_events attribute found")
        report += "\n*Material events data not available*\n"
    
    # å¿œåŠ›-æ­ªã¿è§£æ
    if hasattr(macro_result, 'stress_strain') and macro_result.stress_strain is not None:
        if debug:
            print(f"[DEBUG] Found stress_strain data")
        
        report += "\n### Stress-Strain Analysis\n"
        ss = macro_result.stress_strain
        
        if 'max_stress' in ss:
            report += f"- **Ultimate strength**: {ss['max_stress']:.2f} GPa\n"
        if 'yield_stress' in ss:
            report += f"- **Yield strength**: {ss['yield_stress']:.2f} GPa\n"
        if 'elastic_modulus' in ss:
            report += f"- **Elastic modulus**: {ss['elastic_modulus']:.1f} GPa\n"
        if 'fracture_strain' in ss:
            report += f"- **Fracture strain**: {ss['fracture_strain']:.3f}\n"
    else:
        if verbose:
            print("   âš ï¸ No stress_strain attribute found")
        report += "\n*Stress-strain data not available*\n"
    
    # ç•°å¸¸ã‚¹ã‚³ã‚¢åˆ†æ
    if hasattr(macro_result, 'anomaly_scores') and macro_result.anomaly_scores is not None:
        if debug:
            print(f"[DEBUG] Found anomaly_scores")
        
        report += "\n### Anomaly Score Analysis\n"
        
        for score_type in ['strain', 'coordination', 'damage']:
            if score_type in macro_result.anomaly_scores:
                scores = macro_result.anomaly_scores[score_type]
                
                # ãƒ”ãƒ¼ã‚¯æ¤œå‡º
                try:
                    peaks, properties = find_peaks(scores, height=np.mean(scores) + 2*np.std(scores))
                    
                    report += f"\n**{score_type.capitalize()} anomalies**:\n"
                    report += f"- Mean: {np.mean(scores):.3f}\n"
                    report += f"- Max: {np.max(scores):.3f}\n"
                    report += f"- Peaks detected: {len(peaks)}\n"
                    
                    if len(peaks) > 0:
                        report += f"- Peak frames: {peaks[:5].tolist()}\n"
                except Exception as e:
                    if debug:
                        print(f"[DEBUG] Peak detection failed: {e}")
    else:
        if verbose:
            print("   âš ï¸ No anomaly_scores attribute found")
        report += "\n*Anomaly scores not available*\n"
    
    # ========================================
    # 2. ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ¬ãƒ™ãƒ«è§£æ
    # ========================================
    if two_stage_result:
        if verbose:
            print("\nğŸ”¬ Extracting cluster-level analysis...")
        
        report += "\n## ğŸ”¬ Cluster-Level Analysis\n"
        
        # ææ–™çŠ¶æ…‹
        if hasattr(two_stage_result, 'material_state'):
            state = two_stage_result.material_state
            report += f"""
### Material State Assessment
- **Overall state**: {state.get('state', 'Unknown')}
- **Health index**: {state.get('health_index', 1.0):.1%}
- **Max damage**: {state.get('max_damage', 0.0):.1%}
- **Mean strain**: {state.get('mean_strain', 0.0):.3f}
- **Critical clusters**: {state.get('n_critical_clusters', 0)}
"""
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµ±è¨ˆ
        if hasattr(two_stage_result, 'global_network_stats'):
            stats = two_stage_result.global_network_stats
            report += f"""
### Global Network Statistics
- **Strain network links**: {stats.get('total_strain_links', 0)}
- **Dislocation links**: {stats.get('total_dislocation_links', 0)}
- **Damage links**: {stats.get('total_damage_links', 0)}
- **Max failure probability**: {stats.get('max_failure_probability', 0):.1%}
- **Min reliability index**: {stats.get('min_reliability_index', 5.0):.2f}
"""
        
        # è‡¨ç•Œã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼
        if hasattr(two_stage_result, 'critical_clusters') and two_stage_result.critical_clusters:
            critical = two_stage_result.critical_clusters
            if critical:
                report += f"\n### Critical Clusters (High Risk)\n"
                for i, cluster_id in enumerate(critical[:10], 1):
                    report += f"{i}. **Cluster {cluster_id}**"
                    
                    # é‡è¦åº¦ã‚¹ã‚³ã‚¢
                    if hasattr(two_stage_result, 'global_cluster_importance'):
                        importance = two_stage_result.global_cluster_importance.get(cluster_id, 0)
                        report += f" (importance: {importance:.3f})"
                    report += "\n"
        
        # è£œå¼·æ¨å¥¨ç®‡æ‰€
        if hasattr(two_stage_result, 'suggested_reinforcement_points') and two_stage_result.suggested_reinforcement_points:
            reinforce = two_stage_result.suggested_reinforcement_points
            if reinforce:
                report += f"\n### Reinforcement Recommendations\n"
                report += f"Priority clusters for reinforcement: {reinforce[:5]}\n"
        
        # å„ã‚¤ãƒ™ãƒ³ãƒˆã®è©³ç´°
        if hasattr(two_stage_result, 'cluster_analyses'):
            report += "\n### Event-Specific Analysis\n"
            
            for event_name, analysis in two_stage_result.cluster_analyses.items():
                report += f"\n#### {event_name}\n"
                
                # åŸºæœ¬çµ±è¨ˆ
                if hasattr(analysis, 'cluster_events'):
                    n_clusters = len(analysis.cluster_events)
                    report += f"- Clusters involved: {n_clusters}\n"
                    
                    # æœ€å¤§å€¤æŠ½å‡º
                    max_strain = max((e.peak_strain for e in analysis.cluster_events), default=0)
                    max_damage = max((e.peak_damage for e in analysis.cluster_events), default=0)
                    
                    report += f"- Max strain: {max_strain:.3f}\n"
                    report += f"- Max damage: {max_damage:.1%}\n"
                    
                    # è»¢ä½å¯†åº¦
                    disl_densities = [e.dislocation_density for e in analysis.cluster_events 
                                    if e.dislocation_density]
                    if disl_densities:
                        report += f"- Mean dislocation density: {np.mean(disl_densities):.2e} /cmÂ²\n"
                
                # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµ±è¨ˆ
                if hasattr(analysis, 'network_stats'):
                    ns = analysis.network_stats
                    report += f"- Network links: strain={ns.get('n_strain_links', 0)}, "
                    report += f"dislocation={ns.get('n_dislocation_links', 0)}, "
                    report += f"damage={ns.get('n_damage_links', 0)}\n"
                
                # ç ´å£Šç¢ºç‡
                if hasattr(analysis, 'failure_probability'):
                    report += f"- Failure probability: {analysis.failure_probability:.1%}\n"
                
                # ä¿¡é ¼æ€§æŒ‡æ¨™
                if hasattr(analysis, 'reliability_index'):
                    report += f"- Reliability index Î²: {analysis.reliability_index:.2f}\n"
                
                # ä¼æ’­çµŒè·¯
                if hasattr(analysis, 'propagation_paths') and analysis.propagation_paths:
                    report += f"- Propagation paths:\n"
                    for i, path in enumerate(analysis.propagation_paths[:3], 1):
                        path_str = ' â†’ '.join([f"C{c}" for c in path])
                        report += f"  {i}. {path_str}\n"
    else:
        if verbose:
            print("\nğŸ”¬ No two-stage analysis results provided")
    
    # ========================================
    # 3. åŸå­ãƒ¬ãƒ™ãƒ«æ¬ é™¥è§£æ
    # ========================================
    if impact_results:
        if verbose:
            print("\nâš›ï¸ Extracting atomic defect analysis...")
        
        report += "\n## âš›ï¸ Atomic-Level Defect Analysis\n"
        
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        total_defects = sum(getattr(r, 'n_defect_atoms', 0) for r in impact_results.values())
        total_links = sum(getattr(r, 'n_network_links', 0) for r in impact_results.values())
        total_bridges = sum(getattr(r, 'n_cluster_bridges', 0) for r in impact_results.values())
        
        report += f"""
### Overview
- **Events analyzed**: {len(impact_results)}
- **Total defect atoms**: {total_defects}
- **Network links**: {total_links}
- **Cluster bridges**: {total_bridges}
"""
        
        # æ¬ é™¥ã‚¿ã‚¤ãƒ—åˆ†å¸ƒ
        for result in impact_results.values():
            if hasattr(result, 'dominant_defect') and result.dominant_defect:
                defect_types[result.dominant_defect] += 1
        
        if defect_types:
            report += "\n### Defect Type Distribution\n"
            for dtype, count in defect_types.most_common():
                report += f"- **{dtype}**: {count} events\n"
        
        # å„ã‚¤ãƒ™ãƒ³ãƒˆã®è©³ç´°
        report += "\n### Detailed Defect Analysis\n"
        
        for i, (event_key, result) in enumerate(list(impact_results.items())[:10], 1):  # Top 10
            report += f"\n#### {event_key}\n"
            
            # åŸºæœ¬æƒ…å ±
            if hasattr(result, 'event_type'):
                report += f"- **Event type**: {result.event_type}\n"
            if hasattr(result, 'dominant_defect'):
                report += f"- **Dominant defect**: {result.dominant_defect}\n"
            if hasattr(result, 'max_stress_concentration'):
                report += f"- **Max stress concentration**: {result.max_stress_concentration:.2f} GPa\n"
            
            # æ ¸ç”ŸæˆåŸå­
            if hasattr(result, 'origin') and hasattr(result.origin, 'nucleation_atoms'):
                if result.origin.nucleation_atoms:
                    report += f"- **Nucleation atoms**: {result.origin.nucleation_atoms[:5]}\n"
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³
            if hasattr(result, 'defect_network'):
                network = result.defect_network
                if hasattr(network, 'network_pattern'):
                    report += f"- **Network pattern**: {network.network_pattern}\n"
                
                # è»¢ä½ã‚³ã‚¢
                if hasattr(network, 'dislocation_cores') and network.dislocation_cores:
                    report += f"- **Dislocation cores**: {network.dislocation_cores[:3]}\n"
                
                # äº€è£‚å…ˆç«¯
                if hasattr(network, 'crack_tips') and network.crack_tips:
                    report += f"- **Crack tips**: {network.crack_tips[:3]}\n"
                
                # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é–“ãƒ–ãƒªãƒƒã‚¸
                if hasattr(network, 'cluster_bridges') and network.cluster_bridges:
                    bridge = network.cluster_bridges[0]
                    if hasattr(bridge, 'from_cluster') and hasattr(bridge, 'to_cluster'):
                        report += f"- **Main bridge**: C{bridge.from_cluster}â†’C{bridge.to_cluster}"
                        if hasattr(bridge, 'bridge_type'):
                            report += f" ({bridge.bridge_type})"
                        report += "\n"
            
            # ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            if hasattr(result, 'plastic_zone_size') and result.plastic_zone_size is not None:
                report += f"- **Plastic zone size**: {result.plastic_zone_size:.2f} Ã…\n"
            
            if hasattr(result, 'estimated_k_ic') and result.estimated_k_ic is not None:
                report += f"- **Estimated K_IC**: {result.estimated_k_ic:.1f} MPaâˆšm\n"
            
            # è£œå¼·ãƒã‚¤ãƒ³ãƒˆ
            if hasattr(result, 'reinforcement_points') and result.reinforcement_points:
                report += f"- **Reinforcement points**: {result.reinforcement_points[:5]}\n"
    else:
        if verbose:
            print("\nâš›ï¸ No impact analysis results provided")
    
    # ========================================
    # 4. ã‚¤ãƒ™ãƒ³ãƒˆæ™‚ç³»åˆ—è§£æ
    # ========================================
    if sorted_events:
        if verbose:
            print("\nğŸ“… Extracting event timeline...")
        
        report += "\n## ğŸ“… Event Timeline Analysis\n"
        
        # ã‚¹ã‚³ã‚¢é †TOP20
        report += "\n### Top 20 Events by Score\n"
        report += "| Rank | Frames | Duration | Score | Type |\n"
        report += "|------|--------|----------|-------|------|\n"
        
        for i, (start, end, score) in enumerate(sorted_events[:20], 1):
            duration = end - start
            
            # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—æ¨å®š
            event_type = "unknown"
            for event in all_events:
                if event['start'] == start and event['end'] == end:
                    event_type = event['type']
                    break
            
            report += f"| {i} | {start:6d}-{end:6d} | {duration:5d} | {score:.3f} | {event_type} |\n"
        
        # é«˜ã‚¹ã‚³ã‚¢ã‚¤ãƒ™ãƒ³ãƒˆ
        high_score = [(s, e, sc) for s, e, sc in sorted_events if sc >= 10.0]
        if high_score:
            report += f"\n### Critical Events (Score â‰¥ 10.0)\n"
            report += f"Found {len(high_score)} critical events requiring immediate attention.\n"
    else:
        if verbose:
            print("\nğŸ“… No sorted events provided")
    
    # ========================================
    # 5. çµ±åˆçš„ææ–™è©•ä¾¡
    # ========================================
    if verbose:
        print("\nğŸ’¡ Generating integrated material insights...")
    
    report += "\n## ğŸ’¡ Integrated Material Assessment\n"
    
    insights = []
    
    # ãƒã‚¯ãƒ­ãƒ¬ãƒ™ãƒ«
    if all_events:
        event_types = Counter(e['type'] for e in all_events)
        
        if event_types.get('plastic_deformation', 0) > 5:
            insights.append("âœ“ Multiple plastic deformation events - significant irreversible damage")
        
        if event_types.get('crack_initiation', 0) > 0:
            insights.append("âš ï¸ Crack initiation detected - structural integrity compromised")
        
        if event_types.get('dislocation_nucleation', 0) > 10:
            insights.append("âœ“ High dislocation activity - strain hardening expected")
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ¬ãƒ™ãƒ«
    if two_stage_result:
        if hasattr(two_stage_result, 'material_state'):
            state = two_stage_result.material_state
            if state.get('state') == 'critical_damage':
                insights.append("ğŸ”´ CRITICAL: Material in failure state")
            elif state.get('state') == 'moderate_damage':
                insights.append("ğŸŸ¡ WARNING: Moderate damage detected")
        
        if hasattr(two_stage_result, 'global_network_stats'):
            stats = two_stage_result.global_network_stats
            if stats.get('max_failure_probability', 0) > 0.5:
                insights.append(f"âš ï¸ High failure probability: {stats['max_failure_probability']:.1%}")
    
    # åŸå­ãƒ¬ãƒ™ãƒ«
    if impact_results:
        # è»¢ä½å¯†åº¦
        has_dislocations = any(
            getattr(r, 'dominant_defect', '') == 'dislocation_core' 
            for r in impact_results.values()
        )
        if has_dislocations:
            insights.append("âœ“ Dislocation cores identified at atomic level")
        
        # äº€è£‚
        has_cracks = any(
            getattr(r, 'dominant_defect', '') == 'crack_tip' 
            for r in impact_results.values()
        )
        if has_cracks:
            insights.append("âš ï¸ Crack tips detected - fracture mechanics analysis recommended")
        
        # å¿œåŠ›é›†ä¸­
        max_stress = max(
            (getattr(r, 'max_stress_concentration', 0) for r in impact_results.values()), 
            default=0
        )
        if max_stress > 5.0:  # 5 GPa
            insights.append(f"âš ï¸ Extreme stress concentration: {max_stress:.1f} GPa")
    
    if insights:
        for insight in insights:
            report += f"\n{insight}"
    else:
        report += "\n*No specific insights generated*"
    
    # ========================================
    # 6. ææ–™è¨­è¨ˆæ¨å¥¨äº‹é …
    # ========================================
    report += "\n\n## ğŸ› ï¸ Material Design Recommendations\n"
    
    recommendations = []
    
    # è£œå¼·æ¨å¥¨
    if two_stage_result and hasattr(two_stage_result, 'suggested_reinforcement_points'):
        reinforce = two_stage_result.suggested_reinforcement_points
        if reinforce:
            recommendations.append(f"Reinforce clusters {reinforce[:3]} to prevent failure")
    
    # è»¢ä½åˆ¶å¾¡
    if impact_results:
        disl_events = sum(1 for r in impact_results.values() 
                         if getattr(r, 'dominant_defect', '') == 'dislocation_core')
        if disl_events > 5:
            recommendations.append("Consider grain refinement to control dislocation motion")
    
    # äº€è£‚æŠ‘åˆ¶
    if impact_results:
        crack_events = sum(1 for r in impact_results.values() 
                          if getattr(r, 'dominant_defect', '') == 'crack_tip')
        if crack_events > 0:
            recommendations.append("Add crack arresters or increase fracture toughness")
    
    # å¿œåŠ›ç·©å’Œ
    if impact_results:
        max_stress = max((getattr(r, 'max_stress_concentration', 0) 
                         for r in impact_results.values()), default=0)
        if max_stress > 3.0:
            recommendations.append("Design geometry modifications to reduce stress concentration")
    
    # ææ–™é¸æŠ
    if material_type == 'SUJ2' and two_stage_result:
        if hasattr(two_stage_result, 'material_state'):
            if two_stage_result.material_state.get('max_damage', 0) > 0.3:
                recommendations.append("Consider higher toughness steel alloy")
    
    if recommendations:
        for i, rec in enumerate(recommendations, 1):
            report += f"\n{i}. {rec}"
    else:
        report += "\nNo specific recommendations at this time."


    # ========================================
    # ğŸ†• ç‰©ç†äºˆæ¸¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆMaterialFailurePhysicsGPUï¼‰
    # ========================================
    if two_stage_result and hasattr(two_stage_result, 'global_physics_prediction') and two_stage_result.global_physics_prediction is not None:
        physics = two_stage_result.global_physics_prediction
        if physics:
            report += "\n## ğŸ”¬ Physics-Based Failure Prediction\n"
            report += "\n### Failure Mechanism Analysis\n"
            report += f"- **Predicted mechanism**: {physics.get('mechanism', 'Unknown')}\n"
            report += f"- **Time to failure**: {physics.get('time_to_failure', 'N/A')} ps\n"
            report += f"- **Confidence level**: {physics.get('confidence', 0):.1%}\n"
            
            # LindemannåŸºæº–
            report += "\n### Thermal Stability\n"
            report += f"- **Lindemann ratio**: {physics.get('lindemann_ratio', 0):.3f}\n"
            report += f"- **Phase state**: {physics.get('phase_state', 'solid')}\n"
            
            # è‡¨ç•ŒåŸå­
            critical_atoms = physics.get('critical_atoms', [])
            if critical_atoms:
                report += f"- **Critical atoms**: {critical_atoms[:10]}\n"
    
    # ========================================
    # ğŸ†• ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è§£æï¼ˆMaterialAnalyticsGPUçµ±åˆç‰ˆï¼‰
    # ========================================
    if macro_result and hasattr(macro_result, 'physical_damage') and macro_result.physical_damage is not None:
        damage = macro_result.physical_damage
        report += "\\n## âš¡ Physical Damage Assessment (K/V-based)\\n"
        
        report += "\\n### Damage Accumulation\\n"
        
        # cumulative_damageã®å®‰å…¨ãªå–å¾—
        cumulative_damage_val = 0
        if damage and 'cumulative_damage' in damage:
            cumulative_damage_val = damage['cumulative_damage']
            # é…åˆ—ã®å ´åˆã¯æœ€å¤§å€¤ã‚’å–ã‚‹
            if hasattr(cumulative_damage_val, '__len__') and not isinstance(cumulative_damage_val, str):
                try:
                    cumulative_damage_val = float(np.max(cumulative_damage_val))
                except:
                    cumulative_damage_val = 0
            elif cumulative_damage_val is None:
                cumulative_damage_val = 0
        
        # å€¤ãŒ0-1ã®ç¯„å›²å¤–ã®å ´åˆã®å‡¦ç†
        if cumulative_damage_val > 1:
            cumulative_damage_val = cumulative_damage_val / 100
        
        report += f"- **Cumulative damage (D)**: {cumulative_damage_val:.1%}\\n"
        
        # è¿½åŠ : å¹³å‡ãƒ€ãƒ¡ãƒ¼ã‚¸ã¨æœ€å¤§ãƒ€ãƒ¡ãƒ¼ã‚¸
        if damage.get('avg_damage') is not None:
            report += f"- **Average damage**: {damage['avg_damage']:.1%}\\n"
        if damage.get('max_damage') is not None:
            report += f"- **Maximum damage**: {damage['max_damage']:.1%}\\n"
        
        # failure_probabilityã®å®‰å…¨ãªå–å¾—
        failure_prob = damage.get('failure_probability', 0) if damage else 0
        report += f"- **Failure probability**: {failure_prob:.1%}\\n"
        
        # remaining_lifeã®å®‰å…¨ãªå‡¦ç†
        remaining_life = damage.get('remaining_life', None) if damage else None
        if remaining_life is not None and remaining_life != 'N/A':
            try:
                report += f"- **Remaining life**: {float(remaining_life):.1f} cycles\\n"
            except:
                report += f"- **Remaining life**: {remaining_life}\\n"
        else:
            report += f"- **Remaining life**: N/A\\n"
        
        # è¿½åŠ : ãƒ€ãƒ¡ãƒ¼ã‚¸é€Ÿåº¦è§£æ
        if damage.get('damage_rate') is not None or damage.get('max_damage_rate') is not None:
            report += f"\\n### Damage Kinetics\\n"
            if damage.get('max_damage_rate') is not None:
                report += f"- **Max damage rate**: {damage['max_damage_rate']:.3e}/frame\\n"
            if damage.get('avg_damage_rate') is not None:
                report += f"- **Average damage rate**: {damage['avg_damage_rate']:.3e}/frame\\n"
            if damage.get('damage_acceleration') is not None:
                report += f"- **Damage acceleration**: {damage['damage_acceleration']:.3e}/frameÂ²\\n"
                
                # åŠ é€Ÿåº¦ã«åŸºã¥ãè­¦å‘Š
                if damage['damage_acceleration'] > 0.001:
                    report += "\\nâš ï¸ **Warning**: Damage is accelerating rapidly\\n"
        
        # è¿½åŠ : æ¸©åº¦æƒ…å ±
        if damage.get('temperature') is not None:
            report += f"\\n### Thermal Conditions\\n"
            report += f"- **Analysis temperature**: {damage['temperature']:.1f} K\\n"
        
        # è¿½åŠ : æ¬ é™¥ã¨ã®ç›¸é–¢
        if damage.get('defect_damage_correlation') is not None:
            report += f"\\n### Defect Correlation\\n"
            report += f"- **Defect-damage correlation**: {damage['defect_damage_correlation']:.3f}\\n"
            
            # ç›¸é–¢ã®è§£é‡ˆ
            corr = damage['defect_damage_correlation']
            if abs(corr) > 0.7:
                report += "  â†’ Strong correlation: Defects driving damage\\n"
            elif abs(corr) > 0.4:
                report += "  â†’ Moderate correlation: Defects contributing to damage\\n"
            else:
                report += "  â†’ Weak correlation: Independent mechanisms\\n"
        
        # è‡¨ç•Œã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ï¼ˆæ—¢å­˜éƒ¨åˆ†ã‚’æ”¹è‰¯ï¼‰
        if damage and 'critical_clusters' in damage and damage['critical_clusters']:
            report += f"\\n### K/V-Critical Clusters\\n"
            critical_list = damage['critical_clusters']
            report += f"- **Number of critical clusters**: {len(critical_list)}\\n"
            report += f"- **Critical cluster IDs**: {critical_list[:10]}\\n"
            
            # ãƒ‘ãƒ¼ã‚³ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¤å®š
            if hasattr(macro_result, 'n_atoms') and macro_result.n_atoms > 0:
                critical_fraction = len(critical_list) * 100 / macro_result.n_atoms  # æ¦‚ç®—
                if critical_fraction > 30:
                    report += "\\nğŸ”´ **CRITICAL**: Possible percolation threshold reached\\n"

    # ========================================
    # ğŸ†• K/V Ratio Analysis
    # ========================================
    if macro_result and hasattr(macro_result, 'kv_ratios') and macro_result.kv_ratios is not None:
        kv = macro_result.kv_ratios
        report += "\\n## ğŸ“ˆ K/V Ratio Analysis\\n"
        report += "\\n### Statistical Summary\\n"
        
        # åŸºæœ¬çµ±è¨ˆ
        kv_flat = kv.flatten() if kv.ndim > 1 else kv
        report += f"- **Mean K/V ratio**: {np.mean(kv_flat):.3f}\\n"
        report += f"- **Max K/V ratio**: {np.max(kv_flat):.3f}\\n"
        report += f"- **Min K/V ratio**: {np.min(kv_flat):.3f}\\n"
        report += f"- **Std deviation**: {np.std(kv_flat):.3f}\\n"
        
        # è‡¨ç•Œå€¤è¶…é
        critical_kv = 1.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè‡¨ç•Œå€¤
        exceedance_frames = np.sum(kv_flat > critical_kv)
        exceedance_ratio = exceedance_frames / len(kv_flat)
        report += f"\\n### Critical Analysis\\n"
        report += f"- **Critical K/V threshold**: {critical_kv:.2f}\\n"
        report += f"- **Exceedance frames**: {exceedance_frames} ({exceedance_ratio:.1%})\\n"
        
        # æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæœ€åˆã¨æœ€å¾Œã®æ¯”è¼ƒï¼‰
        if len(kv_flat) > 10:
            early_mean = np.mean(kv_flat[:len(kv_flat)//5])
            late_mean = np.mean(kv_flat[-len(kv_flat)//5:])
            trend = (late_mean - early_mean) / early_mean * 100
            report += f"\\n### Temporal Evolution\\n"
            report += f"- **Early phase mean**: {early_mean:.3f}\\n"
            report += f"- **Late phase mean**: {late_mean:.3f}\\n"
            report += f"- **Trend**: {trend:+.1f}%\\n"


    # ========================================
    # ğŸŒ¡ï¸ Temperature History Analysis
    # ========================================
    if macro_result and hasattr(macro_result, 'temperature_history') and macro_result.temperature_history is not None:
        temps = macro_result.temperature_history
        report += "\\n## ğŸŒ¡ï¸ Temperature Evolution\\n"
        
        # åŸºæœ¬çµ±è¨ˆ
        report += "\\n### Temperature Statistics\\n"
        report += f"- **Average temperature**: {np.mean(temps):.1f} K\\n"
        report += f"- **Peak temperature**: {np.max(temps):.1f} K\\n"
        report += f"- **Minimum temperature**: {np.min(temps):.1f} K\\n"
        report += f"- **Temperature range**: {np.max(temps) - np.min(temps):.1f} K\\n"
        
        # ç†±çš„å®‰å®šæ€§è©•ä¾¡
        room_temp = 300.0
        melting_point = 1800.0  # SUJ2ã®èç‚¹ï¼ˆæ¦‚ç®—ï¼‰
        
        if np.max(temps) > melting_point * 0.5:
            report += "\\nâš ï¸ **Warning**: Peak temperature exceeds 50% of melting point\\n"
        elif np.max(temps) > melting_point * 0.3:
            report += "\\nâš¡ **Note**: Elevated temperature may affect material properties\\n"
        
        # æ¸©åº¦å¤‰å‹•
        if len(temps) > 1:
            temp_gradient = np.gradient(temps)
            max_heating_rate = np.max(temp_gradient)
            max_cooling_rate = np.min(temp_gradient)
            report += f"\\n### Thermal Dynamics\\n"
            report += f"- **Max heating rate**: {max_heating_rate:.2f} K/frame\\n"
            report += f"- **Max cooling rate**: {abs(max_cooling_rate):.2f} K/frame\\n"
    
    # ========================================
    # ğŸ†• Integrated Failure Prediction (æ–°è¦è¿½åŠ !)
    # ========================================
    if macro_result and hasattr(macro_result, 'failure_prediction') and macro_result.failure_prediction is not None:
        fp = macro_result.failure_prediction
        report += "\n## ğŸ¯ Integrated Failure Prediction\n"
        
        # åŸºæœ¬çš„ãªç ´å£Šäºˆæ¸¬
        report += "\n### Basic Failure Assessment\n"
        report += f"- **Failure probability**: {fp.get('failure_probability', 0):.1%}\n"
        report += f"- **Reliability index**: {fp.get('reliability_index', 5.0):.2f}\n"
        report += f"- **Failure mode**: {fp.get('failure_mode', 'Unknown')}\n"
        
        # çµ±åˆç‰ˆã®æ–°ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å¯¾å¿œï¼ˆPATCH 4ã®å†…å®¹ï¼‰
        if 'integrated_failure_probability' in fp:
            report += "\n### ğŸ”¥ Physics-Integrated Assessment\n"
            report += f"- **Integrated failure probability**: {fp['integrated_failure_probability']:.1%}\n"
            
            # å„å¯„ä¸ã®å†…è¨³
            if 'physical_damage_probability' in fp:
                report += f"- **Physical damage contribution**: {fp['physical_damage_probability']:.1%}\n"
            
            traditional_prob = fp.get('failure_probability', 0)
            report += f"- **Traditional mechanics contribution**: {traditional_prob:.1%}\n"
            
            # çµ±åˆç ´å£Šãƒ¢ãƒ¼ãƒ‰
            if 'integrated_failure_mode' in fp:
                mode = fp['integrated_failure_mode']
                report += f"- **Predicted failure mode**: {mode}\n"
                
                # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨äº‹é …
                if mode == 'physical_damage_dominant':
                    report += "  â†’ Recommendation: Focus on reducing K/V ratio\n"
                elif mode == 'combined_failure':
                    report += "  â†’ Recommendation: Multi-faceted reinforcement needed\n"
            
            # çµ±åˆæ®‹å­˜å¯¿å‘½
            if 'integrated_remaining_life' in fp:
                report += f"- **Integrated remaining life**: {fp['integrated_remaining_life']:.1f} cycles\n"
        
        # æ®‹å­˜å¯¿å‘½ï¼ˆæ—¢å­˜ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰
        if 'remaining_life_cycles' in fp:
            report += f"- **Remaining life cycles**: {fp['remaining_life_cycles']:.1f}\n"
    
    # ========================================
    # ğŸ†• ä¿¡é ¼æ€§è§£æï¼ˆMaterialConfidenceAnalyzerGPUï¼‰
    # ========================================
    if two_stage_result and hasattr(two_stage_result, 'cluster_analyses'):
        report += "\n## ğŸ“Š Statistical Confidence Analysis\n"
        
        all_confidence_results = []
        for event_name, analysis in two_stage_result.cluster_analyses.items():
            if hasattr(analysis, 'confidence_results') and analysis.confidence_results:
                all_confidence_results.extend(analysis.confidence_results)
        
        if all_confidence_results:
            report += f"\n### Reliability Assessment ({len(all_confidence_results)} pairs)\n"
            
            # çµ±è¨ˆã‚µãƒãƒªãƒ¼
            critical_pairs = [r for r in all_confidence_results if r.get('is_critical', False)]
            significant_pairs = [r for r in all_confidence_results if r.get('is_significant', False)]
            
            report += f"- **Significant correlations**: {len(significant_pairs)}\n"
            report += f"- **Critical state pairs**: {len(critical_pairs)}\n"
            
            # ææ–™ç‰¹æ€§åˆ¥
            strain_pairs = [r for r in all_confidence_results if r.get('material_property') == 'strain']
            coord_pairs = [r for r in all_confidence_results if r.get('material_property') == 'coordination']
            damage_pairs = [r for r in all_confidence_results if r.get('material_property') == 'damage']
            
            if strain_pairs:
                report += f"\n#### Strain Reliability ({len(strain_pairs)} pairs)\n"
                for r in strain_pairs[:3]:
                    report += f"- C{r['from_cluster']}â†’C{r['to_cluster']}: "
                    report += f"Ï={r.get('strain_correlation', 0):.3f} "
                    report += f"[{r.get('ci_lower', 0):.3f}, {r.get('ci_upper', 0):.3f}]"
                    if r.get('is_critical'):
                        report += " âš ï¸ CRITICAL"
                    report += "\n"
            
            if coord_pairs:
                report += f"\n#### Coordination Defect Analysis ({len(coord_pairs)} pairs)\n"
                max_disl = max((r.get('dislocation_density_i', 0) for r in coord_pairs), default=0)
                report += f"- **Max dislocation density**: {max_disl:.2e} /cmÂ²\n"
            
            if damage_pairs:
                report += f"\n#### Damage Correlation ({len(damage_pairs)} pairs)\n"
                weibull_moduli = [r.get('weibull_modulus_i', 0) for r in damage_pairs if 'weibull_modulus_i' in r]
                if weibull_moduli:
                    report += f"- **Mean Weibull modulus**: {np.mean(weibull_moduli):.2f}\n"
    
    # ========================================
    # ğŸ†• ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã®ç‰©ç†æƒ…å ±
    # ========================================
    if two_stage_result and hasattr(two_stage_result, 'cluster_analyses'):
        for event_name, analysis in two_stage_result.cluster_analyses.items():
            if hasattr(analysis, 'cluster_events'):
                # Lindemannæ¯”ãŒé«˜ã„ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç‰¹å®š
                high_lindemann = [e for e in analysis.cluster_events 
                                if hasattr(e, 'lindemann_ratio') and e.lindemann_ratio and e.lindemann_ratio > 0.1]
                
                if high_lindemann:
                    report += f"\n### âš ï¸ Local Melting Risk in {event_name}\n"
                    for event in high_lindemann[:3]:
                        report += f"- **{event.cluster_name}**: "
                        report += f"Lindemann={event.lindemann_ratio:.3f}, "
                        report += f"T={event.local_temperature:.0f}K, "
                        report += f"Phase={event.phase_state}\n"
    
    # ========================================
    # ğŸ†• çµ±åˆçš„ãƒªã‚¹ã‚¯è©•ä¾¡
    # ========================================
    report += "\n## ğŸ¯ Integrated Risk Assessment\n"
    all_confidence_results = []
    risk_factors = []
    risk_score = 0.0
    
    # ç‰©ç†äºˆæ¸¬ãƒªã‚¹ã‚¯
    if two_stage_result and hasattr(two_stage_result, 'predicted_failure_time'):
        ttf = two_stage_result.predicted_failure_time
        if ttf < 100:
            risk_factors.append(("Imminent failure", 1.0))
            risk_score += 1.0
        elif ttf < 1000:
            risk_factors.append(("Near-term failure", 0.5))
            risk_score += 0.5
    
    # K/Væ¯”ãƒ€ãƒ¡ãƒ¼ã‚¸ãƒªã‚¹ã‚¯
    if macro_result and hasattr(macro_result, 'physical_damage') and macro_result.physical_damage:
        damage_prob = macro_result.physical_damage.get('failure_probability', 0)
        if damage_prob > 0.5:
            risk_factors.append((f"High damage probability ({damage_prob:.1%})", 0.8))
            risk_score += 0.8
    
    # çµ±è¨ˆçš„ä¿¡é ¼æ€§ãƒªã‚¹ã‚¯
    if all_confidence_results:
        n_critical = sum(1 for r in all_confidence_results if r.get('is_critical', False))
        if n_critical > 5:
            risk_factors.append((f"{n_critical} critical correlations", 0.6))
            risk_score += 0.6
    
    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ¤å®š
    if risk_score > 2.0:
        risk_level = "ğŸ”´ CRITICAL"
    elif risk_score > 1.0:
        risk_level = "ğŸŸ¡ HIGH"
    elif risk_score > 0.5:
        risk_level = "ğŸŸ  MODERATE"
    else:
        risk_level = "ğŸŸ¢ LOW"
    
    report += f"\n### Overall Risk Level: {risk_level}\n"
    report += f"**Risk Score**: {risk_score:.2f}\n\n"
    
    if risk_factors:
        report += "**Risk Factors**:\n"
        for factor, weight in risk_factors:
            report += f"- {factor} (weight: {weight:.1f})\n"
 
    # ========================================
    # 7. æŠ€è¡“ä»•æ§˜
    # ========================================
    report += "\n\n## ğŸ“‹ Technical Specifications\n"
    
    # ææ–™ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ï¼ˆçµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ï¼‰
    report += f"\n### Material Properties ({material_type})\n"
    
    # MATERIAL_DATABASEã‹ã‚‰å–å¾—
    props = get_material_parameters(material_type)
    report += f"- Elastic modulus: {props.get('elastic_modulus', props.get('E', 'N/A'))} GPa\n"
    report += f"- Poisson's ratio: {props.get('poisson_ratio', props.get('nu', 'N/A'))}\n"
    report += f"- Yield strength: {props.get('yield_strength', props.get('yield', 'N/A'))} GPa\n"
    report += f"- Ultimate strength: {props.get('ultimate_strength', props.get('ultimate', 'N/A'))} GPa\n"
    report += f"- Fracture toughness: {props.get('fracture_toughness', props.get('K_IC', 'N/A'))} MPaâˆšm\n"
        
    # è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    report += "\n### Analysis Parameters\n"
    report += "- Defect detection: Adaptive thresholding\n"
    report += "- Network analysis: GPU-accelerated\n"
    report += "- Reliability: 95% confidence level\n"
    report += "- Failure criteria: von Mises stress\n"
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    report += f"""

---
*Material Analysis Complete!*
*Version: 2.0.0 - Material LambdaÂ³ GPU Edition (Fixed)*
*Material: {material_type}*
*Total report length: {len(report):,} characters*
"""
    
    # ========================================
    # ä¿å­˜ã¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    # ========================================
    
    try:
        # Markdownãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_path = output_path / 'material_report.md'
        with open(report_path, 'w') as f:
            f.write(report)
        
        # JSONå½¢å¼ã§ã‚‚ä¿å­˜ï¼ˆæ‹¡å¼µç‰ˆï¼‰
        json_data = {
            'version': '3.0.0',  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—
            'material_type': material_type,
            'summary': {
                'n_frames': n_frames,
                'n_atoms': n_atoms,
                'computation_time': computation_time,
                'total_events': len(all_events)
            },
            'events': all_events[:100],
            'metadata': metadata if metadata else {}
        }
        
        # ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ï¼ˆæ‹¡å¼µç‰ˆï¼‰
        if macro_result and hasattr(macro_result, 'physical_damage') and macro_result.physical_damage:
            damage = macro_result.physical_damage
            if damage and isinstance(damage, dict):
                # cumulative_damageãŒé…åˆ—ã®å ´åˆã®å‡¦ç†
                cumulative_damage_val = damage.get('cumulative_damage', 0)
                if hasattr(cumulative_damage_val, '__len__') and not isinstance(cumulative_damage_val, str):
                    try:
                        cumulative_damage_val = float(np.max(cumulative_damage_val))
                    except:
                        cumulative_damage_val = 0
                
                json_data['physical_damage'] = {
                    'max_damage': damage.get('max_damage', 0),
                    'avg_damage': damage.get('avg_damage', 0),
                    'failure_probability': damage.get('failure_probability', 0),
                    'cumulative_damage': cumulative_damage_val,
                    'remaining_life': damage.get('remaining_life', None),
                    'damage_rate': damage.get('max_damage_rate', 0),
                    'damage_acceleration': damage.get('damage_acceleration', 0),
                    'temperature': damage.get('temperature', 300),
                    'defect_correlation': damage.get('defect_damage_correlation', None),
                    'critical_clusters': damage.get('critical_clusters', [])
                }
        
        # K/Væ¯”ãƒ‡ãƒ¼ã‚¿ï¼ˆè¦ç´„ç‰ˆï¼‰
        if macro_result and hasattr(macro_result, 'kv_ratios') and macro_result.kv_ratios is not None:
            kv = macro_result.kv_ratios
            kv_flat = kv.flatten() if kv.ndim > 1 else kv
            json_data['kv_analysis'] = {
                'mean': float(np.mean(kv_flat)),
                'max': float(np.max(kv_flat)),
                'min': float(np.min(kv_flat)),
                'std': float(np.std(kv_flat)),
                'exceedance_ratio': float(np.sum(kv_flat > 1.5) / len(kv_flat))
            }
        
        # æ¸©åº¦å±¥æ­´ï¼ˆè¦ç´„ç‰ˆï¼‰
        if macro_result and hasattr(macro_result, 'temperature_history') and macro_result.temperature_history is not None:
            temps = macro_result.temperature_history
            json_data['temperature_analysis'] = {
                'mean': float(np.mean(temps)),
                'max': float(np.max(temps)),
                'min': float(np.min(temps)),
                'range': float(np.max(temps) - np.min(temps))
            }
        
        json_path = output_path / 'material_analysis_data.json'
        with open(json_path, 'w') as f:
            json.dump(json_data, f, indent=2, default=float)

        # CSVå½¢å¼ã§æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚‚ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        try:
            import pandas as pd
            
            # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            timeseries_data = {}
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·
            if hasattr(macro_result, 'n_frames'):
                timeseries_data['frame'] = list(range(macro_result.n_frames))
            
            # K/Væ¯”
            if hasattr(macro_result, 'kv_ratios') and macro_result.kv_ratios is not None:
                kv = macro_result.kv_ratios
                if kv.ndim == 1:
                    timeseries_data['kv_ratio'] = kv.tolist()
                else:
                    # è¤‡æ•°ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®å ´åˆã¯å¹³å‡
                    timeseries_data['kv_ratio_mean'] = np.mean(kv, axis=1).tolist()
            
            # æ¸©åº¦
            if hasattr(macro_result, 'temperature_history') and macro_result.temperature_history is not None:
                timeseries_data['temperature'] = macro_result.temperature_history.tolist()
            
            # ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸ï¼ˆç´¯ç©ï¼‰
            if hasattr(macro_result, 'physical_damage') and macro_result.physical_damage:
                damage = macro_result.physical_damage
                if 'cumulative_damage' in damage:
                    cum_damage = damage['cumulative_damage']
                    if hasattr(cum_damage, '__len__'):
                        if cum_damage.ndim == 1:
                            timeseries_data['cumulative_damage'] = cum_damage.tolist()
                        else:
                            timeseries_data['cumulative_damage'] = np.mean(cum_damage, axis=1).tolist()
            
            # ç•°å¸¸ã‚¹ã‚³ã‚¢
            if hasattr(macro_result, 'anomaly_scores') and macro_result.anomaly_scores:
                for score_type in ['strain', 'coordination', 'damage', 'combined']:
                    if score_type in macro_result.anomaly_scores:
                        scores = macro_result.anomaly_scores[score_type]
                        timeseries_data[f'anomaly_{score_type}'] = scores.tolist()
            
            # DataFrameã«å¤‰æ›ã—ã¦ä¿å­˜
            if timeseries_data and 'frame' in timeseries_data:
                df = pd.DataFrame(timeseries_data)
                csv_path = output_path / 'material_timeseries.csv'
                df.to_csv(csv_path, index=False)
                
                if verbose:
                    print(f"   ğŸ“Š Timeseries data saved to: {csv_path}")
                    print(f"      Columns: {', '.join(df.columns)}")
                    print(f"      Rows: {len(df)}")
        
        except ImportError:
            if verbose:
                print("   âš ï¸ pandas not available, skipping CSV export")
        except Exception as e:
            logger.warning(f"CSV export failed: {e}")

        # VTKãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆç”¨ãƒ‡ãƒ¼ã‚¿
        vtk_data = prepare_vtk_export_data(
            macro_result, two_stage_result, impact_results
        )
        if vtk_data:
            vtk_path = output_path / 'visualization_data.json'
            with open(vtk_path, 'w') as f:
                json.dump(vtk_data, f, indent=2, default=float)
        
        if verbose:
            print(f"\nâœ¨ COMPLETE! (Material Report v1.0.3)")
            print(f"   ğŸ“„ Report saved to: {report_path}")
            print(f"   ğŸ“Š Data saved to: {json_path}")
            print(f"   ğŸ“ Report length: {len(report):,} characters")
            print(f"   ğŸ’ Material events: {len(all_events)}")
            if two_stage_result:
                print(f"   ğŸ”¬ Critical clusters: {len(getattr(two_stage_result, 'critical_clusters', []))}")
            if impact_results:
                print(f"   âš›ï¸ Defect analyses: {len(impact_results)}")
            print(f"\n   Material analysis complete for {material_type}!")
        
    except Exception as e:
        logger.error(f"Error during report generation: {e}")
        if debug:
            traceback.print_exc()
        raise
    
    return report

# ========================================
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ========================================

def prepare_vtk_export_data(macro_result, two_stage_result, impact_results):
    """
    VTKå¯è¦–åŒ–ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
    
    ParaViewã‚„OVITOã§å¯è¦–åŒ–ã§ãã‚‹å½¢å¼ã«æ•´å½¢
    """
    vtk_data = {
        'format': 'lambda3_material',
        'version': '1.0',
        'frames': []
    }
    
    try:
        # ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿
        if hasattr(macro_result, 'anomaly_scores'):
            n_frames = len(macro_result.anomaly_scores.get('strain', []))
            
            for frame in range(min(n_frames, 100)):  # æœ€åˆã®100ãƒ•ãƒ¬ãƒ¼ãƒ 
                frame_data = {
                    'frame_id': frame,
                    'scalars': {},
                    'vectors': {},
                    'tensors': {}
                }
                
                # ã‚¹ã‚«ãƒ©ãƒ¼å ´
                for score_type in ['strain', 'coordination', 'damage']:
                    if score_type in macro_result.anomaly_scores:
                        scores = macro_result.anomaly_scores[score_type]
                        if frame < len(scores):
                            frame_data['scalars'][score_type] = float(scores[frame])
                
                vtk_data['frames'].append(frame_data)
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æƒ…å ±
        if two_stage_result and hasattr(two_stage_result, 'critical_clusters'):
            vtk_data['clusters'] = {
                'critical': two_stage_result.critical_clusters,
                'reinforcement': getattr(two_stage_result, 'suggested_reinforcement_points', [])
            }
        
        # æ¬ é™¥ä½ç½®
        if impact_results:
            defects = []
            for result in impact_results.values():
                if hasattr(result, 'origin') and hasattr(result.origin, 'nucleation_atoms'):
                    if result.origin.nucleation_atoms:
                        defects.extend(result.origin.nucleation_atoms[:10])
            vtk_data['defect_atoms'] = list(set(defects))
        
        return vtk_data if vtk_data['frames'] else None
        
    except Exception as e:
        logger.warning(f"VTK data preparation failed: {e}")
        return None

def generate_material_comparison_report(
    results_dict: Dict[str, Any],
    material_types: List[str],
    output_dir: str = './comparison_report'
) -> str:
    """
    è¤‡æ•°ææ–™ã®æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    
    Parameters
    ----------
    results_dict : Dict[str, Any]
        ææ–™ã‚¿ã‚¤ãƒ—ã”ã¨ã®è§£æçµæœ
    material_types : List[str]
        æ¯”è¼ƒã™ã‚‹ææ–™ã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆ
    """
    report = "# Material Comparison Report\n\n"
    
    # å„ææ–™ã®çµ±è¨ˆæ¯”è¼ƒ
    report += "## Performance Comparison\n\n"
    report += "| Material | Max Stress | Fracture Strain | Reliability | State |\n"
    report += "|----------|------------|-----------------|-------------|-------|\n"
    
    for material in material_types:
        if material in results_dict:
            result = results_dict[material]
            # çµ±è¨ˆæŠ½å‡ºã¨è¡¨ç¤ºï¼ˆå®Ÿè£…ã¯çµæœæ§‹é€ ã«ä¾å­˜ï¼‰
            max_stress = "N/A"
            fracture_strain = "N/A"
            reliability = "N/A"
            state = "N/A"
            
            # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«åˆã‚ã›ã¦æŠ½å‡º
            if hasattr(result, 'stress_strain'):
                max_stress = f"{result.stress_strain.get('max_stress', 'N/A'):.2f}"
                fracture_strain = f"{result.stress_strain.get('fracture_strain', 'N/A'):.3f}"
            
            report += f"| {material} | {max_stress} | {fracture_strain} | {reliability} | {state} |\n"
    
    return report
