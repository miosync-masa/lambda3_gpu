#!/usr/bin/env python3
"""
Material LambdaÂ³ Detector GPU - Physics-Integrated Edition v3.0
================================================================

ææ–™è§£æç”¨LambdaÂ³æ¤œå‡ºå™¨ã®GPUå®Ÿè£…ï¼ˆç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è¨ˆç®—çµ±åˆç‰ˆï¼‰

ä¸»ãªæ”¹è‰¯ç‚¹ï¼ˆv3.0ï¼‰ï¼š
- PhysicalDamageCalculatorçµ±åˆã«ã‚ˆã‚‹K/Væ¯”ãƒ™ãƒ¼ã‚¹ã®ç‰©ç†çš„ãƒ€ãƒ¡ãƒ¼ã‚¸è¨ˆç®—
- Minerå‰‡ã«ã‚ˆã‚‹ç–²åŠ´ç´¯ç©è©•ä¾¡
- æ¸©åº¦ä¾å­˜æ€§ã‚’è€ƒæ…®ã—ãŸç ´å£Šäºˆæ¸¬
- ãƒ‘ãƒ¼ã‚³ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç†è«–ã«ã‚ˆã‚‹è‡¨ç•Œã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ç‰¹å®š
- MDç‰¹å¾´ã‹ã‚‰ã®K/Væ¯”è‡ªå‹•è¨ˆç®—

Version: 3.0.0 - Physics Integration Edition
Author: ç’°ã¡ã‚ƒã‚“ - Material Master Edition
"""

import numpy as np
import time
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
import warnings
import logging

# CuPyã®æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import cupy as cp
    HAS_GPU = True
except ImportError:
    cp = None
    HAS_GPU = False

# LambdaÂ³ GPU imports
from ..core.gpu_utils import GPUBackend
from ..structures.lambda_structures_gpu import LambdaStructuresGPU
from ..structures.md_features_gpu import MDFeaturesGPU
from ..material.material_md_features_gpu import MaterialMDFeaturesGPU
from ..detection.anomaly_detection_gpu import AnomalyDetectorGPU
from ..detection.boundary_detection_gpu import BoundaryDetectorGPU
from ..detection.topology_breaks_gpu import TopologyBreaksDetectorGPU
from ..detection.extended_detection_gpu import ExtendedDetectorGPU
from ..detection.phase_space_gpu import PhaseSpaceAnalyzerGPU

# Material specific imports
from ..material.material_analytics_gpu import MaterialAnalyticsGPU

# Loggerè¨­å®š
logger = logging.getLogger(__name__)

# ===============================
# Configuration
# ===============================

@dataclass
class MaterialConfig:
    """ææ–™è§£æè¨­å®šï¼ˆç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è§£ææ‹¡å¼µç‰ˆï¼‰"""
    # LambdaÂ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    adaptive_window: bool = True
    extended_detection: bool = True
    use_extended_detection: bool = True
    use_phase_space: bool = True
    sensitivity: float = 1.5
    min_boundary_gap: int = 50
    
    # ææ–™ç‰¹æœ‰ã®è¨­å®š
    material_type: str = 'SUJ2'
    use_material_analytics: bool = True
    
    # ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è§£æè¨­å®šï¼ˆNEW!ï¼‰
    use_physical_damage: bool = True
    damage_temperature: float = 300.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¸©åº¦ [K]
    kv_critical_override: Optional[float] = None  # è‡¨ç•ŒK/Væ¯”ã®ä¸Šæ›¸ã
    
    # GPUè¨­å®š
    gpu_batch_size: int = 10000
    mixed_precision: bool = False
    benchmark_mode: bool = False
    
    # ç•°å¸¸æ¤œå‡ºã®é‡ã¿
    w_lambda_f: float = 0.3
    w_lambda_ff: float = 0.2
    w_rho_t: float = 0.2
    w_topology: float = 0.3
    
    # ææ–™ç‰¹æœ‰ã®é‡ã¿
    w_defect: float = 0.2
    w_coherence: float = 0.1
    w_physical_damage: float = 0.25  # ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸ã®é‡ã¿ï¼ˆNEW!ï¼‰
    
    # é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š
    window_scale: float = 0.005

@dataclass
class MaterialLambda3Result:
    """ææ–™LambdaÂ³è§£æçµæœï¼ˆç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸çµ±åˆç‰ˆï¼‰"""
    # Core LambdaÂ³æ§‹é€ 
    lambda_structures: Dict[str, np.ndarray]
    structural_boundaries: Dict[str, Any]
    topological_breaks: Dict[str, np.ndarray]
    
    # MD/ææ–™ç‰¹å¾´
    md_features: Dict[str, np.ndarray]
    
    # è§£æçµæœ
    anomaly_scores: Dict[str, np.ndarray]
    detected_structures: List[Dict]
    
    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    material_features: Optional[Dict[str, np.ndarray]] = None
    phase_space_analysis: Optional[Dict] = None
    defect_analysis: Optional[Dict] = None
    structural_coherence: Optional[np.ndarray] = None
    failure_prediction: Optional[Dict] = None
    material_events: Optional[List[Tuple[int, int, str]]] = None
    
    # ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è§£æï¼ˆNEW!ï¼‰
    physical_damage: Optional[Dict[str, Any]] = None
    kv_ratios: Optional[np.ndarray] = None
    temperature_history: Optional[np.ndarray] = None
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    n_frames: int = 0
    n_atoms: int = 0
    window_steps: int = 0
    computation_time: float = 0.0
    gpu_info: Dict = field(default_factory=dict)
    critical_events: List = field(default_factory=list)

# ===============================
# Main Detector Class
# ===============================

class MaterialLambda3DetectorGPU(GPUBackend):
    """
    GPUç‰ˆLambdaÂ³ææ–™æ¤œå‡ºå™¨ï¼ˆç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸çµ±åˆç‰ˆ v3.0ï¼‰
    
    å‡¦ç†ãƒ•ãƒ­ãƒ¼ï¼š
    1. å‰å‡¦ç†ï¼ˆãƒãƒƒãƒã”ã¨ï¼‰: MDç‰¹å¾´æŠ½å‡º â†’ æ¬ é™¥è§£æ â†’ Lambdaæ§‹é€ è¨ˆç®— â†’ K/Væ¯”è¨ˆç®—
    2. å¾Œå‡¦ç†ï¼ˆãƒãƒ¼ã‚¸å¾Œï¼‰: å¢ƒç•Œæ¤œå‡º â†’ ç•°å¸¸æ¤œå‡º â†’ ææ–™è§£æ â†’ ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è©•ä¾¡
    """
    
    def __init__(self, config: MaterialConfig = None, device: str = 'auto'):
        # GPUBackendã®åˆæœŸåŒ–
        if device == 'cpu':
            super().__init__(device='cpu', force_cpu=True)
        else:
            super().__init__(device=device, force_cpu=False)
        
        self.config = config or MaterialConfig()
        self.verbose = True
        
        force_cpu_flag = not self.is_gpu
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹æˆ
        self.structure_computer = LambdaStructuresGPU(force_cpu_flag)
        
        # ç‰¹å¾´æŠ½å‡ºå™¨ï¼ˆ2ã¤ã®ç‹¬ç«‹ã—ãŸæŠ½å‡ºå™¨ï¼‰
        self.feature_extractor = MDFeaturesGPU(force_cpu_flag)  # Lambdaæ§‹é€ ç”¨ï¼ˆå…¨åŸå­ï¼‰
        self.material_feature_extractor = MaterialMDFeaturesGPU(force_cpu_flag)  # ææ–™è§£æç”¨ï¼ˆæ¬ é™¥é ˜åŸŸï¼‰
        
        self.anomaly_detector = AnomalyDetectorGPU(force_cpu_flag)
        self.boundary_detector = BoundaryDetectorGPU(force_cpu_flag)
        self.topology_detector = TopologyBreaksDetectorGPU(force_cpu_flag)
        self.extended_detector = ExtendedDetectorGPU(force_cpu_flag)
        self.phase_space_analyzer = PhaseSpaceAnalyzerGPU(force_cpu_flag)
        
        # ææ–™ç‰¹æœ‰ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸å¯¾å¿œç‰ˆï¼‰
        if self.config.use_material_analytics:
            self.material_analytics = MaterialAnalyticsGPU(
                material_type=self.config.material_type,
                force_cpu=force_cpu_flag
            )
        else:
            self.material_analytics = None
        
        # ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ã¨ãƒ‡ãƒã‚¤ã‚¹ã‚’å…±æœ‰
        self._share_resources()
        self._print_initialization_info()
    
    def _share_resources(self):
        """ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ã¨ãƒ‡ãƒã‚¤ã‚¹ã‚’ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé–“ã§å…±æœ‰"""
        components = [
            self.structure_computer, 
            self.feature_extractor,
            self.material_feature_extractor,
            self.anomaly_detector, 
            self.boundary_detector,
            self.topology_detector, 
            self.extended_detector,
            self.phase_space_analyzer
        ]
        
        if self.material_analytics:
            components.append(self.material_analytics)
        
        for component in components:
            if hasattr(component, 'memory_manager'):
                component.memory_manager = self.memory_manager
            if hasattr(component, 'device'):
                component.device = self.device

    def analyze(self,
                trajectory: np.ndarray,
                backbone_indices: Optional[np.ndarray] = None,
                atom_types: Optional[np.ndarray] = None,
                cluster_definition_path: Optional[str] = None,
                cluster_atoms: Optional[Dict[int, List[int]]] = None,
                **kwargs) -> MaterialLambda3Result:
        """
        ææ–™è»Œé“ã®LambdaÂ³è§£æï¼ˆç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸çµ±åˆç‰ˆï¼‰
        """
        start_time = time.time()
        
        # å‰å‡¦ç†
        trajectory, atom_types = self._preprocess_inputs(
            trajectory, atom_types, backbone_indices
        )
        
        n_frames, n_atoms, _ = trajectory.shape
        self._print_analysis_header(n_frames, n_atoms)
        
        # ãƒãƒƒãƒå‡¦ç†ã®åˆ¤å®š
        batch_size = min(self.config.gpu_batch_size, n_frames)
        n_batches = (n_frames + batch_size - 1) // batch_size
        
        if n_batches > 1:
            print(f"Processing in {n_batches} batches of {batch_size} frames")
            result = self._analyze_batched(
                trajectory, backbone_indices, atom_types, 
                batch_size, cluster_definition_path, cluster_atoms
            )
        else:
            result = self._analyze_single_trajectory(
                trajectory, backbone_indices, atom_types,
                cluster_definition_path, cluster_atoms
            )
        
        result.computation_time = time.time() - start_time
        self._print_summary(result)
        
        return result
    
    def _analyze_single_trajectory(self,
                                  trajectory: np.ndarray,
                                  backbone_indices: Optional[np.ndarray],
                                  atom_types: Optional[np.ndarray],
                                  cluster_definition_path: Optional[str] = None,
                                  cluster_atoms: Optional[Dict[int, List[int]]] = None
                                  ) -> MaterialLambda3Result:
        """å˜ä¸€è»Œé“ã®å®Œå…¨è§£æï¼ˆç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è¨ˆç®—çµ±åˆï¼‰"""
        n_frames, n_atoms, _ = trajectory.shape
        
        # æ¬ é™¥é ˜åŸŸã®ç‰¹å®š
        backbone_indices = self._identify_defect_regions(
            cluster_atoms, backbone_indices
        )
        
        # === å‰å‡¦ç† ===
        print("\n[PREPROCESSING]")
        
        # 1. åŸºæœ¬MDç‰¹å¾´æŠ½å‡ºï¼ˆå…¨åŸå­ - Lambdaæ§‹é€ ç”¨ï¼‰
        print("  1. Extracting MD features (full atoms)...")
        md_features = self.feature_extractor.extract_md_features(
            trajectory, 
            None  # å…¨åŸå­ã§è¨ˆç®—
        )
        
        # 2. ææ–™ç‰¹æœ‰ã®ç‰¹å¾´æŠ½å‡ºï¼ˆæ¬ é™¥é ˜åŸŸ - ææ–™è§£æç”¨ï¼‰
        material_features = None
        if self.config.use_material_analytics and backbone_indices is not None:
            print("  2. Extracting material features (defect region)...")
            material_features = self.material_feature_extractor.extract_md_features(
                trajectory, 
                backbone_indices,
                cluster_definition_path=cluster_definition_path,
                atom_types=atom_types
            )
            
            # 3. æ¬ é™¥è§£æ
            print("  3. Computing crystal defect charges...")
            self._add_defect_analysis_to_features(
                trajectory, md_features, cluster_atoms, n_atoms
            )
        
        # 4. K/Væ¯”è¨ˆç®—ï¼ˆNEW!ï¼‰
        kv_ratios = None
        if self.config.use_physical_damage:
            print("  4. Computing K/V ratios...")
            kv_ratios = self._extract_kv_ratios(md_features)
            if kv_ratios is not None:
                print(f"     K/V ratio range: [{np.min(kv_ratios):.2f}, {np.max(kv_ratios):.2f}]")
        
        # 5. Lambdaæ§‹é€ è¨ˆç®—
        initial_window = self._compute_initial_window(n_frames)
        print("  5. Computing LambdaÂ³ structures...")
        lambda_structures = self.structure_computer.compute_lambda_structures(
            trajectory, md_features, initial_window
        )
        
        # === å¾Œå‡¦ç† ===
        print("\n[POSTPROCESSING]")
        
        # è§£æçµæœã‚’çµ±åˆ
        result = self._perform_postprocessing(
            lambda_structures, md_features, material_features,
            n_frames, n_atoms, initial_window,
            kv_ratios=kv_ratios  # K/Væ¯”ã‚’æ¸¡ã™
        )
        
        return result
    
    def _analyze_batched(self,
                        trajectory: np.ndarray,
                        backbone_indices: Optional[np.ndarray],
                        atom_types: Optional[np.ndarray],
                        batch_size: int,
                        cluster_definition_path: Optional[str] = None,
                        cluster_atoms: Optional[Dict[int, List[int]]] = None
                        ) -> MaterialLambda3Result:
        """ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹è§£æï¼ˆç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸å¯¾å¿œï¼‰"""
        print("\nâš¡ Running batched GPU analysis...")
        
        n_frames = trajectory.shape[0]
        
        # æ¬ é™¥é ˜åŸŸã®ç‰¹å®š
        backbone_indices = self._identify_defect_regions(
            cluster_atoms, backbone_indices
        )
        
        batches = self._optimize_batch_plan(n_frames, batch_size)
        
        # Step 1: å‰å‡¦ç†ï¼ˆãƒãƒƒãƒã”ã¨ï¼‰
        batch_results = self._process_batches(
            trajectory, backbone_indices, atom_types,
            batches, cluster_definition_path, cluster_atoms
        )
        
        if not batch_results:
            return self._create_empty_result(n_frames, trajectory.shape[1])
        
        # Step 2: çµæœã‚’ãƒãƒ¼ã‚¸
        print("\n[MERGING]")
        merged_result = self._merge_batch_results(
            batch_results, trajectory.shape, atom_types
        )
        
        # Step 3: å¾Œå‡¦ç†ï¼ˆç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è§£æã‚’å«ã‚€ï¼‰
        print("\n[POSTPROCESSING]")
        final_result = self._complete_analysis(merged_result, atom_types)
        
        return final_result
    
    def _analyze_single_batch(self,
                             batch_trajectory: np.ndarray,
                             backbone_indices: Optional[np.ndarray],
                             atom_types: Optional[np.ndarray],
                             offset: int,
                             cluster_definition_path: Optional[str] = None
                             ) -> Dict:
        """
        å˜ä¸€ãƒãƒƒãƒã®å‰å‡¦ç†ï¼ˆç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è¨ˆç®—å¯¾å¿œï¼‰
        """
        n_atoms = batch_trajectory.shape[1]
        
        # 1. åŸºæœ¬MDç‰¹å¾´æŠ½å‡º
        md_features = self.feature_extractor.extract_md_features(
            batch_trajectory, 
            None  # å…¨åŸå­
        )
        
        # 2. ææ–™ç‰¹æœ‰ã®ç‰¹å¾´æŠ½å‡º
        material_features = None
        if self.config.use_material_analytics and backbone_indices is not None:
            material_features = self.material_feature_extractor.extract_md_features(
                batch_trajectory, 
                backbone_indices,
                cluster_definition_path=cluster_definition_path,
                atom_types=atom_types
            )
            
            # 3. æ¬ é™¥è§£æ
            self._add_defect_analysis_to_features(
                batch_trajectory, md_features, None, n_atoms
            )
        
        # 4. K/Væ¯”è¨ˆç®—ï¼ˆNEW!ï¼‰
        kv_ratios = None
        if self.config.use_physical_damage:
            kv_ratios = self._extract_kv_ratios(md_features)
        
        # 5. Lambdaæ§‹é€ è¨ˆç®—
        window = self._compute_initial_window(len(batch_trajectory))
        lambda_structures = self.structure_computer.compute_lambda_structures(
            batch_trajectory, md_features, window
        )
        
        return {
            'offset': offset,
            'n_frames': len(batch_trajectory),
            'lambda_structures': lambda_structures,
            'md_features': md_features,
            'material_features': material_features,
            'kv_ratios': kv_ratios,  # K/Væ¯”ã‚’ä¿å­˜
            'window': window
        }
    
    def _complete_analysis(self,
                          merged_result: MaterialLambda3Result,
                          atom_types: Optional[np.ndarray]
                          ) -> MaterialLambda3Result:
        """
        ãƒãƒ¼ã‚¸å¾Œã®å¾Œå‡¦ç†ï¼ˆç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è§£æçµ±åˆç‰ˆï¼‰
        """
        lambda_structures = merged_result.lambda_structures
        md_features = merged_result.md_features
        material_features = merged_result.material_features
        n_frames = merged_result.n_frames
        n_atoms = merged_result.n_atoms
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºæ±ºå®š
        initial_window = merged_result.window_steps
        adaptive_windows = self._determine_adaptive_windows(
            lambda_structures, initial_window
        )
        primary_window = adaptive_windows.get('primary', initial_window)
        
        # å¢ƒç•Œãƒ»ãƒˆãƒãƒ­ã‚¸ãƒ¼æ¤œå‡º
        print("  - Detecting boundaries and topology...")
        structural_boundaries = self.boundary_detector.detect_structural_boundaries(
            lambda_structures, adaptive_windows.get('boundary', primary_window // 3)
        )
        topological_breaks = self.topology_detector.detect_topological_breaks(
            lambda_structures, adaptive_windows.get('fast', primary_window // 2)
        )
        
        # ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—
        print("  - Computing anomaly scores...")
        anomaly_scores = self._compute_enhanced_anomaly_scores(
            lambda_structures, structural_boundaries,
            topological_breaks, md_features, merged_result.physical_damage
        )
        
        # ææ–™ç‰¹æœ‰ã®è§£æ
        defect_analysis = None
        structural_coherence = None
        failure_prediction = None
        material_events = None
        physical_damage = None
        temperature_history = None
        
        if self.config.use_material_analytics and self.material_analytics:
            print("  - Material-specific analysis...")
            
            features_for_material = material_features if material_features else md_features
            
            # æ¬ é™¥æƒ…å ±
            if 'defect_charge' in md_features:
                defect_analysis = {
                    'defect_charge': md_features.get('defect_charge'),
                    'cumulative_charge': md_features.get('cumulative_charge')
                }
            
            # æ§‹é€ ä¸€è²«æ€§
            if 'coordination' in features_for_material:
                structural_coherence = self.material_analytics.compute_structural_coherence(
                    features_for_material['coordination'],
                    features_for_material.get('strain', np.zeros((n_frames, 1))),
                    window=primary_window // 2
                )
            
            # æ¸©åº¦å±¥æ­´ã®æŠ½å‡º/æ¨å®š
            temperature_history = self._extract_temperature_history(features_for_material)
            
            # ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è§£æï¼ˆNEW!ï¼‰
            if self.config.use_physical_damage and merged_result.kv_ratios is not None:
                print("  - Computing physics-based damage assessment...")
                physical_damage = self._compute_physical_damage_analysis(
                    merged_result.kv_ratios,
                    temperature_history,
                    defect_analysis
                )
            
            # ç ´å£Šäºˆæ¸¬ï¼ˆç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸çµ±åˆç‰ˆï¼‰
            if 'strain' in features_for_material:
                failure_prediction = self._compute_integrated_failure_prediction(
                    features_for_material,
                    physical_damage,
                    defect_analysis
                )
            
            # ã‚¤ãƒ™ãƒ³ãƒˆåˆ†é¡
            critical_events = self._detect_critical_events(anomaly_scores)
            if critical_events and structural_coherence is not None:
                material_events = self.material_analytics.classify_material_events(
                    critical_events, anomaly_scores,
                    structural_coherence,
                    defect_charge=md_features.get('defect_charge')
                )
        
        # æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        print("  - Detecting structural patterns...")
        detected_structures = self._detect_structural_patterns(
            lambda_structures, structural_boundaries,
            adaptive_windows.get('slow', primary_window * 2)
        )
        
        # ä½ç›¸ç©ºé–“è§£æ
        phase_space_analysis = None
        if self.config.use_phase_space:
            try:
                phase_space_analysis = self.phase_space_analyzer.analyze_phase_space(
                    lambda_structures
                )
            except Exception as e:
                logger.warning(f"Phase space analysis failed: {e}")
        
        print("  âœ… Analysis completed!")
        
        # çµæœã‚’æ›´æ–°
        merged_result.structural_boundaries = structural_boundaries
        merged_result.topological_breaks = topological_breaks
        merged_result.anomaly_scores = anomaly_scores
        merged_result.detected_structures = detected_structures
        merged_result.phase_space_analysis = phase_space_analysis
        merged_result.defect_analysis = defect_analysis
        merged_result.structural_coherence = structural_coherence
        merged_result.failure_prediction = failure_prediction
        merged_result.material_events = material_events
        merged_result.critical_events = self._detect_critical_events(anomaly_scores)
        merged_result.window_steps = primary_window
        merged_result.physical_damage = physical_damage
        merged_result.temperature_history = temperature_history
        
        return merged_result
    
    # === ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è¨ˆç®—é–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆNEW!ï¼‰ ===
    
    def _extract_kv_ratios(self, md_features: Dict) -> Optional[np.ndarray]:
        """MDç‰¹å¾´ã‹ã‚‰K/Væ¯”ã‚’æŠ½å‡ºã¾ãŸã¯è¨ˆç®—"""
        try:
            if 'kv_ratio' in md_features:
                # ç›´æ¥K/Væ¯”ãŒè¨ˆç®—ã•ã‚Œã¦ã„ã‚‹å ´åˆ
                return md_features['kv_ratio']
            
            elif 'kinetic_energy' in md_features:
                K = md_features['kinetic_energy']  # é‹å‹•ã‚¨ãƒãƒ«ã‚®ãƒ¼
                
                # ãƒ“ãƒªã‚¢ãƒ«ãƒ†ãƒ³ã‚½ãƒ«ã¾ãŸã¯åœ§åŠ›ã‹ã‚‰ä½“ç©ã‚’æ¨å®š
                if 'virial_tensor' in md_features:
                    # ãƒ“ãƒªã‚¢ãƒ«ãƒ†ãƒ³ã‚½ãƒ«ã®å¯¾è§’æˆåˆ†ã‹ã‚‰åœ§åŠ›ã‚’è¨ˆç®—
                    virial = md_features['virial_tensor']
                    if virial.ndim == 3:
                        # (n_frames, n_clusters, 6) -> å¯¾è§’æˆåˆ†ã®å¹³å‡
                        pressure = -np.mean(virial[..., :3], axis=-1)
                    else:
                        pressure = np.abs(virial)
                    
                    # åœ§åŠ›ã‹ã‚‰ä»®æƒ³çš„ãªä½“ç©ã‚’æ¨å®šï¼ˆPV = nkTçš„ãªé–¢ä¿‚ã‚’ä»®å®šï¼‰
                    V = np.where(pressure > 1e-10, 1.0 / pressure, 1.0)
                    
                elif 'pressure' in md_features:
                    pressure = np.abs(md_features['pressure'])
                    V = np.where(pressure > 1e-10, 1.0 / pressure, 1.0)
                    
                elif 'volume' in md_features:
                    V = md_features['volume']
                    
                else:
                    # ä½“ç©æƒ…å ±ãŒãªã„å ´åˆã€ä¸€å®šå€¤ã¨ä»®å®š
                    logger.warning("No volume/pressure data for K/V ratio calculation")
                    V = np.ones_like(K)
                
                # K/Væ¯”è¨ˆç®—ï¼ˆã‚¼ãƒ­é™¤ç®—å›é¿ï¼‰
                kv_ratios = np.divide(K, V, out=np.ones_like(K), where=(V > 1e-10))
                
                # ç‰©ç†çš„ã«å¦¥å½“ãªç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
                kv_ratios = np.clip(kv_ratios, 0.01, 100.0)
                
                return kv_ratios
                
        except Exception as e:
            logger.warning(f"Failed to extract K/V ratios: {e}")
            return None
    
    def _extract_temperature_history(self, features: Dict) -> np.ndarray:
        """MDç‰¹å¾´ã‹ã‚‰æ¸©åº¦å±¥æ­´ã‚’æŠ½å‡ºã¾ãŸã¯æ¨å®š"""
        if 'temperature' in features:
            return features['temperature']
        
        elif 'kinetic_energy' in features:
            # é‹å‹•ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‹ã‚‰æ¸©åº¦æ¨å®š
            kb = 8.617e-5  # eV/Kï¼ˆãƒœãƒ«ãƒ„ãƒãƒ³å®šæ•°ï¼‰
            ke = features['kinetic_energy']
            
            # 3/2 kB T = KE/N ï¼ˆç†æƒ³æ°—ä½“è¿‘ä¼¼ï¼‰
            # ã“ã“ã§ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«æ¯”ä¾‹é–¢ä¿‚ã‚’ä»®å®š
            temperature = ke / (1.5 * kb)
            
            # ç‰©ç†çš„ã«å¦¥å½“ãªç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
            temperature = np.clip(temperature, 1.0, 5000.0)
            
            return temperature
        
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¸©åº¦
            n_frames = next(iter(features.values())).shape[0]
            return np.full(n_frames, self.config.damage_temperature)
    
    def _compute_physical_damage_analysis(self,
                                         kv_ratios: np.ndarray,
                                         temperature_history: np.ndarray,
                                         defect_analysis: Optional[Dict]
                                         ) -> Dict[str, Any]:
        """ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸ã®è©³ç´°è§£æ"""
        # å¹³å‡æ¸©åº¦ã‚’ä½¿ç”¨ï¼ˆæ™‚å¤‰æ¸©åº¦å¯¾å¿œã‚‚å¯èƒ½ï¼‰
        avg_temperature = float(np.mean(temperature_history))
        
        # PhysicalDamageCalculatorã‚’ä½¿ç”¨
        damage_result = self.material_analytics.compute_physical_damage(
            kv_ratios,
            temperature=avg_temperature
        )
        
        # çµæœã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
        physical_damage = {
            'cumulative_damage': damage_result.cumulative_damage,
            'damage_rate': damage_result.damage_rate,
            'failure_probability': damage_result.failure_probability,
            'remaining_life': damage_result.remaining_life,
            'critical_clusters': damage_result.critical_clusters,
            'max_damage': float(np.max(damage_result.cumulative_damage)),
            'avg_damage': float(np.mean(damage_result.cumulative_damage)),
            'temperature': avg_temperature
        }
        
        # æ¬ é™¥ã¨ã®ç›¸é–¢ã‚’è¨ˆç®—
        if defect_analysis and 'cumulative_charge' in defect_analysis:
            defect_charge = defect_analysis['cumulative_charge']
            if len(defect_charge) == len(damage_result.cumulative_damage):
                # æ¬ é™¥ã¨ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸ã®ç›¸é–¢
                correlation = np.corrcoef(
                    defect_charge,
                    np.mean(damage_result.cumulative_damage, axis=1) if damage_result.cumulative_damage.ndim > 1 
                    else damage_result.cumulative_damage
                )[0, 1]
                physical_damage['defect_damage_correlation'] = float(correlation)
        
        # ãƒ€ãƒ¡ãƒ¼ã‚¸é€²å±•ã®çµ±è¨ˆ
        if damage_result.damage_rate is not None:
            max_rate = np.max(damage_result.damage_rate)
            avg_rate = np.mean(damage_result.damage_rate)
            physical_damage['max_damage_rate'] = float(max_rate)
            physical_damage['avg_damage_rate'] = float(avg_rate)
            
            # åŠ é€Ÿåº¦ï¼ˆ2æ¬¡å¾®åˆ†ï¼‰
            if len(damage_result.damage_rate) > 2:
                acceleration = np.gradient(damage_result.damage_rate.mean(axis=1) 
                                         if damage_result.damage_rate.ndim > 1 
                                         else damage_result.damage_rate)
                physical_damage['damage_acceleration'] = float(np.max(np.abs(acceleration)))
        
        return physical_damage
    
    def _compute_integrated_failure_prediction(self,
                                              features: Dict,
                                              physical_damage: Optional[Dict],
                                              defect_analysis: Optional[Dict]
                                              ) -> Dict[str, Any]:
        """ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸ã‚’çµ±åˆã—ãŸç ´å£Šäºˆæ¸¬"""
        # å¾“æ¥ã®ç ´å£Šäºˆæ¸¬
        traditional_prediction = self.material_analytics.predict_failure(
            features.get('strain', np.zeros(1)),
            damage_history=features.get('damage'),
            defect_charge=defect_analysis.get('cumulative_charge') if defect_analysis else None
        )
        
        failure_prediction = {
            'failure_probability': traditional_prediction.failure_probability,
            'reliability_index': traditional_prediction.reliability_index,
            'failure_mode': traditional_prediction.failure_mode,
            'remaining_life_cycles': traditional_prediction.remaining_life_cycles
        }
        
        # ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸ã¨ã®çµ±åˆ
        if physical_damage:
            # ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸ã«ã‚ˆã‚‹ç ´å£Šç¢ºç‡
            phys_failure_prob = physical_damage.get('failure_probability', 0.0)
            
            # çµ±åˆç ´å£Šç¢ºç‡ï¼ˆæœ€å¤§å€¤ã‚’æ¡ç”¨ï¼‰
            integrated_prob = max(
                failure_prediction['failure_probability'],
                phys_failure_prob
            )
            
            failure_prediction['integrated_failure_probability'] = integrated_prob
            failure_prediction['physical_damage_probability'] = phys_failure_prob
            
            # æ®‹å­˜å¯¿å‘½ã®æ›´æ–°
            if physical_damage.get('remaining_life'):
                phys_remaining = physical_damage['remaining_life']
                if failure_prediction.get('remaining_life_cycles'):
                    # æœ€å°å€¤ã‚’æ¡ç”¨ï¼ˆã‚ˆã‚Šæ‚²è¦³çš„ãªäºˆæ¸¬ï¼‰
                    failure_prediction['integrated_remaining_life'] = min(
                        failure_prediction['remaining_life_cycles'],
                        phys_remaining
                    )
                else:
                    failure_prediction['integrated_remaining_life'] = phys_remaining
            
            # ç ´å£Šãƒ¢ãƒ¼ãƒ‰ã®çµ±åˆ
            if phys_failure_prob > 0.8:
                failure_prediction['integrated_failure_mode'] = 'physical_damage_dominant'
            elif phys_failure_prob > 0.5 and failure_prediction['failure_probability'] > 0.5:
                failure_prediction['integrated_failure_mode'] = 'combined_failure'
            else:
                failure_prediction['integrated_failure_mode'] = failure_prediction.get('failure_mode', 'safe')
        
        return failure_prediction
    
    def _compute_enhanced_anomaly_scores(self,
                                        lambda_structures: Dict,
                                        boundaries: Dict,
                                        topological_breaks: Dict,
                                        md_features: Dict,
                                        physical_damage: Optional[Dict]
                                        ) -> Dict[str, np.ndarray]:
        """ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸ã‚’è€ƒæ…®ã—ãŸæ‹¡å¼µç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        # åŸºæœ¬ã®ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—
        anomaly_scores = self.anomaly_detector.compute_multiscale_anomalies(
            lambda_structures, boundaries,
            topological_breaks, md_features, self.config
        )
        
        # ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸ã«ã‚ˆã‚‹ç•°å¸¸ã‚¹ã‚³ã‚¢ã®è¿½åŠ 
        if physical_damage and self.config.use_physical_damage:
            n_frames = len(anomaly_scores.get('combined', []))
            
            # ãƒ€ãƒ¡ãƒ¼ã‚¸ãƒ™ãƒ¼ã‚¹ã®ç•°å¸¸ã‚¹ã‚³ã‚¢
            if 'cumulative_damage' in physical_damage:
                damage_data = physical_damage['cumulative_damage']
                
                # å½¢çŠ¶èª¿æ•´
                if damage_data.ndim > 1:
                    damage_score = np.mean(damage_data, axis=1)
                else:
                    damage_score = damage_data
                
                # é•·ã•èª¿æ•´
                if len(damage_score) != n_frames:
                    # è£œé–“ã¾ãŸã¯åˆ‡ã‚Šè©°ã‚
                    if len(damage_score) > n_frames:
                        damage_score = damage_score[:n_frames]
                    else:
                        # ç·šå½¢è£œé–“ã§å»¶é•·
                        x_old = np.linspace(0, 1, len(damage_score))
                        x_new = np.linspace(0, 1, n_frames)
                        damage_score = np.interp(x_new, x_old, damage_score)
                
                anomaly_scores['physical_damage'] = damage_score
                
                # çµ±åˆã‚¹ã‚³ã‚¢ã®å†è¨ˆç®—
                w_damage = self.config.w_physical_damage
                combined = anomaly_scores['combined'] * (1 - w_damage) + damage_score * w_damage
                anomaly_scores['combined'] = combined
        
        return anomaly_scores
    
    # === æ—¢å­˜ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆå¤‰æ›´ãªã—ï¼‰ ===
    
    def _identify_defect_regions(self,
                                cluster_atoms: Optional[Dict[int, List[int]]],
                                backbone_indices: Optional[np.ndarray]
                                ) -> Optional[np.ndarray]:
        """æ¬ é™¥é ˜åŸŸã®ç‰¹å®š"""
        if backbone_indices is not None:
            if backbone_indices.dtype != np.int32:
                backbone_indices = np.array(backbone_indices, dtype=np.int32)
            print(f"  Using provided backbone_indices: {len(backbone_indices)} atoms")
            return backbone_indices
        
        if cluster_atoms is not None:
            defect_indices = []
            for cid, atoms in cluster_atoms.items():
                if str(cid) != "0":  # Cluster 0ï¼ˆå¥å…¨é ˜åŸŸï¼‰ä»¥å¤–
                    if isinstance(atoms, (list, np.ndarray)):
                        defect_indices.extend([int(a) for a in atoms])
                    else:
                        defect_indices.extend(atoms)
            
            if defect_indices:
                backbone_indices = np.array(sorted(set(defect_indices)), dtype=np.int32)
                print(f"  Auto-detected {len(backbone_indices)} defect atoms from {len(cluster_atoms)-1} clusters")
                return backbone_indices
            else:
                print("  âš ï¸ No defect atoms found in clusters")
                return None
        
        print("  â„¹ï¸ No backbone_indices or cluster_atoms provided")
        return None
    
    def _add_defect_analysis_to_features(self,
                                        trajectory: np.ndarray,
                                        md_features: Dict,
                                        cluster_atoms: Optional[Dict],
                                        n_atoms: int):
        """MDç‰¹å¾´ã«æ¬ é™¥è§£æçµæœã‚’è¿½åŠ """
        try:
            trajectory_cpu = self.to_cpu(trajectory) if self.is_gpu else trajectory
            clusters = cluster_atoms if cluster_atoms else {0: list(range(n_atoms))}
            
            defect_result = self.material_analytics.compute_crystal_defect_charge(
                trajectory_cpu, clusters, cutoff=3.5
            )
            
            md_features['defect_charge'] = defect_result.defect_charge
            md_features['cumulative_charge'] = defect_result.cumulative_charge
        except Exception as e:
            logger.warning(f"Defect analysis failed: {e}")
    
    def _preprocess_inputs(self, trajectory, atom_types, backbone_indices):
        """å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨GPUè»¢é€"""
        if atom_types is not None and atom_types.dtype.kind == 'U':
            atom_type_names = np.unique(atom_types)
            type_map = {t: i for i, t in enumerate(atom_type_names)}
            atom_types = np.array([type_map[t] for t in atom_types], dtype=np.int32)
        
        if self.is_gpu and cp is not None:
            print("ğŸ“Š Converting arrays to GPU...")
            trajectory = cp.asarray(trajectory)
            if backbone_indices is not None:
                backbone_indices = cp.asarray(backbone_indices)
            if atom_types is not None:
                atom_types = cp.asarray(atom_types)
        
        return trajectory, atom_types
    
    def _optimize_batch_plan(self, n_frames: int, batch_size: int) -> List[Tuple[int, int]]:
        """ãƒãƒƒãƒè¨ˆç”»ã®æœ€é©åŒ–"""
        MIN_BATCH_SIZE = 1000
        batches = []
        current_pos = 0
        
        while current_pos < n_frames:
            batch_end = min(current_pos + batch_size, n_frames)
            remaining = batch_end - current_pos
            
            if batch_end == n_frames and remaining < MIN_BATCH_SIZE and batches:
                print(f"  Merging last batch ({remaining} frames) with previous")
                prev_start, _ = batches[-1]
                batches[-1] = (prev_start, n_frames)
                break
            
            batches.append((current_pos, batch_end))
            current_pos = batch_end
        
        return batches
    
    def _process_batches(self,
                        trajectory: np.ndarray,
                        backbone_indices: Optional[np.ndarray],
                        atom_types: Optional[np.ndarray],
                        batches: List[Tuple[int, int]],
                        cluster_definition_path: Optional[str],
                        cluster_atoms: Optional[Dict[int, List[int]]] = None
                        ) -> List[Dict]:
        """ãƒãƒƒãƒå‡¦ç†ã®å®Ÿè¡Œ"""
        batch_results = []
        
        print("\n[PREPROCESSING - Batch Processing]")
        for batch_idx, (start_idx, end_idx) in enumerate(batches):
            frames_count = end_idx - start_idx
            print(f"  Batch {batch_idx + 1}/{len(batches)}: "
                  f"frames {start_idx}-{end_idx} ({frames_count} frames)")
            
            try:
                batch_result = self._analyze_single_batch(
                    trajectory[start_idx:end_idx],
                    backbone_indices, atom_types,
                    start_idx, cluster_definition_path
                )
                batch_results.append(batch_result)
                
            except Exception as e:
                print(f"    âš ï¸ Batch failed: {e}")
                continue
            
            finally:
                self.memory_manager.clear_cache()
        
        return batch_results
    
    def _merge_batch_results(self,
                           batch_results: List[Dict],
                           original_shape: Tuple,
                           atom_types: Optional[np.ndarray]
                           ) -> MaterialLambda3Result:
        """ãƒãƒƒãƒçµæœã®çµ±åˆï¼ˆK/Væ¯”å¯¾å¿œç‰ˆï¼‰"""
        print("  Merging batch results...")
        n_frames, n_atoms, _ = original_shape
        
        if not batch_results:
            return self._create_empty_result(n_frames, n_atoms)
        
        # çµæœé…åˆ—ã®åˆæœŸåŒ–
        merged_lambda = {}
        merged_features = {}
        merged_material_features = {}
        merged_kv_ratios = None
        
        # æœ€åˆã®ãƒãƒƒãƒã‹ã‚‰æ§‹é€ ã‚’å–å¾—
        first_batch = batch_results[0]
        
        # Lambdaæ§‹é€ ã®åˆæœŸåŒ–
        for key in first_batch.get('lambda_structures', {}).keys():
            sample = first_batch['lambda_structures'][key]
            if isinstance(sample, (np.ndarray, self.xp.ndarray)):
                shape = (n_frames,) + sample.shape[1:] if sample.ndim > 1 else (n_frames,)
                merged_lambda[key] = np.full(shape, np.nan, dtype=sample.dtype)
        
        # MDç‰¹å¾´ã®åˆæœŸåŒ–
        for key in first_batch.get('md_features', {}).keys():
            sample = first_batch['md_features'][key]
            if isinstance(sample, (np.ndarray, self.xp.ndarray)):
                shape = (n_frames,) + sample.shape[1:] if sample.ndim > 1 else (n_frames,)
                merged_features[key] = np.full(shape, np.nan, dtype=sample.dtype)
        
        # Materialç‰¹å¾´ã®åˆæœŸåŒ–
        if 'material_features' in first_batch and first_batch['material_features']:
            for key in first_batch['material_features'].keys():
                sample = first_batch['material_features'][key]
                if isinstance(sample, (np.ndarray, self.xp.ndarray)):
                    shape = (n_frames,) + sample.shape[1:] if sample.ndim > 1 else (n_frames,)
                    merged_material_features[key] = np.full(shape, np.nan, dtype=sample.dtype)
        
        # K/Væ¯”ã®åˆæœŸåŒ–ï¼ˆNEW!ï¼‰
        if 'kv_ratios' in first_batch and first_batch['kv_ratios'] is not None:
            sample = first_batch['kv_ratios']
            shape = (n_frames,) + sample.shape[1:] if sample.ndim > 1 else (n_frames,)
            merged_kv_ratios = np.full(shape, np.nan, dtype=sample.dtype)
        
        # ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸
        for batch in batch_results:
            offset = batch['offset']
            n_batch_frames = batch['n_frames']
            end_idx = min(offset + n_batch_frames, n_frames)
            
            # Lambdaæ§‹é€ 
            for key, value in batch.get('lambda_structures', {}).items():
                if key in merged_lambda:
                    value = self.to_cpu(value) if hasattr(value, 'get') else value
                    actual_frames = min(len(value), end_idx - offset)
                    merged_lambda[key][offset:offset + actual_frames] = value[:actual_frames]
            
            # MDç‰¹å¾´
            for key, value in batch.get('md_features', {}).items():
                if key in merged_features:
                    value = self.to_cpu(value) if hasattr(value, 'get') else value
                    actual_frames = min(len(value), end_idx - offset)
                    merged_features[key][offset:offset + actual_frames] = value[:actual_frames]
            
            # Materialç‰¹å¾´
            if 'material_features' in batch and batch['material_features']:
                for key, value in batch['material_features'].items():
                    if key in merged_material_features:
                        value = self.to_cpu(value) if hasattr(value, 'get') else value
                        actual_frames = min(len(value), end_idx - offset)
                        merged_material_features[key][offset:offset + actual_frames] = value[:actual_frames]
            
            # K/Væ¯”ï¼ˆNEW!ï¼‰
            if 'kv_ratios' in batch and batch['kv_ratios'] is not None and merged_kv_ratios is not None:
                value = self.to_cpu(batch['kv_ratios']) if hasattr(batch['kv_ratios'], 'get') else batch['kv_ratios']
                actual_frames = min(len(value), end_idx - offset)
                merged_kv_ratios[offset:offset + actual_frames] = value[:actual_frames]
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã®å¹³å‡
        window_steps = int(np.mean([b.get('window', 100) for b in batch_results]))
        
        print(f"  âœ… Merged {n_frames} frames successfully")
        
        return MaterialLambda3Result(
            lambda_structures=merged_lambda,
            md_features=merged_features,
            material_features=merged_material_features if merged_material_features else None,
            kv_ratios=merged_kv_ratios,  # K/Væ¯”ã‚’ä¿å­˜
            structural_boundaries={},
            topological_breaks={},
            anomaly_scores={},
            detected_structures=[],
            n_frames=n_frames,
            n_atoms=n_atoms,
            window_steps=window_steps,
            gpu_info={'computation_mode': 'batched', 'n_batches': len(batch_results)}
        )
    
    def _perform_postprocessing(self,
                              lambda_structures: Dict,
                              md_features: Dict,
                              material_features: Optional[Dict],
                              n_frames: int,
                              n_atoms: int,
                              initial_window: int,
                              kv_ratios: Optional[np.ndarray] = None
                              ) -> MaterialLambda3Result:
        """å˜ä¸€è»Œé“ç”¨ã®å¾Œå‡¦ç†ï¼ˆK/Væ¯”å¯¾å¿œï¼‰"""
        partial_result = MaterialLambda3Result(
            lambda_structures=self._to_cpu_dict(lambda_structures),
            md_features=self._to_cpu_dict(md_features),
            material_features=self._to_cpu_dict(material_features) if material_features else None,
            kv_ratios=self.to_cpu(kv_ratios) if kv_ratios is not None else None,
            structural_boundaries={},
            topological_breaks={},
            anomaly_scores={},
            detected_structures=[],
            n_frames=n_frames,
            n_atoms=n_atoms,
            window_steps=initial_window,
            gpu_info=self._get_gpu_info()
        )
        
        # å¾Œå‡¦ç†ã‚’å®Ÿè¡Œ
        return self._complete_analysis(partial_result, None)
    
    def _compute_initial_window(self, n_frames: int) -> int:
        """åˆæœŸã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã®è¨ˆç®—"""
        return min(50, n_frames // 10)
    
    def _determine_adaptive_windows(self,
                                   lambda_structures: Dict,
                                   initial_window: int
                                   ) -> Dict[str, int]:
        """é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã®æ±ºå®š"""
        if not self.config.adaptive_window:
            return {'primary': initial_window}
        
        return {
            'primary': initial_window,
            'fast': max(10, initial_window // 2),
            'slow': min(500, initial_window * 2),
            'boundary': max(20, initial_window // 3)
        }
    
    def _detect_structural_patterns(self,
                                   lambda_structures: Dict,
                                   boundaries: Dict,
                                   window: int
                                   ) -> List[Dict]:
        """æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º"""
        patterns = []
        
        if isinstance(boundaries, dict) and 'boundary_locations' in boundaries:
            boundary_locs = boundaries['boundary_locations']
            
            if len(boundary_locs) > 0:
                if boundary_locs[0] > 30:
                    patterns.append({
                        'type': 'initial_structure',
                        'start': 0,
                        'end': boundary_locs[0],
                        'duration': boundary_locs[0]
                    })
                
                for i in range(len(boundary_locs) - 1):
                    duration = boundary_locs[i+1] - boundary_locs[i]
                    if duration > 20:
                        pattern_type = 'elastic' if duration < 100 else 'plastic'
                        patterns.append({
                            'type': pattern_type,
                            'start': boundary_locs[i],
                            'end': boundary_locs[i+1],
                            'duration': duration
                        })
        
        return patterns
    
    def _detect_critical_events(self, anomaly_scores: Dict) -> List:
        """è‡¨ç•Œã‚¤ãƒ™ãƒ³ãƒˆã®æ¤œå‡º"""
        events = []
        
        if 'combined' in anomaly_scores:
            scores = anomaly_scores['combined']
            threshold = np.mean(scores) + 1.5 * np.std(scores)
            
            critical_frames = np.where(scores > threshold)[0]
            
            if len(critical_frames) > 0:
                current_start = critical_frames[0]
                current_end = critical_frames[0]
                
                for frame in critical_frames[1:]:
                    if frame == current_end + 1:
                        current_end = frame
                    else:
                        events.append((current_start, current_end))
                        current_start = frame
                        current_end = frame
                
                events.append((current_start, current_end))
        
        return events
    
    def _to_cpu_dict(self, data_dict: Optional[Dict]) -> Dict:
        """GPUé…åˆ—ã‚’CPUã«è»¢é€"""
        if data_dict is None:
            return {}
        
        cpu_dict = {}
        for key, value in data_dict.items():
            if hasattr(value, 'get'):  # CuPyé…åˆ—
                cpu_dict[key] = self.to_cpu(value)
            elif isinstance(value, dict):
                cpu_dict[key] = self._to_cpu_dict(value)
            else:
                cpu_dict[key] = value
        return cpu_dict
    
    def _get_gpu_info(self) -> Dict:
        """GPUæƒ…å ±ã®å–å¾—"""
        gpu_info = {
            'device_name': str(self.device),
            'computation_mode': 'single_batch'
        }
        
        try:
            mem_info = self.memory_manager.get_memory_info()
            gpu_info['memory_used'] = mem_info.used / 1e9
        except:
            gpu_info['memory_used'] = 0.0
        
        return gpu_info
    
    def _create_empty_result(self, n_frames: int, n_atoms: int) -> MaterialLambda3Result:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return MaterialLambda3Result(
            lambda_structures={},
            structural_boundaries={},
            topological_breaks={},
            md_features={},
            anomaly_scores={},
            detected_structures=[],
            n_frames=n_frames,
            n_atoms=n_atoms,
            window_steps=100,
            gpu_info={'computation_mode': 'batched', 'n_batches': 0}
        )
    
    def _print_analysis_header(self, n_frames: int, n_atoms: int):
        """è§£æãƒ˜ãƒƒãƒ€ãƒ¼ã®è¡¨ç¤º"""
        print(f"\n{'='*60}")
        print(f"=== LambdaÂ³ Material Analysis (Physics-Integrated v3.0) ===")
        print(f"{'='*60}")
        print(f"Trajectory: {n_frames} frames, {n_atoms} atoms")
        print(f"Material: {self.config.material_type}")
        print(f"GPU Device: {self.device}")
        print(f"Physical Damage: {'ON' if self.config.use_physical_damage else 'OFF'}")
        
        try:
            mem_info = self.memory_manager.get_memory_info()
            print(f"Available GPU Memory: {mem_info.free / 1e9:.2f} GB")
        except:
            pass
    
    def _print_initialization_info(self):
        """åˆæœŸåŒ–æƒ…å ±ã®è¡¨ç¤º"""
        if self.verbose:
            print(f"\nğŸ’ Material LambdaÂ³ GPU Detector v3.0 Initialized")
            print(f"   Material: {self.config.material_type}")
            print(f"   Device: {self.device}")
            print(f"   GPU Mode: {self.is_gpu}")
            
            try:
                mem_info = self.memory_manager.get_memory_info()
                print(f"   Available Memory: {mem_info.free / 1e9:.2f} GB")
            except:
                pass
            
            print(f"   Batch Size: {self.config.gpu_batch_size} frames")
            print(f"   Material Analytics: {'ON' if self.config.use_material_analytics else 'OFF'}")
            print(f"   Physical Damage: {'ON' if self.config.use_physical_damage else 'OFF'}")
    
    def _print_summary(self, result: MaterialLambda3Result):
        """çµæœã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º"""
        print("\n" + "="*60)
        print("=== Analysis Complete ===")
        print("="*60)
        print(f"Total frames: {result.n_frames}")
        print(f"Computation time: {result.computation_time:.2f} seconds")
        
        if result.computation_time > 0:
            print(f"Speed: {result.n_frames / result.computation_time:.1f} frames/second")
        
        # ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è§£æçµæœï¼ˆNEW!ï¼‰
        if result.physical_damage:
            print(f"\nâš¡ Physical Damage Analysis:")
            print(f"  Max damage: {result.physical_damage['max_damage']:.1%}")
            print(f"  Failure probability: {result.physical_damage['failure_probability']:.1%}")
            if result.physical_damage.get('remaining_life'):
                print(f"  Remaining life: {result.physical_damage['remaining_life']:.1f} cycles")
            print(f"  Critical clusters: {len(result.physical_damage.get('critical_clusters', []))}")
        
        # çµ±åˆç ´å£Šäºˆæ¸¬
        if result.failure_prediction:
            print(f"\nğŸ”¬ Integrated Failure Prediction:")
            if 'integrated_failure_probability' in result.failure_prediction:
                print(f"  Integrated probability: {result.failure_prediction['integrated_failure_probability']:.1%}")
            else:
                print(f"  Traditional probability: {result.failure_prediction['failure_probability']:.1%}")
            print(f"  Reliability index: {result.failure_prediction['reliability_index']:.2f}")
            print(f"  Failure mode: {result.failure_prediction.get('integrated_failure_mode', result.failure_prediction.get('failure_mode', 'unknown'))}")
        
        # ææ–™ã‚¤ãƒ™ãƒ³ãƒˆ
        if result.material_events:
            print(f"\nğŸ“Š Material Events: {len(result.material_events)}")
            event_types = {}
            for event in result.material_events:
                if len(event) >= 3:
                    event_types[event[2]] = event_types.get(event[2], 0) + 1
            
            if event_types:
                print("  Event types:")
                for etype, count in sorted(event_types.items(), key=lambda x: x[1], reverse=True):
                    print(f"    - {etype}: {count}")

# ===============================
# Module Functions
# ===============================

def detect_material_events(trajectory: np.ndarray,
                          atom_types: np.ndarray,
                          config: Optional[MaterialConfig] = None,
                          **kwargs) -> List[Tuple[int, int, str]]:
    """ææ–™ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ¤œå‡ºã™ã‚‹ä¾¿åˆ©é–¢æ•°ï¼ˆç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸å¯¾å¿œç‰ˆï¼‰"""
    config = config or MaterialConfig()
    detector = MaterialLambda3DetectorGPU(config)
    
    result = detector.analyze(
        trajectory=trajectory,
        atom_types=atom_types,
        **kwargs
    )
    
    if hasattr(result, 'material_events') and result.material_events:
        return result.material_events
    
    events = []
    if hasattr(result, 'critical_events'):
        for event in result.critical_events:
            if isinstance(event, tuple) and len(event) >= 2:
                events.append((event[0], event[1], 'material_event'))
    
    return events

def analyze_with_physics(trajectory: np.ndarray,
                        atom_types: Optional[np.ndarray] = None,
                        material_type: str = 'SUJ2',
                        temperature: float = 300.0,
                        **kwargs) -> MaterialLambda3Result:
    """ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è§£æã‚’å«ã‚€å®Œå…¨è§£æã®ä¾¿åˆ©é–¢æ•°"""
    config = MaterialConfig(
        material_type=material_type,
        use_physical_damage=True,
        damage_temperature=temperature
    )
    
    detector = MaterialLambda3DetectorGPU(config)
    return detector.analyze(trajectory, atom_types=atom_types, **kwargs)

# ===============================
# Test Function
# ===============================

if __name__ == "__main__":
    print("ğŸ’ Material LambdaÂ³ Detector GPU v3.0 - Physics Integration Test")
    print("=" * 70)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    n_frames = 100
    n_atoms = 1000
    trajectory = np.random.randn(n_frames, n_atoms, 3).astype(np.float32) * 0.1
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å®šç¾©
    cluster_atoms = {
        0: list(range(0, 900)),      # å¥å…¨é ˜åŸŸ
        1: list(range(900, 950)),    # æ¬ é™¥ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼1
        2: list(range(950, 1000)),   # æ¬ é™¥ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼2
    }
    
    # ç‰©ç†ãƒ€ãƒ¡ãƒ¼ã‚¸è§£æã‚’æœ‰åŠ¹ã«ã—ãŸè¨­å®š
    config = MaterialConfig(
        material_type='SUJ2',
        use_physical_damage=True,
        damage_temperature=300.0
    )
    
    # æ¤œå‡ºå™¨ã®åˆæœŸåŒ–ã¨å®Ÿè¡Œ
    detector = MaterialLambda3DetectorGPU(config)
    result = detector.analyze(
        trajectory=trajectory,
        cluster_atoms=cluster_atoms
    )
    
    print("\nâœ¨ Physical Damage Integration Complete!")
    
    if result.physical_damage:
        print("\nğŸ“Š Physical Damage Summary:")
        print(f"   Max Damage: {result.physical_damage['max_damage']:.1%}")
        print(f"   Failure Probability: {result.physical_damage['failure_probability']:.1%}")
        print(f"   Temperature: {result.physical_damage['temperature']:.1f} K")
    
    print("\nğŸ‰ Test completed successfully!")
    
