#!/usr/bin/env python3
"""
Material LambdaÂ³ Detector GPU - Enhanced with Topological Analysis
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

ææ–™è§£æç”¨LambdaÂ³æ¤œå‡ºå™¨ã®GPUå®Ÿè£…
é‡‘å±ãƒ»ã‚»ãƒ©ãƒŸãƒƒã‚¯ã‚¹ãƒ»ãƒãƒªãƒãƒ¼ã®ç–²åŠ´ãƒ»ç ´å£Šã‚’é«˜é€Ÿæ¤œå‡ºï¼ğŸ’
ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«æ¬ é™¥ã®è“„ç©ã¨æ§‹é€ ä¸€è²«æ€§ã‚’è¿½è·¡

MDç‰ˆã‚’ãƒ™ãƒ¼ã‚¹ã«ææ–™ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼è§£æã«ç‰¹åŒ–

by ç’°ã¡ã‚ƒã‚“ - Material Edition v2.0
"""

import numpy as np
import time
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
import warnings
import logging
from scipy.spatial import cKDTree

logger = logging.getLogger('lambda3_gpu.material_analysis')

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

# CuPyã®æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import cupy as cp
    HAS_GPU = True
except ImportError:
    cp = None
    HAS_GPU = False

# LambdaÂ³ GPU imports
from lambda3_gpu.core.gpu_utils import GPUBackend
try:
    from lambda3_gpu.material_analysis.cuda_kernels import MaterialCUDAKernels
    HAS_CUDA_KERNELS = True
except ImportError:
    MaterialCUDAKernels = None
    HAS_CUDA_KERNELS = False
from lambda3_gpu.material.cluster_structures_gpu import ClusterStructuresGPU
from lambda3_gpu.material.cluster_network_gpu import ClusterNetworkGPU
from lambda3_gpu.material.cluster_causality_analysis_gpu import MaterialCausalityAnalyzerGPU
from lambda3_gpu.material.cluster_confidence_analysis_gpu import MaterialConfidenceAnalyzerGPU

# æ¤œå‡ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆMDç‰ˆã‹ã‚‰æµç”¨ï¼‰
from lambda3_gpu.detection.anomaly_detection_gpu import AnomalyDetectorGPU
from lambda3_gpu.detection.boundary_detection_gpu import BoundaryDetectorGPU
from lambda3_gpu.detection.topology_breaks_gpu import TopologyBreaksDetectorGPU

# ===============================
# Configuration
# ===============================

@dataclass
class MaterialConfig:
    """ææ–™è§£æè¨­å®š"""
    # LambdaÂ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    adaptive_window: bool = True
    sensitivity: float = 1.5  # ææ–™ã¯ä½ã‚ã«
    min_boundary_gap: int = 50  # ææ–™ã¯çŸ­ã„æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«
    
    # ææ–™ç‰¹æœ‰ã®è¨­å®š
    use_coordination: bool = True  # é…ä½æ•°è§£æ
    use_strain: bool = True  # æ­ªã¿è§£æ
    use_damage: bool = True  # æå‚·è§£æ
    use_topological: bool = True  # ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«è§£æï¼ˆæ–°è¦è¿½åŠ ï¼‰
    detect_dislocations: bool = True  # è»¢ä½æ¤œå‡º
    detect_cracks: bool = True  # äº€è£‚æ¤œå‡º
    
    # ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    material_type: str = 'SUJ2'  # 'SUJ2', 'AL7075', 'TI6AL4V'
    crystal_structure: str = 'BCC'  # 'BCC', 'FCC', 'HCP'
    cutoff_distance: float = 3.0  # Ã…
    strain_threshold: float = 0.01  # 1%æ­ªã¿
    damage_threshold: float = 0.5  # 50%æå‚·
    
    # GPUè¨­å®š
    gpu_batch_size: int = 5000  # ææ–™ã¯å°ã•ã‚
    mixed_precision: bool = False
    benchmark_mode: bool = False
    
    # ç•°å¸¸æ¤œå‡ºã®é‡ã¿
    w_strain: float = 0.4  # æ­ªã¿ç•°å¸¸ã®é‡ã¿
    w_coordination: float = 0.3  # é…ä½æ•°ç•°å¸¸ã®é‡ã¿
    w_damage: float = 0.3  # æå‚·ç•°å¸¸ã®é‡ã¿

    # CUDAæœ€é©åŒ–è¨­å®š
    use_cuda_kernels: bool = True  # CUDAã‚«ãƒ¼ãƒãƒ«ä½¿ç”¨
    cuda_kernel_fallback: bool = True  # å¤±æ•—æ™‚ã¯æ¨™æº–å®Ÿè£…ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

@dataclass
class MaterialLambda3Result:
    """ææ–™LambdaÂ³è§£æçµæœ"""
    # Core LambdaÂ³æ§‹é€ 
    cluster_structures: Dict[str, np.ndarray]  # ClusterStructureResult
    structural_boundaries: Dict[str, Any]
    topological_breaks: Dict[str, np.ndarray]
    
    # ææ–™ç‰¹æœ‰ã®ç‰¹å¾´
    material_features: Dict[str, np.ndarray]
    coordination_defects: Optional[np.ndarray] = None
    strain_tensors: Optional[np.ndarray] = None
    damage_accumulation: Optional[np.ndarray] = None
    
    # ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«è§£æçµæœï¼ˆæ–°è¦è¿½åŠ ï¼‰
    topological_charge: Optional[np.ndarray] = None
    topological_charge_cumulative: Optional[np.ndarray] = None
    structural_coherence: Optional[np.ndarray] = None
    
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æ
    strain_network: Optional[List] = None
    dislocation_network: Optional[List] = None
    damage_network: Optional[List] = None
    
    # è§£æçµæœ
    anomaly_scores: Dict[str, np.ndarray] = field(default_factory=dict)
    detected_structures: List[Dict] = field(default_factory=list)
    critical_clusters: List[int] = field(default_factory=list)
    material_events: List[Tuple[int, int, str]] = field(default_factory=list)  # è¿½åŠ 
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    n_frames: int = 0
    n_atoms: int = 0
    n_clusters: int = 0
    window_steps: int = 0
    computation_time: float = 0.0
    gpu_info: Optional[Dict] = None
    critical_events: List = field(default_factory=list)
    
    # ææ–™ç‰¹æ€§
    material_properties: Optional[Dict] = None
    failure_probability: float = 0.0
    reliability_index: float = 0.0

# ===============================
# Material Features GPU
# ===============================

class MaterialFeaturesGPU(GPUBackend):
    """ææ–™ç‰¹å¾´æŠ½å‡ºã®GPUå®Ÿè£…ï¼ˆCUDAæœ€é©åŒ–ç‰ˆï¼‰"""
    
    def __init__(self, force_cpu: bool = False, use_cuda: bool = True):
        super().__init__(force_cpu=force_cpu)
        
        # CUDAã‚«ãƒ¼ãƒãƒ«åˆæœŸåŒ–
        self.cuda_kernels = None
        if use_cuda and HAS_CUDA_KERNELS and not force_cpu:
            try:
                from lambda3_gpu.material_analysis.cuda_kernels import MaterialCUDAKernels
                self.cuda_kernels = MaterialCUDAKernels()
                if self.cuda_kernels.compiled:
                    logger.info("ğŸš€ CUDA kernels enabled for material features")
            except Exception as e:
                logger.warning(f"CUDA kernels disabled: {e}")
    
    def extract_material_features(self,
                                 trajectory: np.ndarray,
                                 cluster_atoms: Dict[int, List[int]],
                                 atom_types: np.ndarray,
                                 config: MaterialConfig) -> Dict[str, np.ndarray]:
        """
        ææ–™ç‰¹å¾´ã‚’æŠ½å‡º
        
        Parameters
        ----------
        trajectory : np.ndarray
            åŸå­ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒª (n_frames, n_atoms, 3)
        cluster_atoms : Dict[int, List[int]]
            ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å®šç¾©
        atom_types : np.ndarray
            åŸå­ã‚¿ã‚¤ãƒ—
        config : MaterialConfig
            è¨­å®š
            
        Returns
        -------
        Dict[str, np.ndarray]
            ææ–™ç‰¹å¾´ã®è¾æ›¸
        """
        features = {}
        n_frames = trajectory.shape[0]
        n_clusters = len(cluster_atoms)
        
        # é…ä½æ•°è¨ˆç®—
        if config.use_coordination:
            if config.use_cuda_kernels and self.cuda_kernels and self.cuda_kernels.compiled:
                features['coordination'] = self._compute_coordination_cuda(
                    trajectory, cluster_atoms, config.cutoff_distance
                )
            else:
                features['coordination'] = self._compute_coordination_numbers(
                    trajectory, cluster_atoms, config.cutoff_distance
                )
        
        # æ­ªã¿è¨ˆç®—
        if config.use_strain:
            if config.use_cuda_kernels and self.cuda_kernels and self.cuda_kernels.compiled:
                features['strain'] = self._compute_strain_tensors_cuda(
                    trajectory, cluster_atoms
                )
            else:
                features['strain'] = self._compute_strain_tensors(
                    trajectory, cluster_atoms
                )
        
        # æå‚·åº¦è¨ˆç®—
        if config.use_damage:
            if config.use_cuda_kernels and self.cuda_kernels and self.cuda_kernels.compiled:
                features['damage'] = self._compute_damage_scores_cuda(
                    trajectory, cluster_atoms, atom_types
                )
            else:
                features['damage'] = self._compute_damage_scores(
                    trajectory, cluster_atoms, atom_types
                )
        
        return features
    
    # ========================================
    # CUDAç‰ˆãƒ¡ã‚½ãƒƒãƒ‰
    # ========================================
    
    def _compute_coordination_cuda(self,
                                  trajectory: np.ndarray,
                                  cluster_atoms: Dict[int, List[int]],
                                  cutoff: float) -> np.ndarray:
        """CUDAç‰ˆé…ä½æ•°è¨ˆç®—"""
        n_frames = trajectory.shape[0]
        n_clusters = len(cluster_atoms)
        coordination = np.zeros((n_frames, n_clusters))
        
        for frame in range(n_frames):
            positions_gpu = cp.asarray(trajectory[frame])
            coord_gpu = self.cuda_kernels.compute_coordination_cuda(
                positions_gpu, cluster_atoms, cutoff
            )
            coordination[frame] = cp.asnumpy(coord_gpu)
        
        return coordination
    
    def _compute_strain_tensors_cuda(self,
                                    trajectory: np.ndarray,
                                    cluster_atoms: Dict[int, List[int]]) -> np.ndarray:
        """CUDAç‰ˆæ­ªã¿ãƒ†ãƒ³ã‚½ãƒ«è¨ˆç®—"""
        n_frames = trajectory.shape[0]
        n_clusters = len(cluster_atoms)
        strain = np.zeros((n_frames, n_clusters))
        
        if n_frames < 2:
            return strain
        
        ref_pos_gpu = cp.asarray(trajectory[0])
        
        for frame in range(1, n_frames):
            curr_pos_gpu = cp.asarray(trajectory[frame])
            strain_gpu = self.cuda_kernels.compute_strain_tensors_cuda(
                ref_pos_gpu, curr_pos_gpu, cluster_atoms, n_frames
            )
            # Voigtè¨˜æ³•ã‹ã‚‰ä¸»æ­ªã¿ã®æœ€å¤§å€¤ã‚’æŠ½å‡º
            max_strain = cp.max(cp.abs(strain_gpu), axis=1)
            strain[frame] = cp.asnumpy(max_strain)
        
        return strain
    
    def _compute_damage_scores_cuda(self,
                                   trajectory: np.ndarray,
                                   cluster_atoms: Dict[int, List[int]],
                                   atom_types: np.ndarray) -> np.ndarray:
        """CUDAç‰ˆæå‚·åº¦è¨ˆç®—"""
        n_frames = trajectory.shape[0]
        n_clusters = len(cluster_atoms)
        damage = np.zeros((n_frames, n_clusters))
        
        ref_pos_gpu = cp.asarray(trajectory[0])
        
        for frame in range(n_frames):
            curr_pos_gpu = cp.asarray(trajectory[frame])
            damage_gpu = self.cuda_kernels.compute_damage_cuda(
                ref_pos_gpu, curr_pos_gpu, cluster_atoms
            )
            damage[frame] = cp.asnumpy(damage_gpu)
        
        return damage
    
    # ========================================
    # æ¨™æº–ç‰ˆãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
    # ========================================
    
    def _compute_coordination_numbers(self,
                                     trajectory: np.ndarray,
                                     cluster_atoms: Dict[int, List[int]],
                                     cutoff: float) -> np.ndarray:
        """é…ä½æ•°è¨ˆç®—ï¼ˆæ¨™æº–ç‰ˆï¼‰"""
        n_frames = trajectory.shape[0]
        n_clusters = len(cluster_atoms)
        coordination = self.zeros((n_frames, n_clusters))
        
        for frame in range(n_frames):
            positions = self.to_gpu(trajectory[frame])
            
            for cluster_id, atoms in cluster_atoms.items():
                if cluster_id >= n_clusters:
                    continue
                    
                coord_sum = 0
                for atom_i in atoms[:10]:  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                    pos_i = positions[atom_i]
                    distances = self.xp.linalg.norm(positions - pos_i, axis=1)
                    neighbors = self.xp.sum((distances > 0) & (distances < cutoff))
                    coord_sum += neighbors
                
                coordination[frame, cluster_id] = coord_sum / min(len(atoms), 10)
        
        return self.to_cpu(coordination)
    
    def _compute_strain_tensors(self,
                               trajectory: np.ndarray,
                               cluster_atoms: Dict[int, List[int]]) -> np.ndarray:
        """æ­ªã¿ãƒ†ãƒ³ã‚½ãƒ«è¨ˆç®—ï¼ˆæ¨™æº–ç‰ˆï¼‰"""
        n_frames = trajectory.shape[0]
        n_clusters = len(cluster_atoms)
        strain = self.zeros((n_frames, n_clusters))
        
        if n_frames < 2:
            return self.to_cpu(strain)
        
        ref_positions = self.to_gpu(trajectory[0])
        
        for frame in range(1, n_frames):
            current_positions = self.to_gpu(trajectory[frame])
            
            for cluster_id, atoms in cluster_atoms.items():
                if cluster_id >= n_clusters or len(atoms) < 4:
                    continue
                
                # ç°¡æ˜“æ­ªã¿ï¼šç›¸å¯¾å¤‰ä½ã®å¹³å‡
                sample_atoms = atoms[:10]
                ref_pos = ref_positions[sample_atoms]
                curr_pos = current_positions[sample_atoms]
                
                displacement = self.xp.linalg.norm(curr_pos - ref_pos, axis=1)
                strain[frame, cluster_id] = self.xp.mean(displacement)
        
        return self.to_cpu(strain)
    
    def _compute_damage_scores(self,
                              trajectory: np.ndarray,
                              cluster_atoms: Dict[int, List[int]],
                              atom_types: np.ndarray) -> np.ndarray:
        """æå‚·åº¦è¨ˆç®—ï¼ˆæ¨™æº–ç‰ˆï¼‰"""
        n_frames = trajectory.shape[0]
        n_clusters = len(cluster_atoms)
        damage = self.zeros((n_frames, n_clusters))
        
        # åˆæœŸæ§‹é€ ã‹ã‚‰ã®å¤‰ä½ã§æå‚·ã‚’æ¨å®š
        ref_positions = self.to_gpu(trajectory[0])
        
        for frame in range(n_frames):
            current_positions = self.to_gpu(trajectory[frame])
            
            for cluster_id, atoms in cluster_atoms.items():
                if cluster_id >= n_clusters:
                    continue
                
                ref_pos = ref_positions[atoms]
                curr_pos = current_positions[atoms]
                
                # RMSDãƒ™ãƒ¼ã‚¹ã®æå‚·åº¦
                rmsd = self.xp.sqrt(self.xp.mean((curr_pos - ref_pos) ** 2))
                damage[frame, cluster_id] = self.xp.tanh(rmsd / 2.0)  # 0-1ã«æ­£è¦åŒ–
        
        return self.to_cpu(damage)
                                  
# ===============================
# Material LambdaÂ³ Detector GPU
# ===============================

class MaterialLambda3DetectorGPU(GPUBackend):
    """ææ–™ç”¨LambdaÂ³æ¤œå‡ºå™¨ï¼ˆGPUç‰ˆï¼‰"""
    
    def __init__(self, config: MaterialConfig = None, device: str = 'auto'):
        """
        Parameters
        ----------
        config : MaterialConfig
            è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        device : str
            'auto', 'gpu', 'cpu'ã®ã„ãšã‚Œã‹
        """
        # GPUBackendã®åˆæœŸåŒ–
        if device == 'cpu':
            super().__init__(device='cpu', force_cpu=True)
        else:
            super().__init__(device=device, force_cpu=False)
        
        self.config = config or MaterialConfig()
        self.verbose = True
        
        # force_cpuãƒ•ãƒ©ã‚°
        force_cpu_flag = not self.is_gpu
        
        # ææ–™ç‰ˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.structure_computer = ClusterStructuresGPU()
        self.structure_computer = ClusterStructuresGPU()
        self.feature_extractor = MaterialFeaturesGPU(
            force_cpu=force_cpu_flag,
            use_cuda=config.use_cuda_kernels  # CUDAã‚«ãƒ¼ãƒãƒ«è¨­å®šã‚’æ¸¡ã™
        )
        self.network_analyzer = ClusterNetworkGPU()
        self.causality_analyzer = MaterialCausalityAnalyzerGPU()
        self.confidence_analyzer = MaterialConfidenceAnalyzerGPU()
        
        # æ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆMDç‰ˆã‹ã‚‰æµç”¨ï¼‰
        self.anomaly_detector = AnomalyDetectorGPU(force_cpu_flag)
        self.boundary_detector = BoundaryDetectorGPU(force_cpu_flag)
        self.topology_detector = TopologyBreaksDetectorGPU(force_cpu_flag)
        
        # ææ–™ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£è¨­å®š
        self._set_material_properties()
        
        # ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ã¨ãƒ‡ãƒã‚¤ã‚¹ã‚’å…±æœ‰
        for component in [self.structure_computer, self.feature_extractor,
                         self.network_analyzer, self.causality_analyzer,
                         self.confidence_analyzer, self.anomaly_detector,
                         self.boundary_detector, self.topology_detector]:
            if hasattr(component, 'memory_manager'):
                component.memory_manager = self.memory_manager
            if hasattr(component, 'device'):
                component.device = self.device
        
        self._print_initialization_info()
    
    def _set_material_properties(self):
        """ææ–™ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’è¨­å®š"""
        if self.config.material_type == 'SUJ2':
            self.material_props = {
                'elastic_modulus': 210.0,  # GPa
                'yield_strength': 1.5,
                'ultimate_strength': 2.0,
                'fatigue_strength': 0.7,
                'fracture_toughness': 30.0
            }
        elif self.config.material_type == 'AL7075':
            self.material_props = {
                'elastic_modulus': 71.7,
                'yield_strength': 0.503,
                'ultimate_strength': 0.572,
                'fatigue_strength': 0.159,
                'fracture_toughness': 23.0
            }
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆé‹¼é‰„ï¼‰
            self.material_props = {
                'elastic_modulus': 210.0,
                'yield_strength': 1.0,
                'ultimate_strength': 1.5,
                'fatigue_strength': 0.5,
                'fracture_toughness': 20.0
            }
    
    # ========================================
    # ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«è§£æãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆæ–°è¦è¿½åŠ ï¼‰
    # ========================================
    
    def _compute_topological_charge(self, 
                                   trajectory: np.ndarray,
                                   cluster_atoms: Dict[int, List[int]],
                                   atom_types: np.ndarray,
                                   cutoff: float = 3.5) -> Dict[str, np.ndarray]:
        """
        ææ–™ã®ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ãƒãƒ£ãƒ¼ã‚¸è¨ˆç®—
        è»¢ä½ãƒ»ç©ºå­”ãƒ»æ ¼å­é–“åŸå­ã®ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«æ¬ é™¥ã‚’å®šé‡åŒ–
        """
        n_frames = trajectory.shape[0]
        n_clusters = len(cluster_atoms)
        
        # å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ãƒãƒ£ãƒ¼ã‚¸
        Q_lambda = np.zeros((n_frames-1, n_clusters))
        
        for frame in range(n_frames-1):
            for cid, atoms in cluster_atoms.items():
                if cid >= n_clusters:
                    continue
                    
                # Burgerså›è·¯ã«ã‚ˆã‚‹è»¢ä½æ¤œå‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
                burgers_vector = self._compute_burgers_vector(
                    trajectory[frame], atoms, cutoff
                )
                
                # é…ä½æ•°æ¬ é™¥ã®å¤‰åŒ–ç‡
                coord_change = self._compute_coordination_change(
                    trajectory[frame], trajectory[frame+1], atoms, cutoff
                )
                
                # ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ãƒãƒ£ãƒ¼ã‚¸ = è»¢ä½å¯†åº¦ + é…ä½æ¬ é™¥å¤‰åŒ–
                Q_lambda[frame, cid] = (
                    np.linalg.norm(burgers_vector) / (len(atoms) + 1) +
                    abs(coord_change) * 0.1  # é‡ã¿ä»˜ã‘
                )
        
        # ç´¯ç©ãƒãƒ£ãƒ¼ã‚¸ï¼ˆæ¬ é™¥ã®è“„ç©ï¼‰
        Q_cumulative = np.cumsum(np.sum(Q_lambda, axis=1))
        
        return {
            'Q_lambda': Q_lambda,
            'Q_cumulative': Q_cumulative
        }
    
    def _compute_burgers_vector(self,
                               positions: np.ndarray,
                               atoms: List[int],
                               cutoff: float) -> np.ndarray:
        """Burgers vectorã®è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        if len(atoms) < 10:
            return np.zeros(3)
        
        # ã‚µãƒ³ãƒ—ãƒ«åŸå­å‘¨ã‚Šã®å›è·¯ã‚’è¨ˆç®—
        center_atom = atoms[len(atoms)//2]
        center_pos = positions[center_atom]
        
        # è¿‘å‚åŸå­
        distances = np.linalg.norm(positions[atoms] - center_pos, axis=1)
        neighbors = [atoms[i] for i in range(len(atoms)) 
                    if 0 < distances[i] < cutoff]
        
        if len(neighbors) < 6:
            return np.zeros(3)
        
        # ç°¡æ˜“Burgerså›è·¯ï¼ˆ6åŸå­ã®é–‰è·¯ï¼‰
        circuit = neighbors[:6]
        burgers = np.zeros(3)
        
        for i in range(len(circuit)):
            j = (i + 1) % len(circuit)
            burgers += positions[circuit[j]] - positions[circuit[i]]
        
        # ç†æƒ³çš„ãªé–‰è·¯ãªã‚‰0ã«ãªã‚‹ã¯ãš
        return burgers
    
    def _compute_coordination_change(self,
                                    pos1: np.ndarray,
                                    pos2: np.ndarray,
                                    atoms: List[int],
                                    cutoff: float) -> float:
        """é…ä½æ•°å¤‰åŒ–ã®è¨ˆç®—"""
        if len(atoms) < 5:
            return 0.0
        
        # ã‚µãƒ³ãƒ—ãƒ«åŸå­ã®é…ä½æ•°å¤‰åŒ–
        sample_atoms = atoms[:min(5, len(atoms))]
        coord_change = 0.0
        
        for atom in sample_atoms:
            # frame1ã§ã®é…ä½æ•°
            dist1 = np.linalg.norm(pos1 - pos1[atom], axis=1)
            coord1 = np.sum((dist1 > 0) & (dist1 < cutoff))
            
            # frame2ã§ã®é…ä½æ•°
            dist2 = np.linalg.norm(pos2 - pos2[atom], axis=1)
            coord2 = np.sum((dist2 > 0) & (dist2 < cutoff))
            
            coord_change += abs(coord2 - coord1)
        
        return coord_change / len(sample_atoms)
    
    def _compute_structural_coherence(self,
                                     coordination: np.ndarray,
                                     strain: np.ndarray,
                                     ideal_coord: int = 8) -> np.ndarray:
        """
        æ§‹é€ ä¸€è²«æ€§ã®è¨ˆç®—
        ç†±ã‚†ã‚‰ãã¨æ°¸ç¶šçš„æ§‹é€ å¤‰åŒ–ã‚’åŒºåˆ¥
        """
        n_frames, n_clusters = coordination.shape
        coherence = np.ones(n_frames)
        
        window = min(50, n_frames // 4)  # æ™‚é–“å¹³å‡ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
        
        for i in range(window, n_frames - window):
            cluster_coherence = []
            
            for c in range(n_clusters):
                # é…ä½æ•°ã®æ™‚é–“çš„ä¸€è²«æ€§
                local_coord = coordination[i-window:i+window, c]
                coord_std = np.std(local_coord)
                coord_mean = np.mean(local_coord)
                
                # ç†æƒ³é…ä½æ•°ã‹ã‚‰ã®ãšã‚Œã®ä¸€è²«æ€§
                if coord_std < 0.5 and abs(coord_mean - ideal_coord) < 1:
                    # å®‰å®šã—ã¦ç†æƒ³æ§‹é€ ã‚’ä¿æŒ
                    cluster_coherence.append(1.0)
                elif coord_std > 2.0:
                    # æ¿€ã—ãæºã‚‰ã„ã§ã„ã‚‹ï¼ˆç†±çš„ï¼‰
                    cluster_coherence.append(0.3)
                else:
                    # æ§‹é€ å¤‰åŒ–ä¸­
                    cluster_coherence.append(1.0 - coord_std / 3.0)
                
                # æ­ªã¿ã«ã‚ˆã‚‹è£œæ­£
                if strain[i, c] > 0.05:  # 5%ä»¥ä¸Šã®æ­ªã¿
                    cluster_coherence[-1] *= (1.0 - min(strain[i, c], 1.0))
            
            coherence[i] = np.mean(cluster_coherence)
        
        # ã‚¨ãƒƒã‚¸å‡¦ç†
        coherence[:window] = coherence[window]
        coherence[-window:] = coherence[-window-1]
        
        return coherence
    
    # ========================================
    # ãƒ¡ã‚¤ãƒ³è§£æãƒ¡ã‚½ãƒƒãƒ‰
    # ========================================
    
    def analyze(self,
               trajectory: np.ndarray,
               atom_types: np.ndarray,
               cluster_atoms: Optional[Dict[int, List[int]]] = None,
               strain_field: Optional[np.ndarray] = None,
               **kwargs) -> MaterialLambda3Result:
        """
        ææ–™ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªã®LambdaÂ³è§£æ
        """
        start_time = time.time()
        
        # cluster_atomsãŒãªã‘ã‚Œã°è‡ªå‹•ç”Ÿæˆ
        if cluster_atoms is None:
            n_atoms = trajectory.shape[1]
            cluster_atoms = {0: list(range(n_atoms))}
        
        # atom_typesãŒæ–‡å­—åˆ—ã®å ´åˆã€æ•°å€¤ã«å¤‰æ›
        if atom_types.dtype.kind == 'U' or atom_types.dtype.kind == 'S':
            # æ–‡å­—åˆ—ã‚’æ•°å€¤ã«ãƒãƒƒãƒ”ãƒ³ã‚°
            unique_types = np.unique(atom_types)
            type_to_id = {atype: i for i, atype in enumerate(unique_types)}
            atom_types_numeric = np.array([type_to_id[atype] for atype in atom_types])
            
            # å…ƒã®æ–‡å­—åˆ—å‹ã‚‚ä¿å­˜ã—ã¦ãŠã
            self.atom_type_labels = unique_types
            print(f"ğŸ“ Atom types mapped: {dict(zip(unique_types, range(len(unique_types))))}")
        else:
            atom_types_numeric = atom_types
        
        # GPUå¤‰æ›
        if self.is_gpu and cp is not None:
            print("ğŸ“Š Converting arrays to GPU...")
            trajectory = cp.asarray(trajectory)
            atom_types = cp.asarray(atom_types_numeric)  # æ•°å€¤é…åˆ—ã‚’GPUã¸
        else:
            atom_types = atom_types_numeric
        
        n_frames, n_atoms, _ = trajectory.shape
        n_clusters = len(cluster_atoms)
        
        print(f"\n{'='*60}")
        print(f"=== Material LambdaÂ³ Analysis (GPU) ===")
        print(f"{'='*60}")
        print(f"Trajectory: {n_frames} frames, {n_atoms} atoms")
        print(f"Clusters: {n_clusters}")
        print(f"Material: {self.config.material_type}")
        print(f"GPU Device: {self.device}")
        
        # ãƒãƒƒãƒå‡¦ç†åˆ¤å®š
        batch_size = min(self.config.gpu_batch_size, n_frames)
        n_batches = (n_frames + batch_size - 1) // batch_size
        
        if n_batches > 1:
            print(f"Processing in {n_batches} batches of {batch_size} frames")
            result = self._analyze_batched(trajectory, cluster_atoms, atom_types, batch_size)
        else:
            result = self._analyze_single_trajectory(trajectory, cluster_atoms, atom_types)
        
        computation_time = time.time() - start_time
        result.computation_time = computation_time
        
        self._print_summary(result)
        
        return result
    
    def _analyze_single_trajectory(self,
                                 trajectory: np.ndarray,
                                 cluster_atoms: Dict[int, List[int]],
                                 atom_types: np.ndarray) -> MaterialLambda3Result:
        """å˜ä¸€è»Œé“ã®è§£æ"""
        n_frames, n_atoms, _ = trajectory.shape
        n_clusters = len(cluster_atoms)
        
        # 1. ææ–™ç‰¹å¾´æŠ½å‡º
        print("\n1. Extracting material features...")
        material_features = self.feature_extractor.extract_material_features(
            trajectory, cluster_atoms, atom_types, self.config
        )
        
        # 2. ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ§‹é€ è¨ˆç®—
        print("\n2. Computing cluster structures...")
        window_size = self._compute_initial_window(n_frames)
        
        # CPUé…åˆ—ã«å¤‰æ›
        if self.is_gpu and hasattr(trajectory, 'get'):
            trajectory_cpu = trajectory.get()
            atom_types_cpu = atom_types.get() if hasattr(atom_types, 'get') else atom_types
        else:
            trajectory_cpu = trajectory
            atom_types_cpu = atom_types
        
        cluster_result = self.structure_computer.compute_cluster_structures(
            trajectory_cpu, 0, n_frames - 1, cluster_atoms,
            atom_types_cpu, window_size, self.config.cutoff_distance
        )
        
        # 2.5. ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«è§£æ
        if self.config.use_topological:
            print("\n2.5. Computing topological charges...")
            topo_charge = self._compute_topological_charge(
                trajectory_cpu, cluster_atoms, atom_types_cpu, self.config.cutoff_distance
            )
            
            print("\n2.6. Computing structural coherence...")
            structural_coherence = self._compute_structural_coherence(
                material_features.get('coordination', np.zeros((n_frames, n_clusters))),
                material_features.get('strain', np.zeros((n_frames, n_clusters))),
                ideal_coord=8 if self.config.crystal_structure == 'BCC' else 12
            )
        else:
            topo_charge = {
                'Q_lambda': np.zeros((n_frames-1, n_clusters)),
                'Q_cumulative': np.zeros(n_frames-1)
            }
            structural_coherence = np.ones(n_frames)
        
        # Lambdaæ§‹é€ ï¼ˆå…¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®é›†ç´„ï¼‰
        if isinstance(cluster_result.cluster_lambda_f_mag, list):
            # è¤‡æ•°ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ï¼šæœ€å¤§å€¤ã§é›†ç´„ï¼ˆæœ€æ‚ªã‚±ãƒ¼ã‚¹ã‚’è¿½è·¡ï¼‰
            lambda_structures = {
                'lambda_F': np.max(cluster_result.cluster_lambda_f, axis=0),
                'lambda_F_mag': np.max(cluster_result.cluster_lambda_f_mag, axis=0),
                'rho_T': np.max(cluster_result.cluster_rho_t, axis=0),
                'coupling': np.mean(cluster_result.cluster_coupling, axis=0),  # çµåˆã¯å¹³å‡
                'Q_lambda': topo_charge['Q_lambda'],
                'Q_cumulative': topo_charge['Q_cumulative'],
                'structural_coherence': structural_coherence
            }
            # å…ƒãƒ‡ãƒ¼ã‚¿ã‚‚ä¿å­˜ï¼ˆTwo-Stageç”¨ï¼‰
            lambda_structures['_per_cluster_data'] = {
                'lambda_f_mag': cluster_result.cluster_lambda_f_mag,
                'rho_t': cluster_result.cluster_rho_t
            }
        else:
            # å˜ä¸€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼
            lambda_structures = {
                'lambda_F': cluster_result.cluster_lambda_f,
                'lambda_F_mag': cluster_result.cluster_lambda_f_mag,
                'rho_T': cluster_result.cluster_rho_t,
                'coupling': cluster_result.cluster_coupling,
                'Q_lambda': topo_charge['Q_lambda'],
                'Q_cumulative': topo_charge['Q_cumulative'],
                'structural_coherence': structural_coherence
            }
        
        # 3. æ§‹é€ å¢ƒç•Œæ¤œå‡º
        print("\n3. Detecting structural boundaries...")
        structural_boundaries = self.boundary_detector.detect_structural_boundaries(
            lambda_structures, window_size // 3
        )
        
        # 4. ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ç ´ã‚Œæ¤œå‡ºï¼ˆå…¨ä½“ã§1å›ã ã‘ï¼‰
        print("\n4. Detecting topological breaks...")
        topological_breaks = self.topology_detector.detect_topological_breaks(
            lambda_structures, window_size // 2
        )
        
        # 5. ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—
        print("\n5. Computing anomaly scores...")
        anomaly_scores = self._compute_material_anomalies(
            lambda_structures, material_features,
            structural_boundaries, topological_breaks
        )
        
        # 6. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æ
        print("\n6. Analyzing material network...")
        network_result = self.network_analyzer.analyze_network(
            {i: anomaly_scores['combined'][i::n_clusters] for i in range(n_clusters)},
            cluster_result.cluster_coupling,
            cluster_result.cluster_centers,
            cluster_result.coordination_numbers,
            cluster_result.local_strain,
            cluster_result.element_composition
        )
        
        # 7. è‡¨ç•Œã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡º
        critical_events = self._detect_critical_events(anomaly_scores)
        
        # 8. ææ–™ã‚¤ãƒ™ãƒ³ãƒˆåˆ†é¡
        material_events = self._classify_material_events(
            critical_events, anomaly_scores, structural_coherence
        )
        
        # çµæœæ§‹ç¯‰
        result = MaterialLambda3Result(
            cluster_structures=self._to_cpu_dict(lambda_structures),
            structural_boundaries=structural_boundaries,
            topological_breaks=self._to_cpu_dict(topological_breaks),
            material_features=self._to_cpu_dict(material_features),
            coordination_defects=cluster_result.coordination_numbers,
            strain_tensors=cluster_result.local_strain,
            damage_accumulation=material_features.get('damage'),
            topological_charge=topo_charge.get('Q_lambda'),
            topological_charge_cumulative=topo_charge.get('Q_cumulative'),
            structural_coherence=structural_coherence,
            strain_network=network_result.strain_network,
            dislocation_network=network_result.dislocation_network,
            damage_network=network_result.damage_network,
            anomaly_scores=self._to_cpu_dict(anomaly_scores),
            detected_structures=self._detect_structural_patterns(
                lambda_structures, structural_boundaries, window_size
            ),
            critical_clusters=network_result.critical_clusters,
            critical_events=critical_events,
            material_events=material_events,
            n_frames=n_frames,
            n_atoms=n_atoms,
            n_clusters=n_clusters,
            window_steps=window_size,
            computation_time=0.0,
            gpu_info=self._get_gpu_info(),
            material_properties=self.material_props,
            failure_probability=self._estimate_failure_probability(
                cluster_result.local_strain
            ),
            reliability_index=self._compute_reliability_index(
                cluster_result.local_strain
            )
        )
        
        return result
       
    def _classify_material_events(self,
                                 critical_events: List,
                                 anomaly_scores: Dict,
                                 structural_coherence: np.ndarray) -> List[Tuple[int, int, str]]:
        """
        ææ–™ã‚¤ãƒ™ãƒ³ãƒˆã®åˆ†é¡
        æ§‹é€ ä¸€è²«æ€§ã‚’ä½¿ã£ã¦ç†±ã‚†ã‚‰ãã¨çœŸã®æ§‹é€ å¤‰åŒ–ã‚’åŒºåˆ¥
        """
        classified_events = []
        
        for event in critical_events:
            if isinstance(event, tuple) and len(event) >= 2:
                start, end = event[0], event[1]
                
                # æ§‹é€ ä¸€è²«æ€§ã®å¹³å‡å€¤
                coherence_mean = np.mean(structural_coherence[start:end+1])
                
                # ç•°å¸¸ã‚¹ã‚³ã‚¢ã®æœ€å¤§å€¤
                if 'strain' in anomaly_scores:
                    strain_max = np.max(anomaly_scores['strain'][start:end+1])
                else:
                    strain_max = 0
                
                if 'damage' in anomaly_scores:
                    damage_max = np.max(anomaly_scores['damage'][start:end+1])
                else:
                    damage_max = 0
                
                # ã‚¤ãƒ™ãƒ³ãƒˆåˆ†é¡
                if coherence_mean < 0.5:  # æ§‹é€ ä¸€è²«æ€§ãŒä½ã„
                    if damage_max > 0.7:
                        event_type = 'crack_initiation'
                    elif strain_max > 2.0:
                        event_type = 'plastic_deformation'
                    else:
                        event_type = 'dislocation_nucleation'
                elif coherence_mean > 0.8:  # æ§‹é€ ä¸€è²«æ€§ãŒé«˜ã„
                    event_type = 'elastic_deformation'
                else:
                    event_type = 'transition_state'
                
                classified_events.append((start, end, event_type))
        
        return classified_events
    
    def _analyze_batched(self,
                        trajectory: np.ndarray,
                        cluster_atoms: Dict[int, List[int]],
                        atom_types: np.ndarray,
                        batch_size: int) -> MaterialLambda3Result:
        """ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹è§£æ"""
        # æ—¢å­˜ã®å®Ÿè£…ã¨åŒã˜
        print("\nâš¡ Running batched GPU analysis for materials...")
        
        n_frames = trajectory.shape[0]
        n_batches = (n_frames + batch_size - 1) // batch_size
        
        batch_results = []
        
        for batch_idx in range(n_batches):
            start_idx = batch_idx * batch_size
            end_idx = min((batch_idx + 1) * batch_size, n_frames)
            
            print(f"  Batch {batch_idx + 1}/{n_batches}: frames {start_idx}-{end_idx}")
            
            batch_trajectory = trajectory[start_idx:end_idx]
            
            batch_result = self._analyze_single_trajectory(
                batch_trajectory, cluster_atoms, atom_types
            )
            batch_result.offset = start_idx
            batch_results.append(batch_result)
            
            self.memory_manager.clear_cache()
        
        print("\n[Step 2] Merging batch results...")
        merged_result = self._merge_batch_results(batch_results, trajectory.shape)
        
        return merged_result
    
    def _compute_material_anomalies(self,
                                   lambda_structures: Dict,
                                   material_features: Dict,
                                   structural_boundaries: Dict,
                                   topological_breaks: Dict) -> Dict[str, np.ndarray]:
        """ææ–™ç‰¹æœ‰ã®ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        scores = {}
        
        # Lambdaç•°å¸¸
        if 'lambda_f_mag' in lambda_structures:
            lambda_anomaly = self._compute_anomaly_score(
                lambda_structures['lambda_f_mag']
            )
            scores['lambda'] = lambda_anomaly
        
        # æ­ªã¿ç•°å¸¸
        if 'strain' in material_features:
            strain_anomaly = self._compute_anomaly_score(
                material_features['strain']
            )
            scores['strain'] = strain_anomaly
        
        # é…ä½æ•°ç•°å¸¸
        if 'coordination' in material_features:
            ideal_coord = 12.0 if self.config.crystal_structure == 'FCC' else 8.0
            coord_defect = np.abs(material_features['coordination'] - ideal_coord)
            scores['coordination'] = coord_defect / ideal_coord
        
        # æå‚·ç•°å¸¸
        if 'damage' in material_features:
            scores['damage'] = material_features['damage']
        
        # ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ç•°å¸¸ï¼ˆæ–°è¦è¿½åŠ ï¼‰
        if 'Q_cumulative' in lambda_structures:
            # ç´¯ç©ãƒãƒ£ãƒ¼ã‚¸ã®åŠ é€Ÿåº¦ï¼ˆæ¬ é™¥ç”Ÿæˆç‡ï¼‰
            q_cum = lambda_structures['Q_cumulative']
            if len(q_cum) > 2:
                q_acceleration = np.abs(np.gradient(np.gradient(q_cum)))
                # ã‚µã‚¤ã‚ºã‚’åˆã‚ã›ã‚‹
                scores['topological'] = np.pad(q_acceleration, 
                                              (0, len(scores.get('lambda', [])) - len(q_acceleration)),
                                              mode='edge')
            else:
                scores['topological'] = np.zeros_like(scores.get('lambda', np.zeros(1)))
        
        # çµ±åˆã‚¹ã‚³ã‚¢
        combined = np.zeros_like(scores.get('lambda', np.zeros(1)))
        weights_sum = 0.0
        
        for key, weight in [('strain', self.config.w_strain),
                            ('coordination', self.config.w_coordination),
                            ('damage', self.config.w_damage),
                            ('topological', 0.2)]:  # ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ã®é‡ã¿
            if key in scores:
                combined += weight * scores[key]
                weights_sum += weight
        
        if weights_sum > 0:
            combined /= weights_sum
        
        scores['combined'] = combined
        
        return scores
    
    def _compute_anomaly_score(self, data: np.ndarray) -> np.ndarray:
        """ç°¡æ˜“ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        if data.size == 0:
            return np.zeros(1)
        
        mean = np.mean(data, axis=0)
        std = np.std(data, axis=0) + 1e-10
        
        z_scores = np.abs((data - mean) / std)
        
        return z_scores
    
    def _estimate_failure_probability(self, strain_tensor: np.ndarray) -> float:
        """ç ´å£Šç¢ºç‡æ¨å®š"""
        if strain_tensor is None or strain_tensor.size == 0:
            return 0.0
        
        # von Miseså¿œåŠ›æ¨å®š
        von_mises_strain = np.mean(np.abs(strain_tensor))
        critical_strain = self.material_props['yield_strength'] / self.material_props['elastic_modulus']
        
        # ç°¡æ˜“ç¢ºç‡
        if von_mises_strain > critical_strain:
            return min(1.0, von_mises_strain / critical_strain)
        
        return 0.0
    
    def _compute_reliability_index(self, strain_tensor: np.ndarray) -> float:
        """ä¿¡é ¼æ€§æŒ‡æ¨™è¨ˆç®—"""
        if strain_tensor is None or strain_tensor.size == 0:
            return 5.0  # é«˜ä¿¡é ¼æ€§
        
        # ç°¡æ˜“Î²æŒ‡æ¨™
        mean_strain = np.mean(np.abs(strain_tensor))
        std_strain = np.std(np.abs(strain_tensor))
        critical_strain = self.material_props['yield_strength'] / self.material_props['elastic_modulus']
        
        if std_strain > 0:
            beta = (critical_strain - mean_strain) / std_strain
            return float(beta)
        
        return 5.0
    
    # ========================================
    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆMDç‰ˆã‹ã‚‰æµç”¨ï¼‰
    # ========================================
    
    def _compute_initial_window(self, n_frames: int) -> int:
        """åˆæœŸã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º"""
        return min(50, n_frames // 10)  # ææ–™ã¯çŸ­ã‚
    
    def _detect_structural_patterns(self, lambda_structures: Dict,
                                   boundaries: Dict, window: int) -> List[Dict]:
        """æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º"""
        patterns = []
        
        if isinstance(boundaries, dict) and 'boundary_locations' in boundaries:
            boundary_locs = boundaries['boundary_locations']
            
            for i in range(len(boundary_locs) - 1):
                duration = boundary_locs[i+1] - boundary_locs[i]
                if duration > 20:  # ææ–™ã¯çŸ­ã„é–¾å€¤
                    pattern_type = 'elastic' if duration < 100 else 'plastic'
                    patterns.append({
                        'type': pattern_type,
                        'start': boundary_locs[i],
                        'end': boundary_locs[i+1],
                        'duration': duration
                    })
        
        return patterns
    
    def _detect_critical_events(self, anomaly_scores: Dict) -> List:
        """è‡¨ç•Œã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡º"""
        events = []
        
        if 'combined' in anomaly_scores:
            scores = anomaly_scores['combined']
            threshold = np.mean(scores) + 1.5 * np.std(scores)  # ææ–™ã¯ä½ã‚
            
            critical_frames = np.where(scores > threshold)[0]
            
            if len(critical_frames) > 0:
                current_start = critical_frames[0]
                current_end = critical_frames[0]
                
                for frame in critical_frames[1:]:
                    if frame == current_end + 1:
                        current_end = frame
                    else:
                        events.append((current_start, current_end))
                        current_start = frame
                        current_end = frame
                
                events.append((current_start, current_end))
        
        return events
    
    def _merge_batch_results(self, batch_results: List, original_shape: Tuple) -> MaterialLambda3Result:
        """ãƒãƒƒãƒçµæœã®ãƒãƒ¼ã‚¸ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        if not batch_results:
            return self._create_empty_result(original_shape[0], original_shape[1])
        
        # æœ€åˆã®ãƒãƒƒãƒã®æ§‹é€ ã‚’ã‚³ãƒ”ãƒ¼
        merged = batch_results[0]
        
        # ä»–ã®ãƒãƒƒãƒã®é‡è¦ãªæƒ…å ±ã‚’ãƒãƒ¼ã‚¸
        for batch in batch_results[1:]:
            merged.critical_clusters.extend(batch.critical_clusters)
            merged.critical_events.extend(batch.critical_events)
            merged.material_events.extend(batch.material_events)
        
        merged.n_frames = original_shape[0]
        
        return merged
    
    def _create_empty_result(self, n_frames: int, n_atoms: int) -> MaterialLambda3Result:
        """ç©ºã®çµæœä½œæˆ"""
        return MaterialLambda3Result(
            cluster_structures={},
            structural_boundaries={},
            topological_breaks={},
            material_features={},
            n_frames=n_frames,
            n_atoms=n_atoms,
            n_clusters=0
        )
    
    def _to_cpu_dict(self, data_dict: Dict) -> Dict:
        """GPUé…åˆ—ã‚’CPUã«è»¢é€"""
        cpu_dict = {}
        for key, value in data_dict.items():
            if hasattr(value, 'get'):
                cpu_dict[key] = value.get()
            elif isinstance(value, dict):
                cpu_dict[key] = self._to_cpu_dict(value)
            else:
                cpu_dict[key] = value
        return cpu_dict
    
    def _get_gpu_info(self) -> Dict:
        """GPUæƒ…å ±å–å¾—"""
        return {
            'device_name': str(self.device),
            'computation_mode': 'single_batch'
        }
    
    def _print_initialization_info(self):
        """åˆæœŸåŒ–æƒ…å ±è¡¨ç¤º"""
        if self.verbose:
            print(f"\nğŸ’ Material LambdaÂ³ Detector Initialized")
            print(f"   Material: {self.config.material_type}")
            print(f"   Crystal: {self.config.crystal_structure}")
            print(f"   Device: {self.device}")
            print(f"   GPU Mode: {self.is_gpu}")
            print(f"   Topological Analysis: {self.config.use_topological}")
            print(f"   Batch Size: {self.config.gpu_batch_size} frames")
    
    def _print_summary(self, result: MaterialLambda3Result):
        """çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print("\n" + "="*60)
        print("=== Material Analysis Complete ===")
        print("="*60)
        print(f"Total frames: {result.n_frames}")
        print(f"Total clusters: {result.n_clusters}")
        print(f"Computation time: {result.computation_time:.2f} seconds")
        
        if result.computation_time > 0:
            print(f"Speed: {result.n_frames / result.computation_time:.1f} frames/second")
        
        print(f"\nMaterial properties:")
        print(f"  Failure probability: {result.failure_probability:.1%}")
        print(f"  Reliability index Î²: {result.reliability_index:.2f}")
        
        print(f"\nDetected features:")
        print(f"  Critical clusters: {len(result.critical_clusters)}")
        print(f"  Critical events: {len(result.critical_events)}")
        print(f"  Material events: {len(result.material_events)}")
        
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
        if result.material_events:
            event_types = {}
            for event in result.material_events:
                if len(event) >= 3:
                    event_type = event[2]
                    event_types[event_type] = event_types.get(event_type, 0) + 1
            
            print(f"\nEvent classification:")
            for etype, count in sorted(event_types.items(), key=lambda x: x[1], reverse=True):
                print(f"  - {etype}: {count}")
        
        # ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«è§£æçµæœ
        if result.topological_charge_cumulative is not None:
            final_charge = result.topological_charge_cumulative[-1] if len(result.topological_charge_cumulative) > 0 else 0
            print(f"\nTopological analysis:")
            print(f"  Final cumulative charge: {final_charge:.3f}")
            print(f"  Mean structural coherence: {np.mean(result.structural_coherence):.3f}")
        
        if result.strain_network:
            print(f"\nNetwork analysis:")
            print(f"  Strain network links: {len(result.strain_network)}")
        if result.dislocation_network:
            print(f"  Dislocation links: {len(result.dislocation_network)}")
        if result.damage_network:
            print(f"  Damage links: {len(result.damage_network)}")

# ===============================
# Module Level Functions
# ===============================

def detect_material_events(
    trajectory: np.ndarray,
    atom_types: np.ndarray,
    config: Optional[MaterialConfig] = None,
    cluster_atoms: Optional[Dict[int, List[int]]] = None,
    **kwargs
) -> List[Tuple[int, int, str]]:
    """
    ææ–™ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ¤œå‡ºã™ã‚‹ä¾¿åˆ©é–¢æ•°
    
    MaterialLambda3DetectorGPUã®ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°
    """
    config = config or MaterialConfig()
    detector = MaterialLambda3DetectorGPU(config)
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å®šç¾©ï¼ˆæŒ‡å®šãªã‘ã‚Œã°å…¨åŸå­ã‚’1ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«ï¼‰
    if cluster_atoms is None:
        n_atoms = trajectory.shape[1]
        cluster_atoms = {0: list(range(n_atoms))}
    
    # è§£æå®Ÿè¡Œ
    result = detector.analyze(
        trajectory=trajectory,
        atom_types=atom_types,
        cluster_atoms=cluster_atoms,
        **kwargs
    )
    
    # material_eventsã‚’è¿”ã™
    if hasattr(result, 'material_events') and result.material_events:
        return result.material_events
    
    # ãªã‘ã‚Œã°critical_eventsã‹ã‚‰ç”Ÿæˆ
    events = []
    if hasattr(result, 'critical_events'):
        for event in result.critical_events:
            if isinstance(event, tuple) and len(event) >= 2:
                # (start, end, type)å½¢å¼ã«å¤‰æ›
                events.append((event[0], event[1], 'material_event'))
    
    return events
