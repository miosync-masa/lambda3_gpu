#!/usr/bin/env python3
"""
Material LambdaÂ³ Detector GPU - Pipeline Edition
================================================

ææ–™è§£æç”¨LambdaÂ³æ¤œå‡ºå™¨ã®GPUå®Ÿè£…ï¼ˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç‰ˆï¼‰
MDç‰ˆã®è¨­è¨ˆæ€æƒ³ã‚’è¸è¥²ã—ã€ææ–™è§£æã«ç‰¹åŒ–

MDç‰ˆã¨åŒã˜3æ®µéšãƒãƒƒãƒå‡¦ç†ã¨é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å®Ÿè£…
ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼è§£æã¯Two-Stageã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã«å§”è­²

Version: 2.0.0
Author: ç’°ã¡ã‚ƒã‚“
"""

import numpy as np
import time
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
import warnings
import logging

# CuPyã®æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import cupy as cp
    HAS_GPU = True
except ImportError:
    cp = None
    HAS_GPU = False

# LambdaÂ³ GPU imports
from ..core.gpu_utils import GPUBackend
from ..structures.lambda_structures_gpu import LambdaStructuresGPU
from ..material.material_md_features_gpu import MaterialMDFeaturesGPU  # ææ–™ç‰ˆMDç‰¹å¾´ã‚’ä½¿ç”¨
from ..detection.anomaly_detection_gpu import AnomalyDetectorGPU
from ..detection.boundary_detection_gpu import BoundaryDetectorGPU
from ..detection.topology_breaks_gpu import TopologyBreaksDetectorGPU
from ..detection.extended_detection_gpu import ExtendedDetectorGPU
from ..detection.phase_space_gpu import PhaseSpaceAnalyzerGPU

# Material specific imports
from ..material.material_analytics_gpu import MaterialAnalyticsGPU

# Loggerè¨­å®š
logger = logging.getLogger(__name__)

# ===============================
# Configuration
# ===============================

@dataclass
class MaterialConfig:
    """ææ–™è§£æè¨­å®šï¼ˆMDç‰ˆã‚’è¸è¥²ï¼‰"""
    # LambdaÂ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆMDç‰ˆã¨åŒã˜ï¼‰
    adaptive_window: bool = True
    extended_detection: bool = True
    use_extended_detection: bool = True
    use_phase_space: bool = True
    sensitivity: float = 1.5  # ææ–™ã¯ä½ã‚ã«
    min_boundary_gap: int = 50  # ææ–™ã¯çŸ­ã„æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«
    
    # ææ–™ç‰¹æœ‰ã®è¨­å®š
    material_type: str = 'SUJ2'  # 'SUJ2', 'AL7075', 'TI6AL4V'
    use_material_analytics: bool = True  # ææ–™ç‰¹æœ‰ã®è§£æã‚’ä½¿ç”¨
    
    # GPUè¨­å®šï¼ˆMDç‰ˆã¨åŒã˜ï¼‰
    gpu_batch_size: int = 10000
    mixed_precision: bool = False
    benchmark_mode: bool = False
    
    # ç•°å¸¸æ¤œå‡ºã®é‡ã¿ï¼ˆMDç‰ˆã¨åŒã˜æ§‹é€ ï¼‰
    w_lambda_f: float = 0.3
    w_lambda_ff: float = 0.2
    w_rho_t: float = 0.2
    w_topology: float = 0.3
    
    # ææ–™ç‰¹æœ‰ã®é‡ã¿
    w_defect: float = 0.2  # æ¬ é™¥ãƒãƒ£ãƒ¼ã‚¸ã®é‡ã¿
    w_coherence: float = 0.1  # æ§‹é€ ä¸€è²«æ€§ã®é‡ã¿
    
    # é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š
    window_scale: float = 0.005

@dataclass
class MaterialLambda3Result:
    """ææ–™LambdaÂ³è§£æçµæœï¼ˆMDç‰ˆã¨åŒã˜æ§‹é€ ï¼‰"""
    # Core LambdaÂ³æ§‹é€ ï¼ˆMDç‰ˆã¨åŒã˜ï¼‰- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãªã—
    lambda_structures: Dict[str, np.ndarray]
    structural_boundaries: Dict[str, Any]
    topological_breaks: Dict[str, np.ndarray]
    
    # MD/ææ–™ç‰¹å¾´ - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãªã—
    md_features: Dict[str, np.ndarray]
    
    # è§£æçµæœ - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãªã—
    anomaly_scores: Dict[str, np.ndarray]
    detected_structures: List[Dict]
    
    # ã“ã“ã‹ã‚‰ä¸‹ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚ã‚Š
    material_features: Optional[Dict[str, np.ndarray]] = None
    phase_space_analysis: Optional[Dict] = None
    defect_analysis: Optional[Dict] = None
    structural_coherence: Optional[np.ndarray] = None
    failure_prediction: Optional[Dict] = None
    material_events: Optional[List[Tuple[int, int, str]]] = None
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    n_frames: int = 0
    n_atoms: int = 0
    window_steps: int = 0
    computation_time: float = 0.0
    gpu_info: Dict = field(default_factory=dict)
    critical_events: List = field(default_factory=list)

# ===============================
# Main Detector Class
# ===============================
class MaterialLambda3DetectorGPU(GPUBackend):
    """
    GPUç‰ˆLambdaÂ³ææ–™æ¤œå‡ºå™¨ï¼ˆMDç‰ˆã®è¨­è¨ˆã‚’è¸è¥²ï¼‰
    
    MDç‰ˆã¨åŒã˜3æ®µéšãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè£…ã—ã€
    ææ–™ç‰¹æœ‰ã®è§£æã¯MaterialAnalyticsGPUã«å§”è­²
    """
    
    def __init__(self, config: MaterialConfig = None, device: str = 'auto'):
        """
        Parameters
        ----------
        config : MaterialConfig, optional
            è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        device : str, default='auto'
            'auto', 'gpu', 'cpu'ã®ã„ãšã‚Œã‹
        """
        # GPUBackendã®åˆæœŸåŒ–ï¼ˆMDç‰ˆã¨åŒã˜ï¼‰
        if device == 'cpu':
            super().__init__(device='cpu', force_cpu=True)
        else:
            super().__init__(device=device, force_cpu=False)
        
        self.config = config or MaterialConfig()
        self.verbose = True
        
        # force_cpuãƒ•ãƒ©ã‚°ã‚’æ±ºå®š
        force_cpu_flag = not self.is_gpu
        
        # MDç‰ˆã¨åŒã˜ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹æˆï¼ˆææ–™ç‰ˆã«æœ€é©åŒ–ï¼‰
        self.structure_computer = LambdaStructuresGPU(force_cpu_flag)
        self.feature_extractor = MaterialMDFeaturesGPU(force_cpu_flag)  # ææ–™ç‰ˆMDç‰¹å¾´æŠ½å‡º
        self.anomaly_detector = AnomalyDetectorGPU(force_cpu_flag)
        self.boundary_detector = BoundaryDetectorGPU(force_cpu_flag)
        self.topology_detector = TopologyBreaksDetectorGPU(force_cpu_flag)
        self.extended_detector = ExtendedDetectorGPU(force_cpu_flag)
        self.phase_space_analyzer = PhaseSpaceAnalyzerGPU(force_cpu_flag)
        
        # ææ–™ç‰¹æœ‰ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        if self.config.use_material_analytics:
            self.material_analytics = MaterialAnalyticsGPU(
                material_type=self.config.material_type,
                force_cpu=force_cpu_flag
            )
            # ===== ä¿®æ­£: material_feature_extractorã‚’é©åˆ‡ã«è¨­å®š =====
            # ã™ã§ã«self.feature_extractorãŒMaterialMDFeaturesGPUãªã®ã§ã€ãã‚Œã‚’ä½¿ã†
            self.material_feature_extractor = self.feature_extractor
        else:
            self.material_analytics = None
            self.material_feature_extractor = None
        
        # ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ã¨ãƒ‡ãƒã‚¤ã‚¹ã‚’å…±æœ‰ï¼ˆMDç‰ˆã¨åŒã˜ï¼‰
        for component in [self.structure_computer, self.feature_extractor,
                         self.anomaly_detector, self.boundary_detector,
                         self.topology_detector, self.extended_detector,
                         self.phase_space_analyzer]:
            if hasattr(component, 'memory_manager'):
                component.memory_manager = self.memory_manager
            if hasattr(component, 'device'):
                component.device = self.device
        
        # material_analyticsã®ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å…±æœ‰
        if self.material_analytics:
            self.material_analytics.memory_manager = self.memory_manager
            self.material_analytics.device = self.device
            # material_feature_extractorã¯self.feature_extractorã¨åŒã˜ãªã®ã§ã€ã™ã§ã«å…±æœ‰æ¸ˆã¿
        
        self._print_initialization_info()    

    def analyze(self,
            trajectory: np.ndarray,
            backbone_indices: Optional[np.ndarray] = None,
            atom_types: Optional[np.ndarray] = None,
            cluster_definition_path: Optional[str] = None,
            cluster_atoms: Optional[Dict[int, List[int]]] = None,  # â† è¿½åŠ ï¼
            **kwargs) -> MaterialLambda3Result:
        """
        ææ–™è»Œé“ã®LambdaÂ³è§£æï¼ˆMDç‰ˆã¨åŒã˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰
        
        Parameters
        ----------
        trajectory : np.ndarray
            ææ–™è»Œé“ (n_frames, n_atoms, 3)
        backbone_indices : np.ndarray, optional
            é‡è¦åŸå­ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆææ–™ã§ã¯æ¬ é™¥é ˜åŸŸãªã©ï¼‰
        atom_types : np.ndarray, optional
            åŸå­ã‚¿ã‚¤ãƒ—é…åˆ—
        cluster_definition_path : str, optional
            ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆæ¬ é™¥é ˜åŸŸã®è‡ªå‹•æ¤œå‡ºã«ä½¿ç”¨ï¼‰
            
        Returns
        -------
        MaterialLambda3Result
            è§£æçµæœ
        """
        start_time = time.time()
        
        # åŸå­ã‚¿ã‚¤ãƒ—ã®å‰å‡¦ç†ï¼ˆæ–‡å­—åˆ—â†’æ•°å€¤å¤‰æ›ï¼‰
        atom_type_names = None
        if atom_types is not None and atom_types.dtype.kind == 'U':  # æ–‡å­—åˆ—ã®å ´åˆ
            atom_type_names = np.unique(atom_types)  # å…ƒã®åå‰ã‚’ä¿å­˜
            type_map = {t: i for i, t in enumerate(atom_type_names)}
            atom_types = np.array([type_map[t] for t in atom_types], dtype=np.int32)
        
        # NumPyé…åˆ—ã‚’GPUï¼ˆCuPyé…åˆ—ï¼‰ã«å¤‰æ›
        if self.is_gpu and cp is not None:
            print("ğŸ“Š Converting arrays to GPU...")
            trajectory = cp.asarray(trajectory)
            if backbone_indices is not None:
                backbone_indices = cp.asarray(backbone_indices)
            if atom_types is not None:
                atom_types = cp.asarray(atom_types) 
        
        n_frames, n_atoms, _ = trajectory.shape
        
        print(f"\n{'='*60}")
        print(f"=== LambdaÂ³ Material Analysis (GPU) ===")
        print(f"{'='*60}")
        print(f"Trajectory: {n_frames} frames, {n_atoms} atoms")
        print(f"Material: {self.config.material_type}")
        print(f"GPU Device: {self.device}")
        
        # ãƒ¡ãƒ¢ãƒªæƒ…å ±ã®å®‰å…¨ãªå–å¾—ï¼ˆMDç‰ˆã¨åŒã˜ï¼‰
        try:
            mem_info = self.memory_manager.get_memory_info()
            print(f"Available GPU Memory: {mem_info.free / 1e9:.2f} GB")
        except Exception as e:
            print(f"Memory info unavailable: {e}")
        
        # ãƒãƒƒãƒå‡¦ç†ã®åˆ¤å®šï¼ˆMDç‰ˆã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
        batch_size = min(self.config.gpu_batch_size, n_frames)
        n_batches = (n_frames + batch_size - 1) // batch_size
        
        if n_batches > 1:
            print(f"Processing in {n_batches} batches of {batch_size} frames")
            result = self._analyze_batched(trajectory, backbone_indices, 
                                          atom_types, batch_size, 
                                          cluster_definition_path)
        else:
            # å˜ä¸€ãƒãƒƒãƒå‡¦ç†
            result = self._analyze_single_trajectory(trajectory, backbone_indices, 
                                                    atom_types, cluster_definition_path)
        
        computation_time = time.time() - start_time
        result.computation_time = computation_time
        
        self._print_summary(result)
        
        return result

    def _analyze_single_trajectory(self,
                             trajectory: np.ndarray,
                             backbone_indices: Optional[np.ndarray],
                             atom_types: Optional[np.ndarray],
                             cluster_definition_path: Optional[str] = None,
                             cluster_atoms: Optional[Dict[int, List[int]]] = None) -> MaterialLambda3Result:  # â† è¿½åŠ 
        """å˜ä¸€è»Œé“ã®è§£æï¼ˆMDç‰ˆã¨åŒã˜æ§‹é€ ï¼‰"""
        n_frames, n_atoms, _ = trajectory.shape

        if cluster_atoms is not None:
            # Cluster 0ä»¥å¤–ã‚’æ¬ é™¥ã¨ã—ã¦æ‰±ã†
            defect_indices = []
            for cid, atoms in cluster_atoms.items():
                if str(cid) != "0":  # Cluster 0ï¼ˆå¥å…¨é ˜åŸŸï¼‰ä»¥å¤–
                    defect_indices.extend(atoms)
            backbone_indices = np.array(sorted(defect_indices))
            print(f"   Using {len(backbone_indices)} defect atoms from clusters")

        # 1. MDç‰¹å¾´æŠ½å‡ºï¼ˆææ–™ç‰ˆMDç‰¹å¾´æŠ½å‡ºã‚’ä½¿ç”¨ï¼‰
        print("\n1. Extracting MD features on GPU...")
        md_features = self.feature_extractor.extract_md_features(
            trajectory, backbone_indices,
            cluster_definition_path=cluster_definition_path,
            atom_types=atom_types
        )
        
        # 1.5. ææ–™ç‰¹å¾´æŠ½å‡ºï¼ˆææ–™ç‰¹æœ‰ï¼‰
        material_features = None
        if self.config.use_material_analytics and self.material_feature_extractor:
            print("\n1.5. Extracting material-specific features...")
            
            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å®šç¾©ãŒæ¸¡ã•ã‚Œã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ã†ã€ãªã‘ã‚Œã°ç°¡æ˜“å®šç¾©
            if cluster_atoms is not None:
                clusters_for_features = cluster_atoms
                print(f"    Using provided clusters: {len(clusters_for_features)} clusters")
            else:
                # ç°¡æ˜“ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å®šç¾©ï¼ˆTwo-Stageã§è©³ç´°åŒ–ï¼‰
                clusters_for_features = {0: list(range(n_atoms))}
                print("    Using simple cluster definition (all atoms)")
            
            material_features = self.material_feature_extractor.extract_md_features(
                trajectory=self.to_cpu(trajectory) if self.is_gpu else trajectory,
                backbone_indices=backbone_indices,  # æ¬ é™¥é ˜åŸŸã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                cluster_definition_path=cluster_definition_path,
                atom_types=self.to_cpu(atom_types) if atom_types is not None and self.is_gpu else atom_types
            ) 
        
        # 2. åˆæœŸã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºï¼ˆMDç‰ˆã¨åŒã˜ï¼‰
        initial_window = self._compute_initial_window(n_frames)
        
        # 3. Lambdaæ§‹é€ è¨ˆç®—ï¼ˆMDç‰ˆã¨åŒã˜ï¼‰
        print("\n2. Computing LambdaÂ³ structures (first pass)...")
        lambda_structures = self.structure_computer.compute_lambda_structures(
            trajectory, md_features, initial_window
        )
        
        # 4. é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºæ±ºå®šï¼ˆMDç‰ˆã¨åŒã˜ï¼‰
        adaptive_windows = self._determine_adaptive_windows(
            lambda_structures, initial_window
        )
        primary_window = adaptive_windows.get('primary', initial_window)
        
        # 5. æ§‹é€ å¢ƒç•Œæ¤œå‡ºï¼ˆMDç‰ˆã¨åŒã˜ï¼‰
        print("\n3. Detecting structural boundaries...")
        boundary_window = adaptive_windows.get('boundary', primary_window // 3)
        structural_boundaries = self.boundary_detector.detect_structural_boundaries(
            lambda_structures, boundary_window
        )
        
        # 6. ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ç ´ã‚Œæ¤œå‡ºï¼ˆMDç‰ˆã¨åŒã˜ï¼‰
        print("\n4. Detecting topological breaks...")
        fast_window = adaptive_windows.get('fast', primary_window // 2)
        topological_breaks = self.topology_detector.detect_topological_breaks(
            lambda_structures, fast_window
        )
        
        # 7. ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç•°å¸¸æ¤œå‡ºï¼ˆMDç‰ˆã¨åŒã˜ï¼‰
        print("\n5. Computing multi-scale anomaly scores...")
        anomaly_scores = self.anomaly_detector.compute_multiscale_anomalies(
            lambda_structures,
            structural_boundaries,
            topological_breaks,
            md_features,
            self.config
        )
        
        # 7.5. ææ–™ç‰¹æœ‰ã®è§£æï¼ˆææ–™è¿½åŠ ï¼‰
        defect_analysis = None
        structural_coherence = None
        failure_prediction = None
        material_events = None
        
        if self.config.use_material_analytics and self.material_analytics:
            print("\n5.5. Performing material-specific analysis...")
            
            # æ¬ é™¥è§£æ
            if atom_types is not None:
                trajectory_cpu = self.to_cpu(trajectory) if self.is_gpu else trajectory
                defect_result = self.material_analytics.compute_crystal_defect_charge(
                    trajectory_cpu,
                    {0: list(range(n_atoms))},  # ç°¡æ˜“ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼
                    cutoff=3.5
                )
                defect_analysis = {
                    'defect_charge': defect_result.defect_charge,
                    'cumulative_charge': defect_result.cumulative_charge
                }
            
            # æ§‹é€ ä¸€è²«æ€§
            if material_features and 'coordination' in material_features:
                structural_coherence = self.material_analytics.compute_structural_coherence(
                    material_features['coordination'],
                    material_features.get('strain', np.zeros((n_frames, 1))),
                    window=primary_window // 2
                )
            
            # ç ´å£Šäºˆæ¸¬
            if material_features and 'strain' in material_features:
                failure_prediction = self.material_analytics.predict_failure(
                    material_features['strain'],
                    damage_history=material_features.get('damage'),
                    defect_charge=defect_analysis['cumulative_charge'] if defect_analysis else None
                )
                failure_prediction = {
                    'failure_probability': failure_prediction.failure_probability,
                    'reliability_index': failure_prediction.reliability_index,
                    'failure_mode': failure_prediction.failure_mode
                }
        
        # 8. æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºï¼ˆMDç‰ˆã¨åŒã˜ï¼‰
        print("\n6. Detecting structural patterns...")
        slow_window = adaptive_windows.get('slow', primary_window * 2)
        detected_structures = self._detect_structural_patterns(
            lambda_structures, structural_boundaries, slow_window
        )
        
        # 9. ä½ç›¸ç©ºé–“è§£æï¼ˆMDç‰ˆã¨åŒã˜ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        phase_space_analysis = None
        if self.config.use_phase_space:
            print("\n7. Performing phase space analysis...")
            try:
                phase_space_analysis = self.phase_space_analyzer.analyze_phase_space(
                    lambda_structures
                )
            except Exception as e:
                print(f"Phase space analysis failed: {e}")
        
        # è‡¨ç•Œã‚¤ãƒ™ãƒ³ãƒˆã®æ¤œå‡ºï¼ˆMDç‰ˆã¨åŒã˜ï¼‰
        critical_events = self._detect_critical_events(anomaly_scores)
        
        # ææ–™ã‚¤ãƒ™ãƒ³ãƒˆã®åˆ†é¡
        if self.config.use_material_analytics and self.material_analytics:
            if critical_events and structural_coherence is not None:
                material_events = self.material_analytics.classify_material_events(
                    critical_events,
                    anomaly_scores,
                    structural_coherence,
                    defect_charge=defect_analysis['defect_charge'] if defect_analysis else None
                )
        
        # GPUæƒ…å ±ã‚’åé›†ï¼ˆMDç‰ˆã¨åŒã˜ï¼‰
        gpu_info = self._get_gpu_info()
        
        # çµæœã‚’æ§‹ç¯‰
        result = MaterialLambda3Result(
            lambda_structures=self._to_cpu_dict(lambda_structures),
            structural_boundaries=structural_boundaries,
            topological_breaks=self._to_cpu_dict(topological_breaks),
            md_features=self._to_cpu_dict(md_features),
            material_features=self._to_cpu_dict(material_features) if material_features else None,
            anomaly_scores=self._to_cpu_dict(anomaly_scores),
            detected_structures=detected_structures,
            phase_space_analysis=phase_space_analysis,
            defect_analysis=defect_analysis,
            structural_coherence=structural_coherence,
            failure_prediction=failure_prediction,
            material_events=material_events,
            critical_events=critical_events,
            n_frames=n_frames,
            n_atoms=n_atoms,
            window_steps=primary_window,
            computation_time=0.0,
            gpu_info=gpu_info
        )
        
        return result
    
    def _analyze_batched(self,
                    trajectory: np.ndarray,
                    backbone_indices: Optional[np.ndarray],
                    atom_types: Optional[np.ndarray],
                    batch_size: int,
                    cluster_definition_path: Optional[str] = None,
                    cluster_atoms: Optional[Dict[int, List[int]]] = None) -> MaterialLambda3Result:
        """ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹è§£æï¼ˆColabå¯¾å¿œç‰ˆï¼‰"""
        print("\nâš¡ Running batched GPU analysis...")
        
        n_frames = trajectory.shape[0]
        
        # ===== Colabå¯¾å¿œï¼šæœ€å°ãƒãƒƒãƒå‡¦ç† =====
        MIN_BATCH_SIZE = 1000  # æœ€å°1000ãƒ•ãƒ¬ãƒ¼ãƒ 
        
        # ãƒãƒƒãƒè¨ˆç”»ã‚’æœ€é©åŒ–
        batches = []
        current_pos = 0
        
        while current_pos < n_frames:
            batch_end = min(current_pos + batch_size, n_frames)
            remaining_frames = batch_end - current_pos
            
            # æœ€å¾Œã®å°ã•ã„ãƒãƒƒãƒã‚’å‡¦ç†
            if batch_end == n_frames and remaining_frames < MIN_BATCH_SIZE and len(batches) > 0:
                # å‰ã®ãƒãƒƒãƒã¨çµåˆ
                print(f"  âš ï¸ Last batch too small ({remaining_frames} frames), merging with previous")
                prev_start, _ = batches[-1]
                batches[-1] = (prev_start, n_frames)
                break
            else:
                batches.append((current_pos, batch_end))
                current_pos = batch_end
        
        print(f"  Optimized to {len(batches)} batches")
        
        # ãƒãƒƒãƒã”ã¨ã®çµæœã‚’è“„ç©
        batch_results = []
        
        # Step 1: ãƒãƒƒãƒå‡¦ç†
        print("\n[Step 1] Processing batches for feature extraction...")
        for batch_idx, (start_idx, end_idx) in enumerate(batches):
            print(f"  Batch {batch_idx + 1}/{len(batches)}: frames {start_idx}-{end_idx} ({end_idx-start_idx} frames)")
            
            try:
                batch_trajectory = trajectory[start_idx:end_idx]
                
                # ãƒãƒƒãƒè§£æ
                batch_result = self._analyze_single_batch(
                    batch_trajectory, backbone_indices, atom_types, start_idx,
                    cluster_definition_path
                )
                
                batch_results.append(batch_result)
                
            except Exception as e:
                print(f"  âš ï¸ Batch {batch_idx + 1} failed: {e}")
                # å¤±æ•—ã—ãŸãƒãƒƒãƒã¯ã‚¹ã‚­ãƒƒãƒ—
                continue
            
            finally:
                # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
                self.memory_manager.clear_cache()
        
        if not batch_results:
            print("  âŒ All batches failed!")
            return self._create_empty_result(n_frames, trajectory.shape[1])
        
        # Step 2: çµæœã‚’ãƒãƒ¼ã‚¸ï¼ˆMaterialLambda3Resultã‚’è¿”ã™ï¼‰
        print("\n[Step 2] Merging batch results...")
        merged_result = self._merge_batch_results(batch_results, trajectory.shape, atom_types)
        
        # Step 3: å®Œäº†å‡¦ç†
        print("\n[Step 3] Completing analysis on merged data...")
        
        # ===== é‡è¦ï¼šMaterialLambda3Resultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ãã®ã¾ã¾æ¸¡ã™ =====
        # merged_resultã¯ã™ã§ã«MaterialLambda3Resultãªã®ã§ã€å¤‰æ›ä¸è¦ï¼
        
        try:
            final_result = self._complete_analysis(merged_result, atom_types)
        except AttributeError as e:
            if "'NoneType'" in str(e):
                print(f"  âš ï¸ NoneType error in _complete_analysis: {e}")
                print("  Using merged result without additional analysis")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã¯æœ€ä½é™ã®è§£æã§è¿”ã™
                merged_result.structural_boundaries = {'boundary_locations': np.array([])}
                merged_result.topological_breaks = {'break_points': np.array([])}
                merged_result.anomaly_scores = {'combined': np.zeros(n_frames)}
                merged_result.critical_events = []
                merged_result.material_events = []
                return merged_result
            else:
                raise
        
        return final_result
    
    def _analyze_single_batch(self,
                            batch_trajectory: np.ndarray,
                            backbone_indices: Optional[np.ndarray],
                            atom_types: Optional[np.ndarray],
                            offset: int,
                            cluster_definition_path: Optional[str] = None) -> Dict:
        """å˜ä¸€ãƒãƒƒãƒã®è§£æï¼ˆMDç‰ˆã¨åŒã˜ - ç‰¹å¾´æŠ½å‡ºã¨Lambdaæ§‹é€ è¨ˆç®—ã®ã¿ï¼‰"""
        # MDç‰¹å¾´æŠ½å‡ºï¼ˆé‡ã„å‡¦ç†ï¼‰
        md_features = self.feature_extractor.extract_md_features(
            batch_trajectory, backbone_indices,
            cluster_definition_path=cluster_definition_path,
            atom_types=atom_types
        )
        
        # ææ–™ç‰¹å¾´æŠ½å‡ºï¼ˆé‡ã„å‡¦ç†ï¼‰
        material_features = None
        if self.config.use_material_analytics and self.material_feature_extractor:
            n_atoms = batch_trajectory.shape[1]
            simple_clusters = {0: list(range(n_atoms))}
            
            batch_traj_cpu = self.to_cpu(batch_trajectory) if self.is_gpu else batch_trajectory
            atom_types_cpu = self.to_cpu(atom_types) if atom_types is not None and self.is_gpu else atom_types
            
            material_features = self.material_feature_extractor.extract_md_features(
                trajectory=batch_traj_cpu,
                backbone_indices=None,  # ãƒãƒƒãƒå‡¦ç†ã§ã¯çœç•¥
                cluster_definition_path=cluster_definition_path,
                atom_types=atom_types_cpu
            )
        
        window = self._compute_initial_window(len(batch_trajectory))
        
        # Lambdaæ§‹é€ è¨ˆç®—ï¼ˆé‡ã„å‡¦ç†ï¼‰
        lambda_structures = self.structure_computer.compute_lambda_structures(
            batch_trajectory, md_features, window
        )
        
        return {
            'offset': offset,
            'n_frames': len(batch_trajectory),
            'lambda_structures': lambda_structures,
            'md_features': md_features,
            'material_features': material_features,
            'window': window
        }

    def _merge_batch_results(self,
                       batch_results: List[Dict],
                       original_shape: Tuple,
                       atom_types: Optional[np.ndarray]) -> MaterialLambda3Result:
        """
        ãƒãƒƒãƒçµæœã®çµ±åˆï¼ˆã‚¿ãƒ³ãƒ‘ã‚¯è³ªç‰ˆã¨åŒã˜æ–¹å¼ï¼‰
        """
        print("  Merging data from all batches...")
        
        n_frames, n_atoms, _ = original_shape
        
        if not batch_results:
            return self._create_empty_result(n_frames, n_atoms)
        
        # çµæœã‚’ä¿å­˜ã™ã‚‹è¾æ›¸ã‚’åˆæœŸåŒ–
        merged_lambda_structures = {}
        merged_md_features = {}
        merged_material_features = {} if self.config.use_material_analytics else None
        
        # æœ€åˆã®ãƒãƒƒãƒã‹ã‚‰ã‚­ãƒ¼ã¨å½¢çŠ¶ã‚’å–å¾—
        first_batch = batch_results[0]
        lambda_keys = first_batch.get('lambda_structures', {}).keys()
        feature_keys = first_batch.get('md_features', {}).keys()
        
        print(f"    Lambda structure keys: {list(lambda_keys)}")
        print(f"    MD feature keys: {list(feature_keys)}")
        
        # Lambdaæ§‹é€ ã®é…åˆ—ã‚’åˆæœŸåŒ–
        for key in lambda_keys:
            sample = first_batch['lambda_structures'][key]
            if isinstance(sample, (np.ndarray, self.xp.ndarray)):
                rest_shape = sample.shape[1:] if len(sample.shape) > 1 else ()
                full_shape = (n_frames,) + rest_shape
                dtype = sample.dtype
                merged_lambda_structures[key] = np.full(full_shape, np.nan, dtype=dtype)
        
        # MDç‰¹å¾´ã®é…åˆ—ã‚’åˆæœŸåŒ–
        for key in feature_keys:
            sample = first_batch['md_features'][key]
            if isinstance(sample, (np.ndarray, self.xp.ndarray)):
                rest_shape = sample.shape[1:] if len(sample.shape) > 1 else ()
                full_shape = (n_frames,) + rest_shape
                dtype = sample.dtype
                merged_md_features[key] = np.full(full_shape, np.nan, dtype=dtype)
        
        # ææ–™ç‰¹å¾´ã®é…åˆ—ã‚’åˆæœŸåŒ–
        if merged_material_features is not None and first_batch.get('material_features'):
            material_keys = first_batch['material_features'].keys()
            print(f"    Material feature keys: {list(material_keys)}")
            
            for key in material_keys:
                sample = first_batch['material_features'][key]
                if isinstance(sample, (np.ndarray, self.xp.ndarray)):
                    rest_shape = sample.shape[1:] if len(sample.shape) > 1 else ()
                    full_shape = (n_frames,) + rest_shape
                    dtype = sample.dtype
                    merged_material_features[key] = np.full(full_shape, np.nan, dtype=dtype)
        
        # å„ãƒãƒƒãƒã®çµæœã‚’æ­£ã—ã„ä½ç½®ã«é…ç½®
        for batch_idx, batch_result in enumerate(batch_results):
            offset = batch_result['offset']
            batch_n_frames = batch_result['n_frames']
            end_idx = offset + batch_n_frames
            
            # ç¯„å›²ãƒã‚§ãƒƒã‚¯
            if end_idx > n_frames:
                end_idx = n_frames
                batch_n_frames = end_idx - offset
            
            # Lambdaæ§‹é€ ã‚’ãƒãƒ¼ã‚¸
            for key, value in batch_result.get('lambda_structures', {}).items():
                if key in merged_lambda_structures:
                    if hasattr(value, 'get'):  # CuPyé…åˆ—ã®å ´åˆ
                        value = self.to_cpu(value)
                    actual_frames = min(len(value), batch_n_frames)
                    merged_lambda_structures[key][offset:offset + actual_frames] = value[:actual_frames]
            
            # MDç‰¹å¾´ã‚’ãƒãƒ¼ã‚¸
            for key, value in batch_result.get('md_features', {}).items():
                if key in merged_md_features:
                    if hasattr(value, 'get'):
                        value = self.to_cpu(value)
                    actual_frames = min(len(value), batch_n_frames)
                    merged_md_features[key][offset:offset + actual_frames] = value[:actual_frames]
            
            # ææ–™ç‰¹å¾´ã‚’ãƒãƒ¼ã‚¸
            if merged_material_features is not None and batch_result.get('material_features'):
                for key, value in batch_result['material_features'].items():
                    if key in merged_material_features:
                        if hasattr(value, 'get'):
                            value = self.to_cpu(value)
                            actual_frames = min(len(value), batch_n_frames)
                            merged_material_features[key][offset:offset + actual_frames] = value[:actual_frames]
        
        # ===== NaNå‡¦ç†ã‚’å‰Šé™¤ï¼ã‚¿ãƒ³ãƒ‘ã‚¯è³ªç‰ˆã¨åŒã˜æ–¹å¼ =====
        print("    Checking NaN values...")
        
        # NaNãƒã‚§ãƒƒã‚¯ï¼ˆè­¦å‘Šã®ã¿ã€åŸ‹ã‚ãªã„ï¼‰
        for key, arr in merged_lambda_structures.items():
            nan_count = np.isnan(arr).sum()
            if nan_count > 0:
                print(f"    âš ï¸ {key} has {nan_count} unprocessed frames")
                # NaNåŸ‹ã‚ã¯å‰Šé™¤ï¼ãã®ã¾ã¾æ¸¡ã™
        
        # MDç‰¹å¾´ã®NaNãƒã‚§ãƒƒã‚¯ï¼ˆè­¦å‘Šã®ã¿ï¼‰
        for key, arr in merged_md_features.items():
            if isinstance(arr, np.ndarray) and arr.dtype != object:
                nan_count = np.isnan(arr).sum() if arr.dtype in [np.float32, np.float64] else 0
                if nan_count > 0:
                    print(f"    âš ï¸ MD feature {key} has {nan_count} NaN values")
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¹ãƒ†ãƒƒãƒ—ã®è¨ˆç®—
        window_steps = 100  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        if 'window' in first_batch:
            windows = [b.get('window', 100) for b in batch_results if 'window' in b]
            if windows:
                window_steps = int(np.mean(windows))
        
        # GPUæƒ…å ±ã®æ§‹ç¯‰
        gpu_info = {
            'computation_mode': 'batched',
            'n_batches': len(batch_results),
            'device_name': str(self.device),
            'batch_sizes': [b['n_frames'] for b in batch_results],
            'nan_handling': 'preserved'  # NaNä¿æŒãƒ•ãƒ©ã‚°
        }
        
        print(f"  âœ… Merged {n_frames} frames successfully")
        
        # ãƒãƒ¼ã‚¸çµæœã‚’è¿”ã™ï¼ˆè§£æã¯æœªå®Œäº†ï¼‰
        return MaterialLambda3Result(
            lambda_structures=merged_lambda_structures,
            structural_boundaries={},  # å¾Œã§è¨ˆç®—
            topological_breaks={},      # å¾Œã§è¨ˆç®—
            md_features=merged_md_features,
            material_features=merged_material_features,
            anomaly_scores={},          # å¾Œã§è¨ˆç®—
            detected_structures=[],     # å¾Œã§è¨ˆç®—
            critical_events=[],         # å¾Œã§è¨ˆç®—
            n_frames=n_frames,
            n_atoms=n_atoms,
            window_steps=window_steps,
            computation_time=0.0,
            gpu_info=gpu_info
        )
     
    def _complete_analysis(self, 
                          merged_result: MaterialLambda3Result,
                          atom_types: Optional[np.ndarray]) -> MaterialLambda3Result:
        """ãƒãƒ¼ã‚¸å¾Œã®ãƒ‡ãƒ¼ã‚¿ã§è§£æã‚’å®Œäº†ï¼ˆMDç‰ˆã¨åŒã˜ - å¢ƒç•Œæ¤œå‡ºã€ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—ãªã©ï¼‰"""
        
        lambda_structures = merged_result.lambda_structures
        md_features = merged_result.md_features
        material_features = merged_result.material_features
        n_frames = merged_result.n_frames
        n_atoms = merged_result.n_atoms
        
        # é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºæ±ºå®š
        initial_window = merged_result.window_steps
        adaptive_windows = self._determine_adaptive_windows(
            lambda_structures, initial_window
        )
        primary_window = adaptive_windows.get('primary', initial_window)
        
        # 5. æ§‹é€ å¢ƒç•Œæ¤œå‡ºï¼ˆå…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã§å®Ÿè¡Œ - è»½ã„å‡¦ç†ï¼‰
        print("  - Detecting structural boundaries...")
        boundary_window = adaptive_windows.get('boundary', primary_window // 3)
        structural_boundaries = self.boundary_detector.detect_structural_boundaries(
            lambda_structures, boundary_window
        )
        
        # 6. ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ç ´ã‚Œæ¤œå‡ºï¼ˆå…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã§å®Ÿè¡Œ - è»½ã„å‡¦ç†ï¼‰
        print("  - Detecting topological breaks...")
        fast_window = adaptive_windows.get('fast', primary_window // 2)
        topological_breaks = self.topology_detector.detect_topological_breaks(
            lambda_structures, fast_window
        )
        
        # 7. ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç•°å¸¸æ¤œå‡ºï¼ˆå…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã§å®Ÿè¡Œ - è»½ã„å‡¦ç†ï¼‰
        print("  - Computing anomaly scores...")
        anomaly_scores = self.anomaly_detector.compute_multiscale_anomalies(
            lambda_structures,
            structural_boundaries,
            topological_breaks,
            md_features,
            self.config
        )
        
        # 7.5. ææ–™ç‰¹æœ‰ã®è§£æï¼ˆææ–™è¿½åŠ ï¼‰
        defect_analysis = None
        structural_coherence = None
        failure_prediction = None
        material_events = None
        
        if self.config.use_material_analytics and self.material_analytics:
            print("  - Performing material-specific analysis...")
            
            # æ¬ é™¥è§£æ
            if atom_types is not None:
                # ãƒ€ãƒŸãƒ¼ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªä½œæˆï¼ˆLambdaæ§‹é€ ã‹ã‚‰æ¨å®šï¼‰
                # æœ¬æ¥ã¯ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªå…¨ä½“ã‚’ä¿æŒã™ã¹ãã ãŒã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®ãŸã‚çœç•¥
                # Two-Stageã§è©³ç´°è§£æ
                pass
            
            # æ§‹é€ ä¸€è²«æ€§
            if material_features and 'coordination' in material_features:
                structural_coherence = self.material_analytics.compute_structural_coherence(
                    material_features['coordination'],
                    material_features.get('strain', np.zeros((n_frames, 1))),
                    window=primary_window // 2
                )
            
            # ç ´å£Šäºˆæ¸¬
            if material_features and 'strain' in material_features:
                failure_prediction = self.material_analytics.predict_failure(
                    material_features['strain'],
                    damage_history=material_features.get('damage')
                )
                failure_prediction = {
                    'failure_probability': failure_prediction.failure_probability,
                    'reliability_index': failure_prediction.reliability_index,
                    'failure_mode': failure_prediction.failure_mode
                }
        
        # 8. æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        print("  - Detecting structural patterns...")
        slow_window = adaptive_windows.get('slow', primary_window * 2)
        detected_structures = self._detect_structural_patterns(
            lambda_structures, structural_boundaries, slow_window
        )
        
        # 9. ä½ç›¸ç©ºé–“è§£æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        phase_space_analysis = None
        if self.config.use_phase_space:
            print("  - Performing phase space analysis...")
            try:
                phase_space_analysis = self.phase_space_analyzer.analyze_phase_space(
                    lambda_structures
                )
            except Exception as e:
                print(f"    Phase space analysis failed: {e}")
        
        # è‡¨ç•Œã‚¤ãƒ™ãƒ³ãƒˆã®æ¤œå‡º
        critical_events = self._detect_critical_events(anomaly_scores)
        
        # ææ–™ã‚¤ãƒ™ãƒ³ãƒˆã®åˆ†é¡
        if self.config.use_material_analytics and self.material_analytics:
            if critical_events and structural_coherence is not None:
                material_events = self.material_analytics.classify_material_events(
                    critical_events,
                    anomaly_scores,
                    structural_coherence
                )
        
        print("  âœ… Analysis completed!")
        
        # çµæœã‚’æ›´æ–°
        merged_result.structural_boundaries = structural_boundaries
        merged_result.topological_breaks = topological_breaks
        merged_result.anomaly_scores = anomaly_scores
        merged_result.detected_structures = detected_structures
        merged_result.phase_space_analysis = phase_space_analysis
        merged_result.defect_analysis = defect_analysis
        merged_result.structural_coherence = structural_coherence
        merged_result.failure_prediction = failure_prediction
        merged_result.material_events = material_events
        merged_result.critical_events = critical_events
        merged_result.window_steps = primary_window
        
        return merged_result
    
    # === ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆMDç‰ˆã¨åŒã˜ï¼‰ ===
    
    def _compute_initial_window(self, n_frames: int) -> int:
        """åˆæœŸã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã®è¨ˆç®—"""
        return min(50, n_frames // 10)  # ææ–™ã¯çŸ­ã‚ã«
    
    def _determine_adaptive_windows(self, lambda_structures: Dict, 
                                   initial_window: int) -> Dict[str, int]:
        """é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã®æ±ºå®šï¼ˆMDç‰ˆã¨åŒã˜ï¼‰"""
        if not self.config.adaptive_window:
            return {'primary': initial_window}
        
        # Lambdaæ§‹é€ ã®å¤‰å‹•ã‹ã‚‰æœ€é©ãªã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’æ¨å®š
        windows = {
            'primary': initial_window,
            'fast': max(10, initial_window // 2),
            'slow': min(500, initial_window * 2),
            'boundary': max(20, initial_window // 3)
        }
        
        return windows
    
    def _detect_structural_patterns(self, lambda_structures: Dict,
                                   boundaries: Dict, window: int) -> List[Dict]:
        """æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡ºï¼ˆMDç‰ˆã¨åŒã˜ï¼‰"""
        patterns = []
        
        if isinstance(boundaries, dict) and 'boundary_locations' in boundaries:
            boundary_locs = boundaries['boundary_locations']
            
            # å¢ƒç•Œé–“ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ§‹é€ ã¨ã—ã¦èªè­˜
            if len(boundary_locs) > 0:
                # æœ€åˆã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
                if boundary_locs[0] > 30:  # ææ–™ã¯çŸ­ã‚ã®é–¾å€¤
                    patterns.append({
                        'type': 'initial_structure',
                        'start': 0,
                        'end': boundary_locs[0],
                        'duration': boundary_locs[0]
                    })
                
                # ä¸­é–“ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
                for i in range(len(boundary_locs) - 1):
                    duration = boundary_locs[i+1] - boundary_locs[i]
                    if duration > 20:  # ææ–™ã¯çŸ­ã‚ã®é–¾å€¤
                        pattern_type = 'elastic' if duration < 100 else 'plastic'
                        patterns.append({
                            'type': pattern_type,
                            'start': boundary_locs[i],
                            'end': boundary_locs[i+1],
                            'duration': duration
                        })
        
        return patterns
    
    def _detect_critical_events(self, anomaly_scores: Dict) -> List:
        """è‡¨ç•Œã‚¤ãƒ™ãƒ³ãƒˆã®æ¤œå‡ºï¼ˆMDç‰ˆã¨åŒã˜ï¼‰"""
        events = []
        
        if 'combined' in anomaly_scores:
            scores = anomaly_scores['combined']
            threshold = np.mean(scores) + 1.5 * np.std(scores)  # ææ–™ã¯ä½ã‚ã®é–¾å€¤
            
            # é–¾å€¤ã‚’è¶…ãˆã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¤œå‡º
            critical_frames = np.where(scores > threshold)[0]
            
            # é€£ç¶šã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            if len(critical_frames) > 0:
                current_event_start = critical_frames[0]
                current_event_end = critical_frames[0]
                
                for frame in critical_frames[1:]:
                    if frame == current_event_end + 1:
                        current_event_end = frame
                    else:
                        # ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¨˜éŒ²
                        events.append((current_event_start, current_event_end))
                        current_event_start = frame
                        current_event_end = frame
                
                # æœ€å¾Œã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¨˜éŒ²
                events.append((current_event_start, current_event_end))
        
        return events
    
    def _to_cpu_dict(self, data_dict: Optional[Dict]) -> Dict:
        """è¾æ›¸å†…ã®GPUé…åˆ—ã‚’CPUã«è»¢é€ï¼ˆMDç‰ˆã¨åŒã˜ï¼‰"""
        if data_dict is None:
            return {}
        
        cpu_dict = {}
        for key, value in data_dict.items():
            if hasattr(value, 'get'):  # CuPyé…åˆ—ã®å ´åˆ
                cpu_dict[key] = self.to_cpu(value)
            elif isinstance(value, dict):
                cpu_dict[key] = self._to_cpu_dict(value)
            else:
                cpu_dict[key] = value
        return cpu_dict
    
    def _get_gpu_info(self) -> Dict:
        """GPUæƒ…å ±ã‚’å®‰å…¨ã«å–å¾—ï¼ˆMDç‰ˆã¨åŒã˜ï¼‰"""
        gpu_info = {
            'device_name': str(self.device),
            'computation_mode': 'single_batch'
        }
        
        try:
            mem_info = self.memory_manager.get_memory_info()
            gpu_info['memory_used'] = mem_info.used / 1e9
        except:
            gpu_info['memory_used'] = 0.0
        
        return gpu_info
    
    def _create_empty_result(self, n_frames: int, n_atoms: int) -> MaterialLambda3Result:
        """ç©ºã®çµæœã‚’ä½œæˆï¼ˆMDç‰ˆã¨åŒã˜ï¼‰"""
        return MaterialLambda3Result(
            lambda_structures={},
            structural_boundaries={},
            topological_breaks={},
            md_features={},
            anomaly_scores={},
            detected_structures=[],
            critical_events=[],
            n_frames=n_frames,
            n_atoms=n_atoms,
            window_steps=100,
            computation_time=0.0,
            gpu_info={'computation_mode': 'batched', 'n_batches': 0}
        )
    
    def _print_initialization_info(self):
        """åˆæœŸåŒ–æƒ…å ±ã®è¡¨ç¤º"""
        if self.verbose:
            print(f"\nğŸ’ Material LambdaÂ³ GPU Detector Initialized")
            print(f"   Material: {self.config.material_type}")
            print(f"   Device: {self.device}")
            print(f"   GPU Mode: {self.is_gpu}")
            print(f"   Memory Limit: {self.memory_manager.max_memory / 1e9:.2f} GB")
            
            try:
                mem_info = self.memory_manager.get_memory_info()
                print(f"   Available: {mem_info.free / 1e9:.2f} GB")
            except:
                pass
            
            print(f"   Batch Size: {self.config.gpu_batch_size} frames")
            print(f"   Extended Detection: {'ON' if self.config.use_extended_detection else 'OFF'}")
            print(f"   Phase Space Analysis: {'ON' if self.config.use_phase_space else 'OFF'}")
            print(f"   Material Analytics: {'ON' if self.config.use_material_analytics else 'OFF'}")
    
    def _print_summary(self, result: MaterialLambda3Result):
        """çµæœã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º"""
        print("\n" + "="*60)
        print("=== Analysis Complete ===")
        print("="*60)
        print(f"Total frames: {result.n_frames}")
        print(f"Computation time: {result.computation_time:.2f} seconds")
        
        if result.computation_time > 0:
            print(f"Speed: {result.n_frames / result.computation_time:.1f} frames/second")
        
        if result.gpu_info:
            print(f"\nGPU Performance:")
            print(f"  Memory used: {result.gpu_info.get('memory_used', 0):.2f} GB")
            print(f"  Computation mode: {result.gpu_info.get('computation_mode', 'unknown')}")
        
        print(f"\nDetected features:")
        if isinstance(result.structural_boundaries, dict):
            n_boundaries = len(result.structural_boundaries.get('boundary_locations', []))
        else:
            n_boundaries = 0
        print(f"  Structural boundaries: {n_boundaries}")
        print(f"  Detected patterns: {len(result.detected_structures)}")
        print(f"  Critical events: {len(result.critical_events)}")
        
        # ææ–™ç‰¹æœ‰ã®çµæœ
        if result.failure_prediction:
            print(f"\nMaterial Analysis:")
            print(f"  Failure probability: {result.failure_prediction['failure_probability']:.1%}")
            print(f"  Reliability index: {result.failure_prediction['reliability_index']:.2f}")
            print(f"  Failure mode: {result.failure_prediction.get('failure_mode', 'unknown')}")
        
        if result.material_events:
            print(f"  Material events: {len(result.material_events)}")
            event_types = {}
            for event in result.material_events:
                if len(event) >= 3:
                    event_type = event[2]
                    event_types[event_type] = event_types.get(event_type, 0) + 1
            if event_types:
                print("  Event types:")
                for etype, count in sorted(event_types.items(), key=lambda x: x[1], reverse=True):
                    print(f"    - {etype}: {count}")
        
        if 'combined' in result.anomaly_scores:
            scores = result.anomaly_scores['combined']
            print(f"\nAnomaly statistics:")
            print(f"  Mean score: {np.mean(scores):.3f}")
            print(f"  Max score: {np.max(scores):.3f}")
            print(f"  Frames > 1.5Ïƒ: {np.sum(scores > 1.5)}")
    
    # === è¿½åŠ ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¡ã‚½ãƒƒãƒ‰ ===
    
    def enable_mixed_precision(self):
        """æ··åˆç²¾åº¦ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–"""
        self.config.mixed_precision = True
        print("âœ“ Mixed precision mode enabled")
    
    def benchmark_mode(self, enable: bool = True):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆ"""
        self.config.benchmark_mode = enable
        if enable:
            print("â±ï¸ Benchmark mode enabled - timing all operations")
    
    def set_batch_size(self, batch_size: int):
        """ãƒãƒƒãƒã‚µã‚¤ã‚ºã®è¨­å®š"""
        self.config.gpu_batch_size = batch_size
        print(f"âœ“ Batch size set to {batch_size} frames")

# ===============================
# Module Level Functions
# ===============================

def detect_material_events(
    trajectory: np.ndarray,
    atom_types: np.ndarray,
    config: Optional[MaterialConfig] = None,
    **kwargs
) -> List[Tuple[int, int, str]]:
    """
    ææ–™ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ¤œå‡ºã™ã‚‹ä¾¿åˆ©é–¢æ•°
    
    MaterialLambda3DetectorGPUã®ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°
    """
    config = config or MaterialConfig()
    detector = MaterialLambda3DetectorGPU(config)
    
    # è§£æå®Ÿè¡Œ
    result = detector.analyze(
        trajectory=trajectory,
        atom_types=atom_types,
        **kwargs
    )
    
    # material_eventsã‚’è¿”ã™
    if hasattr(result, 'material_events') and result.material_events:
        return result.material_events
    
    # ãªã‘ã‚Œã°critical_eventsã‹ã‚‰ç”Ÿæˆ
    events = []
    if hasattr(result, 'critical_events'):
        for event in result.critical_events:
            if isinstance(event, tuple) and len(event) >= 2:
                # (start, end, type)å½¢å¼ã«å¤‰æ›
                events.append((event[0], event[1], 'material_event'))
    
    return events
