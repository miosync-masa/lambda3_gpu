#!/usr/bin/env python3
"""
Material LambdaÂ³ Detector GPU
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

ææ–™è§£æç”¨LambdaÂ³æ¤œå‡ºå™¨ã®GPUå®Ÿè£…
é‡‘å±ãƒ»ã‚»ãƒ©ãƒŸãƒƒã‚¯ã‚¹ãƒ»ãƒãƒªãƒãƒ¼ã®ç–²åŠ´ãƒ»ç ´å£Šã‚’é«˜é€Ÿæ¤œå‡ºï¼ğŸ’

MDç‰ˆã‚’ãƒ™ãƒ¼ã‚¹ã«ææ–™ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼è§£æã«ç‰¹åŒ–

by ç’°ã¡ã‚ƒã‚“ - Material Edition v1.0
"""

import numpy as np
import time
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
import warnings
import logging

logger = logging.getLogger('lambda3_gpu.material_analysis')

# CuPyã®æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import cupy as cp
    HAS_GPU = True
except ImportError:
    cp = None
    HAS_GPU = False

# LambdaÂ³ GPU imports
from ..core.gpu_utils import GPUBackend
from ..material.cluster_structures_gpu import ClusterStructuresGPU
from ..material.cluster_network_gpu import ClusterNetworkGPU
from ..material.cluster_causality_analysis_gpu import MaterialCausalityAnalyzerGPU
from ..material.cluster_confidence_analysis_gpu import MaterialConfidenceAnalyzerGPU

# æ¤œå‡ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆMDç‰ˆã‹ã‚‰æµç”¨ï¼‰
from ..detection.anomaly_detection_gpu import AnomalyDetectorGPU
from ..detection.boundary_detection_gpu import BoundaryDetectorGPU
from ..detection.topology_breaks_gpu import TopologyBreaksDetectorGPU

# ===============================
# Configuration
# ===============================

@dataclass
class MaterialConfig:
    """ææ–™è§£æè¨­å®š"""
    # LambdaÂ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    adaptive_window: bool = True
    sensitivity: float = 1.5  # ææ–™ã¯ä½ã‚ã«
    min_boundary_gap: int = 50  # ææ–™ã¯çŸ­ã„æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«
    
    # ææ–™ç‰¹æœ‰ã®è¨­å®š
    use_coordination: bool = True  # é…ä½æ•°è§£æ
    use_strain: bool = True  # æ­ªã¿è§£æ
    use_damage: bool = True  # æå‚·è§£æ
    detect_dislocations: bool = True  # è»¢ä½æ¤œå‡º
    detect_cracks: bool = True  # äº€è£‚æ¤œå‡º
    
    # ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    material_type: str = 'SUJ2'  # 'SUJ2', 'AL7075', 'TI6AL4V'
    crystal_structure: str = 'BCC'  # 'BCC', 'FCC', 'HCP'
    cutoff_distance: float = 3.0  # Ã…
    strain_threshold: float = 0.01  # 1%æ­ªã¿
    damage_threshold: float = 0.5  # 50%æå‚·
    
    # GPUè¨­å®š
    gpu_batch_size: int = 5000  # ææ–™ã¯å°ã•ã‚
    mixed_precision: bool = False
    benchmark_mode: bool = False
    
    # ç•°å¸¸æ¤œå‡ºã®é‡ã¿
    w_strain: float = 0.4  # æ­ªã¿ç•°å¸¸ã®é‡ã¿
    w_coordination: float = 0.3  # é…ä½æ•°ç•°å¸¸ã®é‡ã¿
    w_damage: float = 0.3  # æå‚·ç•°å¸¸ã®é‡ã¿

@dataclass
class MaterialLambda3Result:
    """ææ–™LambdaÂ³è§£æçµæœ"""
    # Core LambdaÂ³æ§‹é€ 
    cluster_structures: Dict[str, np.ndarray]  # ClusterStructureResult
    structural_boundaries: Dict[str, Any]
    topological_breaks: Dict[str, np.ndarray]
    
    # ææ–™ç‰¹æœ‰ã®ç‰¹å¾´
    material_features: Dict[str, np.ndarray]
    coordination_defects: Optional[np.ndarray] = None
    strain_tensors: Optional[np.ndarray] = None
    damage_accumulation: Optional[np.ndarray] = None
    
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æ
    strain_network: Optional[List] = None
    dislocation_network: Optional[List] = None
    damage_network: Optional[List] = None
    
    # è§£æçµæœ
    anomaly_scores: Dict[str, np.ndarray] = field(default_factory=dict)
    detected_structures: List[Dict] = field(default_factory=list)
    critical_clusters: List[int] = field(default_factory=list)
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    n_frames: int = 0
    n_atoms: int = 0
    n_clusters: int = 0
    window_steps: int = 0
    computation_time: float = 0.0
    gpu_info: Optional[Dict] = None
    critical_events: List = field(default_factory=list)
    
    # ææ–™ç‰¹æ€§
    material_properties: Optional[Dict] = None
    failure_probability: float = 0.0
    reliability_index: float = 0.0

# ===============================
# Material Features GPU
# ===============================

class MaterialFeaturesGPU(GPUBackend):
    """ææ–™ç‰¹å¾´æŠ½å‡ºã®GPUå®Ÿè£…"""
    
    def __init__(self, force_cpu: bool = False):
        super().__init__(force_cpu=force_cpu)
    
    def extract_material_features(self,
                                 trajectory: np.ndarray,
                                 cluster_atoms: Dict[int, List[int]],
                                 atom_types: np.ndarray,
                                 config: MaterialConfig) -> Dict[str, np.ndarray]:
        """
        ææ–™ç‰¹å¾´ã‚’æŠ½å‡º
        
        Parameters
        ----------
        trajectory : np.ndarray
            åŸå­ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒª (n_frames, n_atoms, 3)
        cluster_atoms : Dict[int, List[int]]
            ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å®šç¾©
        atom_types : np.ndarray
            åŸå­ã‚¿ã‚¤ãƒ—
        config : MaterialConfig
            è¨­å®š
            
        Returns
        -------
        Dict[str, np.ndarray]
            ææ–™ç‰¹å¾´ã®è¾æ›¸
        """
        features = {}
        n_frames = trajectory.shape[0]
        n_clusters = len(cluster_atoms)
        
        # é…ä½æ•°è¨ˆç®—
        if config.use_coordination:
            features['coordination'] = self._compute_coordination_numbers(
                trajectory, cluster_atoms, config.cutoff_distance
            )
        
        # æ­ªã¿è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if config.use_strain:
            features['strain'] = self._compute_strain_tensors(
                trajectory, cluster_atoms
            )
        
        # æå‚·åº¦è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if config.use_damage:
            features['damage'] = self._compute_damage_scores(
                trajectory, cluster_atoms, atom_types
            )
        
        return features
    
    def _compute_coordination_numbers(self,
                                     trajectory: np.ndarray,
                                     cluster_atoms: Dict[int, List[int]],
                                     cutoff: float) -> np.ndarray:
        """é…ä½æ•°è¨ˆç®—"""
        n_frames = trajectory.shape[0]
        n_clusters = len(cluster_atoms)
        coordination = self.zeros((n_frames, n_clusters))
        
        for frame in range(n_frames):
            positions = self.to_gpu(trajectory[frame])
            
            for cluster_id, atoms in cluster_atoms.items():
                if cluster_id >= n_clusters:
                    continue
                    
                coord_sum = 0
                for atom_i in atoms[:10]:  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                    pos_i = positions[atom_i]
                    distances = self.xp.linalg.norm(positions - pos_i, axis=1)
                    neighbors = self.xp.sum((distances > 0) & (distances < cutoff))
                    coord_sum += neighbors
                
                coordination[frame, cluster_id] = coord_sum / min(len(atoms), 10)
        
        return self.to_cpu(coordination)
    
    def _compute_strain_tensors(self,
                               trajectory: np.ndarray,
                               cluster_atoms: Dict[int, List[int]]) -> np.ndarray:
        """æ­ªã¿ãƒ†ãƒ³ã‚½ãƒ«è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        n_frames = trajectory.shape[0]
        n_clusters = len(cluster_atoms)
        strain = self.zeros((n_frames, n_clusters))
        
        if n_frames < 2:
            return self.to_cpu(strain)
        
        ref_positions = self.to_gpu(trajectory[0])
        
        for frame in range(1, n_frames):
            current_positions = self.to_gpu(trajectory[frame])
            
            for cluster_id, atoms in cluster_atoms.items():
                if cluster_id >= n_clusters or len(atoms) < 4:
                    continue
                
                # ç°¡æ˜“æ­ªã¿ï¼šç›¸å¯¾å¤‰ä½ã®å¹³å‡
                sample_atoms = atoms[:10]
                ref_pos = ref_positions[sample_atoms]
                curr_pos = current_positions[sample_atoms]
                
                displacement = self.xp.linalg.norm(curr_pos - ref_pos, axis=1)
                strain[frame, cluster_id] = self.xp.mean(displacement)
        
        return self.to_cpu(strain)
    
    def _compute_damage_scores(self,
                              trajectory: np.ndarray,
                              cluster_atoms: Dict[int, List[int]],
                              atom_types: np.ndarray) -> np.ndarray:
        """æå‚·åº¦è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        n_frames = trajectory.shape[0]
        n_clusters = len(cluster_atoms)
        damage = self.zeros((n_frames, n_clusters))
        
        # åˆæœŸæ§‹é€ ã‹ã‚‰ã®å¤‰ä½ã§æå‚·ã‚’æ¨å®š
        ref_positions = self.to_gpu(trajectory[0])
        
        for frame in range(n_frames):
            current_positions = self.to_gpu(trajectory[frame])
            
            for cluster_id, atoms in cluster_atoms.items():
                if cluster_id >= n_clusters:
                    continue
                
                ref_pos = ref_positions[atoms]
                curr_pos = current_positions[atoms]
                
                # RMSDãƒ™ãƒ¼ã‚¹ã®æå‚·åº¦
                rmsd = self.xp.sqrt(self.xp.mean((curr_pos - ref_pos) ** 2))
                damage[frame, cluster_id] = self.xp.tanh(rmsd / 2.0)  # 0-1ã«æ­£è¦åŒ–
        
        return self.to_cpu(damage)

# ===============================
# Material LambdaÂ³ Detector GPU
# ===============================

class MaterialLambda3DetectorGPU(GPUBackend):
    """ææ–™ç”¨LambdaÂ³æ¤œå‡ºå™¨ï¼ˆGPUç‰ˆï¼‰"""
    
    def __init__(self, config: MaterialConfig = None, device: str = 'auto'):
        """
        Parameters
        ----------
        config : MaterialConfig
            è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        device : str
            'auto', 'gpu', 'cpu'ã®ã„ãšã‚Œã‹
        """
        # GPUBackendã®åˆæœŸåŒ–
        if device == 'cpu':
            super().__init__(device='cpu', force_cpu=True)
        else:
            super().__init__(device=device, force_cpu=False)
        
        self.config = config or MaterialConfig()
        self.verbose = True
        
        # force_cpuãƒ•ãƒ©ã‚°
        force_cpu_flag = not self.is_gpu
        
        # ææ–™ç‰ˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.structure_computer = ClusterStructuresGPU()
        self.feature_extractor = MaterialFeaturesGPU(force_cpu_flag)
        self.network_analyzer = ClusterNetworkGPU()
        self.causality_analyzer = MaterialCausalityAnalyzerGPU()
        self.confidence_analyzer = MaterialConfidenceAnalyzerGPU()
        
        # æ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆMDç‰ˆã‹ã‚‰æµç”¨ï¼‰
        self.anomaly_detector = AnomalyDetectorGPU(force_cpu_flag)
        self.boundary_detector = BoundaryDetectorGPU(force_cpu_flag)
        self.topology_detector = TopologyBreaksDetectorGPU(force_cpu_flag)
        
        # ææ–™ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£è¨­å®š
        self._set_material_properties()
        
        # ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ã¨ãƒ‡ãƒã‚¤ã‚¹ã‚’å…±æœ‰
        for component in [self.structure_computer, self.feature_extractor,
                         self.network_analyzer, self.causality_analyzer,
                         self.confidence_analyzer, self.anomaly_detector,
                         self.boundary_detector, self.topology_detector]:
            if hasattr(component, 'memory_manager'):
                component.memory_manager = self.memory_manager
            if hasattr(component, 'device'):
                component.device = self.device
        
        self._print_initialization_info()
    
    def _set_material_properties(self):
        """ææ–™ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’è¨­å®š"""
        if self.config.material_type == 'SUJ2':
            self.material_props = {
                'elastic_modulus': 210.0,  # GPa
                'yield_strength': 1.5,
                'ultimate_strength': 2.0,
                'fatigue_strength': 0.7,
                'fracture_toughness': 30.0
            }
        elif self.config.material_type == 'AL7075':
            self.material_props = {
                'elastic_modulus': 71.7,
                'yield_strength': 0.503,
                'ultimate_strength': 0.572,
                'fatigue_strength': 0.159,
                'fracture_toughness': 23.0
            }
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆé‹¼é‰„ï¼‰
            self.material_props = {
                'elastic_modulus': 210.0,
                'yield_strength': 1.0,
                'ultimate_strength': 1.5,
                'fatigue_strength': 0.5,
                'fracture_toughness': 20.0
            }
    
    def analyze(self,
               trajectory: np.ndarray,
               cluster_atoms: Dict[int, List[int]],
               atom_types: np.ndarray) -> MaterialLambda3Result:
        """
        ææ–™ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªã®LambdaÂ³è§£æ
        
        Parameters
        ----------
        trajectory : np.ndarray
            åŸå­ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒª (n_frames, n_atoms, 3)
        cluster_atoms : Dict[int, List[int]]
            ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å®šç¾©
        atom_types : np.ndarray
            åŸå­ã‚¿ã‚¤ãƒ—é…åˆ—
            
        Returns
        -------
        MaterialLambda3Result
            è§£æçµæœ
        """
        start_time = time.time()
        
        # GPUå¤‰æ›
        if self.is_gpu and cp is not None:
            print("ğŸ“Š Converting arrays to GPU...")
            trajectory = cp.asarray(trajectory)
            atom_types = cp.asarray(atom_types) if isinstance(atom_types, np.ndarray) else atom_types
        
        n_frames, n_atoms, _ = trajectory.shape
        n_clusters = len(cluster_atoms)
        
        print(f"\n{'='*60}")
        print(f"=== Material LambdaÂ³ Analysis (GPU) ===")
        print(f"{'='*60}")
        print(f"Trajectory: {n_frames} frames, {n_atoms} atoms")
        print(f"Clusters: {n_clusters}")
        print(f"Material: {self.config.material_type}")
        print(f"GPU Device: {self.device}")
        
        # ãƒãƒƒãƒå‡¦ç†åˆ¤å®š
        batch_size = min(self.config.gpu_batch_size, n_frames)
        n_batches = (n_frames + batch_size - 1) // batch_size
        
        if n_batches > 1:
            print(f"Processing in {n_batches} batches of {batch_size} frames")
            result = self._analyze_batched(trajectory, cluster_atoms, atom_types, batch_size)
        else:
            result = self._analyze_single_trajectory(trajectory, cluster_atoms, atom_types)
        
        computation_time = time.time() - start_time
        result.computation_time = computation_time
        
        self._print_summary(result)
        
        return result
    
    def _analyze_single_trajectory(self,
                                 trajectory: np.ndarray,
                                 cluster_atoms: Dict[int, List[int]],
                                 atom_types: np.ndarray) -> MaterialLambda3Result:
        """å˜ä¸€è»Œé“ã®è§£æ"""
        n_frames, n_atoms, _ = trajectory.shape
        n_clusters = len(cluster_atoms)
        
        # 1. ææ–™ç‰¹å¾´æŠ½å‡º
        print("\n1. Extracting material features...")
        material_features = self.feature_extractor.extract_material_features(
            trajectory, cluster_atoms, atom_types, self.config
        )
        
        # 2. ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ§‹é€ è¨ˆç®—
        print("\n2. Computing cluster structures...")
        window_size = self._compute_initial_window(n_frames)
        
        # CPUé…åˆ—ã«å¤‰æ›ï¼ˆClusterStructuresGPUã®æœŸå¾…ã™ã‚‹å½¢å¼ï¼‰
        if self.is_gpu and hasattr(trajectory, 'get'):
            trajectory_cpu = trajectory.get()
            atom_types_cpu = atom_types.get() if hasattr(atom_types, 'get') else atom_types
        else:
            trajectory_cpu = trajectory
            atom_types_cpu = atom_types
        
        cluster_result = self.structure_computer.compute_cluster_structures(
            trajectory_cpu,
            0,
            n_frames - 1,
            cluster_atoms,
            atom_types_cpu,
            window_size,
            self.config.cutoff_distance
        )
        
        # Lambdaæ§‹é€ ã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
        lambda_structures = {
            'lambda_f': cluster_result.cluster_lambda_f,
            'lambda_f_mag': cluster_result.cluster_lambda_f_mag,
            'rho_t': cluster_result.cluster_rho_t,
            'coupling': cluster_result.cluster_coupling
        }
        
        # 3. æ§‹é€ å¢ƒç•Œæ¤œå‡º
        print("\n3. Detecting structural boundaries...")
        structural_boundaries = self.boundary_detector.detect_structural_boundaries(
            lambda_structures, window_size // 3
        )
        
        # 4. ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ç ´ã‚Œæ¤œå‡º
        print("\n4. Detecting topological breaks...")
        topological_breaks = self.topology_detector.detect_topological_breaks(
            lambda_structures, window_size // 2
        )
        
        # 5. ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—
        print("\n5. Computing anomaly scores...")
        anomaly_scores = self._compute_material_anomalies(
            lambda_structures,
            material_features,
            structural_boundaries,
            topological_breaks
        )
        
        # 6. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æ
        print("\n6. Analyzing material network...")
        network_result = self.network_analyzer.analyze_network(
            {i: anomaly_scores['combined'][i::n_clusters] for i in range(n_clusters)},
            cluster_result.cluster_coupling,
            cluster_result.cluster_centers,
            cluster_result.coordination_numbers,
            cluster_result.local_strain,
            cluster_result.element_composition
        )
        
        # 7. è‡¨ç•Œã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡º
        critical_events = self._detect_critical_events(anomaly_scores)
        
        # çµæœæ§‹ç¯‰
        result = MaterialLambda3Result(
            cluster_structures=self._to_cpu_dict(lambda_structures),
            structural_boundaries=structural_boundaries,
            topological_breaks=self._to_cpu_dict(topological_breaks),
            material_features=self._to_cpu_dict(material_features),
            coordination_defects=cluster_result.coordination_numbers,
            strain_tensors=cluster_result.local_strain,
            damage_accumulation=material_features.get('damage'),
            strain_network=network_result.strain_network,
            dislocation_network=network_result.dislocation_network,
            damage_network=network_result.damage_network,
            anomaly_scores=self._to_cpu_dict(anomaly_scores),
            detected_structures=self._detect_structural_patterns(
                lambda_structures, structural_boundaries, window_size
            ),
            critical_clusters=network_result.critical_clusters,
            critical_events=critical_events,
            n_frames=n_frames,
            n_atoms=n_atoms,
            n_clusters=n_clusters,
            window_steps=window_size,
            computation_time=0.0,
            gpu_info=self._get_gpu_info(),
            material_properties=self.material_props,
            failure_probability=self._estimate_failure_probability(
                cluster_result.local_strain
            ),
            reliability_index=self._compute_reliability_index(
                cluster_result.local_strain
            )
        )
        
        return result
    
    def _analyze_batched(self,
                        trajectory: np.ndarray,
                        cluster_atoms: Dict[int, List[int]],
                        atom_types: np.ndarray,
                        batch_size: int) -> MaterialLambda3Result:
        """ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹è§£æ"""
        print("\nâš¡ Running batched GPU analysis for materials...")
        
        n_frames = trajectory.shape[0]
        n_batches = (n_frames + batch_size - 1) // batch_size
        
        # ãƒãƒƒãƒçµæœã‚’è“„ç©
        batch_results = []
        
        for batch_idx in range(n_batches):
            start_idx = batch_idx * batch_size
            end_idx = min((batch_idx + 1) * batch_size, n_frames)
            
            print(f"  Batch {batch_idx + 1}/{n_batches}: frames {start_idx}-{end_idx}")
            
            batch_trajectory = trajectory[start_idx:end_idx]
            
            # ãƒãƒƒãƒè§£æ
            batch_result = self._analyze_single_trajectory(
                batch_trajectory, cluster_atoms, atom_types
            )
            batch_result.offset = start_idx
            batch_results.append(batch_result)
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
            self.memory_manager.clear_cache()
        
        # çµæœãƒãƒ¼ã‚¸
        print("\n[Step 2] Merging batch results...")
        merged_result = self._merge_batch_results(batch_results, trajectory.shape)
        
        return merged_result
    
    def _compute_material_anomalies(self,
                                   lambda_structures: Dict,
                                   material_features: Dict,
                                   structural_boundaries: Dict,
                                   topological_breaks: Dict) -> Dict[str, np.ndarray]:
        """ææ–™ç‰¹æœ‰ã®ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        scores = {}
        
        # Lambdaç•°å¸¸
        if 'lambda_f_mag' in lambda_structures:
            lambda_anomaly = self._compute_anomaly_score(
                lambda_structures['lambda_f_mag']
            )
            scores['lambda'] = lambda_anomaly
        
        # æ­ªã¿ç•°å¸¸
        if 'strain' in material_features:
            strain_anomaly = self._compute_anomaly_score(
                material_features['strain']
            )
            scores['strain'] = strain_anomaly
        
        # é…ä½æ•°ç•°å¸¸
        if 'coordination' in material_features:
            ideal_coord = 12.0 if self.config.crystal_structure == 'FCC' else 8.0
            coord_defect = np.abs(material_features['coordination'] - ideal_coord)
            scores['coordination'] = coord_defect / ideal_coord
        
        # æå‚·ç•°å¸¸
        if 'damage' in material_features:
            scores['damage'] = material_features['damage']
        
        # çµ±åˆã‚¹ã‚³ã‚¢
        combined = np.zeros_like(scores.get('lambda', np.zeros(1)))
        weights_sum = 0.0
        
        if 'strain' in scores:
            combined += self.config.w_strain * scores['strain']
            weights_sum += self.config.w_strain
        
        if 'coordination' in scores:
            combined += self.config.w_coordination * scores['coordination']
            weights_sum += self.config.w_coordination
        
        if 'damage' in scores:
            combined += self.config.w_damage * scores['damage']
            weights_sum += self.config.w_damage
        
        if weights_sum > 0:
            combined /= weights_sum
        
        scores['combined'] = combined
        
        return scores
    
    def _compute_anomaly_score(self, data: np.ndarray) -> np.ndarray:
        """ç°¡æ˜“ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        if data.size == 0:
            return np.zeros(1)
        
        mean = np.mean(data, axis=0)
        std = np.std(data, axis=0) + 1e-10
        
        z_scores = np.abs((data - mean) / std)
        
        return z_scores
    
    def _estimate_failure_probability(self, strain_tensor: np.ndarray) -> float:
        """ç ´å£Šç¢ºç‡æ¨å®š"""
        if strain_tensor is None or strain_tensor.size == 0:
            return 0.0
        
        # von Miseså¿œåŠ›æ¨å®š
        von_mises_strain = np.mean(np.abs(strain_tensor))
        critical_strain = self.material_props['yield_strength'] / self.material_props['elastic_modulus']
        
        # ç°¡æ˜“ç¢ºç‡
        if von_mises_strain > critical_strain:
            return min(1.0, von_mises_strain / critical_strain)
        
        return 0.0
    
    def _compute_reliability_index(self, strain_tensor: np.ndarray) -> float:
        """ä¿¡é ¼æ€§æŒ‡æ¨™è¨ˆç®—"""
        if strain_tensor is None or strain_tensor.size == 0:
            return 5.0  # é«˜ä¿¡é ¼æ€§
        
        # ç°¡æ˜“Î²æŒ‡æ¨™
        mean_strain = np.mean(np.abs(strain_tensor))
        std_strain = np.std(np.abs(strain_tensor))
        critical_strain = self.material_props['yield_strength'] / self.material_props['elastic_modulus']
        
        if std_strain > 0:
            beta = (critical_strain - mean_strain) / std_strain
            return float(beta)
        
        return 5.0
    
    # ========================================
    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆMDç‰ˆã‹ã‚‰æµç”¨ï¼‰
    # ========================================
    
    def _compute_initial_window(self, n_frames: int) -> int:
        """åˆæœŸã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º"""
        return min(50, n_frames // 10)  # ææ–™ã¯çŸ­ã‚
    
    def _detect_structural_patterns(self, lambda_structures: Dict,
                                   boundaries: Dict, window: int) -> List[Dict]:
        """æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º"""
        patterns = []
        
        if isinstance(boundaries, dict) and 'boundary_locations' in boundaries:
            boundary_locs = boundaries['boundary_locations']
            
            for i in range(len(boundary_locs) - 1):
                duration = boundary_locs[i+1] - boundary_locs[i]
                if duration > 20:  # ææ–™ã¯çŸ­ã„é–¾å€¤
                    pattern_type = 'elastic' if duration < 100 else 'plastic'
                    patterns.append({
                        'type': pattern_type,
                        'start': boundary_locs[i],
                        'end': boundary_locs[i+1],
                        'duration': duration
                    })
        
        return patterns
    
    def _detect_critical_events(self, anomaly_scores: Dict) -> List:
        """è‡¨ç•Œã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡º"""
        events = []
        
        if 'combined' in anomaly_scores:
            scores = anomaly_scores['combined']
            threshold = np.mean(scores) + 1.5 * np.std(scores)  # ææ–™ã¯ä½ã‚
            
            critical_frames = np.where(scores > threshold)[0]
            
            if len(critical_frames) > 0:
                current_start = critical_frames[0]
                current_end = critical_frames[0]
                
                for frame in critical_frames[1:]:
                    if frame == current_end + 1:
                        current_end = frame
                    else:
                        events.append((current_start, current_end))
                        current_start = frame
                        current_end = frame
                
                events.append((current_start, current_end))
        
        return events
    
    def _merge_batch_results(self, batch_results: List, original_shape: Tuple) -> MaterialLambda3Result:
        """ãƒãƒƒãƒçµæœã®ãƒãƒ¼ã‚¸ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        if not batch_results:
            return self._create_empty_result(original_shape[0], original_shape[1])
        
        # æœ€åˆã®ãƒãƒƒãƒã®æ§‹é€ ã‚’ã‚³ãƒ”ãƒ¼
        merged = batch_results[0]
        
        # ä»–ã®ãƒãƒƒãƒã®é‡è¦ãªæƒ…å ±ã‚’ãƒãƒ¼ã‚¸
        for batch in batch_results[1:]:
            merged.critical_clusters.extend(batch.critical_clusters)
            merged.critical_events.extend(batch.critical_events)
        
        merged.n_frames = original_shape[0]
        
        return merged
    
    def _create_empty_result(self, n_frames: int, n_atoms: int) -> MaterialLambda3Result:
        """ç©ºã®çµæœä½œæˆ"""
        return MaterialLambda3Result(
            cluster_structures={},
            structural_boundaries={},
            topological_breaks={},
            material_features={},
            n_frames=n_frames,
            n_atoms=n_atoms,
            n_clusters=0
        )
    
    def _to_cpu_dict(self, data_dict: Dict) -> Dict:
        """GPUé…åˆ—ã‚’CPUã«è»¢é€"""
        cpu_dict = {}
        for key, value in data_dict.items():
            if hasattr(value, 'get'):
                cpu_dict[key] = value.get()
            elif isinstance(value, dict):
                cpu_dict[key] = self._to_cpu_dict(value)
            else:
                cpu_dict[key] = value
        return cpu_dict
    
    def _get_gpu_info(self) -> Dict:
        """GPUæƒ…å ±å–å¾—"""
        return {
            'device_name': str(self.device),
            'computation_mode': 'single_batch'
        }
    
    def _print_initialization_info(self):
        """åˆæœŸåŒ–æƒ…å ±è¡¨ç¤º"""
        if self.verbose:
            print(f"\nğŸ’ Material LambdaÂ³ Detector Initialized")
            print(f"   Material: {self.config.material_type}")
            print(f"   Crystal: {self.config.crystal_structure}")
            print(f"   Device: {self.device}")
            print(f"   GPU Mode: {self.is_gpu}")
            print(f"   Batch Size: {self.config.gpu_batch_size} frames")
    
    def _print_summary(self, result: MaterialLambda3Result):
        """çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print("\n" + "="*60)
        print("=== Material Analysis Complete ===")
        print("="*60)
        print(f"Total frames: {result.n_frames}")
        print(f"Total clusters: {result.n_clusters}")
        print(f"Computation time: {result.computation_time:.2f} seconds")
        
        if result.computation_time > 0:
            print(f"Speed: {result.n_frames / result.computation_time:.1f} frames/second")
        
        print(f"\nMaterial properties:")
        print(f"  Failure probability: {result.failure_probability:.1%}")
        print(f"  Reliability index Î²: {result.reliability_index:.2f}")
        
        print(f"\nDetected features:")
        print(f"  Critical clusters: {len(result.critical_clusters)}")
        print(f"  Critical events: {len(result.critical_events)}")
        
        if result.strain_network:
            print(f"  Strain network links: {len(result.strain_network)}")
        if result.dislocation_network:
            print(f"  Dislocation links: {len(result.dislocation_network)}")
        if result.damage_network:
            print(f"  Damage links: {len(result.damage_network)}")
