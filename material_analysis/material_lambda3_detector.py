#!/usr/bin/env python3
"""
Material LambdaÂ³ Detector GPU - Refactored Pipeline Edition
==========================================================

ææ–™è§£æç”¨LambdaÂ³æ¤œå‡ºå™¨ã®GPUå®Ÿè£…ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼‰

ä¸»ãªæ”¹å–„ç‚¹ï¼š
- å‰å‡¦ç†ï¼ˆãƒãƒƒãƒã”ã¨ï¼‰ã¨å¾Œå‡¦ç†ï¼ˆãƒãƒ¼ã‚¸å¾Œï¼‰ã®æ˜ç¢ºãªåˆ†é›¢
- MaterialAnalyticsGPUã®æ¬ é™¥è§£æã‚’å‰å‡¦ç†ã«ç§»å‹•
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªãƒãƒƒãƒå‡¦ç†

Version: 2.1.0
Author: ç’°ã¡ã‚ƒã‚“
"""

import numpy as np
import time
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
import warnings
import logging

# CuPyã®æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import cupy as cp
    HAS_GPU = True
except ImportError:
    cp = None
    HAS_GPU = False

# LambdaÂ³ GPU imports
from ..core.gpu_utils import GPUBackend
from ..structures.lambda_structures_gpu import LambdaStructuresGPU
from ..structures.md_features import MDFeaturesGPU  # åŸºæœ¬MDç‰¹å¾´æŠ½å‡º
from ..material.material_md_features_gpu import MaterialMDFeaturesGPU  # ææ–™ç‰¹å¾´æŠ½å‡º
from ..detection.anomaly_detection_gpu import AnomalyDetectorGPU
from ..detection.boundary_detection_gpu import BoundaryDetectorGPU
from ..detection.topology_breaks_gpu import TopologyBreaksDetectorGPU
from ..detection.extended_detection_gpu import ExtendedDetectorGPU
from ..detection.phase_space_gpu import PhaseSpaceAnalyzerGPU

# Material specific imports
from ..material.material_analytics_gpu import MaterialAnalyticsGPU

# Loggerè¨­å®š
logger = logging.getLogger(__name__)

# ===============================
# Configuration
# ===============================

@dataclass
class MaterialConfig:
    """ææ–™è§£æè¨­å®š"""
    # LambdaÂ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    adaptive_window: bool = True
    extended_detection: bool = True
    use_extended_detection: bool = True
    use_phase_space: bool = True
    sensitivity: float = 1.5
    min_boundary_gap: int = 50
    
    # ææ–™ç‰¹æœ‰ã®è¨­å®š
    material_type: str = 'SUJ2'
    use_material_analytics: bool = True
    
    # GPUè¨­å®š
    gpu_batch_size: int = 10000
    mixed_precision: bool = False
    benchmark_mode: bool = False
    
    # ç•°å¸¸æ¤œå‡ºã®é‡ã¿
    w_lambda_f: float = 0.3
    w_lambda_ff: float = 0.2
    w_rho_t: float = 0.2
    w_topology: float = 0.3
    
    # ææ–™ç‰¹æœ‰ã®é‡ã¿
    w_defect: float = 0.2
    w_coherence: float = 0.1
    
    # é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š
    window_scale: float = 0.005

@dataclass
class MaterialLambda3Result:
    """ææ–™LambdaÂ³è§£æçµæœ"""
    # Core LambdaÂ³æ§‹é€ 
    lambda_structures: Dict[str, np.ndarray]
    structural_boundaries: Dict[str, Any]
    topological_breaks: Dict[str, np.ndarray]
    
    # MD/ææ–™ç‰¹å¾´
    md_features: Dict[str, np.ndarray]
    
    # è§£æçµæœ
    anomaly_scores: Dict[str, np.ndarray]
    detected_structures: List[Dict]
    
    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    material_features: Optional[Dict[str, np.ndarray]] = None
    phase_space_analysis: Optional[Dict] = None
    defect_analysis: Optional[Dict] = None
    structural_coherence: Optional[np.ndarray] = None
    failure_prediction: Optional[Dict] = None
    material_events: Optional[List[Tuple[int, int, str]]] = None
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    n_frames: int = 0
    n_atoms: int = 0
    window_steps: int = 0
    computation_time: float = 0.0
    gpu_info: Dict = field(default_factory=dict)
    critical_events: List = field(default_factory=list)

# ===============================
# Main Detector Class
# ===============================

class MaterialLambda3DetectorGPU(GPUBackend):
    """
    GPUç‰ˆLambdaÂ³ææ–™æ¤œå‡ºå™¨ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼‰
    
    å‡¦ç†ãƒ•ãƒ­ãƒ¼ï¼š
    1. å‰å‡¦ç†ï¼ˆãƒãƒƒãƒã”ã¨ï¼‰: MDç‰¹å¾´æŠ½å‡º â†’ æ¬ é™¥è§£æ â†’ Lambdaæ§‹é€ è¨ˆç®—
    2. å¾Œå‡¦ç†ï¼ˆãƒãƒ¼ã‚¸å¾Œï¼‰: å¢ƒç•Œæ¤œå‡º â†’ ç•°å¸¸æ¤œå‡º â†’ ææ–™è§£æï¼ˆMDç‰¹å¾´ãƒ™ãƒ¼ã‚¹ï¼‰
    """
    
    def __init__(self, config: MaterialConfig = None, device: str = 'auto'):
        # GPUBackendã®åˆæœŸåŒ–
        if device == 'cpu':
            super().__init__(device='cpu', force_cpu=True)
        else:
            super().__init__(device=device, force_cpu=False)
        
        self.config = config or MaterialConfig()
        self.verbose = True
        
        force_cpu_flag = not self.is_gpu
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹æˆ
        self.structure_computer = LambdaStructuresGPU(force_cpu_flag)
        
        # === é‡è¦: 2ã¤ã®ç‹¬ç«‹ã—ãŸç‰¹å¾´æŠ½å‡ºå™¨ ===
        # Lambdaæ§‹é€ è¨ˆç®—ç”¨ï¼ˆå…¨åŸå­ï¼‰
        self.feature_extractor = MDFeaturesGPU(force_cpu_flag)
        # ææ–™è§£æç”¨ï¼ˆæ¬ é™¥é ˜åŸŸï¼‰
        self.material_feature_extractor = MaterialMDFeaturesGPU(force_cpu_flag)
        
        self.anomaly_detector = AnomalyDetectorGPU(force_cpu_flag)
        self.boundary_detector = BoundaryDetectorGPU(force_cpu_flag)
        self.topology_detector = TopologyBreaksDetectorGPU(force_cpu_flag)
        self.extended_detector = ExtendedDetectorGPU(force_cpu_flag)
        self.phase_space_analyzer = PhaseSpaceAnalyzerGPU(force_cpu_flag)
        
        # ææ–™ç‰¹æœ‰ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        if self.config.use_material_analytics:
            self.material_analytics = MaterialAnalyticsGPU(
                material_type=self.config.material_type,
                force_cpu=force_cpu_flag
            )
        else:
            self.material_analytics = None
        
        # ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ã¨ãƒ‡ãƒã‚¤ã‚¹ã‚’å…±æœ‰
        self._share_resources()
        self._print_initialization_info()
    
    def _share_resources(self):
        """ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ã¨ãƒ‡ãƒã‚¤ã‚¹ã‚’ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé–“ã§å…±æœ‰"""
        components = [
            self.structure_computer, 
            self.feature_extractor,  # åŸºæœ¬MDç‰¹å¾´æŠ½å‡ºå™¨
            self.material_feature_extractor,  # ææ–™ç‰¹å¾´æŠ½å‡ºå™¨
            self.anomaly_detector, 
            self.boundary_detector,
            self.topology_detector, 
            self.extended_detector,
            self.phase_space_analyzer
        ]
        
        if self.material_analytics:
            components.append(self.material_analytics)
        
        for component in components:
            if hasattr(component, 'memory_manager'):
                component.memory_manager = self.memory_manager
            if hasattr(component, 'device'):
                component.device = self.device

    def analyze(self,
                trajectory: np.ndarray,
                backbone_indices: Optional[np.ndarray] = None,
                atom_types: Optional[np.ndarray] = None,
                cluster_definition_path: Optional[str] = None,
                cluster_atoms: Optional[Dict[int, List[int]]] = None,
                **kwargs) -> MaterialLambda3Result:
        """
        ææ–™è»Œé“ã®LambdaÂ³è§£æ
        """
        start_time = time.time()
        
        # å‰å‡¦ç†
        trajectory, atom_types = self._preprocess_inputs(
            trajectory, atom_types, backbone_indices
        )
        
        n_frames, n_atoms, _ = trajectory.shape
        self._print_analysis_header(n_frames, n_atoms)
        
        # ãƒãƒƒãƒå‡¦ç†ã®åˆ¤å®š
        batch_size = min(self.config.gpu_batch_size, n_frames)
        n_batches = (n_frames + batch_size - 1) // batch_size
        
        if n_batches > 1:
            print(f"Processing in {n_batches} batches of {batch_size} frames")
            result = self._analyze_batched(
                trajectory, backbone_indices, atom_types, 
                batch_size, cluster_definition_path, cluster_atoms
            )
        else:
            result = self._analyze_single_trajectory(
                trajectory, backbone_indices, atom_types,
                cluster_definition_path, cluster_atoms
            )
        
        result.computation_time = time.time() - start_time
        self._print_summary(result)
        
        return result
    
    def _preprocess_inputs(self, trajectory, atom_types, backbone_indices):
        """å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨GPUè»¢é€"""
        # åŸå­ã‚¿ã‚¤ãƒ—ã®æ–‡å­—åˆ—â†’æ•°å€¤å¤‰æ›
        if atom_types is not None and atom_types.dtype.kind == 'U':
            atom_type_names = np.unique(atom_types)
            type_map = {t: i for i, t in enumerate(atom_type_names)}
            atom_types = np.array([type_map[t] for t in atom_types], dtype=np.int32)
        
        # GPUè»¢é€
        if self.is_gpu and cp is not None:
            print("ğŸ“Š Converting arrays to GPU...")
            trajectory = cp.asarray(trajectory)
            if backbone_indices is not None:
                backbone_indices = cp.asarray(backbone_indices)
            if atom_types is not None:
                atom_types = cp.asarray(atom_types)
        
        return trajectory, atom_types
    
    def _analyze_single_trajectory(self,
                                  trajectory: np.ndarray,
                                  backbone_indices: Optional[np.ndarray],
                                  atom_types: Optional[np.ndarray],
                                  cluster_definition_path: Optional[str] = None,
                                  cluster_atoms: Optional[Dict[int, List[int]]] = None
                                  ) -> MaterialLambda3Result:
        """å˜ä¸€è»Œé“ã®å®Œå…¨è§£æ"""
        n_frames, n_atoms, _ = trajectory.shape
        
        # æ¬ é™¥é ˜åŸŸã®ç‰¹å®š
        backbone_indices = self._identify_defect_regions(
            cluster_atoms, backbone_indices
        )
        
        # === å‰å‡¦ç† ===
        print("\n[PREPROCESSING]")
        
        # 1. åŸºæœ¬MDç‰¹å¾´æŠ½å‡ºï¼ˆå…¨åŸå­ - Lambdaæ§‹é€ ç”¨ï¼‰
        print("  1. Extracting MD features (full atoms)...")
        md_features = self.feature_extractor.extract_md_features(
            trajectory, 
            None,  # å…¨åŸå­ã§è¨ˆç®—
            cluster_definition_path=cluster_definition_path,
            atom_types=atom_types
        )
        
        # 2. ææ–™ç‰¹æœ‰ã®ç‰¹å¾´æŠ½å‡ºï¼ˆæ¬ é™¥é ˜åŸŸ - ææ–™è§£æç”¨ï¼‰
        material_features = None
        if self.config.use_material_analytics and backbone_indices is not None:
            print("  2. Extracting material features (defect region)...")
            material_features = self.material_feature_extractor.extract_md_features(
                trajectory, 
                backbone_indices,  # æ¬ é™¥é ˜åŸŸã®ã¿
                cluster_definition_path=cluster_definition_path,
                atom_types=atom_types
            )
            
            # æ¬ é™¥è§£æçµæœã‚’MDç‰¹å¾´ã«è¿½åŠ ï¼ˆå‚ç…§ç”¨ï¼‰
            print("  3. Computing crystal defect charges...")
            self._add_defect_analysis_to_features(
                trajectory, md_features, cluster_atoms, n_atoms
            )
        
        # 4. Lambdaæ§‹é€ è¨ˆç®—ï¼ˆåŸºæœ¬MDç‰¹å¾´ã‚’ä½¿ç”¨ï¼‰
        initial_window = self._compute_initial_window(n_frames)
        print("  4. Computing LambdaÂ³ structures...")
        lambda_structures = self.structure_computer.compute_lambda_structures(
            trajectory, md_features, initial_window  # md_featuresï¼ˆå…¨åŸå­ï¼‰ã‚’ä½¿ç”¨
        )
        
        # === å¾Œå‡¦ç† ===
        print("\n[POSTPROCESSING]")
        
        # è§£æçµæœã‚’çµ±åˆ
        result = self._perform_postprocessing(
            lambda_structures, md_features, material_features,
            n_frames, n_atoms, initial_window
        )
        
        return result
    
    def _analyze_batched(self,
                        trajectory: np.ndarray,
                        backbone_indices: Optional[np.ndarray],
                        atom_types: Optional[np.ndarray],
                        batch_size: int,
                        cluster_definition_path: Optional[str] = None,
                        cluster_atoms: Optional[Dict[int, List[int]]] = None
                        ) -> MaterialLambda3Result:
        """ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹è§£æ"""
        print("\nâš¡ Running batched GPU analysis...")
        
        n_frames = trajectory.shape[0]
        batches = self._optimize_batch_plan(n_frames, batch_size)
        
        # Step 1: å‰å‡¦ç†ï¼ˆãƒãƒƒãƒã”ã¨ï¼‰
        batch_results = self._process_batches(
            trajectory, backbone_indices, atom_types,
            batches, cluster_definition_path
        )
        
        if not batch_results:
            return self._create_empty_result(n_frames, trajectory.shape[1])
        
        # Step 2: çµæœã‚’ãƒãƒ¼ã‚¸
        print("\n[MERGING]")
        merged_result = self._merge_batch_results(
            batch_results, trajectory.shape, atom_types
        )
        
        # Step 3: å¾Œå‡¦ç†
        print("\n[POSTPROCESSING]")
        final_result = self._complete_analysis(merged_result, atom_types)
        
        return final_result
    
    def _analyze_single_batch(self,
                             batch_trajectory: np.ndarray,
                             backbone_indices: Optional[np.ndarray],
                             atom_types: Optional[np.ndarray],
                             offset: int,
                             cluster_definition_path: Optional[str] = None
                             ) -> Dict:
        """
        å˜ä¸€ãƒãƒƒãƒã®å‰å‡¦ç†
        
        å®Ÿè¡Œå†…å®¹ï¼š
        1. åŸºæœ¬MDç‰¹å¾´æŠ½å‡ºï¼ˆMDFeaturesGPU - å…¨åŸå­ï¼‰
        2. ææ–™ç‰¹å¾´æŠ½å‡ºï¼ˆMaterialMDFeaturesGPU - æ¬ é™¥é ˜åŸŸï¼‰
        3. æ¬ é™¥è§£æï¼ˆMaterialAnalyticsGPU - ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªå¿…è¦ï¼‰
        4. Lambdaæ§‹é€ è¨ˆç®—
        """
        n_atoms = batch_trajectory.shape[1]
        
        # 1. åŸºæœ¬MDç‰¹å¾´æŠ½å‡ºï¼ˆå…¨åŸå­ - Lambdaæ§‹é€ ç”¨ï¼‰
        md_features = self.feature_extractor.extract_md_features(
            batch_trajectory, 
            None,  # å…¨åŸå­ã§è¨ˆç®—
            cluster_definition_path=cluster_definition_path,
            atom_types=atom_types
        )
        
        # 2. ææ–™ç‰¹æœ‰ã®ç‰¹å¾´æŠ½å‡ºï¼ˆæ¬ é™¥é ˜åŸŸ - ææ–™è§£æç”¨ï¼‰
        material_features = None
        if self.config.use_material_analytics and backbone_indices is not None:
            material_features = self.material_feature_extractor.extract_md_features(
                batch_trajectory, 
                backbone_indices,  # æ¬ é™¥é ˜åŸŸã®ã¿
                cluster_definition_path=cluster_definition_path,
                atom_types=atom_types
            )
            
            # 3. æ¬ é™¥è§£æï¼ˆå‰å‡¦ç†ã§å®Ÿè¡Œï¼‰
            self._add_defect_analysis_to_features(
                batch_trajectory, md_features, None, n_atoms
            )
        
        # 4. Lambdaæ§‹é€ è¨ˆç®—ï¼ˆåŸºæœ¬MDç‰¹å¾´ã‚’ä½¿ç”¨ï¼‰
        window = self._compute_initial_window(len(batch_trajectory))
        lambda_structures = self.structure_computer.compute_lambda_structures(
            batch_trajectory, md_features, window  # md_featuresï¼ˆå…¨åŸå­ï¼‰ã‚’ä½¿ç”¨
        )
        
        return {
            'offset': offset,
            'n_frames': len(batch_trajectory),
            'lambda_structures': lambda_structures,
            'md_features': md_features,
            'material_features': material_features,  # åˆ¥é€”ä¿æŒ
            'window': window
        }
    
    def _complete_analysis(self,
                          merged_result: MaterialLambda3Result,
                          atom_types: Optional[np.ndarray]
                          ) -> MaterialLambda3Result:
        """
        ãƒãƒ¼ã‚¸å¾Œã®å¾Œå‡¦ç†
        
        å®Ÿè¡Œå†…å®¹ï¼š
        1. å¢ƒç•Œæ¤œå‡ºãƒ»ãƒˆãƒãƒ­ã‚¸ãƒ¼è§£æ
        2. ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—
        3. ææ–™ç‰¹æœ‰ã®è§£æï¼ˆMDç‰¹å¾´ãƒ™ãƒ¼ã‚¹ï¼‰
        """
        lambda_structures = merged_result.lambda_structures
        md_features = merged_result.md_features
        n_frames = merged_result.n_frames
        n_atoms = merged_result.n_atoms
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºæ±ºå®š
        initial_window = merged_result.window_steps
        adaptive_windows = self._determine_adaptive_windows(
            lambda_structures, initial_window
        )
        primary_window = adaptive_windows.get('primary', initial_window)
        
        # å¢ƒç•Œãƒ»ãƒˆãƒãƒ­ã‚¸ãƒ¼æ¤œå‡º
        print("  - Detecting boundaries and topology...")
        structural_boundaries = self.boundary_detector.detect_structural_boundaries(
            lambda_structures, adaptive_windows.get('boundary', primary_window // 3)
        )
        topological_breaks = self.topology_detector.detect_topological_breaks(
            lambda_structures, adaptive_windows.get('fast', primary_window // 2)
        )
        
        # ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—
        print("  - Computing anomaly scores...")
        anomaly_scores = self.anomaly_detector.compute_multiscale_anomalies(
            lambda_structures, structural_boundaries,
            topological_breaks, md_features, self.config
        )
        
        # ææ–™ç‰¹æœ‰ã®è§£æï¼ˆMDç‰¹å¾´ãƒ™ãƒ¼ã‚¹ï¼‰
        defect_analysis = None
        structural_coherence = None
        failure_prediction = None
        material_events = None
        
        if self.config.use_material_analytics and self.material_analytics:
            print("  - Material-specific analysis...")
            
            # æ¬ é™¥æƒ…å ±ã®å–å¾—
            if 'defect_charge' in md_features:
                defect_analysis = {
                    'defect_charge': md_features.get('defect_charge'),
                    'cumulative_charge': md_features.get('cumulative_charge')
                }
            
            # æ§‹é€ ä¸€è²«æ€§
            if 'coordination' in md_features:
                structural_coherence = self.material_analytics.compute_structural_coherence(
                    md_features['coordination'],
                    md_features.get('strain', np.zeros((n_frames, 1))),
                    window=primary_window // 2
                )
            
            # ç ´å£Šäºˆæ¸¬
            if 'strain' in md_features:
                failure_prediction = self.material_analytics.predict_failure(
                    md_features['strain'],
                    damage_history=md_features.get('damage'),
                    defect_charge=md_features.get('cumulative_charge')
                )
                failure_prediction = {
                    'failure_probability': failure_prediction.failure_probability,
                    'reliability_index': failure_prediction.reliability_index,
                    'failure_mode': failure_prediction.failure_mode
                }
            
            # ã‚¤ãƒ™ãƒ³ãƒˆåˆ†é¡
            critical_events = self._detect_critical_events(anomaly_scores)
            if critical_events and structural_coherence is not None:
                material_events = self.material_analytics.classify_material_events(
                    critical_events, anomaly_scores,
                    structural_coherence,
                    defect_charge=md_features.get('defect_charge')
                )
        
        # æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        print("  - Detecting structural patterns...")
        detected_structures = self._detect_structural_patterns(
            lambda_structures, structural_boundaries,
            adaptive_windows.get('slow', primary_window * 2)
        )
        
        # ä½ç›¸ç©ºé–“è§£æ
        phase_space_analysis = None
        if self.config.use_phase_space:
            try:
                phase_space_analysis = self.phase_space_analyzer.analyze_phase_space(
                    lambda_structures
                )
            except Exception as e:
                logger.warning(f"Phase space analysis failed: {e}")
        
        print("  âœ… Analysis completed!")
        
        # çµæœã‚’æ›´æ–°
        merged_result.structural_boundaries = structural_boundaries
        merged_result.topological_breaks = topological_breaks
        merged_result.anomaly_scores = anomaly_scores
        merged_result.detected_structures = detected_structures
        merged_result.phase_space_analysis = phase_space_analysis
        merged_result.defect_analysis = defect_analysis
        merged_result.structural_coherence = structural_coherence
        merged_result.failure_prediction = failure_prediction
        merged_result.material_events = material_events
        merged_result.critical_events = self._detect_critical_events(anomaly_scores)
        merged_result.window_steps = primary_window
        
        return merged_result
    
    # === ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ ===
    
    def _identify_defect_regions(self,
                                cluster_atoms: Optional[Dict[int, List[int]]],
                                backbone_indices: Optional[np.ndarray]
                                ) -> Optional[np.ndarray]:
        """æ¬ é™¥é ˜åŸŸã®ç‰¹å®š"""
        if cluster_atoms is not None:
            defect_indices = []
            for cid, atoms in cluster_atoms.items():
                if str(cid) != "0":  # Cluster 0ï¼ˆå¥å…¨é ˜åŸŸï¼‰ä»¥å¤–
                    defect_indices.extend(atoms)
            if defect_indices:
                backbone_indices = np.array(sorted(defect_indices))
                print(f"  Using {len(backbone_indices)} defect atoms from clusters")
        return backbone_indices
    
    def _add_defect_analysis_to_features(self,
                                        trajectory: np.ndarray,
                                        md_features: Dict,
                                        cluster_atoms: Optional[Dict],
                                        n_atoms: int):
        """MDç‰¹å¾´ã«æ¬ é™¥è§£æçµæœã‚’è¿½åŠ """
        try:
            trajectory_cpu = self.to_cpu(trajectory) if self.is_gpu else trajectory
            clusters = cluster_atoms if cluster_atoms else {0: list(range(n_atoms))}
            
            defect_result = self.material_analytics.compute_crystal_defect_charge(
                trajectory_cpu, clusters, cutoff=3.5
            )
            
            md_features['defect_charge'] = defect_result.defect_charge
            md_features['cumulative_charge'] = defect_result.cumulative_charge
        except Exception as e:
            logger.warning(f"Defect analysis failed: {e}")
    
    def _optimize_batch_plan(self, n_frames: int, batch_size: int) -> List[Tuple[int, int]]:
        """ãƒãƒƒãƒè¨ˆç”»ã®æœ€é©åŒ–"""
        MIN_BATCH_SIZE = 1000
        batches = []
        current_pos = 0
        
        while current_pos < n_frames:
            batch_end = min(current_pos + batch_size, n_frames)
            remaining = batch_end - current_pos
            
            # æœ€å¾Œã®å°ã•ã„ãƒãƒƒãƒã‚’å‰ã®ãƒãƒƒãƒã¨çµåˆ
            if batch_end == n_frames and remaining < MIN_BATCH_SIZE and batches:
                print(f"  Merging last batch ({remaining} frames) with previous")
                prev_start, _ = batches[-1]
                batches[-1] = (prev_start, n_frames)
                break
            
            batches.append((current_pos, batch_end))
            current_pos = batch_end
        
        return batches
    
    def _process_batches(self,
                        trajectory: np.ndarray,
                        backbone_indices: Optional[np.ndarray],
                        atom_types: Optional[np.ndarray],
                        batches: List[Tuple[int, int]],
                        cluster_definition_path: Optional[str]
                        ) -> List[Dict]:
        """ãƒãƒƒãƒå‡¦ç†ã®å®Ÿè¡Œ"""
        batch_results = []
        
        print("\n[PREPROCESSING - Batch Processing]")
        for batch_idx, (start_idx, end_idx) in enumerate(batches):
            frames_count = end_idx - start_idx
            print(f"  Batch {batch_idx + 1}/{len(batches)}: "
                  f"frames {start_idx}-{end_idx} ({frames_count} frames)")
            
            try:
                batch_result = self._analyze_single_batch(
                    trajectory[start_idx:end_idx],
                    backbone_indices, atom_types,
                    start_idx, cluster_definition_path
                )
                batch_results.append(batch_result)
                
            except Exception as e:
                print(f"    âš ï¸ Batch failed: {e}")
                continue
            
            finally:
                self.memory_manager.clear_cache()
        
        return batch_results
    
    def _merge_batch_results(self,
                           batch_results: List[Dict],
                           original_shape: Tuple,
                           atom_types: Optional[np.ndarray]
                           ) -> MaterialLambda3Result:
        """ãƒãƒƒãƒçµæœã®çµ±åˆ"""
        print("  Merging batch results...")
        n_frames, n_atoms, _ = original_shape
        
        if not batch_results:
            return self._create_empty_result(n_frames, n_atoms)
        
        # çµæœé…åˆ—ã®åˆæœŸåŒ–
        merged_lambda = {}
        merged_features = {}
        
        # æœ€åˆã®ãƒãƒƒãƒã‹ã‚‰æ§‹é€ ã‚’å–å¾—
        first_batch = batch_results[0]
        
        # Lambdaæ§‹é€ ã®åˆæœŸåŒ–
        for key in first_batch.get('lambda_structures', {}).keys():
            sample = first_batch['lambda_structures'][key]
            if isinstance(sample, (np.ndarray, self.xp.ndarray)):
                shape = (n_frames,) + sample.shape[1:] if sample.ndim > 1 else (n_frames,)
                merged_lambda[key] = np.full(shape, np.nan, dtype=sample.dtype)
        
        # MDç‰¹å¾´ã®åˆæœŸåŒ–
        for key in first_batch.get('md_features', {}).keys():
            sample = first_batch['md_features'][key]
            if isinstance(sample, (np.ndarray, self.xp.ndarray)):
                shape = (n_frames,) + sample.shape[1:] if sample.ndim > 1 else (n_frames,)
                merged_features[key] = np.full(shape, np.nan, dtype=sample.dtype)
        
        # ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸
        for batch in batch_results:
            offset = batch['offset']
            n_batch_frames = batch['n_frames']
            end_idx = min(offset + n_batch_frames, n_frames)
            
            # Lambdaæ§‹é€ 
            for key, value in batch.get('lambda_structures', {}).items():
                if key in merged_lambda:
                    value = self.to_cpu(value) if hasattr(value, 'get') else value
                    actual_frames = min(len(value), end_idx - offset)
                    merged_lambda[key][offset:offset + actual_frames] = value[:actual_frames]
            
            # MDç‰¹å¾´
            for key, value in batch.get('md_features', {}).items():
                if key in merged_features:
                    value = self.to_cpu(value) if hasattr(value, 'get') else value
                    actual_frames = min(len(value), end_idx - offset)
                    merged_features[key][offset:offset + actual_frames] = value[:actual_frames]
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã®å¹³å‡
        window_steps = int(np.mean([b.get('window', 100) for b in batch_results]))
        
        print(f"  âœ… Merged {n_frames} frames successfully")
        
        return MaterialLambda3Result(
            lambda_structures=merged_lambda,
            md_features=merged_features,
            material_features=merged_features,
            structural_boundaries={},
            topological_breaks={},
            anomaly_scores={},
            detected_structures=[],
            n_frames=n_frames,
            n_atoms=n_atoms,
            window_steps=window_steps,
            gpu_info={'computation_mode': 'batched', 'n_batches': len(batch_results)}
        )
    
    def _perform_postprocessing(self,
                              lambda_structures: Dict,
                              md_features: Dict,
                              material_features: Optional[Dict],
                              n_frames: int,
                              n_atoms: int,
                              initial_window: int
                              ) -> MaterialLambda3Result:
        """å˜ä¸€è»Œé“ç”¨ã®å¾Œå‡¦ç†"""
        # MaterialLambda3Resultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        partial_result = MaterialLambda3Result(
            lambda_structures=self._to_cpu_dict(lambda_structures),
            md_features=self._to_cpu_dict(md_features),
            material_features=self._to_cpu_dict(material_features) if material_features else md_features,
            structural_boundaries={},
            topological_breaks={},
            anomaly_scores={},
            detected_structures=[],
            n_frames=n_frames,
            n_atoms=n_atoms,
            window_steps=initial_window,
            gpu_info=self._get_gpu_info()
        )
        
        # å¾Œå‡¦ç†ã‚’å®Ÿè¡Œ
        return self._complete_analysis(partial_result, None)
    
    def _compute_initial_window(self, n_frames: int) -> int:
        """åˆæœŸã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã®è¨ˆç®—"""
        return min(50, n_frames // 10)
    
    def _determine_adaptive_windows(self,
                                   lambda_structures: Dict,
                                   initial_window: int
                                   ) -> Dict[str, int]:
        """é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã®æ±ºå®š"""
        if not self.config.adaptive_window:
            return {'primary': initial_window}
        
        return {
            'primary': initial_window,
            'fast': max(10, initial_window // 2),
            'slow': min(500, initial_window * 2),
            'boundary': max(20, initial_window // 3)
        }
    
    def _detect_structural_patterns(self,
                                   lambda_structures: Dict,
                                   boundaries: Dict,
                                   window: int
                                   ) -> List[Dict]:
        """æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º"""
        patterns = []
        
        if isinstance(boundaries, dict) and 'boundary_locations' in boundaries:
            boundary_locs = boundaries['boundary_locations']
            
            if len(boundary_locs) > 0:
                # æœ€åˆã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
                if boundary_locs[0] > 30:
                    patterns.append({
                        'type': 'initial_structure',
                        'start': 0,
                        'end': boundary_locs[0],
                        'duration': boundary_locs[0]
                    })
                
                # ä¸­é–“ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
                for i in range(len(boundary_locs) - 1):
                    duration = boundary_locs[i+1] - boundary_locs[i]
                    if duration > 20:
                        pattern_type = 'elastic' if duration < 100 else 'plastic'
                        patterns.append({
                            'type': pattern_type,
                            'start': boundary_locs[i],
                            'end': boundary_locs[i+1],
                            'duration': duration
                        })
        
        return patterns
    
    def _detect_critical_events(self, anomaly_scores: Dict) -> List:
        """è‡¨ç•Œã‚¤ãƒ™ãƒ³ãƒˆã®æ¤œå‡º"""
        events = []
        
        if 'combined' in anomaly_scores:
            scores = anomaly_scores['combined']
            threshold = np.mean(scores) + 1.5 * np.std(scores)
            
            critical_frames = np.where(scores > threshold)[0]
            
            if len(critical_frames) > 0:
                current_start = critical_frames[0]
                current_end = critical_frames[0]
                
                for frame in critical_frames[1:]:
                    if frame == current_end + 1:
                        current_end = frame
                    else:
                        events.append((current_start, current_end))
                        current_start = frame
                        current_end = frame
                
                events.append((current_start, current_end))
        
        return events
    
    def _to_cpu_dict(self, data_dict: Optional[Dict]) -> Dict:
        """GPUé…åˆ—ã‚’CPUã«è»¢é€"""
        if data_dict is None:
            return {}
        
        cpu_dict = {}
        for key, value in data_dict.items():
            if hasattr(value, 'get'):  # CuPyé…åˆ—
                cpu_dict[key] = self.to_cpu(value)
            elif isinstance(value, dict):
                cpu_dict[key] = self._to_cpu_dict(value)
            else:
                cpu_dict[key] = value
        return cpu_dict
    
    def _get_gpu_info(self) -> Dict:
        """GPUæƒ…å ±ã®å–å¾—"""
        gpu_info = {
            'device_name': str(self.device),
            'computation_mode': 'single_batch'
        }
        
        try:
            mem_info = self.memory_manager.get_memory_info()
            gpu_info['memory_used'] = mem_info.used / 1e9
        except:
            gpu_info['memory_used'] = 0.0
        
        return gpu_info
    
    def _create_empty_result(self, n_frames: int, n_atoms: int) -> MaterialLambda3Result:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return MaterialLambda3Result(
            lambda_structures={},
            structural_boundaries={},
            topological_breaks={},
            md_features={},
            anomaly_scores={},
            detected_structures=[],
            n_frames=n_frames,
            n_atoms=n_atoms,
            window_steps=100,
            gpu_info={'computation_mode': 'batched', 'n_batches': 0}
        )
    
    def _print_analysis_header(self, n_frames: int, n_atoms: int):
        """è§£æãƒ˜ãƒƒãƒ€ãƒ¼ã®è¡¨ç¤º"""
        print(f"\n{'='*60}")
        print(f"=== LambdaÂ³ Material Analysis (GPU) ===")
        print(f"{'='*60}")
        print(f"Trajectory: {n_frames} frames, {n_atoms} atoms")
        print(f"Material: {self.config.material_type}")
        print(f"GPU Device: {self.device}")
        
        try:
            mem_info = self.memory_manager.get_memory_info()
            print(f"Available GPU Memory: {mem_info.free / 1e9:.2f} GB")
        except:
            pass
    
    def _print_initialization_info(self):
        """åˆæœŸåŒ–æƒ…å ±ã®è¡¨ç¤º"""
        if self.verbose:
            print(f"\nğŸ’ Material LambdaÂ³ GPU Detector Initialized")
            print(f"   Material: {self.config.material_type}")
            print(f"   Device: {self.device}")
            print(f"   GPU Mode: {self.is_gpu}")
            
            try:
                mem_info = self.memory_manager.get_memory_info()
                print(f"   Available Memory: {mem_info.free / 1e9:.2f} GB")
            except:
                pass
            
            print(f"   Batch Size: {self.config.gpu_batch_size} frames")
            print(f"   Material Analytics: {'ON' if self.config.use_material_analytics else 'OFF'}")
    
    def _print_summary(self, result: MaterialLambda3Result):
        """çµæœã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º"""
        print("\n" + "="*60)
        print("=== Analysis Complete ===")
        print("="*60)
        print(f"Total frames: {result.n_frames}")
        print(f"Computation time: {result.computation_time:.2f} seconds")
        
        if result.computation_time > 0:
            print(f"Speed: {result.n_frames / result.computation_time:.1f} frames/second")
        
        if result.failure_prediction:
            print(f"\nMaterial Analysis:")
            print(f"  Failure probability: {result.failure_prediction['failure_probability']:.1%}")
            print(f"  Reliability index: {result.failure_prediction['reliability_index']:.2f}")
            print(f"  Failure mode: {result.failure_prediction.get('failure_mode', 'unknown')}")
        
        if result.material_events:
            print(f"  Material events: {len(result.material_events)}")
            event_types = {}
            for event in result.material_events:
                if len(event) >= 3:
                    event_types[event[2]] = event_types.get(event[2], 0) + 1
            
            if event_types:
                print("  Event types:")
                for etype, count in sorted(event_types.items(), key=lambda x: x[1], reverse=True):
                    print(f"    - {etype}: {count}")

# ===============================
# Module Functions
# ===============================

def detect_material_events(trajectory: np.ndarray,
                          atom_types: np.ndarray,
                          config: Optional[MaterialConfig] = None,
                          **kwargs) -> List[Tuple[int, int, str]]:
    """ææ–™ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ¤œå‡ºã™ã‚‹ä¾¿åˆ©é–¢æ•°"""
    config = config or MaterialConfig()
    detector = MaterialLambda3DetectorGPU(config)
    
    result = detector.analyze(
        trajectory=trajectory,
        atom_types=atom_types,
        **kwargs
    )
    
    if hasattr(result, 'material_events') and result.material_events:
        return result.material_events
    
    events = []
    if hasattr(result, 'critical_events'):
        for event in result.critical_events:
            if isinstance(event, tuple) and len(event) >= 2:
                events.append((event[0], event[1], 'material_event'))
    
    return events
